{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9dbbad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d8ab06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topologies = [\n",
    "    [4, 8, 16, 32, 16, 8, 4],\n",
    "    [10 for _ in range(3)],\n",
    "    [10 for _ in range(5)],\n",
    "    [10 for _ in range(10)],\n",
    "    [23 for _ in range(12)],\n",
    "    [3 for _ in range(20)],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0117ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mlp import MultilayerPerceptron\n",
    "\n",
    "models = []\n",
    "for topology in topologies:\n",
    "    model = MultilayerPerceptron(3, topology, 1, learning_rate=0.1)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc3448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"data/Spiral3d.csv\", delimiter=\",\")\n",
    "X = data[:, :-1].T\n",
    "y = data[:, -1:].T\n",
    "\n",
    "p, N = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7002855",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalized = standardize(X.T).T\n",
    "\n",
    "X_train = X_normalized[:, :int(0.75 * N)]\n",
    "y_train = y[:, :int(0.75 * N)]\n",
    "X_test = X_normalized[:, int(0.75 * N):]\n",
    "y_test = y[:, int(0.75 * N):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db8cb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1 with topology [4, 8, 16, 32, 16, 8, 4]\n",
      "Epoch: 0, MSE: 0.27806440269377225, Learning Rate: 0.1\n",
      "Epoch: 1, MSE: 0.2729976490354146, Learning Rate: 0.099995\n",
      "Epoch: 2, MSE: 0.2730095781118696, Learning Rate: 0.09999000000000001\n",
      "Epoch: 3, MSE: 0.27301458450720706, Learning Rate: 0.099985\n",
      "Epoch: 4, MSE: 0.2730176433274917, Learning Rate: 0.09998000000000001\n",
      "Epoch: 5, MSE: 0.27301951721160117, Learning Rate: 0.09997500000000001\n",
      "Epoch: 6, MSE: 0.27302058147119823, Learning Rate: 0.09997\n",
      "Epoch: 7, MSE: 0.2730210652679945, Learning Rate: 0.09996500000000001\n",
      "Epoch: 8, MSE: 0.27302111777931487, Learning Rate: 0.09996000000000001\n",
      "Epoch: 9, MSE: 0.2730208405289193, Learning Rate: 0.09995500000000002\n",
      "Epoch: 10, MSE: 0.27302030512801406, Learning Rate: 0.09995000000000001\n",
      "Epoch: 11, MSE: 0.2730195636094399, Learning Rate: 0.099945\n",
      "Epoch: 12, MSE: 0.2730186547371349, Learning Rate: 0.09994\n",
      "Epoch: 13, MSE: 0.2730176080127786, Learning Rate: 0.099935\n",
      "Epoch: 14, MSE: 0.2730164463066624, Learning Rate: 0.09993\n",
      "Epoch: 15, MSE: 0.27301518763574245, Learning Rate: 0.099925\n",
      "Epoch: 16, MSE: 0.27301384639588094, Learning Rate: 0.09992000000000001\n",
      "Epoch: 17, MSE: 0.27301243423489685, Learning Rate: 0.099915\n",
      "Epoch: 18, MSE: 0.27301096068333236, Learning Rate: 0.09991\n",
      "Epoch: 19, MSE: 0.2730094336182002, Learning Rate: 0.09990500000000001\n",
      "Epoch: 20, MSE: 0.2730078596093226, Learning Rate: 0.0999\n",
      "Epoch: 21, MSE: 0.27300624418164676, Learning Rate: 0.09989500000000001\n",
      "Epoch: 22, MSE: 0.2730045920165128, Learning Rate: 0.09989\n",
      "Epoch: 23, MSE: 0.2730029071078731, Learning Rate: 0.099885\n",
      "Epoch: 24, MSE: 0.2730011928848571, Learning Rate: 0.09988000000000001\n",
      "Epoch: 25, MSE: 0.2729994523088793, Learning Rate: 0.099875\n",
      "Epoch: 26, MSE: 0.27299768795128104, Learning Rate: 0.09987000000000001\n",
      "Epoch: 27, MSE: 0.2729959020559204, Learning Rate: 0.09986500000000001\n",
      "Epoch: 28, MSE: 0.2729940965900274, Learning Rate: 0.09986\n",
      "Epoch: 29, MSE: 0.27299227328582315, Learning Rate: 0.09985500000000001\n",
      "Epoch: 30, MSE: 0.2729904336748065, Learning Rate: 0.09985000000000001\n",
      "Epoch: 31, MSE: 0.27298857911617913, Learning Rate: 0.099845\n",
      "Epoch: 32, MSE: 0.2729867108205564, Learning Rate: 0.09984\n",
      "Epoch: 33, MSE: 0.27298482986984196, Learning Rate: 0.09983500000000001\n",
      "Epoch: 34, MSE: 0.2729829372339879, Learning Rate: 0.09983\n",
      "Epoch: 35, MSE: 0.2729810337851873, Learning Rate: 0.099825\n",
      "Epoch: 36, MSE: 0.2729791203099532, Learning Rate: 0.09982\n",
      "Epoch: 37, MSE: 0.27297719751944277, Learning Rate: 0.099815\n",
      "Epoch: 38, MSE: 0.27297526605831546, Learning Rate: 0.09981000000000001\n",
      "Epoch: 39, MSE: 0.27297332651236816, Learning Rate: 0.099805\n",
      "Epoch: 40, MSE: 0.27297137941513583, Learning Rate: 0.0998\n",
      "Epoch: 41, MSE: 0.2729694252536206, Learning Rate: 0.09979500000000001\n",
      "Epoch: 42, MSE: 0.272967464473282, Learning Rate: 0.09979\n",
      "Epoch: 43, MSE: 0.2729654974823925, Learning Rate: 0.09978500000000001\n",
      "Epoch: 44, MSE: 0.2729635246558576, Learning Rate: 0.09978000000000001\n",
      "Epoch: 45, MSE: 0.2729615463385714, Learning Rate: 0.099775\n",
      "Epoch: 46, MSE: 0.27295956284837636, Learning Rate: 0.09977000000000001\n",
      "Epoch: 47, MSE: 0.27295757447867064, Learning Rate: 0.099765\n",
      "Epoch: 48, MSE: 0.2729555815007298, Learning Rate: 0.09976000000000002\n",
      "Epoch: 49, MSE: 0.2729535841657603, Learning Rate: 0.09975500000000001\n",
      "Epoch: 50, MSE: 0.2729515827067268, Learning Rate: 0.09975\n",
      "Epoch: 51, MSE: 0.2729495773399899, Learning Rate: 0.099745\n",
      "Epoch: 52, MSE: 0.27294756826676175, Learning Rate: 0.09974\n",
      "Epoch: 53, MSE: 0.2729455556744177, Learning Rate: 0.099735\n",
      "Epoch: 54, MSE: 0.27294353973766733, Learning Rate: 0.09973\n",
      "Epoch: 55, MSE: 0.272941520619614, Learning Rate: 0.09972500000000001\n",
      "Epoch: 56, MSE: 0.2729394984727055, Learning Rate: 0.09972\n",
      "Epoch: 57, MSE: 0.27293747343959185, Learning Rate: 0.099715\n",
      "Epoch: 58, MSE: 0.2729354456539067, Learning Rate: 0.09971000000000001\n",
      "Epoch: 59, MSE: 0.2729334152409679, Learning Rate: 0.099705\n",
      "Epoch: 60, MSE: 0.2729313823184217, Learning Rate: 0.09970000000000001\n",
      "Epoch: 61, MSE: 0.27292934699681787, Learning Rate: 0.099695\n",
      "Epoch: 62, MSE: 0.2729273093801412, Learning Rate: 0.09969\n",
      "Epoch: 63, MSE: 0.2729252695662941, Learning Rate: 0.09968500000000001\n",
      "Epoch: 64, MSE: 0.27292322764753585, Learning Rate: 0.09968\n",
      "Epoch: 65, MSE: 0.27292118371088625, Learning Rate: 0.09967500000000001\n",
      "Epoch: 66, MSE: 0.27291913783849336, Learning Rate: 0.09967000000000001\n",
      "Epoch: 67, MSE: 0.2729170901079677, Learning Rate: 0.099665\n",
      "Epoch: 68, MSE: 0.2729150405926968, Learning Rate: 0.09966000000000001\n",
      "Epoch: 69, MSE: 0.2729129893621297, Learning Rate: 0.09965500000000001\n",
      "Epoch: 70, MSE: 0.27291093648203474, Learning Rate: 0.09965000000000002\n",
      "Epoch: 71, MSE: 0.27290888201474583, Learning Rate: 0.099645\n",
      "Epoch: 72, MSE: 0.2729068260193789, Learning Rate: 0.09964\n",
      "Epoch: 73, MSE: 0.27290476855204576, Learning Rate: 0.099635\n",
      "Epoch: 74, MSE: 0.27290270966603425, Learning Rate: 0.09963\n",
      "Epoch: 75, MSE: 0.2729006494119917, Learning Rate: 0.099625\n",
      "Epoch: 76, MSE: 0.272898587838083, Learning Rate: 0.09962\n",
      "Epoch: 77, MSE: 0.2728965249901426, Learning Rate: 0.09961500000000001\n",
      "Epoch: 78, MSE: 0.27289446091181546, Learning Rate: 0.09961\n",
      "Epoch: 79, MSE: 0.2728923956446843, Learning Rate: 0.099605\n",
      "Epoch: 80, MSE: 0.2728903292283921, Learning Rate: 0.09960000000000001\n",
      "Epoch: 81, MSE: 0.2728882617007533, Learning Rate: 0.099595\n",
      "Epoch: 82, MSE: 0.27288619309786216, Learning Rate: 0.09959000000000001\n",
      "Epoch: 83, MSE: 0.27288412345418417, Learning Rate: 0.099585\n",
      "Epoch: 84, MSE: 0.2728820528026499, Learning Rate: 0.09958\n",
      "Epoch: 85, MSE: 0.27287998117474155, Learning Rate: 0.09957500000000001\n",
      "Epoch: 86, MSE: 0.2728779086005691, Learning Rate: 0.09957\n",
      "Epoch: 87, MSE: 0.2728758351089466, Learning Rate: 0.09956500000000001\n",
      "Epoch: 88, MSE: 0.2728737607274616, Learning Rate: 0.09956000000000001\n",
      "Epoch: 89, MSE: 0.27287168548253626, Learning Rate: 0.099555\n",
      "Epoch: 90, MSE: 0.27286960939949456, Learning Rate: 0.09955000000000001\n",
      "Epoch: 91, MSE: 0.27286753250261403, Learning Rate: 0.099545\n",
      "Epoch: 92, MSE: 0.27286545481518093, Learning Rate: 0.09954\n",
      "Epoch: 93, MSE: 0.2728633763595429, Learning Rate: 0.099535\n",
      "Epoch: 94, MSE: 0.2728612971571513, Learning Rate: 0.09953000000000001\n",
      "Epoch: 95, MSE: 0.2728592172286104, Learning Rate: 0.099525\n",
      "Epoch: 96, MSE: 0.27285713659371635, Learning Rate: 0.09952\n",
      "Epoch: 97, MSE: 0.2728550552714981, Learning Rate: 0.099515\n",
      "Epoch: 98, MSE: 0.2728529732802521, Learning Rate: 0.09951\n",
      "Epoch: 99, MSE: 0.27285089063757917, Learning Rate: 0.09950500000000001\n",
      "Epoch: 100, MSE: 0.27284880736041905, Learning Rate: 0.0995\n",
      "Epoch: 101, MSE: 0.27284672346507677, Learning Rate: 0.099495\n",
      "Epoch: 102, MSE: 0.27284463896725597, Learning Rate: 0.09949000000000001\n",
      "Epoch: 103, MSE: 0.27284255388208495, Learning Rate: 0.099485\n",
      "Epoch: 104, MSE: 0.2728404682241444, Learning Rate: 0.09948000000000001\n",
      "Epoch: 105, MSE: 0.2728383820074889, Learning Rate: 0.09947500000000001\n",
      "Epoch: 106, MSE: 0.27283629524567343, Learning Rate: 0.09947\n",
      "Epoch: 107, MSE: 0.27283420795177526, Learning Rate: 0.09946500000000001\n",
      "Epoch: 108, MSE: 0.272832120138413, Learning Rate: 0.09946\n",
      "Epoch: 109, MSE: 0.27283003181776966, Learning Rate: 0.09945500000000002\n",
      "Epoch: 110, MSE: 0.27282794300160673, Learning Rate: 0.09945000000000001\n",
      "Epoch: 111, MSE: 0.2728258537012883, Learning Rate: 0.099445\n",
      "Epoch: 112, MSE: 0.27282376392779417, Learning Rate: 0.09944\n",
      "Epoch: 113, MSE: 0.2728216736917329, Learning Rate: 0.099435\n",
      "Epoch: 114, MSE: 0.27281958300336523, Learning Rate: 0.09943\n",
      "Epoch: 115, MSE: 0.2728174918726121, Learning Rate: 0.099425\n",
      "Epoch: 116, MSE: 0.2728154003090724, Learning Rate: 0.09942000000000001\n",
      "Epoch: 117, MSE: 0.27281330832203216, Learning Rate: 0.099415\n",
      "Epoch: 118, MSE: 0.2728112159204796, Learning Rate: 0.09941\n",
      "Epoch: 119, MSE: 0.2728091231131187, Learning Rate: 0.09940500000000001\n",
      "Epoch: 120, MSE: 0.2728070299083772, Learning Rate: 0.0994\n",
      "Epoch: 121, MSE: 0.2728049363144177, Learning Rate: 0.09939500000000001\n",
      "Epoch: 122, MSE: 0.27280284233915203, Learning Rate: 0.09939\n",
      "Epoch: 123, MSE: 0.2728007479902456, Learning Rate: 0.099385\n",
      "Epoch: 124, MSE: 0.27279865327513025, Learning Rate: 0.09938000000000001\n",
      "Epoch: 125, MSE: 0.27279655820101123, Learning Rate: 0.099375\n",
      "Epoch: 126, MSE: 0.27279446277487995, Learning Rate: 0.09937000000000001\n",
      "Epoch: 127, MSE: 0.2727923670035143, Learning Rate: 0.09936500000000001\n",
      "Epoch: 128, MSE: 0.27279027089349456, Learning Rate: 0.09936\n",
      "Epoch: 129, MSE: 0.27278817445120634, Learning Rate: 0.09935500000000001\n",
      "Epoch: 130, MSE: 0.27278607768284796, Learning Rate: 0.09935000000000001\n",
      "Epoch: 131, MSE: 0.2727839805944398, Learning Rate: 0.099345\n",
      "Epoch: 132, MSE: 0.2727818831918268, Learning Rate: 0.09934\n",
      "Epoch: 133, MSE: 0.2727797854806882, Learning Rate: 0.099335\n",
      "Epoch: 134, MSE: 0.27277768746654085, Learning Rate: 0.09933\n",
      "Epoch: 135, MSE: 0.27277558915474887, Learning Rate: 0.099325\n",
      "Epoch: 136, MSE: 0.27277349055052463, Learning Rate: 0.09932\n",
      "Epoch: 137, MSE: 0.27277139165893505, Learning Rate: 0.099315\n",
      "Epoch: 138, MSE: 0.2727692924849095, Learning Rate: 0.09931000000000001\n",
      "Epoch: 139, MSE: 0.27276719303323965, Learning Rate: 0.099305\n",
      "Epoch: 140, MSE: 0.2727650933085905, Learning Rate: 0.0993\n",
      "Epoch: 141, MSE: 0.2727629933154982, Learning Rate: 0.09929500000000001\n",
      "Epoch: 142, MSE: 0.272760893058378, Learning Rate: 0.09929\n",
      "Epoch: 143, MSE: 0.2727587925415291, Learning Rate: 0.09928500000000001\n",
      "Epoch: 144, MSE: 0.27275669176913536, Learning Rate: 0.09928000000000001\n",
      "Epoch: 145, MSE: 0.272754590745271, Learning Rate: 0.099275\n",
      "Epoch: 146, MSE: 0.272752489473905, Learning Rate: 0.09927000000000001\n",
      "Epoch: 147, MSE: 0.27275038795890355, Learning Rate: 0.099265\n",
      "Epoch: 148, MSE: 0.27274828620402963, Learning Rate: 0.09926000000000001\n",
      "Epoch: 149, MSE: 0.27274618421295693, Learning Rate: 0.09925500000000001\n",
      "Epoch: 150, MSE: 0.27274408198925904, Learning Rate: 0.09925\n",
      "Epoch: 151, MSE: 0.272741979536423, Learning Rate: 0.09924500000000001\n",
      "Epoch: 152, MSE: 0.2727398768578477, Learning Rate: 0.09924\n",
      "Epoch: 153, MSE: 0.27273777395684845, Learning Rate: 0.099235\n",
      "Epoch: 154, MSE: 0.2727356708366555, Learning Rate: 0.09923\n",
      "Epoch: 155, MSE: 0.27273356750042277, Learning Rate: 0.09922500000000001\n",
      "Epoch: 156, MSE: 0.272731463951225, Learning Rate: 0.09922\n",
      "Epoch: 157, MSE: 0.2727293601920631, Learning Rate: 0.099215\n",
      "Epoch: 158, MSE: 0.2727272562258651, Learning Rate: 0.09921\n",
      "Epoch: 159, MSE: 0.2727251520554905, Learning Rate: 0.099205\n",
      "Epoch: 160, MSE: 0.2727230476837272, Learning Rate: 0.09920000000000001\n",
      "Epoch: 161, MSE: 0.2727209431133019, Learning Rate: 0.099195\n",
      "Epoch: 162, MSE: 0.27271883834687133, Learning Rate: 0.09919\n",
      "Epoch: 163, MSE: 0.2727167333870349, Learning Rate: 0.09918500000000001\n",
      "Epoch: 164, MSE: 0.27271462823632914, Learning Rate: 0.09918\n",
      "Epoch: 165, MSE: 0.2727125228972321, Learning Rate: 0.09917500000000001\n",
      "Epoch: 166, MSE: 0.27271041737216456, Learning Rate: 0.09917000000000001\n",
      "Epoch: 167, MSE: 0.2727083116634924, Learning Rate: 0.099165\n",
      "Epoch: 168, MSE: 0.2727062057735304, Learning Rate: 0.09916000000000001\n",
      "Epoch: 169, MSE: 0.2727040997045342, Learning Rate: 0.09915500000000001\n",
      "Epoch: 170, MSE: 0.27270199345871543, Learning Rate: 0.09915000000000002\n",
      "Epoch: 171, MSE: 0.2726998870382346, Learning Rate: 0.09914500000000001\n",
      "Epoch: 172, MSE: 0.27269778044520215, Learning Rate: 0.09914\n",
      "Epoch: 173, MSE: 0.2726956736816837, Learning Rate: 0.099135\n",
      "Epoch: 174, MSE: 0.27269356674969897, Learning Rate: 0.09913\n",
      "Epoch: 175, MSE: 0.27269145965122316, Learning Rate: 0.099125\n",
      "Epoch: 176, MSE: 0.2726893523881902, Learning Rate: 0.09912\n",
      "Epoch: 177, MSE: 0.27268724496249064, Learning Rate: 0.09911500000000001\n",
      "Epoch: 178, MSE: 0.27268513737597533, Learning Rate: 0.09911\n",
      "Epoch: 179, MSE: 0.27268302963045443, Learning Rate: 0.099105\n",
      "Epoch: 180, MSE: 0.27268092172770125, Learning Rate: 0.09910000000000001\n",
      "Epoch: 181, MSE: 0.27267881366945074, Learning Rate: 0.099095\n",
      "Epoch: 182, MSE: 0.27267670545740114, Learning Rate: 0.09909000000000001\n",
      "Epoch: 183, MSE: 0.2726745970932151, Learning Rate: 0.099085\n",
      "Epoch: 184, MSE: 0.27267248857852244, Learning Rate: 0.09908\n",
      "Epoch: 185, MSE: 0.2726703799149175, Learning Rate: 0.09907500000000001\n",
      "Epoch: 186, MSE: 0.27266827110396213, Learning Rate: 0.09907\n",
      "Epoch: 187, MSE: 0.2726661621471867, Learning Rate: 0.09906500000000001\n",
      "Epoch: 188, MSE: 0.27266405304609004, Learning Rate: 0.09906000000000001\n",
      "Epoch: 189, MSE: 0.27266194380214165, Learning Rate: 0.099055\n",
      "Epoch: 190, MSE: 0.27265983441677966, Learning Rate: 0.09905000000000001\n",
      "Epoch: 191, MSE: 0.2726577248914139, Learning Rate: 0.09904500000000001\n",
      "Epoch: 192, MSE: 0.2726556152274275, Learning Rate: 0.09904\n",
      "Epoch: 193, MSE: 0.27265350542617545, Learning Rate: 0.099035\n",
      "Epoch: 194, MSE: 0.2726513954889848, Learning Rate: 0.09903\n",
      "Epoch: 195, MSE: 0.27264928541715777, Learning Rate: 0.099025\n",
      "Epoch: 196, MSE: 0.27264717521197096, Learning Rate: 0.09902\n",
      "Epoch: 197, MSE: 0.2726450648746758, Learning Rate: 0.099015\n",
      "Epoch: 198, MSE: 0.2726429544065004, Learning Rate: 0.09901\n",
      "Epoch: 199, MSE: 0.2726408438086483, Learning Rate: 0.09900500000000001\n",
      "Epoch: 200, MSE: 0.2726387330823, Learning Rate: 0.099\n",
      "Epoch: 201, MSE: 0.27263662222861434, Learning Rate: 0.098995\n",
      "Epoch: 202, MSE: 0.2726345112487281, Learning Rate: 0.09899000000000001\n",
      "Epoch: 203, MSE: 0.27263240014375506, Learning Rate: 0.098985\n",
      "Epoch: 204, MSE: 0.27263028891478974, Learning Rate: 0.09898000000000001\n",
      "Epoch: 205, MSE: 0.27262817756290614, Learning Rate: 0.09897500000000001\n",
      "Epoch: 206, MSE: 0.2726260660891573, Learning Rate: 0.09897\n",
      "Epoch: 207, MSE: 0.27262395449457727, Learning Rate: 0.09896500000000001\n",
      "Epoch: 208, MSE: 0.2726218427801815, Learning Rate: 0.09896\n",
      "Epoch: 209, MSE: 0.2726197309469659, Learning Rate: 0.09895500000000002\n",
      "Epoch: 210, MSE: 0.27261761899591, Learning Rate: 0.09895000000000001\n",
      "Epoch: 211, MSE: 0.27261550692797215, Learning Rate: 0.098945\n",
      "Epoch: 212, MSE: 0.272613394744097, Learning Rate: 0.09894\n",
      "Epoch: 213, MSE: 0.2726112824452099, Learning Rate: 0.098935\n",
      "Epoch: 214, MSE: 0.27260917003222135, Learning Rate: 0.09893\n",
      "Epoch: 215, MSE: 0.27260705750602393, Learning Rate: 0.098925\n",
      "Epoch: 216, MSE: 0.27260494486749487, Learning Rate: 0.09892000000000001\n",
      "Epoch: 217, MSE: 0.272602832117497, Learning Rate: 0.098915\n",
      "Epoch: 218, MSE: 0.2726007192568765, Learning Rate: 0.09891\n",
      "Epoch: 219, MSE: 0.2725986062864654, Learning Rate: 0.098905\n",
      "Epoch: 220, MSE: 0.272596493207082, Learning Rate: 0.0989\n",
      "Epoch: 221, MSE: 0.2725943800195279, Learning Rate: 0.09889500000000001\n",
      "Epoch: 222, MSE: 0.27259226672459513, Learning Rate: 0.09889\n",
      "Epoch: 223, MSE: 0.2725901533230561, Learning Rate: 0.098885\n",
      "Epoch: 224, MSE: 0.27258803981567664, Learning Rate: 0.09888000000000001\n",
      "Epoch: 225, MSE: 0.2725859262032047, Learning Rate: 0.098875\n",
      "Epoch: 226, MSE: 0.27258381248637664, Learning Rate: 0.09887000000000001\n",
      "Epoch: 227, MSE: 0.2725816986659181, Learning Rate: 0.09886500000000001\n",
      "Epoch: 228, MSE: 0.2725795847425401, Learning Rate: 0.09886\n",
      "Epoch: 229, MSE: 0.2725774707169439, Learning Rate: 0.09885500000000001\n",
      "Epoch: 230, MSE: 0.27257535658981646, Learning Rate: 0.09885000000000001\n",
      "Epoch: 231, MSE: 0.27257324236183716, Learning Rate: 0.09884500000000002\n",
      "Epoch: 232, MSE: 0.27257112803367034, Learning Rate: 0.09884\n",
      "Epoch: 233, MSE: 0.2725690136059718, Learning Rate: 0.098835\n",
      "Epoch: 234, MSE: 0.2725668990793844, Learning Rate: 0.09883\n",
      "Epoch: 235, MSE: 0.2725647844545433, Learning Rate: 0.098825\n",
      "Epoch: 236, MSE: 0.27256266973207166, Learning Rate: 0.09882\n",
      "Epoch: 237, MSE: 0.27256055491258213, Learning Rate: 0.098815\n",
      "Epoch: 238, MSE: 0.27255843999667884, Learning Rate: 0.09881000000000001\n",
      "Epoch: 239, MSE: 0.27255632498495397, Learning Rate: 0.098805\n",
      "Epoch: 240, MSE: 0.2725542098779933, Learning Rate: 0.0988\n",
      "Epoch: 241, MSE: 0.2725520946763709, Learning Rate: 0.09879500000000001\n",
      "Epoch: 242, MSE: 0.2725499793806534, Learning Rate: 0.09879\n",
      "Epoch: 243, MSE: 0.27254786399139624, Learning Rate: 0.09878500000000001\n",
      "Epoch: 244, MSE: 0.27254574850914826, Learning Rate: 0.09878\n",
      "Epoch: 245, MSE: 0.2725436329344487, Learning Rate: 0.098775\n",
      "Epoch: 246, MSE: 0.27254151726782944, Learning Rate: 0.09877000000000001\n",
      "Epoch: 247, MSE: 0.2725394015098116, Learning Rate: 0.098765\n",
      "Epoch: 248, MSE: 0.2725372856609117, Learning Rate: 0.09876000000000001\n",
      "Epoch: 249, MSE: 0.2725351697216351, Learning Rate: 0.09875500000000001\n",
      "Epoch: 250, MSE: 0.27253305369248093, Learning Rate: 0.09875\n",
      "Epoch: 251, MSE: 0.2725309375739408, Learning Rate: 0.09874500000000001\n",
      "Epoch: 252, MSE: 0.27252882136649814, Learning Rate: 0.09874000000000001\n",
      "Epoch: 253, MSE: 0.27252670507062976, Learning Rate: 0.098735\n",
      "Epoch: 254, MSE: 0.27252458868680457, Learning Rate: 0.09873\n",
      "Epoch: 255, MSE: 0.2725224722154851, Learning Rate: 0.09872500000000001\n",
      "Epoch: 256, MSE: 0.27252035565712723, Learning Rate: 0.09872\n",
      "Epoch: 257, MSE: 0.27251823901217664, Learning Rate: 0.098715\n",
      "Epoch: 258, MSE: 0.27251612228107813, Learning Rate: 0.09871\n",
      "Epoch: 259, MSE: 0.27251400546426546, Learning Rate: 0.098705\n",
      "Epoch: 260, MSE: 0.2725118885621677, Learning Rate: 0.09870000000000001\n",
      "Epoch: 261, MSE: 0.27250977157520684, Learning Rate: 0.098695\n",
      "Epoch: 262, MSE: 0.2725076545037992, Learning Rate: 0.09869\n",
      "Epoch: 263, MSE: 0.27250553734835525, Learning Rate: 0.09868500000000001\n",
      "Epoch: 264, MSE: 0.27250342010927814, Learning Rate: 0.09868\n",
      "Epoch: 265, MSE: 0.2725013027869678, Learning Rate: 0.09867500000000001\n",
      "Epoch: 266, MSE: 0.2724991853818163, Learning Rate: 0.09867000000000001\n",
      "Epoch: 267, MSE: 0.2724970678942097, Learning Rate: 0.098665\n",
      "Epoch: 268, MSE: 0.27249495032452825, Learning Rate: 0.09866000000000001\n",
      "Epoch: 269, MSE: 0.2724928326731507, Learning Rate: 0.098655\n",
      "Epoch: 270, MSE: 0.2724907149404453, Learning Rate: 0.09865000000000002\n",
      "Epoch: 271, MSE: 0.2724885971267787, Learning Rate: 0.09864500000000001\n",
      "Epoch: 272, MSE: 0.27248647923251007, Learning Rate: 0.09864\n",
      "Epoch: 273, MSE: 0.2724843612579936, Learning Rate: 0.098635\n",
      "Epoch: 274, MSE: 0.272482243203581, Learning Rate: 0.09863\n",
      "Epoch: 275, MSE: 0.27248012506961666, Learning Rate: 0.098625\n",
      "Epoch: 276, MSE: 0.2724780068564401, Learning Rate: 0.09862\n",
      "Epoch: 277, MSE: 0.2724758885643879, Learning Rate: 0.09861500000000001\n",
      "Epoch: 278, MSE: 0.27247377019379093, Learning Rate: 0.09861\n",
      "Epoch: 279, MSE: 0.272471651744974, Learning Rate: 0.098605\n",
      "Epoch: 280, MSE: 0.2724695332182611, Learning Rate: 0.09860000000000001\n",
      "Epoch: 281, MSE: 0.27246741461396884, Learning Rate: 0.098595\n",
      "Epoch: 282, MSE: 0.2724652959324091, Learning Rate: 0.09859000000000001\n",
      "Epoch: 283, MSE: 0.27246317717389207, Learning Rate: 0.098585\n",
      "Epoch: 284, MSE: 0.27246105833872175, Learning Rate: 0.09858\n",
      "Epoch: 285, MSE: 0.27245893942719945, Learning Rate: 0.09857500000000001\n",
      "Epoch: 286, MSE: 0.2724568204396212, Learning Rate: 0.09857\n",
      "Epoch: 287, MSE: 0.27245470137627875, Learning Rate: 0.09856500000000001\n",
      "Epoch: 288, MSE: 0.2724525822374608, Learning Rate: 0.09856000000000001\n",
      "Epoch: 289, MSE: 0.27245046302345305, Learning Rate: 0.098555\n",
      "Epoch: 290, MSE: 0.2724483437345359, Learning Rate: 0.09855000000000001\n",
      "Epoch: 291, MSE: 0.2724462243709869, Learning Rate: 0.09854500000000001\n",
      "Epoch: 292, MSE: 0.2724441049330783, Learning Rate: 0.09854000000000002\n",
      "Epoch: 293, MSE: 0.27244198542108145, Learning Rate: 0.098535\n",
      "Epoch: 294, MSE: 0.272439865835262, Learning Rate: 0.09853\n",
      "Epoch: 295, MSE: 0.2724377461758842, Learning Rate: 0.098525\n",
      "Epoch: 296, MSE: 0.2724356264432049, Learning Rate: 0.09852\n",
      "Epoch: 297, MSE: 0.27243350663748245, Learning Rate: 0.098515\n",
      "Epoch: 298, MSE: 0.2724313867589695, Learning Rate: 0.09851\n",
      "Epoch: 299, MSE: 0.27242926680791435, Learning Rate: 0.09850500000000001\n",
      "Epoch: 300, MSE: 0.2724271467845646, Learning Rate: 0.0985\n",
      "Epoch: 301, MSE: 0.272425026689162, Learning Rate: 0.098495\n",
      "Epoch: 302, MSE: 0.27242290652194734, Learning Rate: 0.09849000000000001\n",
      "Epoch: 303, MSE: 0.27242078628315886, Learning Rate: 0.098485\n",
      "Epoch: 304, MSE: 0.2724186659730286, Learning Rate: 0.09848000000000001\n",
      "Epoch: 305, MSE: 0.2724165455917892, Learning Rate: 0.09847500000000001\n",
      "Epoch: 306, MSE: 0.2724144251396672, Learning Rate: 0.09847\n",
      "Epoch: 307, MSE: 0.2724123046168892, Learning Rate: 0.09846500000000001\n",
      "Epoch: 308, MSE: 0.2724101840236765, Learning Rate: 0.09846\n",
      "Epoch: 309, MSE: 0.2724080633602495, Learning Rate: 0.09845500000000001\n",
      "Epoch: 310, MSE: 0.27240594262682444, Learning Rate: 0.09845000000000001\n",
      "Epoch: 311, MSE: 0.272403821823617, Learning Rate: 0.098445\n",
      "Epoch: 312, MSE: 0.27240170095083727, Learning Rate: 0.09844000000000001\n",
      "Epoch: 313, MSE: 0.27239958000869396, Learning Rate: 0.098435\n",
      "Epoch: 314, MSE: 0.27239745899739404, Learning Rate: 0.09843\n",
      "Epoch: 315, MSE: 0.2723953379171427, Learning Rate: 0.098425\n",
      "Epoch: 316, MSE: 0.2723932167681388, Learning Rate: 0.09842000000000001\n",
      "Epoch: 317, MSE: 0.2723910955505825, Learning Rate: 0.098415\n",
      "Epoch: 318, MSE: 0.2723889742646709, Learning Rate: 0.09841\n",
      "Epoch: 319, MSE: 0.2723868529105968, Learning Rate: 0.098405\n",
      "Epoch: 320, MSE: 0.27238473148855286, Learning Rate: 0.0984\n",
      "Epoch: 321, MSE: 0.2723826099987283, Learning Rate: 0.09839500000000001\n",
      "Epoch: 322, MSE: 0.2723804884413096, Learning Rate: 0.09839\n",
      "Epoch: 323, MSE: 0.2723783668164816, Learning Rate: 0.098385\n",
      "Epoch: 324, MSE: 0.2723762451244292, Learning Rate: 0.09838000000000001\n",
      "Epoch: 325, MSE: 0.27237412336533035, Learning Rate: 0.098375\n",
      "Epoch: 326, MSE: 0.27237200153936475, Learning Rate: 0.09837000000000001\n",
      "Epoch: 327, MSE: 0.2723698796467072, Learning Rate: 0.09836500000000001\n",
      "Epoch: 328, MSE: 0.2723677576875349, Learning Rate: 0.09836\n",
      "Epoch: 329, MSE: 0.27236563566201655, Learning Rate: 0.09835500000000001\n",
      "Epoch: 330, MSE: 0.27236351357032434, Learning Rate: 0.09835\n",
      "Epoch: 331, MSE: 0.27236139141262705, Learning Rate: 0.09834500000000002\n",
      "Epoch: 332, MSE: 0.27235926918908854, Learning Rate: 0.09834000000000001\n",
      "Epoch: 333, MSE: 0.27235714689987406, Learning Rate: 0.098335\n",
      "Epoch: 334, MSE: 0.27235502454514643, Learning Rate: 0.09833\n",
      "Epoch: 335, MSE: 0.2723529021250654, Learning Rate: 0.098325\n",
      "Epoch: 336, MSE: 0.2723507796397908, Learning Rate: 0.09832\n",
      "Epoch: 337, MSE: 0.27234865708947753, Learning Rate: 0.098315\n",
      "Epoch: 338, MSE: 0.27234653447428253, Learning Rate: 0.09831000000000001\n",
      "Epoch: 339, MSE: 0.2723444117943578, Learning Rate: 0.098305\n",
      "Epoch: 340, MSE: 0.27234228904985475, Learning Rate: 0.0983\n",
      "Epoch: 341, MSE: 0.27234016624092333, Learning Rate: 0.09829500000000001\n",
      "Epoch: 342, MSE: 0.2723380433677125, Learning Rate: 0.09829\n",
      "Epoch: 343, MSE: 0.27233592043036714, Learning Rate: 0.09828500000000001\n",
      "Epoch: 344, MSE: 0.27233379742903296, Learning Rate: 0.09828\n",
      "Epoch: 345, MSE: 0.27233167436385286, Learning Rate: 0.098275\n",
      "Epoch: 346, MSE: 0.2723295512349684, Learning Rate: 0.09827000000000001\n",
      "Epoch: 347, MSE: 0.27232742804251847, Learning Rate: 0.098265\n",
      "Epoch: 348, MSE: 0.27232530478664274, Learning Rate: 0.09826000000000001\n",
      "Epoch: 349, MSE: 0.2723231814674781, Learning Rate: 0.09825500000000001\n",
      "Epoch: 350, MSE: 0.2723210580851587, Learning Rate: 0.09825\n",
      "Epoch: 351, MSE: 0.27231893463981854, Learning Rate: 0.09824500000000001\n",
      "Epoch: 352, MSE: 0.27231681113159134, Learning Rate: 0.09824000000000001\n",
      "Epoch: 353, MSE: 0.27231468756060573, Learning Rate: 0.09823500000000002\n",
      "Epoch: 354, MSE: 0.27231256392699316, Learning Rate: 0.09823\n",
      "Epoch: 355, MSE: 0.2723104402308803, Learning Rate: 0.098225\n",
      "Epoch: 356, MSE: 0.2723083164723948, Learning Rate: 0.09822\n",
      "Epoch: 357, MSE: 0.27230619265166134, Learning Rate: 0.098215\n",
      "Epoch: 358, MSE: 0.2723040687688029, Learning Rate: 0.09821\n",
      "Epoch: 359, MSE: 0.2723019448239441, Learning Rate: 0.098205\n",
      "Epoch: 360, MSE: 0.27229982081720355, Learning Rate: 0.09820000000000001\n",
      "Epoch: 361, MSE: 0.27229769674870397, Learning Rate: 0.098195\n",
      "Epoch: 362, MSE: 0.272295572618562, Learning Rate: 0.09819\n",
      "Epoch: 363, MSE: 0.27229344842689585, Learning Rate: 0.09818500000000001\n",
      "Epoch: 364, MSE: 0.27229132417382035, Learning Rate: 0.09818\n",
      "Epoch: 365, MSE: 0.27228919985945227, Learning Rate: 0.09817500000000001\n",
      "Epoch: 366, MSE: 0.27228707548390413, Learning Rate: 0.09817000000000001\n",
      "Epoch: 367, MSE: 0.27228495104728856, Learning Rate: 0.098165\n",
      "Epoch: 368, MSE: 0.27228282654971653, Learning Rate: 0.09816000000000001\n",
      "Epoch: 369, MSE: 0.27228070199129867, Learning Rate: 0.098155\n",
      "Epoch: 370, MSE: 0.27227857737214295, Learning Rate: 0.09815000000000002\n",
      "Epoch: 371, MSE: 0.27227645269235895, Learning Rate: 0.09814500000000001\n",
      "Epoch: 372, MSE: 0.27227432795205075, Learning Rate: 0.09814\n",
      "Epoch: 373, MSE: 0.2722722031513259, Learning Rate: 0.098135\n",
      "Epoch: 374, MSE: 0.27227007829028815, Learning Rate: 0.09813\n",
      "Epoch: 375, MSE: 0.27226795336904003, Learning Rate: 0.098125\n",
      "Epoch: 376, MSE: 0.27226582838768526, Learning Rate: 0.09812\n",
      "Epoch: 377, MSE: 0.27226370334632416, Learning Rate: 0.09811500000000001\n",
      "Epoch: 378, MSE: 0.2722615782450581, Learning Rate: 0.09811\n",
      "Epoch: 379, MSE: 0.2722594530839839, Learning Rate: 0.098105\n",
      "Epoch: 380, MSE: 0.27225732786320095, Learning Rate: 0.0981\n",
      "Epoch: 381, MSE: 0.27225520258280705, Learning Rate: 0.098095\n",
      "Epoch: 382, MSE: 0.2722530772428978, Learning Rate: 0.09809000000000001\n",
      "Epoch: 383, MSE: 0.2722509518435679, Learning Rate: 0.098085\n",
      "Epoch: 384, MSE: 0.27224882638491127, Learning Rate: 0.09808\n",
      "Epoch: 385, MSE: 0.2722467008670225, Learning Rate: 0.09807500000000001\n",
      "Epoch: 386, MSE: 0.2722445752899933, Learning Rate: 0.09807\n",
      "Epoch: 387, MSE: 0.27224244965391364, Learning Rate: 0.09806500000000001\n",
      "Epoch: 388, MSE: 0.2722403239588761, Learning Rate: 0.09806000000000001\n",
      "Epoch: 389, MSE: 0.2722381982049686, Learning Rate: 0.098055\n",
      "Epoch: 390, MSE: 0.2722360723922803, Learning Rate: 0.09805000000000001\n",
      "Epoch: 391, MSE: 0.2722339465208991, Learning Rate: 0.09804500000000001\n",
      "Epoch: 392, MSE: 0.27223182059091167, Learning Rate: 0.09804000000000002\n",
      "Epoch: 393, MSE: 0.27222969460240487, Learning Rate: 0.09803500000000001\n",
      "Epoch: 394, MSE: 0.2722275685554627, Learning Rate: 0.09803\n",
      "Epoch: 395, MSE: 0.2722254424501684, Learning Rate: 0.098025\n",
      "Epoch: 396, MSE: 0.2722233162866086, Learning Rate: 0.09802\n",
      "Epoch: 397, MSE: 0.2722211900648631, Learning Rate: 0.098015\n",
      "Epoch: 398, MSE: 0.27221906378501587, Learning Rate: 0.09801\n",
      "Epoch: 399, MSE: 0.2722169374471461, Learning Rate: 0.09800500000000001\n",
      "Epoch: 400, MSE: 0.2722148110513347, Learning Rate: 0.098\n",
      "Epoch: 401, MSE: 0.272212684597661, Learning Rate: 0.097995\n",
      "Epoch: 402, MSE: 0.27221055808620487, Learning Rate: 0.09799000000000001\n",
      "Epoch: 403, MSE: 0.272208431517043, Learning Rate: 0.097985\n",
      "Epoch: 404, MSE: 0.2722063048902525, Learning Rate: 0.09798000000000001\n",
      "Epoch: 405, MSE: 0.2722041782059101, Learning Rate: 0.097975\n",
      "Epoch: 406, MSE: 0.27220205146409177, Learning Rate: 0.09797\n",
      "Epoch: 407, MSE: 0.27219992466487203, Learning Rate: 0.09796500000000001\n",
      "Epoch: 408, MSE: 0.2721977978083251, Learning Rate: 0.09796\n",
      "Epoch: 409, MSE: 0.27219567089452457, Learning Rate: 0.09795500000000001\n",
      "Epoch: 410, MSE: 0.2721935439235438, Learning Rate: 0.09795000000000001\n",
      "Epoch: 411, MSE: 0.27219141689545323, Learning Rate: 0.097945\n",
      "Epoch: 412, MSE: 0.2721892898103268, Learning Rate: 0.09794000000000001\n",
      "Epoch: 413, MSE: 0.27218716266823295, Learning Rate: 0.097935\n",
      "Epoch: 414, MSE: 0.2721850354692434, Learning Rate: 0.09793\n",
      "Epoch: 415, MSE: 0.27218290821342667, Learning Rate: 0.097925\n",
      "Epoch: 416, MSE: 0.2721807809008519, Learning Rate: 0.09792000000000001\n",
      "Epoch: 417, MSE: 0.27217865353158677, Learning Rate: 0.097915\n",
      "Epoch: 418, MSE: 0.27217652610569937, Learning Rate: 0.09791\n",
      "Epoch: 419, MSE: 0.2721743986232556, Learning Rate: 0.097905\n",
      "Epoch: 420, MSE: 0.27217227108432335, Learning Rate: 0.0979\n",
      "Epoch: 421, MSE: 0.2721701434889669, Learning Rate: 0.09789500000000001\n",
      "Epoch: 422, MSE: 0.2721680158372508, Learning Rate: 0.09789\n",
      "Epoch: 423, MSE: 0.2721658881292411, Learning Rate: 0.097885\n",
      "Epoch: 424, MSE: 0.27216376036499956, Learning Rate: 0.09788000000000001\n",
      "Epoch: 425, MSE: 0.2721616325445915, Learning Rate: 0.097875\n",
      "Epoch: 426, MSE: 0.2721595046680778, Learning Rate: 0.09787000000000001\n",
      "Epoch: 427, MSE: 0.27215737673552065, Learning Rate: 0.09786500000000001\n",
      "Epoch: 428, MSE: 0.27215524874698294, Learning Rate: 0.09786\n",
      "Epoch: 429, MSE: 0.2721531207025245, Learning Rate: 0.09785500000000001\n",
      "Epoch: 430, MSE: 0.27215099260220527, Learning Rate: 0.09785\n",
      "Epoch: 431, MSE: 0.2721488644460862, Learning Rate: 0.09784500000000002\n",
      "Epoch: 432, MSE: 0.2721467362342266, Learning Rate: 0.09784000000000001\n",
      "Epoch: 433, MSE: 0.2721446079666833, Learning Rate: 0.097835\n",
      "Epoch: 434, MSE: 0.27214247964351623, Learning Rate: 0.09783\n",
      "Epoch: 435, MSE: 0.2721403512647818, Learning Rate: 0.097825\n",
      "Epoch: 436, MSE: 0.2721382228305382, Learning Rate: 0.09782\n",
      "Epoch: 437, MSE: 0.2721360943408418, Learning Rate: 0.097815\n",
      "Epoch: 438, MSE: 0.2721339657957484, Learning Rate: 0.09781000000000001\n",
      "Epoch: 439, MSE: 0.27213183719531375, Learning Rate: 0.097805\n",
      "Epoch: 440, MSE: 0.2721297085395927, Learning Rate: 0.0978\n",
      "Epoch: 441, MSE: 0.2721275798286407, Learning Rate: 0.097795\n",
      "Epoch: 442, MSE: 0.27212545106251035, Learning Rate: 0.09779\n",
      "Epoch: 443, MSE: 0.27212332224125657, Learning Rate: 0.09778500000000001\n",
      "Epoch: 444, MSE: 0.2721211933649324, Learning Rate: 0.09778\n",
      "Epoch: 445, MSE: 0.27211906443359024, Learning Rate: 0.097775\n",
      "Epoch: 446, MSE: 0.2721169354472822, Learning Rate: 0.09777000000000001\n",
      "Epoch: 447, MSE: 0.2721148064060595, Learning Rate: 0.097765\n",
      "Epoch: 448, MSE: 0.2721126773099745, Learning Rate: 0.09776000000000001\n",
      "Epoch: 449, MSE: 0.2721105481590771, Learning Rate: 0.09775500000000001\n",
      "Epoch: 450, MSE: 0.2721084189534196, Learning Rate: 0.09775\n",
      "Epoch: 451, MSE: 0.2721062896930494, Learning Rate: 0.09774500000000001\n",
      "Epoch: 452, MSE: 0.27210416037801755, Learning Rate: 0.09774000000000001\n",
      "Epoch: 453, MSE: 0.27210203100837216, Learning Rate: 0.09773500000000002\n",
      "Epoch: 454, MSE: 0.27209990158416253, Learning Rate: 0.09773\n",
      "Epoch: 455, MSE: 0.2720977721054374, Learning Rate: 0.097725\n",
      "Epoch: 456, MSE: 0.27209564257224295, Learning Rate: 0.09772\n",
      "Epoch: 457, MSE: 0.27209351298462847, Learning Rate: 0.097715\n",
      "Epoch: 458, MSE: 0.27209138334264027, Learning Rate: 0.09771\n",
      "Epoch: 459, MSE: 0.27208925364632425, Learning Rate: 0.097705\n",
      "Epoch: 460, MSE: 0.27208712389572726, Learning Rate: 0.09770000000000001\n",
      "Epoch: 461, MSE: 0.27208499409089465, Learning Rate: 0.097695\n",
      "Epoch: 462, MSE: 0.2720828642318719, Learning Rate: 0.09769\n",
      "Epoch: 463, MSE: 0.27208073431870433, Learning Rate: 0.09768500000000001\n",
      "Epoch: 464, MSE: 0.27207860435143655, Learning Rate: 0.09768\n",
      "Epoch: 465, MSE: 0.27207647433011267, Learning Rate: 0.09767500000000001\n",
      "Epoch: 466, MSE: 0.2720743442547764, Learning Rate: 0.09767\n",
      "Epoch: 467, MSE: 0.27207221412547106, Learning Rate: 0.097665\n",
      "Epoch: 468, MSE: 0.2720700839422405, Learning Rate: 0.09766000000000001\n",
      "Epoch: 469, MSE: 0.2720679537051263, Learning Rate: 0.097655\n",
      "Epoch: 470, MSE: 0.27206582341417196, Learning Rate: 0.09765000000000001\n",
      "Epoch: 471, MSE: 0.2720636930694191, Learning Rate: 0.09764500000000001\n",
      "Epoch: 472, MSE: 0.2720615626709089, Learning Rate: 0.09764\n",
      "Epoch: 473, MSE: 0.2720594322186834, Learning Rate: 0.09763500000000001\n",
      "Epoch: 474, MSE: 0.27205730171278314, Learning Rate: 0.09763\n",
      "Epoch: 475, MSE: 0.27205517115324857, Learning Rate: 0.097625\n",
      "Epoch: 476, MSE: 0.27205304054012075, Learning Rate: 0.09762\n",
      "Epoch: 477, MSE: 0.2720509098734386, Learning Rate: 0.09761500000000001\n",
      "Epoch: 478, MSE: 0.272048779153243, Learning Rate: 0.09761\n",
      "Epoch: 479, MSE: 0.27204664837957226, Learning Rate: 0.097605\n",
      "Epoch: 480, MSE: 0.27204451755246556, Learning Rate: 0.0976\n",
      "Epoch: 481, MSE: 0.2720423866719615, Learning Rate: 0.097595\n",
      "Epoch: 482, MSE: 0.2720402557380982, Learning Rate: 0.09759000000000001\n",
      "Epoch: 483, MSE: 0.272038124750914, Learning Rate: 0.097585\n",
      "Epoch: 484, MSE: 0.2720359937104471, Learning Rate: 0.09758\n",
      "Epoch: 485, MSE: 0.2720338626167339, Learning Rate: 0.09757500000000001\n",
      "Epoch: 486, MSE: 0.272031731469811, Learning Rate: 0.09757\n",
      "Epoch: 487, MSE: 0.2720296002697176, Learning Rate: 0.09756500000000001\n",
      "Epoch: 488, MSE: 0.2720274690164876, Learning Rate: 0.09756000000000001\n",
      "Epoch: 489, MSE: 0.2720253377101581, Learning Rate: 0.097555\n",
      "Epoch: 490, MSE: 0.2720232063507655, Learning Rate: 0.09755000000000001\n",
      "Epoch: 491, MSE: 0.2720210749383444, Learning Rate: 0.097545\n",
      "Epoch: 492, MSE: 0.27201894347293093, Learning Rate: 0.09754000000000002\n",
      "Epoch: 493, MSE: 0.27201681195455946, Learning Rate: 0.09753500000000001\n",
      "Epoch: 494, MSE: 0.2720146803832647, Learning Rate: 0.09753\n",
      "Epoch: 495, MSE: 0.272012548759081, Learning Rate: 0.097525\n",
      "Epoch: 496, MSE: 0.2720104170820439, Learning Rate: 0.09752\n",
      "Epoch: 497, MSE: 0.2720082853521851, Learning Rate: 0.097515\n",
      "Epoch: 498, MSE: 0.2720061535695402, Learning Rate: 0.09751\n",
      "Epoch: 499, MSE: 0.272004021734141, Learning Rate: 0.09750500000000001\n",
      "Epoch: 500, MSE: 0.27200188984602097, Learning Rate: 0.0975\n",
      "Epoch: 501, MSE: 0.2719997579052143, Learning Rate: 0.097495\n",
      "Epoch: 502, MSE: 0.27199762591175103, Learning Rate: 0.09749000000000001\n",
      "Epoch: 503, MSE: 0.2719954938656657, Learning Rate: 0.097485\n",
      "Epoch: 504, MSE: 0.27199336176698874, Learning Rate: 0.09748000000000001\n",
      "Epoch: 505, MSE: 0.27199122961575245, Learning Rate: 0.097475\n",
      "Epoch: 506, MSE: 0.27198909741198896, Learning Rate: 0.09747\n",
      "Epoch: 507, MSE: 0.2719869651557287, Learning Rate: 0.09746500000000001\n",
      "Epoch: 508, MSE: 0.2719848328470036, Learning Rate: 0.09746\n",
      "Epoch: 509, MSE: 0.27198270048584283, Learning Rate: 0.09745500000000001\n",
      "Epoch: 510, MSE: 0.2719805680722785, Learning Rate: 0.09745000000000001\n",
      "Epoch: 511, MSE: 0.27197843560634044, Learning Rate: 0.097445\n",
      "Epoch: 512, MSE: 0.27197630308805765, Learning Rate: 0.09744000000000001\n",
      "Epoch: 513, MSE: 0.27197417051746203, Learning Rate: 0.09743500000000001\n",
      "Epoch: 514, MSE: 0.27197203789458135, Learning Rate: 0.09743\n",
      "Epoch: 515, MSE: 0.2719699052194451, Learning Rate: 0.097425\n",
      "Epoch: 516, MSE: 0.27196777249208304, Learning Rate: 0.09742\n",
      "Epoch: 517, MSE: 0.2719656397125244, Learning Rate: 0.097415\n",
      "Epoch: 518, MSE: 0.27196350688079657, Learning Rate: 0.09741\n",
      "Epoch: 519, MSE: 0.27196137399692943, Learning Rate: 0.097405\n",
      "Epoch: 520, MSE: 0.27195924106095004, Learning Rate: 0.0974\n",
      "Epoch: 521, MSE: 0.27195710807288676, Learning Rate: 0.09739500000000001\n",
      "Epoch: 522, MSE: 0.27195497503276755, Learning Rate: 0.09739\n",
      "Epoch: 523, MSE: 0.27195284194061903, Learning Rate: 0.097385\n",
      "Epoch: 524, MSE: 0.2719507087964707, Learning Rate: 0.09738000000000001\n",
      "Epoch: 525, MSE: 0.27194857560034813, Learning Rate: 0.097375\n",
      "Epoch: 526, MSE: 0.27194644235227783, Learning Rate: 0.09737000000000001\n",
      "Epoch: 527, MSE: 0.27194430905228734, Learning Rate: 0.09736500000000001\n",
      "Epoch: 528, MSE: 0.27194217570040247, Learning Rate: 0.09736\n",
      "Epoch: 529, MSE: 0.2719400422966508, Learning Rate: 0.09735500000000001\n",
      "Epoch: 530, MSE: 0.27193790884105756, Learning Rate: 0.09735\n",
      "Epoch: 531, MSE: 0.2719357753336485, Learning Rate: 0.09734500000000001\n",
      "Epoch: 532, MSE: 0.2719336417744495, Learning Rate: 0.09734000000000001\n",
      "Epoch: 533, MSE: 0.2719315081634862, Learning Rate: 0.097335\n",
      "Epoch: 534, MSE: 0.2719293745007842, Learning Rate: 0.09733000000000001\n",
      "Epoch: 535, MSE: 0.27192724078636826, Learning Rate: 0.097325\n",
      "Epoch: 536, MSE: 0.2719251070202629, Learning Rate: 0.09732\n",
      "Epoch: 537, MSE: 0.2719229732024939, Learning Rate: 0.097315\n",
      "Epoch: 538, MSE: 0.2719208393330852, Learning Rate: 0.09731000000000001\n",
      "Epoch: 539, MSE: 0.27191870541206103, Learning Rate: 0.097305\n",
      "Epoch: 540, MSE: 0.2719165714394457, Learning Rate: 0.0973\n",
      "Epoch: 541, MSE: 0.2719144374152631, Learning Rate: 0.097295\n",
      "Epoch: 542, MSE: 0.27191230333953764, Learning Rate: 0.09729\n",
      "Epoch: 543, MSE: 0.27191016921229233, Learning Rate: 0.09728500000000001\n",
      "Epoch: 544, MSE: 0.27190803503355065, Learning Rate: 0.09728\n",
      "Epoch: 545, MSE: 0.2719059008033365, Learning Rate: 0.097275\n",
      "Epoch: 546, MSE: 0.2719037665216727, Learning Rate: 0.09727000000000001\n",
      "Epoch: 547, MSE: 0.27190163218858104, Learning Rate: 0.097265\n",
      "Epoch: 548, MSE: 0.2718994978040871, Learning Rate: 0.09726000000000001\n",
      "Epoch: 549, MSE: 0.27189736336821035, Learning Rate: 0.09725500000000001\n",
      "Epoch: 550, MSE: 0.2718952288809751, Learning Rate: 0.09725\n",
      "Epoch: 551, MSE: 0.2718930943424033, Learning Rate: 0.09724500000000001\n",
      "Epoch: 552, MSE: 0.27189095975251654, Learning Rate: 0.09724000000000001\n",
      "Epoch: 553, MSE: 0.27188882511133694, Learning Rate: 0.09723500000000002\n",
      "Epoch: 554, MSE: 0.2718866904188862, Learning Rate: 0.09723000000000001\n",
      "Epoch: 555, MSE: 0.271884555675187, Learning Rate: 0.097225\n",
      "Epoch: 556, MSE: 0.2718824208802588, Learning Rate: 0.09722\n",
      "Epoch: 557, MSE: 0.2718802860341249, Learning Rate: 0.097215\n",
      "Epoch: 558, MSE: 0.2718781511368061, Learning Rate: 0.09721\n",
      "Epoch: 559, MSE: 0.27187601618832175, Learning Rate: 0.097205\n",
      "Epoch: 560, MSE: 0.27187388118869416, Learning Rate: 0.09720000000000001\n",
      "Epoch: 561, MSE: 0.2718717461379437, Learning Rate: 0.097195\n",
      "Epoch: 562, MSE: 0.271869611036091, Learning Rate: 0.09719\n",
      "Epoch: 563, MSE: 0.2718674758831556, Learning Rate: 0.09718500000000001\n",
      "Epoch: 564, MSE: 0.2718653406791587, Learning Rate: 0.09718\n",
      "Epoch: 565, MSE: 0.2718632054241201, Learning Rate: 0.09717500000000001\n",
      "Epoch: 566, MSE: 0.2718610701180598, Learning Rate: 0.09717\n",
      "Epoch: 567, MSE: 0.2718589347609973, Learning Rate: 0.097165\n",
      "Epoch: 568, MSE: 0.2718567993529518, Learning Rate: 0.09716000000000001\n",
      "Epoch: 569, MSE: 0.271854663893944, Learning Rate: 0.097155\n",
      "Epoch: 570, MSE: 0.2718525283839926, Learning Rate: 0.09715000000000001\n",
      "Epoch: 571, MSE: 0.271850392823117, Learning Rate: 0.09714500000000001\n",
      "Epoch: 572, MSE: 0.2718482572113359, Learning Rate: 0.09714\n",
      "Epoch: 573, MSE: 0.27184612154866816, Learning Rate: 0.09713500000000001\n",
      "Epoch: 574, MSE: 0.2718439858351341, Learning Rate: 0.09713000000000001\n",
      "Epoch: 575, MSE: 0.27184185007074957, Learning Rate: 0.097125\n",
      "Epoch: 576, MSE: 0.27183971425553566, Learning Rate: 0.09712\n",
      "Epoch: 577, MSE: 0.2718375783895094, Learning Rate: 0.097115\n",
      "Epoch: 578, MSE: 0.2718354424726903, Learning Rate: 0.09711\n",
      "Epoch: 579, MSE: 0.2718333065050948, Learning Rate: 0.097105\n",
      "Epoch: 580, MSE: 0.2718311704867426, Learning Rate: 0.0971\n",
      "Epoch: 581, MSE: 0.2718290344176492, Learning Rate: 0.097095\n",
      "Epoch: 582, MSE: 0.2718268982978354, Learning Rate: 0.09709000000000001\n",
      "Epoch: 583, MSE: 0.27182476212731654, Learning Rate: 0.097085\n",
      "Epoch: 584, MSE: 0.27182262590611134, Learning Rate: 0.09708\n",
      "Epoch: 585, MSE: 0.2718204896342362, Learning Rate: 0.09707500000000001\n",
      "Epoch: 586, MSE: 0.27181835331170867, Learning Rate: 0.09707\n",
      "Epoch: 587, MSE: 0.2718162169385466, Learning Rate: 0.09706500000000001\n",
      "Epoch: 588, MSE: 0.271814080514767, Learning Rate: 0.09706000000000001\n",
      "Epoch: 589, MSE: 0.2718119440403853, Learning Rate: 0.097055\n",
      "Epoch: 590, MSE: 0.27180980751541906, Learning Rate: 0.09705000000000001\n",
      "Epoch: 591, MSE: 0.27180767093988595, Learning Rate: 0.097045\n",
      "Epoch: 592, MSE: 0.27180553431380117, Learning Rate: 0.09704000000000002\n",
      "Epoch: 593, MSE: 0.271803397637181, Learning Rate: 0.09703500000000001\n",
      "Epoch: 594, MSE: 0.2718012609100432, Learning Rate: 0.09703\n",
      "Epoch: 595, MSE: 0.27179912413240165, Learning Rate: 0.09702500000000001\n",
      "Epoch: 596, MSE: 0.2717969873042751, Learning Rate: 0.09702\n",
      "Epoch: 597, MSE: 0.27179485042567786, Learning Rate: 0.097015\n",
      "Epoch: 598, MSE: 0.2717927134966263, Learning Rate: 0.09701\n",
      "Epoch: 599, MSE: 0.27179057651713545, Learning Rate: 0.09700500000000001\n",
      "Epoch: 600, MSE: 0.27178843948722126, Learning Rate: 0.097\n",
      "Epoch: 601, MSE: 0.27178630240689966, Learning Rate: 0.096995\n",
      "Epoch: 602, MSE: 0.2717841652761858, Learning Rate: 0.09699\n",
      "Epoch: 603, MSE: 0.271782028095095, Learning Rate: 0.096985\n",
      "Epoch: 604, MSE: 0.2717798908636427, Learning Rate: 0.09698000000000001\n",
      "Epoch: 605, MSE: 0.2717777535818432, Learning Rate: 0.096975\n",
      "Epoch: 606, MSE: 0.27177561624971147, Learning Rate: 0.09697\n",
      "Epoch: 607, MSE: 0.27177347886726294, Learning Rate: 0.09696500000000001\n",
      "Epoch: 608, MSE: 0.2717713414345129, Learning Rate: 0.09696\n",
      "Epoch: 609, MSE: 0.27176920395147547, Learning Rate: 0.09695500000000001\n",
      "Epoch: 610, MSE: 0.27176706641816456, Learning Rate: 0.09695000000000001\n",
      "Epoch: 611, MSE: 0.2717649288345952, Learning Rate: 0.096945\n",
      "Epoch: 612, MSE: 0.2717627912007822, Learning Rate: 0.09694000000000001\n",
      "Epoch: 613, MSE: 0.27176065351673945, Learning Rate: 0.09693500000000001\n",
      "Epoch: 614, MSE: 0.27175851578248067, Learning Rate: 0.09693000000000002\n",
      "Epoch: 615, MSE: 0.2717563779980209, Learning Rate: 0.096925\n",
      "Epoch: 616, MSE: 0.271754240163372, Learning Rate: 0.09692\n",
      "Epoch: 617, MSE: 0.2717521022785509, Learning Rate: 0.096915\n",
      "Epoch: 618, MSE: 0.27174996434356874, Learning Rate: 0.09691\n",
      "Epoch: 619, MSE: 0.2717478263584417, Learning Rate: 0.096905\n",
      "Epoch: 620, MSE: 0.27174568832318086, Learning Rate: 0.0969\n",
      "Epoch: 621, MSE: 0.271743550237801, Learning Rate: 0.09689500000000001\n",
      "Epoch: 622, MSE: 0.27174141210231473, Learning Rate: 0.09689\n",
      "Epoch: 623, MSE: 0.2717392739167362, Learning Rate: 0.096885\n",
      "Epoch: 624, MSE: 0.2717371356810793, Learning Rate: 0.09688000000000001\n",
      "Epoch: 625, MSE: 0.27173499739535545, Learning Rate: 0.096875\n",
      "Epoch: 626, MSE: 0.27173285905957817, Learning Rate: 0.09687000000000001\n",
      "Epoch: 627, MSE: 0.27173072067376125, Learning Rate: 0.096865\n",
      "Epoch: 628, MSE: 0.2717285822379169, Learning Rate: 0.09686\n",
      "Epoch: 629, MSE: 0.2717264437520584, Learning Rate: 0.09685500000000001\n",
      "Epoch: 630, MSE: 0.2717243052161973, Learning Rate: 0.09685\n",
      "Epoch: 631, MSE: 0.2717221666303471, Learning Rate: 0.09684500000000001\n",
      "Epoch: 632, MSE: 0.2717200279945202, Learning Rate: 0.09684000000000001\n",
      "Epoch: 633, MSE: 0.2717178893087297, Learning Rate: 0.096835\n",
      "Epoch: 634, MSE: 0.27171575057298597, Learning Rate: 0.09683000000000001\n",
      "Epoch: 635, MSE: 0.2717136117873034, Learning Rate: 0.09682500000000001\n",
      "Epoch: 636, MSE: 0.2717114729516933, Learning Rate: 0.09682\n",
      "Epoch: 637, MSE: 0.2717093340661675, Learning Rate: 0.096815\n",
      "Epoch: 638, MSE: 0.2717071951307378, Learning Rate: 0.09681000000000001\n",
      "Epoch: 639, MSE: 0.27170505614541757, Learning Rate: 0.096805\n",
      "Epoch: 640, MSE: 0.2717029171102168, Learning Rate: 0.0968\n",
      "Epoch: 641, MSE: 0.27170077802514897, Learning Rate: 0.096795\n",
      "Epoch: 642, MSE: 0.271698638890224, Learning Rate: 0.09679\n",
      "Epoch: 643, MSE: 0.2716964997054554, Learning Rate: 0.09678500000000001\n",
      "Epoch: 644, MSE: 0.27169436047085327, Learning Rate: 0.09678\n",
      "Epoch: 645, MSE: 0.27169222118643, Learning Rate: 0.096775\n",
      "Epoch: 646, MSE: 0.2716900818521965, Learning Rate: 0.09677000000000001\n",
      "Epoch: 647, MSE: 0.2716879424681637, Learning Rate: 0.096765\n",
      "Epoch: 648, MSE: 0.27168580303434364, Learning Rate: 0.09676000000000001\n",
      "Epoch: 649, MSE: 0.2716836635507474, Learning Rate: 0.09675500000000001\n",
      "Epoch: 650, MSE: 0.2716815240173849, Learning Rate: 0.09675\n",
      "Epoch: 651, MSE: 0.27167938443426815, Learning Rate: 0.09674500000000001\n",
      "Epoch: 652, MSE: 0.27167724480140854, Learning Rate: 0.09674\n",
      "Epoch: 653, MSE: 0.2716751051188162, Learning Rate: 0.09673500000000002\n",
      "Epoch: 654, MSE: 0.27167296538650154, Learning Rate: 0.09673000000000001\n",
      "Epoch: 655, MSE: 0.2716708256044762, Learning Rate: 0.096725\n",
      "Epoch: 656, MSE: 0.27166868577274983, Learning Rate: 0.09672\n",
      "Epoch: 657, MSE: 0.27166654589133443, Learning Rate: 0.096715\n",
      "Epoch: 658, MSE: 0.2716644059602393, Learning Rate: 0.09671\n",
      "Epoch: 659, MSE: 0.2716622659794749, Learning Rate: 0.096705\n",
      "Epoch: 660, MSE: 0.27166012594905237, Learning Rate: 0.09670000000000001\n",
      "Epoch: 661, MSE: 0.2716579858689811, Learning Rate: 0.096695\n",
      "Epoch: 662, MSE: 0.27165584573927243, Learning Rate: 0.09669\n",
      "Epoch: 663, MSE: 0.27165370555993545, Learning Rate: 0.09668500000000001\n",
      "Epoch: 664, MSE: 0.2716515653309806, Learning Rate: 0.09668\n",
      "Epoch: 665, MSE: 0.27164942505241785, Learning Rate: 0.09667500000000001\n",
      "Epoch: 666, MSE: 0.2716472847242578, Learning Rate: 0.09667\n",
      "Epoch: 667, MSE: 0.27164514434650905, Learning Rate: 0.096665\n",
      "Epoch: 668, MSE: 0.2716430039191823, Learning Rate: 0.09666000000000001\n",
      "Epoch: 669, MSE: 0.27164086344228816, Learning Rate: 0.096655\n",
      "Epoch: 670, MSE: 0.27163872291583435, Learning Rate: 0.09665000000000001\n",
      "Epoch: 671, MSE: 0.27163658233983223, Learning Rate: 0.09664500000000001\n",
      "Epoch: 672, MSE: 0.27163444171429046, Learning Rate: 0.09664\n",
      "Epoch: 673, MSE: 0.2716323010392186, Learning Rate: 0.09663500000000001\n",
      "Epoch: 674, MSE: 0.2716301603146266, Learning Rate: 0.09663000000000001\n",
      "Epoch: 675, MSE: 0.27162801954052307, Learning Rate: 0.09662500000000002\n",
      "Epoch: 676, MSE: 0.27162587871691796, Learning Rate: 0.09662\n",
      "Epoch: 677, MSE: 0.27162373784382027, Learning Rate: 0.096615\n",
      "Epoch: 678, MSE: 0.27162159692123977, Learning Rate: 0.09661\n",
      "Epoch: 679, MSE: 0.27161945594918413, Learning Rate: 0.096605\n",
      "Epoch: 680, MSE: 0.27161731492766455, Learning Rate: 0.0966\n",
      "Epoch: 681, MSE: 0.27161517385668793, Learning Rate: 0.096595\n",
      "Epoch: 682, MSE: 0.27161303273626447, Learning Rate: 0.09659000000000001\n",
      "Epoch: 683, MSE: 0.2716108915664036, Learning Rate: 0.096585\n",
      "Epoch: 684, MSE: 0.2716087503471116, Learning Rate: 0.09658\n",
      "Epoch: 685, MSE: 0.2716066090784001, Learning Rate: 0.09657500000000001\n",
      "Epoch: 686, MSE: 0.271604467760277, Learning Rate: 0.09657\n",
      "Epoch: 687, MSE: 0.2716023263927505, Learning Rate: 0.09656500000000001\n",
      "Epoch: 688, MSE: 0.27160018497582994, Learning Rate: 0.09656\n",
      "Epoch: 689, MSE: 0.27159804350952277, Learning Rate: 0.096555\n",
      "Epoch: 690, MSE: 0.2715959019938381, Learning Rate: 0.09655000000000001\n",
      "Epoch: 691, MSE: 0.2715937604287845, Learning Rate: 0.096545\n",
      "Epoch: 692, MSE: 0.27159161881437055, Learning Rate: 0.09654000000000001\n",
      "Epoch: 693, MSE: 0.27158947715060394, Learning Rate: 0.09653500000000001\n",
      "Epoch: 694, MSE: 0.271587335437493, Learning Rate: 0.09653\n",
      "Epoch: 695, MSE: 0.2715851936750467, Learning Rate: 0.096525\n",
      "Epoch: 696, MSE: 0.27158305186327264, Learning Rate: 0.09652000000000001\n",
      "Epoch: 697, MSE: 0.2715809100021793, Learning Rate: 0.096515\n",
      "Epoch: 698, MSE: 0.27157876809177467, Learning Rate: 0.09651\n",
      "Epoch: 699, MSE: 0.27157662613206673, Learning Rate: 0.09650500000000001\n",
      "Epoch: 700, MSE: 0.2715744841230629, Learning Rate: 0.0965\n",
      "Epoch: 701, MSE: 0.2715723420647719, Learning Rate: 0.096495\n",
      "Epoch: 702, MSE: 0.2715701999572004, Learning Rate: 0.09649\n",
      "Epoch: 703, MSE: 0.27156805780035803, Learning Rate: 0.096485\n",
      "Epoch: 704, MSE: 0.27156591559425186, Learning Rate: 0.09648000000000001\n",
      "Epoch: 705, MSE: 0.27156377333888904, Learning Rate: 0.096475\n",
      "Epoch: 706, MSE: 0.2715616310342764, Learning Rate: 0.09647\n",
      "Epoch: 707, MSE: 0.27155948868042384, Learning Rate: 0.09646500000000001\n",
      "Epoch: 708, MSE: 0.2715573462773378, Learning Rate: 0.09646\n",
      "Epoch: 709, MSE: 0.27155520382502496, Learning Rate: 0.09645500000000001\n",
      "Epoch: 710, MSE: 0.271553061323495, Learning Rate: 0.09645000000000001\n",
      "Epoch: 711, MSE: 0.27155091877275234, Learning Rate: 0.096445\n",
      "Epoch: 712, MSE: 0.2715487761728073, Learning Rate: 0.09644000000000001\n",
      "Epoch: 713, MSE: 0.2715466335236653, Learning Rate: 0.096435\n",
      "Epoch: 714, MSE: 0.27154449082533433, Learning Rate: 0.09643000000000002\n",
      "Epoch: 715, MSE: 0.27154234807782096, Learning Rate: 0.09642500000000001\n",
      "Epoch: 716, MSE: 0.2715402052811334, Learning Rate: 0.09642\n",
      "Epoch: 717, MSE: 0.27153806243527795, Learning Rate: 0.096415\n",
      "Epoch: 718, MSE: 0.2715359195402623, Learning Rate: 0.09641\n",
      "Epoch: 719, MSE: 0.2715337765960927, Learning Rate: 0.096405\n",
      "Epoch: 720, MSE: 0.2715316336027779, Learning Rate: 0.0964\n",
      "Epoch: 721, MSE: 0.27152949056032244, Learning Rate: 0.09639500000000001\n",
      "Epoch: 722, MSE: 0.27152734746873497, Learning Rate: 0.09639\n",
      "Epoch: 723, MSE: 0.27152520432802135, Learning Rate: 0.096385\n",
      "Epoch: 724, MSE: 0.27152306113818897, Learning Rate: 0.09638000000000001\n",
      "Epoch: 725, MSE: 0.27152091789924454, Learning Rate: 0.096375\n",
      "Epoch: 726, MSE: 0.27151877461119467, Learning Rate: 0.09637000000000001\n",
      "Epoch: 727, MSE: 0.27151663127404635, Learning Rate: 0.096365\n",
      "Epoch: 728, MSE: 0.27151448788780636, Learning Rate: 0.09636\n",
      "Epoch: 729, MSE: 0.2715123444524803, Learning Rate: 0.09635500000000001\n",
      "Epoch: 730, MSE: 0.2715102009680757, Learning Rate: 0.09635\n",
      "Epoch: 731, MSE: 0.27150805743459827, Learning Rate: 0.09634500000000001\n",
      "Epoch: 732, MSE: 0.2715059138520559, Learning Rate: 0.09634000000000001\n",
      "Epoch: 733, MSE: 0.2715037702204541, Learning Rate: 0.096335\n",
      "Epoch: 734, MSE: 0.27150162653979887, Learning Rate: 0.09633000000000001\n",
      "Epoch: 735, MSE: 0.2714994828100968, Learning Rate: 0.09632500000000001\n",
      "Epoch: 736, MSE: 0.2714973390313545, Learning Rate: 0.09632000000000002\n",
      "Epoch: 737, MSE: 0.2714951952035782, Learning Rate: 0.096315\n",
      "Epoch: 738, MSE: 0.27149305132677426, Learning Rate: 0.09631\n",
      "Epoch: 739, MSE: 0.2714909074009484, Learning Rate: 0.096305\n",
      "Epoch: 740, MSE: 0.2714887634261078, Learning Rate: 0.0963\n",
      "Epoch: 741, MSE: 0.27148661940225716, Learning Rate: 0.096295\n",
      "Epoch: 742, MSE: 0.2714844753294027, Learning Rate: 0.09629\n",
      "Epoch: 743, MSE: 0.2714823312075527, Learning Rate: 0.09628500000000001\n",
      "Epoch: 744, MSE: 0.2714801870367105, Learning Rate: 0.09628\n",
      "Epoch: 745, MSE: 0.27147804281688287, Learning Rate: 0.096275\n",
      "Epoch: 746, MSE: 0.2714758985480766, Learning Rate: 0.09627000000000001\n",
      "Epoch: 747, MSE: 0.2714737542302962, Learning Rate: 0.096265\n",
      "Epoch: 748, MSE: 0.27147160986354885, Learning Rate: 0.09626000000000001\n",
      "Epoch: 749, MSE: 0.2714694654478389, Learning Rate: 0.09625500000000001\n",
      "Epoch: 750, MSE: 0.2714673209831738, Learning Rate: 0.09625\n",
      "Epoch: 751, MSE: 0.271465176469558, Learning Rate: 0.09624500000000001\n",
      "Epoch: 752, MSE: 0.2714630319069981, Learning Rate: 0.09624\n",
      "Epoch: 753, MSE: 0.2714608872954982, Learning Rate: 0.09623500000000001\n",
      "Epoch: 754, MSE: 0.2714587426350659, Learning Rate: 0.09623000000000001\n",
      "Epoch: 755, MSE: 0.2714565979257058, Learning Rate: 0.096225\n",
      "Epoch: 756, MSE: 0.2714544531674235, Learning Rate: 0.09622\n",
      "Epoch: 757, MSE: 0.27145230836022444, Learning Rate: 0.096215\n",
      "Epoch: 758, MSE: 0.2714501635041144, Learning Rate: 0.09621\n",
      "Epoch: 759, MSE: 0.27144801859909856, Learning Rate: 0.096205\n",
      "Epoch: 760, MSE: 0.2714458736451829, Learning Rate: 0.09620000000000001\n",
      "Epoch: 761, MSE: 0.27144372864237215, Learning Rate: 0.096195\n",
      "Epoch: 762, MSE: 0.2714415835906719, Learning Rate: 0.09619\n",
      "Epoch: 763, MSE: 0.27143943849008756, Learning Rate: 0.096185\n",
      "Epoch: 764, MSE: 0.2714372933406247, Learning Rate: 0.09618\n",
      "Epoch: 765, MSE: 0.271435148142287, Learning Rate: 0.09617500000000001\n",
      "Epoch: 766, MSE: 0.2714330028950813, Learning Rate: 0.09617\n",
      "Epoch: 767, MSE: 0.27143085759901314, Learning Rate: 0.096165\n",
      "Epoch: 768, MSE: 0.2714287122540866, Learning Rate: 0.09616000000000001\n",
      "Epoch: 769, MSE: 0.27142656686030703, Learning Rate: 0.096155\n",
      "Epoch: 770, MSE: 0.2714244214176786, Learning Rate: 0.09615000000000001\n",
      "Epoch: 771, MSE: 0.2714222759262088, Learning Rate: 0.09614500000000001\n",
      "Epoch: 772, MSE: 0.2714201303859003, Learning Rate: 0.09614\n",
      "Epoch: 773, MSE: 0.2714179847967591, Learning Rate: 0.09613500000000001\n",
      "Epoch: 774, MSE: 0.2714158391587892, Learning Rate: 0.09613000000000001\n",
      "Epoch: 775, MSE: 0.271413693471997, Learning Rate: 0.09612500000000002\n",
      "Epoch: 776, MSE: 0.27141154773638715, Learning Rate: 0.09612000000000001\n",
      "Epoch: 777, MSE: 0.2714094019519637, Learning Rate: 0.096115\n",
      "Epoch: 778, MSE: 0.27140725611873145, Learning Rate: 0.09611\n",
      "Epoch: 779, MSE: 0.27140511023669595, Learning Rate: 0.096105\n",
      "Epoch: 780, MSE: 0.271402964305862, Learning Rate: 0.0961\n",
      "Epoch: 781, MSE: 0.2714008183262335, Learning Rate: 0.096095\n",
      "Epoch: 782, MSE: 0.27139867229781545, Learning Rate: 0.09609000000000001\n",
      "Epoch: 783, MSE: 0.27139652622061233, Learning Rate: 0.096085\n",
      "Epoch: 784, MSE: 0.27139438009463, Learning Rate: 0.09608\n",
      "Epoch: 785, MSE: 0.27139223391987216, Learning Rate: 0.09607500000000001\n",
      "Epoch: 786, MSE: 0.2713900876963431, Learning Rate: 0.09607\n",
      "Epoch: 787, MSE: 0.2713879414240478, Learning Rate: 0.09606500000000001\n",
      "Epoch: 788, MSE: 0.27138579510299105, Learning Rate: 0.09606\n",
      "Epoch: 789, MSE: 0.2713836487331763, Learning Rate: 0.096055\n",
      "Epoch: 790, MSE: 0.2713815023146097, Learning Rate: 0.09605000000000001\n",
      "Epoch: 791, MSE: 0.27137935584729406, Learning Rate: 0.096045\n",
      "Epoch: 792, MSE: 0.2713772093312349, Learning Rate: 0.09604000000000001\n",
      "Epoch: 793, MSE: 0.2713750627664357, Learning Rate: 0.09603500000000001\n",
      "Epoch: 794, MSE: 0.27137291615290143, Learning Rate: 0.09603\n",
      "Epoch: 795, MSE: 0.2713707694906367, Learning Rate: 0.09602500000000001\n",
      "Epoch: 796, MSE: 0.2713686227796455, Learning Rate: 0.09602\n",
      "Epoch: 797, MSE: 0.27136647601993175, Learning Rate: 0.09601500000000002\n",
      "Epoch: 798, MSE: 0.27136432921149967, Learning Rate: 0.09601\n",
      "Epoch: 799, MSE: 0.27136218235435405, Learning Rate: 0.09600500000000001\n",
      "Epoch: 800, MSE: 0.271360035448499, Learning Rate: 0.096\n",
      "Epoch: 801, MSE: 0.2713578884939387, Learning Rate: 0.095995\n",
      "Epoch: 802, MSE: 0.2713557414906769, Learning Rate: 0.09599\n",
      "Epoch: 803, MSE: 0.27135359443871715, Learning Rate: 0.095985\n",
      "Epoch: 804, MSE: 0.27135144733806493, Learning Rate: 0.09598000000000001\n",
      "Epoch: 805, MSE: 0.271349300188724, Learning Rate: 0.095975\n",
      "Epoch: 806, MSE: 0.2713471529906977, Learning Rate: 0.09597\n",
      "Epoch: 807, MSE: 0.27134500574398995, Learning Rate: 0.09596500000000001\n",
      "Epoch: 808, MSE: 0.2713428584486062, Learning Rate: 0.09596\n",
      "Epoch: 809, MSE: 0.27134071110454855, Learning Rate: 0.09595500000000001\n",
      "Epoch: 810, MSE: 0.27133856371182236, Learning Rate: 0.09595000000000001\n",
      "Epoch: 811, MSE: 0.2713364162704313, Learning Rate: 0.095945\n",
      "Epoch: 812, MSE: 0.27133426878037803, Learning Rate: 0.09594000000000001\n",
      "Epoch: 813, MSE: 0.27133212124166783, Learning Rate: 0.095935\n",
      "Epoch: 814, MSE: 0.2713299736543042, Learning Rate: 0.09593000000000002\n",
      "Epoch: 815, MSE: 0.2713278260182902, Learning Rate: 0.09592500000000001\n",
      "Epoch: 816, MSE: 0.2713256783336306, Learning Rate: 0.09592\n",
      "Epoch: 817, MSE: 0.2713235306003287, Learning Rate: 0.095915\n",
      "Epoch: 818, MSE: 0.2713213828183878, Learning Rate: 0.09591\n",
      "Epoch: 819, MSE: 0.2713192349878125, Learning Rate: 0.095905\n",
      "Epoch: 820, MSE: 0.27131708710860564, Learning Rate: 0.0959\n",
      "Epoch: 821, MSE: 0.27131493918077215, Learning Rate: 0.09589500000000001\n",
      "Epoch: 822, MSE: 0.2713127912043141, Learning Rate: 0.09589\n",
      "Epoch: 823, MSE: 0.2713106431792372, Learning Rate: 0.095885\n",
      "Epoch: 824, MSE: 0.27130849510554184, Learning Rate: 0.09588\n",
      "Epoch: 825, MSE: 0.2713063469832341, Learning Rate: 0.095875\n",
      "Epoch: 826, MSE: 0.2713041988123174, Learning Rate: 0.09587000000000001\n",
      "Epoch: 827, MSE: 0.27130205059279433, Learning Rate: 0.095865\n",
      "Epoch: 828, MSE: 0.2712999023246686, Learning Rate: 0.09586\n",
      "Epoch: 829, MSE: 0.2712977540079445, Learning Rate: 0.09585500000000001\n",
      "Epoch: 830, MSE: 0.2712956056426246, Learning Rate: 0.09585\n",
      "Epoch: 831, MSE: 0.2712934572287123, Learning Rate: 0.09584500000000001\n",
      "Epoch: 832, MSE: 0.27129130876621194, Learning Rate: 0.09584000000000001\n",
      "Epoch: 833, MSE: 0.2712891602551254, Learning Rate: 0.095835\n",
      "Epoch: 834, MSE: 0.27128701169545766, Learning Rate: 0.09583000000000001\n",
      "Epoch: 835, MSE: 0.2712848630872111, Learning Rate: 0.09582500000000001\n",
      "Epoch: 836, MSE: 0.27128271443038926, Learning Rate: 0.09582000000000002\n",
      "Epoch: 837, MSE: 0.271280565724996, Learning Rate: 0.09581500000000001\n",
      "Epoch: 838, MSE: 0.27127841697103344, Learning Rate: 0.09581\n",
      "Epoch: 839, MSE: 0.2712762681685056, Learning Rate: 0.095805\n",
      "Epoch: 840, MSE: 0.27127411931741624, Learning Rate: 0.0958\n",
      "Epoch: 841, MSE: 0.2712719704177664, Learning Rate: 0.095795\n",
      "Epoch: 842, MSE: 0.2712698214695621, Learning Rate: 0.09579\n",
      "Epoch: 843, MSE: 0.27126767247280503, Learning Rate: 0.09578500000000001\n",
      "Epoch: 844, MSE: 0.2712655234274986, Learning Rate: 0.09578\n",
      "Epoch: 845, MSE: 0.27126337433364633, Learning Rate: 0.095775\n",
      "Epoch: 846, MSE: 0.2712612251912499, Learning Rate: 0.09577000000000001\n",
      "Epoch: 847, MSE: 0.27125907600031335, Learning Rate: 0.095765\n",
      "Epoch: 848, MSE: 0.2712569267608405, Learning Rate: 0.09576000000000001\n",
      "Epoch: 849, MSE: 0.2712547774728336, Learning Rate: 0.095755\n",
      "Epoch: 850, MSE: 0.27125262813629575, Learning Rate: 0.09575\n",
      "Epoch: 851, MSE: 0.27125047875123026, Learning Rate: 0.09574500000000001\n",
      "Epoch: 852, MSE: 0.27124832931763965, Learning Rate: 0.09574\n",
      "Epoch: 853, MSE: 0.2712461798355275, Learning Rate: 0.09573500000000001\n",
      "Epoch: 854, MSE: 0.2712440303048957, Learning Rate: 0.09573000000000001\n",
      "Epoch: 855, MSE: 0.27124188072574845, Learning Rate: 0.095725\n",
      "Epoch: 856, MSE: 0.27123973109808747, Learning Rate: 0.09572000000000001\n",
      "Epoch: 857, MSE: 0.27123758142191606, Learning Rate: 0.095715\n",
      "Epoch: 858, MSE: 0.2712354316972388, Learning Rate: 0.09571\n",
      "Epoch: 859, MSE: 0.27123328192405566, Learning Rate: 0.095705\n",
      "Epoch: 860, MSE: 0.27123113210237193, Learning Rate: 0.09570000000000001\n",
      "Epoch: 861, MSE: 0.2712289822321886, Learning Rate: 0.095695\n",
      "Epoch: 862, MSE: 0.27122683231350897, Learning Rate: 0.09569\n",
      "Epoch: 863, MSE: 0.27122468234633673, Learning Rate: 0.095685\n",
      "Epoch: 864, MSE: 0.2712225323306736, Learning Rate: 0.09568\n",
      "Epoch: 865, MSE: 0.2712203822665233, Learning Rate: 0.09567500000000001\n",
      "Epoch: 866, MSE: 0.2712182321538885, Learning Rate: 0.09567\n",
      "Epoch: 867, MSE: 0.27121608199277025, Learning Rate: 0.095665\n",
      "Epoch: 868, MSE: 0.2712139317831729, Learning Rate: 0.09566000000000001\n",
      "Epoch: 869, MSE: 0.27121178152509784, Learning Rate: 0.095655\n",
      "Epoch: 870, MSE: 0.27120963121854985, Learning Rate: 0.09565000000000001\n",
      "Epoch: 871, MSE: 0.27120748086353, Learning Rate: 0.09564500000000001\n",
      "Epoch: 872, MSE: 0.2712053304600399, Learning Rate: 0.09564\n",
      "Epoch: 873, MSE: 0.2712031800080848, Learning Rate: 0.09563500000000001\n",
      "Epoch: 874, MSE: 0.2712010295076661, Learning Rate: 0.09563\n",
      "Epoch: 875, MSE: 0.271198878958785, Learning Rate: 0.09562500000000002\n",
      "Epoch: 876, MSE: 0.27119672836144604, Learning Rate: 0.09562000000000001\n",
      "Epoch: 877, MSE: 0.27119457771565075, Learning Rate: 0.095615\n",
      "Epoch: 878, MSE: 0.27119242702140156, Learning Rate: 0.09561\n",
      "Epoch: 879, MSE: 0.2711902762787013, Learning Rate: 0.095605\n",
      "Epoch: 880, MSE: 0.2711881254875529, Learning Rate: 0.0956\n",
      "Epoch: 881, MSE: 0.2711859746479575, Learning Rate: 0.095595\n",
      "Epoch: 882, MSE: 0.27118382375991884, Learning Rate: 0.09559000000000001\n",
      "Epoch: 883, MSE: 0.2711816728234389, Learning Rate: 0.095585\n",
      "Epoch: 884, MSE: 0.27117952183852007, Learning Rate: 0.09558\n",
      "Epoch: 885, MSE: 0.27117737080516524, Learning Rate: 0.09557500000000001\n",
      "Epoch: 886, MSE: 0.27117521972337527, Learning Rate: 0.09557\n",
      "Epoch: 887, MSE: 0.2711730685931545, Learning Rate: 0.09556500000000001\n",
      "Epoch: 888, MSE: 0.2711709174145043, Learning Rate: 0.09556\n",
      "Epoch: 889, MSE: 0.2711687661874256, Learning Rate: 0.095555\n",
      "Epoch: 890, MSE: 0.27116661491192395, Learning Rate: 0.09555000000000001\n",
      "Epoch: 891, MSE: 0.27116446358799967, Learning Rate: 0.095545\n",
      "Epoch: 892, MSE: 0.2711623122156541, Learning Rate: 0.09554000000000001\n",
      "Epoch: 893, MSE: 0.2711601607948922, Learning Rate: 0.09553500000000001\n",
      "Epoch: 894, MSE: 0.27115800932571404, Learning Rate: 0.09553\n",
      "Epoch: 895, MSE: 0.27115585780812235, Learning Rate: 0.09552500000000001\n",
      "Epoch: 896, MSE: 0.27115370624211943, Learning Rate: 0.09552000000000001\n",
      "Epoch: 897, MSE: 0.2711515546277084, Learning Rate: 0.095515\n",
      "Epoch: 898, MSE: 0.2711494029648901, Learning Rate: 0.09551\n",
      "Epoch: 899, MSE: 0.271147251253668, Learning Rate: 0.095505\n",
      "Epoch: 900, MSE: 0.2711450994940425, Learning Rate: 0.0955\n",
      "Epoch: 901, MSE: 0.2711429476860167, Learning Rate: 0.095495\n",
      "Epoch: 902, MSE: 0.27114079582959344, Learning Rate: 0.09549\n",
      "Epoch: 903, MSE: 0.27113864392477377, Learning Rate: 0.095485\n",
      "Epoch: 904, MSE: 0.2711364919715605, Learning Rate: 0.09548000000000001\n",
      "Epoch: 905, MSE: 0.2711343399699561, Learning Rate: 0.095475\n",
      "Epoch: 906, MSE: 0.2711321879199616, Learning Rate: 0.09547\n",
      "Epoch: 907, MSE: 0.2711300358215785, Learning Rate: 0.09546500000000001\n",
      "Epoch: 908, MSE: 0.27112788367481133, Learning Rate: 0.09546\n",
      "Epoch: 909, MSE: 0.2711257314796594, Learning Rate: 0.09545500000000001\n",
      "Epoch: 910, MSE: 0.2711235792361267, Learning Rate: 0.09545000000000001\n",
      "Epoch: 911, MSE: 0.27112142694421465, Learning Rate: 0.095445\n",
      "Epoch: 912, MSE: 0.2711192746039246, Learning Rate: 0.09544000000000001\n",
      "Epoch: 913, MSE: 0.27111712221525874, Learning Rate: 0.095435\n",
      "Epoch: 914, MSE: 0.27111496977822075, Learning Rate: 0.09543000000000001\n",
      "Epoch: 915, MSE: 0.27111281729280967, Learning Rate: 0.09542500000000001\n",
      "Epoch: 916, MSE: 0.2711106647590295, Learning Rate: 0.09542\n",
      "Epoch: 917, MSE: 0.27110851217688114, Learning Rate: 0.09541500000000001\n",
      "Epoch: 918, MSE: 0.2711063595463671, Learning Rate: 0.09541\n",
      "Epoch: 919, MSE: 0.27110420686748954, Learning Rate: 0.095405\n",
      "Epoch: 920, MSE: 0.27110205414024924, Learning Rate: 0.0954\n",
      "Epoch: 921, MSE: 0.27109990136464923, Learning Rate: 0.09539500000000001\n",
      "Epoch: 922, MSE: 0.27109774854069085, Learning Rate: 0.09539\n",
      "Epoch: 923, MSE: 0.27109559566837527, Learning Rate: 0.095385\n",
      "Epoch: 924, MSE: 0.27109344274770525, Learning Rate: 0.09538\n",
      "Epoch: 925, MSE: 0.271091289778683, Learning Rate: 0.095375\n",
      "Epoch: 926, MSE: 0.2710891367613089, Learning Rate: 0.09537000000000001\n",
      "Epoch: 927, MSE: 0.27108698369558604, Learning Rate: 0.095365\n",
      "Epoch: 928, MSE: 0.2710848305815152, Learning Rate: 0.09536\n",
      "Epoch: 929, MSE: 0.27108267741909925, Learning Rate: 0.09535500000000001\n",
      "Epoch: 930, MSE: 0.2710805242083389, Learning Rate: 0.09535\n",
      "Epoch: 931, MSE: 0.2710783709492363, Learning Rate: 0.09534500000000001\n",
      "Epoch: 932, MSE: 0.2710762176417927, Learning Rate: 0.09534000000000001\n",
      "Epoch: 933, MSE: 0.27107406428601066, Learning Rate: 0.095335\n",
      "Epoch: 934, MSE: 0.27107191088189214, Learning Rate: 0.09533000000000001\n",
      "Epoch: 935, MSE: 0.2710697574294375, Learning Rate: 0.09532500000000001\n",
      "Epoch: 936, MSE: 0.27106760392864904, Learning Rate: 0.09532000000000002\n",
      "Epoch: 937, MSE: 0.27106545037952884, Learning Rate: 0.095315\n",
      "Epoch: 938, MSE: 0.2710632967820773, Learning Rate: 0.09531\n",
      "Epoch: 939, MSE: 0.2710611431362981, Learning Rate: 0.095305\n",
      "Epoch: 940, MSE: 0.2710589894421912, Learning Rate: 0.0953\n",
      "Epoch: 941, MSE: 0.2710568356997591, Learning Rate: 0.095295\n",
      "Epoch: 942, MSE: 0.2710546819090023, Learning Rate: 0.09529\n",
      "Epoch: 943, MSE: 0.2710525280699233, Learning Rate: 0.09528500000000001\n",
      "Epoch: 944, MSE: 0.27105037418252365, Learning Rate: 0.09528\n",
      "Epoch: 945, MSE: 0.271048220246805, Learning Rate: 0.095275\n",
      "Epoch: 946, MSE: 0.2710460662627678, Learning Rate: 0.09527000000000001\n",
      "Epoch: 947, MSE: 0.2710439122304155, Learning Rate: 0.095265\n",
      "Epoch: 948, MSE: 0.2710417581497481, Learning Rate: 0.09526000000000001\n",
      "Epoch: 949, MSE: 0.2710396040207671, Learning Rate: 0.095255\n",
      "Epoch: 950, MSE: 0.271037449843475, Learning Rate: 0.09525\n",
      "Epoch: 951, MSE: 0.27103529561787326, Learning Rate: 0.09524500000000001\n",
      "Epoch: 952, MSE: 0.2710331413439618, Learning Rate: 0.09524\n",
      "Epoch: 953, MSE: 0.27103098702174355, Learning Rate: 0.09523500000000001\n",
      "Epoch: 954, MSE: 0.27102883265122024, Learning Rate: 0.09523000000000001\n",
      "Epoch: 955, MSE: 0.27102667823239257, Learning Rate: 0.095225\n",
      "Epoch: 956, MSE: 0.27102452376526154, Learning Rate: 0.09522000000000001\n",
      "Epoch: 957, MSE: 0.2710223692498299, Learning Rate: 0.09521500000000001\n",
      "Epoch: 958, MSE: 0.2710202146860978, Learning Rate: 0.09521\n",
      "Epoch: 959, MSE: 0.27101806007406687, Learning Rate: 0.095205\n",
      "Epoch: 960, MSE: 0.2710159054137394, Learning Rate: 0.0952\n",
      "Epoch: 961, MSE: 0.2710137507051157, Learning Rate: 0.095195\n",
      "Epoch: 962, MSE: 0.27101159594819824, Learning Rate: 0.09519\n",
      "Epoch: 963, MSE: 0.27100944114298764, Learning Rate: 0.095185\n",
      "Epoch: 964, MSE: 0.27100728628948445, Learning Rate: 0.09518\n",
      "Epoch: 965, MSE: 0.27100513138769156, Learning Rate: 0.09517500000000001\n",
      "Epoch: 966, MSE: 0.27100297643760957, Learning Rate: 0.09517\n",
      "Epoch: 967, MSE: 0.2710008214392398, Learning Rate: 0.095165\n",
      "Epoch: 968, MSE: 0.27099866639258424, Learning Rate: 0.09516000000000001\n",
      "Epoch: 969, MSE: 0.27099651129764313, Learning Rate: 0.095155\n",
      "Epoch: 970, MSE: 0.2709943561544182, Learning Rate: 0.09515000000000001\n",
      "Epoch: 971, MSE: 0.2709922009629109, Learning Rate: 0.09514500000000001\n",
      "Epoch: 972, MSE: 0.27099004572312263, Learning Rate: 0.09514\n",
      "Epoch: 973, MSE: 0.2709878904350537, Learning Rate: 0.09513500000000001\n",
      "Epoch: 974, MSE: 0.2709857350987063, Learning Rate: 0.09513\n",
      "Epoch: 975, MSE: 0.2709835797140819, Learning Rate: 0.09512500000000002\n",
      "Epoch: 976, MSE: 0.27098142428118155, Learning Rate: 0.09512000000000001\n",
      "Epoch: 977, MSE: 0.2709792688000048, Learning Rate: 0.095115\n",
      "Epoch: 978, MSE: 0.270977113270555, Learning Rate: 0.09511000000000001\n",
      "Epoch: 979, MSE: 0.27097495769283275, Learning Rate: 0.095105\n",
      "Epoch: 980, MSE: 0.2709728020668379, Learning Rate: 0.0951\n",
      "Epoch: 981, MSE: 0.27097064639257384, Learning Rate: 0.095095\n",
      "Epoch: 982, MSE: 0.2709684906700407, Learning Rate: 0.09509000000000001\n",
      "Epoch: 983, MSE: 0.2709663348992393, Learning Rate: 0.095085\n",
      "Epoch: 984, MSE: 0.2709641790801711, Learning Rate: 0.09508\n",
      "Epoch: 985, MSE: 0.2709620232128373, Learning Rate: 0.095075\n",
      "Epoch: 986, MSE: 0.27095986729723914, Learning Rate: 0.09507\n",
      "Epoch: 987, MSE: 0.2709577113333775, Learning Rate: 0.09506500000000001\n",
      "Epoch: 988, MSE: 0.27095555532125315, Learning Rate: 0.09506\n",
      "Epoch: 989, MSE: 0.2709533992608679, Learning Rate: 0.095055\n",
      "Epoch: 990, MSE: 0.27095124315222263, Learning Rate: 0.09505000000000001\n",
      "Epoch: 991, MSE: 0.27094908699531883, Learning Rate: 0.095045\n",
      "Epoch: 992, MSE: 0.27094693079015636, Learning Rate: 0.09504000000000001\n",
      "Epoch: 993, MSE: 0.27094477453673715, Learning Rate: 0.09503500000000001\n",
      "Epoch: 994, MSE: 0.2709426182350625, Learning Rate: 0.09503\n",
      "Epoch: 995, MSE: 0.2709404618851324, Learning Rate: 0.09502500000000001\n",
      "Epoch: 996, MSE: 0.270938305486949, Learning Rate: 0.09502000000000001\n",
      "Epoch: 997, MSE: 0.27093614904051244, Learning Rate: 0.09501500000000002\n",
      "Epoch: 998, MSE: 0.27093399254582506, Learning Rate: 0.09501\n",
      "Epoch: 999, MSE: 0.270931836002886, Learning Rate: 0.095005\n",
      "Epoch: 1000, MSE: 0.27092967941169727, Learning Rate: 0.095\n",
      "Epoch: 1001, MSE: 0.2709275227722608, Learning Rate: 0.094995\n",
      "Epoch: 1002, MSE: 0.270925366084576, Learning Rate: 0.09499\n",
      "Epoch: 1003, MSE: 0.2709232093486448, Learning Rate: 0.094985\n",
      "Epoch: 1004, MSE: 0.2709210525644675, Learning Rate: 0.09498000000000001\n",
      "Epoch: 1005, MSE: 0.27091889573204503, Learning Rate: 0.094975\n",
      "Epoch: 1006, MSE: 0.2709167388513797, Learning Rate: 0.09497\n",
      "Epoch: 1007, MSE: 0.27091458192247037, Learning Rate: 0.09496500000000001\n",
      "Epoch: 1008, MSE: 0.2709124249453201, Learning Rate: 0.09496\n",
      "Epoch: 1009, MSE: 0.27091026791992834, Learning Rate: 0.09495500000000001\n",
      "Epoch: 1010, MSE: 0.2709081108462956, Learning Rate: 0.09495\n",
      "Epoch: 1011, MSE: 0.2709059537244239, Learning Rate: 0.094945\n",
      "Epoch: 1012, MSE: 0.27090379655431485, Learning Rate: 0.09494000000000001\n",
      "Epoch: 1013, MSE: 0.27090163933596756, Learning Rate: 0.094935\n",
      "Epoch: 1014, MSE: 0.27089948206938386, Learning Rate: 0.09493000000000001\n",
      "Epoch: 1015, MSE: 0.27089732475456463, Learning Rate: 0.09492500000000001\n",
      "Epoch: 1016, MSE: 0.2708951673915108, Learning Rate: 0.09492\n",
      "Epoch: 1017, MSE: 0.2708930099802223, Learning Rate: 0.09491500000000001\n",
      "Epoch: 1018, MSE: 0.27089085252070066, Learning Rate: 0.09491000000000001\n",
      "Epoch: 1019, MSE: 0.2708886950129468, Learning Rate: 0.094905\n",
      "Epoch: 1020, MSE: 0.2708865374569618, Learning Rate: 0.0949\n",
      "Epoch: 1021, MSE: 0.2708843798527456, Learning Rate: 0.09489500000000001\n",
      "Epoch: 1022, MSE: 0.27088222220030034, Learning Rate: 0.09489\n",
      "Epoch: 1023, MSE: 0.2708800644996253, Learning Rate: 0.094885\n",
      "Epoch: 1024, MSE: 0.27087790675072254, Learning Rate: 0.09488\n",
      "Epoch: 1025, MSE: 0.2708757489535922, Learning Rate: 0.094875\n",
      "Epoch: 1026, MSE: 0.2708735911082362, Learning Rate: 0.09487000000000001\n",
      "Epoch: 1027, MSE: 0.27087143321465235, Learning Rate: 0.094865\n",
      "Epoch: 1028, MSE: 0.2708692752728448, Learning Rate: 0.09486\n",
      "Epoch: 1029, MSE: 0.2708671172828126, Learning Rate: 0.09485500000000001\n",
      "Epoch: 1030, MSE: 0.2708649592445568, Learning Rate: 0.09485\n",
      "Epoch: 1031, MSE: 0.27086280115807804, Learning Rate: 0.09484500000000001\n",
      "Epoch: 1032, MSE: 0.27086064302337703, Learning Rate: 0.09484000000000001\n",
      "Epoch: 1033, MSE: 0.27085848484045455, Learning Rate: 0.094835\n",
      "Epoch: 1034, MSE: 0.2708563266093117, Learning Rate: 0.09483000000000001\n",
      "Epoch: 1035, MSE: 0.2708541683299493, Learning Rate: 0.094825\n",
      "Epoch: 1036, MSE: 0.27085201000236736, Learning Rate: 0.09482000000000002\n",
      "Epoch: 1037, MSE: 0.27084985162656633, Learning Rate: 0.09481500000000001\n",
      "Epoch: 1038, MSE: 0.27084769320254787, Learning Rate: 0.09481\n",
      "Epoch: 1039, MSE: 0.27084553473031237, Learning Rate: 0.094805\n",
      "Epoch: 1040, MSE: 0.27084337620986126, Learning Rate: 0.0948\n",
      "Epoch: 1041, MSE: 0.2708412176411934, Learning Rate: 0.094795\n",
      "Epoch: 1042, MSE: 0.27083905902430977, Learning Rate: 0.09479\n",
      "Epoch: 1043, MSE: 0.27083690035921276, Learning Rate: 0.09478500000000001\n",
      "Epoch: 1044, MSE: 0.27083474164590154, Learning Rate: 0.09478\n",
      "Epoch: 1045, MSE: 0.27083258288437706, Learning Rate: 0.094775\n",
      "Epoch: 1046, MSE: 0.2708304240746401, Learning Rate: 0.09477000000000001\n",
      "Epoch: 1047, MSE: 0.27082826521669107, Learning Rate: 0.094765\n",
      "Epoch: 1048, MSE: 0.27082610631053095, Learning Rate: 0.09476000000000001\n",
      "Epoch: 1049, MSE: 0.27082394735616083, Learning Rate: 0.094755\n",
      "Epoch: 1050, MSE: 0.2708217883535792, Learning Rate: 0.09475\n",
      "Epoch: 1051, MSE: 0.2708196293027892, Learning Rate: 0.09474500000000001\n",
      "Epoch: 1052, MSE: 0.27081747020378955, Learning Rate: 0.09474\n",
      "Epoch: 1053, MSE: 0.27081531105658224, Learning Rate: 0.09473500000000001\n",
      "Epoch: 1054, MSE: 0.270813151861167, Learning Rate: 0.09473000000000001\n",
      "Epoch: 1055, MSE: 0.27081099261754454, Learning Rate: 0.094725\n",
      "Epoch: 1056, MSE: 0.2708088333257154, Learning Rate: 0.09472000000000001\n",
      "Epoch: 1057, MSE: 0.27080667398568026, Learning Rate: 0.09471500000000001\n",
      "Epoch: 1058, MSE: 0.2708045145974397, Learning Rate: 0.09471000000000002\n",
      "Epoch: 1059, MSE: 0.2708023551609945, Learning Rate: 0.094705\n",
      "Epoch: 1060, MSE: 0.27080019567634417, Learning Rate: 0.0947\n",
      "Epoch: 1061, MSE: 0.2707980361434912, Learning Rate: 0.094695\n",
      "Epoch: 1062, MSE: 0.27079587656243387, Learning Rate: 0.09469\n",
      "Epoch: 1063, MSE: 0.27079371693317456, Learning Rate: 0.094685\n",
      "Epoch: 1064, MSE: 0.2707915572557125, Learning Rate: 0.09468\n",
      "Epoch: 1065, MSE: 0.2707893975300488, Learning Rate: 0.09467500000000001\n",
      "Epoch: 1066, MSE: 0.2707872377561833, Learning Rate: 0.09467\n",
      "Epoch: 1067, MSE: 0.2707850779341176, Learning Rate: 0.094665\n",
      "Epoch: 1068, MSE: 0.2707829180638521, Learning Rate: 0.09466000000000001\n",
      "Epoch: 1069, MSE: 0.27078075814538527, Learning Rate: 0.094655\n",
      "Epoch: 1070, MSE: 0.2707785981787209, Learning Rate: 0.09465000000000001\n",
      "Epoch: 1071, MSE: 0.27077643816385605, Learning Rate: 0.094645\n",
      "Epoch: 1072, MSE: 0.27077427810079363, Learning Rate: 0.09464\n",
      "Epoch: 1073, MSE: 0.27077211798953277, Learning Rate: 0.09463500000000001\n",
      "Epoch: 1074, MSE: 0.27076995783007546, Learning Rate: 0.09463\n",
      "Epoch: 1075, MSE: 0.27076779762242004, Learning Rate: 0.09462500000000001\n",
      "Epoch: 1076, MSE: 0.270765637366568, Learning Rate: 0.09462000000000001\n",
      "Epoch: 1077, MSE: 0.27076347706252074, Learning Rate: 0.094615\n",
      "Epoch: 1078, MSE: 0.2707613167102761, Learning Rate: 0.09461\n",
      "Epoch: 1079, MSE: 0.27075915630983755, Learning Rate: 0.09460500000000001\n",
      "Epoch: 1080, MSE: 0.27075699586120394, Learning Rate: 0.0946\n",
      "Epoch: 1081, MSE: 0.2707548353643754, Learning Rate: 0.094595\n",
      "Epoch: 1082, MSE: 0.2707526748193521, Learning Rate: 0.09459000000000001\n",
      "Epoch: 1083, MSE: 0.27075051422613594, Learning Rate: 0.094585\n",
      "Epoch: 1084, MSE: 0.2707483535847262, Learning Rate: 0.09458\n",
      "Epoch: 1085, MSE: 0.27074619289512397, Learning Rate: 0.094575\n",
      "Epoch: 1086, MSE: 0.2707440321573285, Learning Rate: 0.09457\n",
      "Epoch: 1087, MSE: 0.27074187137134154, Learning Rate: 0.09456500000000001\n",
      "Epoch: 1088, MSE: 0.2707397105371621, Learning Rate: 0.09456\n",
      "Epoch: 1089, MSE: 0.2707375496547921, Learning Rate: 0.094555\n",
      "Epoch: 1090, MSE: 0.2707353887242292, Learning Rate: 0.09455000000000001\n",
      "Epoch: 1091, MSE: 0.27073322774547715, Learning Rate: 0.094545\n",
      "Epoch: 1092, MSE: 0.2707310667185339, Learning Rate: 0.09454000000000001\n",
      "Epoch: 1093, MSE: 0.2707289056434008, Learning Rate: 0.09453500000000001\n",
      "Epoch: 1094, MSE: 0.2707267445200777, Learning Rate: 0.09453\n",
      "Epoch: 1095, MSE: 0.2707245833485655, Learning Rate: 0.09452500000000001\n",
      "Epoch: 1096, MSE: 0.2707224221288636, Learning Rate: 0.09452\n",
      "Epoch: 1097, MSE: 0.27072026086097384, Learning Rate: 0.09451500000000002\n",
      "Epoch: 1098, MSE: 0.2707180995448955, Learning Rate: 0.09451000000000001\n",
      "Epoch: 1099, MSE: 0.2707159381806282, Learning Rate: 0.094505\n",
      "Epoch: 1100, MSE: 0.2707137767681729, Learning Rate: 0.0945\n",
      "Epoch: 1101, MSE: 0.2707116153075313, Learning Rate: 0.094495\n",
      "Epoch: 1102, MSE: 0.270709453798701, Learning Rate: 0.09449\n",
      "Epoch: 1103, MSE: 0.27070729224168416, Learning Rate: 0.094485\n",
      "Epoch: 1104, MSE: 0.270705130636481, Learning Rate: 0.09448000000000001\n",
      "Epoch: 1105, MSE: 0.27070296898309054, Learning Rate: 0.094475\n",
      "Epoch: 1106, MSE: 0.27070080728151463, Learning Rate: 0.09447\n",
      "Epoch: 1107, MSE: 0.2706986455317526, Learning Rate: 0.09446500000000001\n",
      "Epoch: 1108, MSE: 0.2706964837338046, Learning Rate: 0.09446\n",
      "Epoch: 1109, MSE: 0.2706943218876714, Learning Rate: 0.09445500000000001\n",
      "Epoch: 1110, MSE: 0.270692159993353, Learning Rate: 0.09445\n",
      "Epoch: 1111, MSE: 0.2706899980508496, Learning Rate: 0.094445\n",
      "Epoch: 1112, MSE: 0.2706878360601611, Learning Rate: 0.09444000000000001\n",
      "Epoch: 1113, MSE: 0.27068567402128874, Learning Rate: 0.094435\n",
      "Epoch: 1114, MSE: 0.2706835119342315, Learning Rate: 0.09443000000000001\n",
      "Epoch: 1115, MSE: 0.2706813497989901, Learning Rate: 0.09442500000000001\n",
      "Epoch: 1116, MSE: 0.2706791876155656, Learning Rate: 0.09442\n",
      "Epoch: 1117, MSE: 0.2706770253839577, Learning Rate: 0.09441500000000001\n",
      "Epoch: 1118, MSE: 0.27067486310416566, Learning Rate: 0.09441000000000001\n",
      "Epoch: 1119, MSE: 0.27067270077619027, Learning Rate: 0.09440500000000002\n",
      "Epoch: 1120, MSE: 0.27067053840003213, Learning Rate: 0.0944\n",
      "Epoch: 1121, MSE: 0.2706683759756908, Learning Rate: 0.094395\n",
      "Epoch: 1122, MSE: 0.27066621350316766, Learning Rate: 0.09439\n",
      "Epoch: 1123, MSE: 0.27066405098246177, Learning Rate: 0.094385\n",
      "Epoch: 1124, MSE: 0.2706618884135723, Learning Rate: 0.09438\n",
      "Epoch: 1125, MSE: 0.27065972579650194, Learning Rate: 0.094375\n",
      "Epoch: 1126, MSE: 0.2706575631312494, Learning Rate: 0.09437000000000001\n",
      "Epoch: 1127, MSE: 0.27065540041781505, Learning Rate: 0.094365\n",
      "Epoch: 1128, MSE: 0.2706532376561992, Learning Rate: 0.09436\n",
      "Epoch: 1129, MSE: 0.27065107484640144, Learning Rate: 0.09435500000000001\n",
      "Epoch: 1130, MSE: 0.27064891198842267, Learning Rate: 0.09435\n",
      "Epoch: 1131, MSE: 0.27064674908226194, Learning Rate: 0.09434500000000001\n",
      "Epoch: 1132, MSE: 0.2706445861279216, Learning Rate: 0.09434000000000001\n",
      "Epoch: 1133, MSE: 0.2706424231253988, Learning Rate: 0.094335\n",
      "Epoch: 1134, MSE: 0.2706402600746957, Learning Rate: 0.09433000000000001\n",
      "Epoch: 1135, MSE: 0.27063809697581187, Learning Rate: 0.094325\n",
      "Epoch: 1136, MSE: 0.2706359338287471, Learning Rate: 0.09432000000000001\n",
      "Epoch: 1137, MSE: 0.2706337706335023, Learning Rate: 0.09431500000000001\n",
      "Epoch: 1138, MSE: 0.270631607390077, Learning Rate: 0.09431\n",
      "Epoch: 1139, MSE: 0.2706294440984714, Learning Rate: 0.094305\n",
      "Epoch: 1140, MSE: 0.2706272807586853, Learning Rate: 0.0943\n",
      "Epoch: 1141, MSE: 0.27062511737072015, Learning Rate: 0.094295\n",
      "Epoch: 1142, MSE: 0.2706229539345746, Learning Rate: 0.09429\n",
      "Epoch: 1143, MSE: 0.2706207904502481, Learning Rate: 0.09428500000000001\n",
      "Epoch: 1144, MSE: 0.2706186269177426, Learning Rate: 0.09428\n",
      "Epoch: 1145, MSE: 0.2706164633370576, Learning Rate: 0.094275\n",
      "Epoch: 1146, MSE: 0.270614299708192, Learning Rate: 0.09427\n",
      "Epoch: 1147, MSE: 0.2706121360311481, Learning Rate: 0.094265\n",
      "Epoch: 1148, MSE: 0.27060997230592354, Learning Rate: 0.09426000000000001\n",
      "Epoch: 1149, MSE: 0.2706078085325199, Learning Rate: 0.094255\n",
      "Epoch: 1150, MSE: 0.2706056447109365, Learning Rate: 0.09425\n",
      "Epoch: 1151, MSE: 0.2706034808411742, Learning Rate: 0.09424500000000001\n",
      "Epoch: 1152, MSE: 0.2706013169232325, Learning Rate: 0.09424\n",
      "Epoch: 1153, MSE: 0.2705991529571114, Learning Rate: 0.09423500000000001\n",
      "Epoch: 1154, MSE: 0.270596988942811, Learning Rate: 0.09423000000000001\n",
      "Epoch: 1155, MSE: 0.270594824880331, Learning Rate: 0.094225\n",
      "Epoch: 1156, MSE: 0.27059266076967253, Learning Rate: 0.09422000000000001\n",
      "Epoch: 1157, MSE: 0.27059049661083384, Learning Rate: 0.09421500000000001\n",
      "Epoch: 1158, MSE: 0.2705883324038167, Learning Rate: 0.09421000000000002\n",
      "Epoch: 1159, MSE: 0.2705861681486209, Learning Rate: 0.09420500000000001\n",
      "Epoch: 1160, MSE: 0.27058400384524545, Learning Rate: 0.0942\n",
      "Epoch: 1161, MSE: 0.27058183949369063, Learning Rate: 0.094195\n",
      "Epoch: 1162, MSE: 0.2705796750939568, Learning Rate: 0.09419\n",
      "Epoch: 1163, MSE: 0.27057751064604346, Learning Rate: 0.094185\n",
      "Epoch: 1164, MSE: 0.2705753461499518, Learning Rate: 0.09418\n",
      "Epoch: 1165, MSE: 0.27057318160568034, Learning Rate: 0.09417500000000001\n",
      "Epoch: 1166, MSE: 0.27057101701322966, Learning Rate: 0.09417\n",
      "Epoch: 1167, MSE: 0.2705688523726005, Learning Rate: 0.094165\n",
      "Epoch: 1168, MSE: 0.270566687683791, Learning Rate: 0.09416000000000001\n",
      "Epoch: 1169, MSE: 0.27056452294680333, Learning Rate: 0.094155\n",
      "Epoch: 1170, MSE: 0.27056235816163665, Learning Rate: 0.09415000000000001\n",
      "Epoch: 1171, MSE: 0.27056019332828996, Learning Rate: 0.094145\n",
      "Epoch: 1172, MSE: 0.27055802844676374, Learning Rate: 0.09414\n",
      "Epoch: 1173, MSE: 0.27055586351705807, Learning Rate: 0.09413500000000001\n",
      "Epoch: 1174, MSE: 0.27055369853917405, Learning Rate: 0.09413\n",
      "Epoch: 1175, MSE: 0.27055153351310995, Learning Rate: 0.09412500000000001\n",
      "Epoch: 1176, MSE: 0.27054936843886596, Learning Rate: 0.09412000000000001\n",
      "Epoch: 1177, MSE: 0.27054720331644283, Learning Rate: 0.094115\n",
      "Epoch: 1178, MSE: 0.27054503814583986, Learning Rate: 0.09411000000000001\n",
      "Epoch: 1179, MSE: 0.27054287292705725, Learning Rate: 0.094105\n",
      "Epoch: 1180, MSE: 0.27054070766009486, Learning Rate: 0.09410000000000002\n",
      "Epoch: 1181, MSE: 0.2705385423449521, Learning Rate: 0.094095\n",
      "Epoch: 1182, MSE: 0.27053637698163024, Learning Rate: 0.09409000000000001\n",
      "Epoch: 1183, MSE: 0.27053421157012875, Learning Rate: 0.094085\n",
      "Epoch: 1184, MSE: 0.2705320461104463, Learning Rate: 0.09408\n",
      "Epoch: 1185, MSE: 0.2705298806025837, Learning Rate: 0.094075\n",
      "Epoch: 1186, MSE: 0.2705277150465414, Learning Rate: 0.09407\n",
      "Epoch: 1187, MSE: 0.27052554944231844, Learning Rate: 0.09406500000000001\n",
      "Epoch: 1188, MSE: 0.27052338378991475, Learning Rate: 0.09406\n",
      "Epoch: 1189, MSE: 0.2705212180893312, Learning Rate: 0.094055\n",
      "Epoch: 1190, MSE: 0.2705190523405664, Learning Rate: 0.09405000000000001\n",
      "Epoch: 1191, MSE: 0.2705168865436208, Learning Rate: 0.094045\n",
      "Epoch: 1192, MSE: 0.27051472069849397, Learning Rate: 0.09404000000000001\n",
      "Epoch: 1193, MSE: 0.270512554805187, Learning Rate: 0.09403500000000001\n",
      "Epoch: 1194, MSE: 0.2705103888636983, Learning Rate: 0.09403\n",
      "Epoch: 1195, MSE: 0.270508222874029, Learning Rate: 0.09402500000000001\n",
      "Epoch: 1196, MSE: 0.270506056836178, Learning Rate: 0.09402\n",
      "Epoch: 1197, MSE: 0.2705038907501454, Learning Rate: 0.09401500000000002\n",
      "Epoch: 1198, MSE: 0.27050172461593097, Learning Rate: 0.09401000000000001\n",
      "Epoch: 1199, MSE: 0.2704995584335355, Learning Rate: 0.094005\n",
      "Epoch: 1200, MSE: 0.27049739220295743, Learning Rate: 0.094\n",
      "Epoch: 1201, MSE: 0.2704952259241971, Learning Rate: 0.093995\n",
      "Epoch: 1202, MSE: 0.2704930595972555, Learning Rate: 0.09399\n",
      "Epoch: 1203, MSE: 0.2704908932221306, Learning Rate: 0.093985\n",
      "Epoch: 1204, MSE: 0.2704887267988234, Learning Rate: 0.09398000000000001\n",
      "Epoch: 1205, MSE: 0.27048656032733354, Learning Rate: 0.093975\n",
      "Epoch: 1206, MSE: 0.2704843938076614, Learning Rate: 0.09397\n",
      "Epoch: 1207, MSE: 0.2704822272398056, Learning Rate: 0.093965\n",
      "Epoch: 1208, MSE: 0.27048006062376634, Learning Rate: 0.09396\n",
      "Epoch: 1209, MSE: 0.2704778939595444, Learning Rate: 0.09395500000000001\n",
      "Epoch: 1210, MSE: 0.2704757272471383, Learning Rate: 0.09395\n",
      "Epoch: 1211, MSE: 0.2704735604865497, Learning Rate: 0.093945\n",
      "Epoch: 1212, MSE: 0.27047139367777684, Learning Rate: 0.09394000000000001\n",
      "Epoch: 1213, MSE: 0.27046922682081925, Learning Rate: 0.093935\n",
      "Epoch: 1214, MSE: 0.2704670599156776, Learning Rate: 0.09393000000000001\n",
      "Epoch: 1215, MSE: 0.2704648929623507, Learning Rate: 0.09392500000000001\n",
      "Epoch: 1216, MSE: 0.270462725960841, Learning Rate: 0.09392\n",
      "Epoch: 1217, MSE: 0.27046055891114507, Learning Rate: 0.09391500000000001\n",
      "Epoch: 1218, MSE: 0.2704583918132644, Learning Rate: 0.09391000000000001\n",
      "Epoch: 1219, MSE: 0.2704562246671991, Learning Rate: 0.09390500000000002\n",
      "Epoch: 1220, MSE: 0.27045405747294765, Learning Rate: 0.09390000000000001\n",
      "Epoch: 1221, MSE: 0.2704518902305107, Learning Rate: 0.093895\n",
      "Epoch: 1222, MSE: 0.27044972293988734, Learning Rate: 0.09389\n",
      "Epoch: 1223, MSE: 0.270447555601078, Learning Rate: 0.093885\n",
      "Epoch: 1224, MSE: 0.27044538821408337, Learning Rate: 0.09388\n",
      "Epoch: 1225, MSE: 0.27044322077890115, Learning Rate: 0.093875\n",
      "Epoch: 1226, MSE: 0.27044105329553275, Learning Rate: 0.09387000000000001\n",
      "Epoch: 1227, MSE: 0.2704388857639766, Learning Rate: 0.093865\n",
      "Epoch: 1228, MSE: 0.27043671818423404, Learning Rate: 0.09386\n",
      "Epoch: 1229, MSE: 0.27043455055630394, Learning Rate: 0.09385500000000001\n",
      "Epoch: 1230, MSE: 0.27043238288018523, Learning Rate: 0.09385\n",
      "Epoch: 1231, MSE: 0.27043021515587956, Learning Rate: 0.09384500000000001\n",
      "Epoch: 1232, MSE: 0.2704280473833853, Learning Rate: 0.09384\n",
      "Epoch: 1233, MSE: 0.2704258795627022, Learning Rate: 0.093835\n",
      "Epoch: 1234, MSE: 0.270423711693831, Learning Rate: 0.09383000000000001\n",
      "Epoch: 1235, MSE: 0.27042154377677036, Learning Rate: 0.093825\n",
      "Epoch: 1236, MSE: 0.27041937581152065, Learning Rate: 0.09382000000000001\n",
      "Epoch: 1237, MSE: 0.27041720779808187, Learning Rate: 0.09381500000000001\n",
      "Epoch: 1238, MSE: 0.27041503973645353, Learning Rate: 0.09381\n",
      "Epoch: 1239, MSE: 0.2704128716266337, Learning Rate: 0.09380500000000001\n",
      "Epoch: 1240, MSE: 0.27041070346862434, Learning Rate: 0.0938\n",
      "Epoch: 1241, MSE: 0.27040853526242464, Learning Rate: 0.093795\n",
      "Epoch: 1242, MSE: 0.2704063670080348, Learning Rate: 0.09379\n",
      "Epoch: 1243, MSE: 0.270404198705453, Learning Rate: 0.09378500000000001\n",
      "Epoch: 1244, MSE: 0.2704020303546798, Learning Rate: 0.09378\n",
      "Epoch: 1245, MSE: 0.27039986195571497, Learning Rate: 0.093775\n",
      "Epoch: 1246, MSE: 0.2703976935085583, Learning Rate: 0.09377\n",
      "Epoch: 1247, MSE: 0.2703955250132091, Learning Rate: 0.093765\n",
      "Epoch: 1248, MSE: 0.27039335646966756, Learning Rate: 0.09376000000000001\n",
      "Epoch: 1249, MSE: 0.2703911878779337, Learning Rate: 0.093755\n",
      "Epoch: 1250, MSE: 0.2703890192380057, Learning Rate: 0.09375\n",
      "Epoch: 1251, MSE: 0.2703868505498853, Learning Rate: 0.09374500000000001\n",
      "Epoch: 1252, MSE: 0.27038468181357034, Learning Rate: 0.09374\n",
      "Epoch: 1253, MSE: 0.2703825130290616, Learning Rate: 0.09373500000000001\n",
      "Epoch: 1254, MSE: 0.2703803441963583, Learning Rate: 0.09373000000000001\n",
      "Epoch: 1255, MSE: 0.27037817531546093, Learning Rate: 0.093725\n",
      "Epoch: 1256, MSE: 0.2703760063863683, Learning Rate: 0.09372000000000001\n",
      "Epoch: 1257, MSE: 0.27037383740908055, Learning Rate: 0.093715\n",
      "Epoch: 1258, MSE: 0.2703716683835959, Learning Rate: 0.09371000000000002\n",
      "Epoch: 1259, MSE: 0.2703694993099166, Learning Rate: 0.093705\n",
      "Epoch: 1260, MSE: 0.27036733018804043, Learning Rate: 0.0937\n",
      "Epoch: 1261, MSE: 0.2703651610179684, Learning Rate: 0.093695\n",
      "Epoch: 1262, MSE: 0.2703629917996989, Learning Rate: 0.09369\n",
      "Epoch: 1263, MSE: 0.270360822533232, Learning Rate: 0.093685\n",
      "Epoch: 1264, MSE: 0.2703586532185672, Learning Rate: 0.09368\n",
      "Epoch: 1265, MSE: 0.2703564838557054, Learning Rate: 0.09367500000000001\n",
      "Epoch: 1266, MSE: 0.27035431444464453, Learning Rate: 0.09367\n",
      "Epoch: 1267, MSE: 0.27035214498538546, Learning Rate: 0.093665\n",
      "Epoch: 1268, MSE: 0.2703499754779271, Learning Rate: 0.09366000000000001\n",
      "Epoch: 1269, MSE: 0.2703478059222698, Learning Rate: 0.093655\n",
      "Epoch: 1270, MSE: 0.27034563631841313, Learning Rate: 0.09365000000000001\n",
      "Epoch: 1271, MSE: 0.2703434666663552, Learning Rate: 0.093645\n",
      "Epoch: 1272, MSE: 0.2703412969660977, Learning Rate: 0.09364\n",
      "Epoch: 1273, MSE: 0.27033912721763953, Learning Rate: 0.09363500000000001\n",
      "Epoch: 1274, MSE: 0.27033695742097974, Learning Rate: 0.09363\n",
      "Epoch: 1275, MSE: 0.27033478757611856, Learning Rate: 0.09362500000000001\n",
      "Epoch: 1276, MSE: 0.2703326176830556, Learning Rate: 0.09362000000000001\n",
      "Epoch: 1277, MSE: 0.27033044774179077, Learning Rate: 0.093615\n",
      "Epoch: 1278, MSE: 0.27032827775232343, Learning Rate: 0.09361000000000001\n",
      "Epoch: 1279, MSE: 0.2703261077146528, Learning Rate: 0.09360500000000001\n",
      "Epoch: 1280, MSE: 0.2703239376287785, Learning Rate: 0.0936\n",
      "Epoch: 1281, MSE: 0.2703217674947008, Learning Rate: 0.09359500000000001\n",
      "Epoch: 1282, MSE: 0.2703195973124189, Learning Rate: 0.09359\n",
      "Epoch: 1283, MSE: 0.2703174270819328, Learning Rate: 0.093585\n",
      "Epoch: 1284, MSE: 0.2703152568032419, Learning Rate: 0.09358\n",
      "Epoch: 1285, MSE: 0.2703130864763456, Learning Rate: 0.093575\n",
      "Epoch: 1286, MSE: 0.2703109161012433, Learning Rate: 0.09357\n",
      "Epoch: 1287, MSE: 0.27030874567793556, Learning Rate: 0.09356500000000001\n",
      "Epoch: 1288, MSE: 0.2703065752064208, Learning Rate: 0.09356\n",
      "Epoch: 1289, MSE: 0.2703044046866992, Learning Rate: 0.093555\n",
      "Epoch: 1290, MSE: 0.2703022341187706, Learning Rate: 0.09355000000000001\n",
      "Epoch: 1291, MSE: 0.2703000635026339, Learning Rate: 0.093545\n",
      "Epoch: 1292, MSE: 0.27029789283828926, Learning Rate: 0.09354000000000001\n",
      "Epoch: 1293, MSE: 0.2702957221257367, Learning Rate: 0.09353500000000001\n",
      "Epoch: 1294, MSE: 0.270293551364975, Learning Rate: 0.09353\n",
      "Epoch: 1295, MSE: 0.27029138055600416, Learning Rate: 0.09352500000000001\n",
      "Epoch: 1296, MSE: 0.27028920969882303, Learning Rate: 0.09352\n",
      "Epoch: 1297, MSE: 0.2702870387934322, Learning Rate: 0.09351500000000001\n",
      "Epoch: 1298, MSE: 0.27028486783983086, Learning Rate: 0.09351000000000001\n",
      "Epoch: 1299, MSE: 0.2702826968380184, Learning Rate: 0.093505\n",
      "Epoch: 1300, MSE: 0.2702805257879948, Learning Rate: 0.09350000000000001\n",
      "Epoch: 1301, MSE: 0.2702783546897592, Learning Rate: 0.093495\n",
      "Epoch: 1302, MSE: 0.2702761835433113, Learning Rate: 0.09349\n",
      "Epoch: 1303, MSE: 0.2702740123486507, Learning Rate: 0.093485\n",
      "Epoch: 1304, MSE: 0.2702718411057775, Learning Rate: 0.09348000000000001\n",
      "Epoch: 1305, MSE: 0.2702696698146895, Learning Rate: 0.093475\n",
      "Epoch: 1306, MSE: 0.2702674984753883, Learning Rate: 0.09347\n",
      "Epoch: 1307, MSE: 0.2702653270878728, Learning Rate: 0.093465\n",
      "Epoch: 1308, MSE: 0.2702631556521425, Learning Rate: 0.09346\n",
      "Epoch: 1309, MSE: 0.27026098416819605, Learning Rate: 0.09345500000000001\n",
      "Epoch: 1310, MSE: 0.2702588126360344, Learning Rate: 0.09345\n",
      "Epoch: 1311, MSE: 0.27025664105565705, Learning Rate: 0.093445\n",
      "Epoch: 1312, MSE: 0.2702544694270617, Learning Rate: 0.09344000000000001\n",
      "Epoch: 1313, MSE: 0.2702522977502507, Learning Rate: 0.093435\n",
      "Epoch: 1314, MSE: 0.2702501260252206, Learning Rate: 0.09343000000000001\n",
      "Epoch: 1315, MSE: 0.2702479542519734, Learning Rate: 0.09342500000000001\n",
      "Epoch: 1316, MSE: 0.27024578243050795, Learning Rate: 0.09342\n",
      "Epoch: 1317, MSE: 0.2702436105608236, Learning Rate: 0.09341500000000001\n",
      "Epoch: 1318, MSE: 0.2702414386429191, Learning Rate: 0.09341\n",
      "Epoch: 1319, MSE: 0.2702392666767946, Learning Rate: 0.09340500000000002\n",
      "Epoch: 1320, MSE: 0.27023709466245016, Learning Rate: 0.0934\n",
      "Epoch: 1321, MSE: 0.27023492259988463, Learning Rate: 0.093395\n",
      "Epoch: 1322, MSE: 0.27023275048909806, Learning Rate: 0.09339\n",
      "Epoch: 1323, MSE: 0.2702305783300902, Learning Rate: 0.093385\n",
      "Epoch: 1324, MSE: 0.2702284061228597, Learning Rate: 0.09338\n",
      "Epoch: 1325, MSE: 0.27022623386740574, Learning Rate: 0.093375\n",
      "Epoch: 1326, MSE: 0.2702240615637295, Learning Rate: 0.09337000000000001\n",
      "Epoch: 1327, MSE: 0.27022188921182944, Learning Rate: 0.093365\n",
      "Epoch: 1328, MSE: 0.27021971681170526, Learning Rate: 0.09336\n",
      "Epoch: 1329, MSE: 0.27021754436335566, Learning Rate: 0.09335500000000001\n",
      "Epoch: 1330, MSE: 0.2702153718667812, Learning Rate: 0.09335\n",
      "Epoch: 1331, MSE: 0.2702131993219818, Learning Rate: 0.09334500000000001\n",
      "Epoch: 1332, MSE: 0.2702110267289559, Learning Rate: 0.09334\n",
      "Epoch: 1333, MSE: 0.2702088540877034, Learning Rate: 0.093335\n",
      "Epoch: 1334, MSE: 0.2702066813982234, Learning Rate: 0.09333000000000001\n",
      "Epoch: 1335, MSE: 0.2702045086605151, Learning Rate: 0.093325\n",
      "Epoch: 1336, MSE: 0.27020233587457987, Learning Rate: 0.09332000000000001\n",
      "Epoch: 1337, MSE: 0.2702001630404157, Learning Rate: 0.09331500000000001\n",
      "Epoch: 1338, MSE: 0.27019799015802276, Learning Rate: 0.09331\n",
      "Epoch: 1339, MSE: 0.27019581722739894, Learning Rate: 0.09330500000000001\n",
      "Epoch: 1340, MSE: 0.2701936442485463, Learning Rate: 0.09330000000000001\n",
      "Epoch: 1341, MSE: 0.27019147122146214, Learning Rate: 0.093295\n",
      "Epoch: 1342, MSE: 0.2701892981461475, Learning Rate: 0.09329\n",
      "Epoch: 1343, MSE: 0.2701871250226006, Learning Rate: 0.093285\n",
      "Epoch: 1344, MSE: 0.27018495185082214, Learning Rate: 0.09328\n",
      "Epoch: 1345, MSE: 0.2701827786308102, Learning Rate: 0.093275\n",
      "Epoch: 1346, MSE: 0.270180605362565, Learning Rate: 0.09327\n",
      "Epoch: 1347, MSE: 0.27017843204608655, Learning Rate: 0.093265\n",
      "Epoch: 1348, MSE: 0.2701762586813733, Learning Rate: 0.09326000000000001\n",
      "Epoch: 1349, MSE: 0.27017408526842546, Learning Rate: 0.093255\n",
      "Epoch: 1350, MSE: 0.2701719118072422, Learning Rate: 0.09325\n",
      "Epoch: 1351, MSE: 0.27016973829782354, Learning Rate: 0.09324500000000001\n",
      "Epoch: 1352, MSE: 0.2701675647401676, Learning Rate: 0.09324\n",
      "Epoch: 1353, MSE: 0.2701653911342757, Learning Rate: 0.09323500000000001\n",
      "Epoch: 1354, MSE: 0.27016321748014577, Learning Rate: 0.09323000000000001\n",
      "Epoch: 1355, MSE: 0.2701610437777777, Learning Rate: 0.093225\n",
      "Epoch: 1356, MSE: 0.2701588700271718, Learning Rate: 0.09322000000000001\n",
      "Epoch: 1357, MSE: 0.27015669622832605, Learning Rate: 0.093215\n",
      "Epoch: 1358, MSE: 0.2701545223812405, Learning Rate: 0.09321000000000002\n",
      "Epoch: 1359, MSE: 0.27015234848591535, Learning Rate: 0.09320500000000001\n",
      "Epoch: 1360, MSE: 0.27015017454234896, Learning Rate: 0.0932\n",
      "Epoch: 1361, MSE: 0.2701480005505418, Learning Rate: 0.09319500000000001\n",
      "Epoch: 1362, MSE: 0.2701458265104924, Learning Rate: 0.09319\n",
      "Epoch: 1363, MSE: 0.27014365242220156, Learning Rate: 0.093185\n",
      "Epoch: 1364, MSE: 0.2701414782856668, Learning Rate: 0.09318\n",
      "Epoch: 1365, MSE: 0.2701393041008891, Learning Rate: 0.09317500000000001\n",
      "Epoch: 1366, MSE: 0.2701371298678671, Learning Rate: 0.09317\n",
      "Epoch: 1367, MSE: 0.27013495558660044, Learning Rate: 0.093165\n",
      "Epoch: 1368, MSE: 0.27013278125708906, Learning Rate: 0.09316\n",
      "Epoch: 1369, MSE: 0.27013060687933166, Learning Rate: 0.093155\n",
      "Epoch: 1370, MSE: 0.27012843245332796, Learning Rate: 0.09315000000000001\n",
      "Epoch: 1371, MSE: 0.27012625797907797, Learning Rate: 0.093145\n",
      "Epoch: 1372, MSE: 0.27012408345657923, Learning Rate: 0.09314\n",
      "Epoch: 1373, MSE: 0.2701219088858336, Learning Rate: 0.09313500000000001\n",
      "Epoch: 1374, MSE: 0.27011973426683916, Learning Rate: 0.09313\n",
      "Epoch: 1375, MSE: 0.270117559599596, Learning Rate: 0.09312500000000001\n",
      "Epoch: 1376, MSE: 0.2701153848841033, Learning Rate: 0.09312000000000001\n",
      "Epoch: 1377, MSE: 0.27011321012035966, Learning Rate: 0.093115\n",
      "Epoch: 1378, MSE: 0.2701110353083649, Learning Rate: 0.09311000000000001\n",
      "Epoch: 1379, MSE: 0.2701088604481193, Learning Rate: 0.09310500000000001\n",
      "Epoch: 1380, MSE: 0.27010668553962164, Learning Rate: 0.09310000000000002\n",
      "Epoch: 1381, MSE: 0.2701045105828712, Learning Rate: 0.093095\n",
      "Epoch: 1382, MSE: 0.27010233557786767, Learning Rate: 0.09309\n",
      "Epoch: 1383, MSE: 0.27010016052461067, Learning Rate: 0.093085\n",
      "Epoch: 1384, MSE: 0.2700979854230991, Learning Rate: 0.09308\n",
      "Epoch: 1385, MSE: 0.27009581027333246, Learning Rate: 0.093075\n",
      "Epoch: 1386, MSE: 0.2700936350753106, Learning Rate: 0.09307\n",
      "Epoch: 1387, MSE: 0.2700914598290328, Learning Rate: 0.09306500000000001\n",
      "Epoch: 1388, MSE: 0.270089284534498, Learning Rate: 0.09306\n",
      "Epoch: 1389, MSE: 0.2700871091917058, Learning Rate: 0.093055\n",
      "Epoch: 1390, MSE: 0.2700849338006565, Learning Rate: 0.09305000000000001\n",
      "Epoch: 1391, MSE: 0.2700827583613479, Learning Rate: 0.093045\n",
      "Epoch: 1392, MSE: 0.2700805828737808, Learning Rate: 0.09304000000000001\n",
      "Epoch: 1393, MSE: 0.2700784073379536, Learning Rate: 0.093035\n",
      "Epoch: 1394, MSE: 0.2700762317538662, Learning Rate: 0.09303\n",
      "Epoch: 1395, MSE: 0.27007405612151786, Learning Rate: 0.09302500000000001\n",
      "Epoch: 1396, MSE: 0.2700718804409087, Learning Rate: 0.09302\n",
      "Epoch: 1397, MSE: 0.27006970471203573, Learning Rate: 0.09301500000000001\n",
      "Epoch: 1398, MSE: 0.2700675289349015, Learning Rate: 0.09301000000000001\n",
      "Epoch: 1399, MSE: 0.27006535310950386, Learning Rate: 0.093005\n",
      "Epoch: 1400, MSE: 0.27006317723584256, Learning Rate: 0.093\n",
      "Epoch: 1401, MSE: 0.2700610013139163, Learning Rate: 0.09299500000000001\n",
      "Epoch: 1402, MSE: 0.2700588253437247, Learning Rate: 0.09299\n",
      "Epoch: 1403, MSE: 0.2700566493252677, Learning Rate: 0.092985\n",
      "Epoch: 1404, MSE: 0.27005447325854437, Learning Rate: 0.09298000000000001\n",
      "Epoch: 1405, MSE: 0.27005229714355417, Learning Rate: 0.092975\n",
      "Epoch: 1406, MSE: 0.27005012098029557, Learning Rate: 0.09297\n",
      "Epoch: 1407, MSE: 0.2700479447687692, Learning Rate: 0.092965\n",
      "Epoch: 1408, MSE: 0.2700457685089744, Learning Rate: 0.09296\n",
      "Epoch: 1409, MSE: 0.27004359220090923, Learning Rate: 0.09295500000000001\n",
      "Epoch: 1410, MSE: 0.2700414158445746, Learning Rate: 0.09295\n",
      "Epoch: 1411, MSE: 0.2700392394399693, Learning Rate: 0.092945\n",
      "Epoch: 1412, MSE: 0.270037062987092, Learning Rate: 0.09294000000000001\n",
      "Epoch: 1413, MSE: 0.2700348864859441, Learning Rate: 0.092935\n",
      "Epoch: 1414, MSE: 0.27003270993652223, Learning Rate: 0.09293000000000001\n",
      "Epoch: 1415, MSE: 0.27003053333882715, Learning Rate: 0.09292500000000001\n",
      "Epoch: 1416, MSE: 0.27002835669285885, Learning Rate: 0.09292\n",
      "Epoch: 1417, MSE: 0.27002617999861506, Learning Rate: 0.09291500000000001\n",
      "Epoch: 1418, MSE: 0.2700240032560974, Learning Rate: 0.09291\n",
      "Epoch: 1419, MSE: 0.27002182646530326, Learning Rate: 0.09290500000000002\n",
      "Epoch: 1420, MSE: 0.27001964962623215, Learning Rate: 0.09290000000000001\n",
      "Epoch: 1421, MSE: 0.2700174727388852, Learning Rate: 0.092895\n",
      "Epoch: 1422, MSE: 0.27001529580325934, Learning Rate: 0.09289000000000001\n",
      "Epoch: 1423, MSE: 0.2700131188193559, Learning Rate: 0.092885\n",
      "Epoch: 1424, MSE: 0.27001094178717344, Learning Rate: 0.09288\n",
      "Epoch: 1425, MSE: 0.27000876470671065, Learning Rate: 0.092875\n",
      "Epoch: 1426, MSE: 0.27000658757796797, Learning Rate: 0.09287000000000001\n",
      "Epoch: 1427, MSE: 0.27000441040094475, Learning Rate: 0.092865\n",
      "Epoch: 1428, MSE: 0.27000223317563965, Learning Rate: 0.09286\n",
      "Epoch: 1429, MSE: 0.270000055902052, Learning Rate: 0.09285500000000001\n",
      "Epoch: 1430, MSE: 0.2699978785801812, Learning Rate: 0.09285\n",
      "Epoch: 1431, MSE: 0.26999570121002775, Learning Rate: 0.09284500000000001\n",
      "Epoch: 1432, MSE: 0.2699935237915895, Learning Rate: 0.09284\n",
      "Epoch: 1433, MSE: 0.26999134632486643, Learning Rate: 0.092835\n",
      "Epoch: 1434, MSE: 0.2699891688098583, Learning Rate: 0.09283000000000001\n",
      "Epoch: 1435, MSE: 0.2699869912465627, Learning Rate: 0.092825\n",
      "Epoch: 1436, MSE: 0.26998481363498134, Learning Rate: 0.09282000000000001\n",
      "Epoch: 1437, MSE: 0.2699826359751127, Learning Rate: 0.09281500000000001\n",
      "Epoch: 1438, MSE: 0.26998045826695505, Learning Rate: 0.09281\n",
      "Epoch: 1439, MSE: 0.2699782805105096, Learning Rate: 0.09280500000000001\n",
      "Epoch: 1440, MSE: 0.2699761027057735, Learning Rate: 0.09280000000000001\n",
      "Epoch: 1441, MSE: 0.26997392485274735, Learning Rate: 0.09279500000000002\n",
      "Epoch: 1442, MSE: 0.26997174695143006, Learning Rate: 0.09279\n",
      "Epoch: 1443, MSE: 0.2699695690018229, Learning Rate: 0.092785\n",
      "Epoch: 1444, MSE: 0.2699673910039216, Learning Rate: 0.09278\n",
      "Epoch: 1445, MSE: 0.26996521295772885, Learning Rate: 0.092775\n",
      "Epoch: 1446, MSE: 0.2699630348632419, Learning Rate: 0.09277\n",
      "Epoch: 1447, MSE: 0.2699608567204605, Learning Rate: 0.092765\n",
      "Epoch: 1448, MSE: 0.2699586785293853, Learning Rate: 0.09276000000000001\n",
      "Epoch: 1449, MSE: 0.2699565002900142, Learning Rate: 0.092755\n",
      "Epoch: 1450, MSE: 0.26995432200234626, Learning Rate: 0.09275\n",
      "Epoch: 1451, MSE: 0.2699521436663819, Learning Rate: 0.09274500000000001\n",
      "Epoch: 1452, MSE: 0.2699499652821191, Learning Rate: 0.09274\n",
      "Epoch: 1453, MSE: 0.2699477868495582, Learning Rate: 0.09273500000000001\n",
      "Epoch: 1454, MSE: 0.2699456083686996, Learning Rate: 0.09273\n",
      "Epoch: 1455, MSE: 0.26994342983954017, Learning Rate: 0.092725\n",
      "Epoch: 1456, MSE: 0.2699412512620812, Learning Rate: 0.09272000000000001\n",
      "Epoch: 1457, MSE: 0.26993907263632083, Learning Rate: 0.092715\n",
      "Epoch: 1458, MSE: 0.26993689396225884, Learning Rate: 0.09271000000000001\n",
      "Epoch: 1459, MSE: 0.26993471523989443, Learning Rate: 0.09270500000000001\n",
      "Epoch: 1460, MSE: 0.269932536469226, Learning Rate: 0.0927\n",
      "Epoch: 1461, MSE: 0.26993035765025436, Learning Rate: 0.092695\n",
      "Epoch: 1462, MSE: 0.26992817878297864, Learning Rate: 0.09269000000000001\n",
      "Epoch: 1463, MSE: 0.2699259998673978, Learning Rate: 0.092685\n",
      "Epoch: 1464, MSE: 0.269923820903511, Learning Rate: 0.09268\n",
      "Epoch: 1465, MSE: 0.269921641891317, Learning Rate: 0.09267500000000001\n",
      "Epoch: 1466, MSE: 0.2699194628308164, Learning Rate: 0.09267\n",
      "Epoch: 1467, MSE: 0.2699172837220076, Learning Rate: 0.092665\n",
      "Epoch: 1468, MSE: 0.26991510456488993, Learning Rate: 0.09266\n",
      "Epoch: 1469, MSE: 0.26991292535946315, Learning Rate: 0.092655\n",
      "Epoch: 1470, MSE: 0.26991074610572674, Learning Rate: 0.09265000000000001\n",
      "Epoch: 1471, MSE: 0.2699085668036794, Learning Rate: 0.092645\n",
      "Epoch: 1472, MSE: 0.2699063874533195, Learning Rate: 0.09264\n",
      "Epoch: 1473, MSE: 0.2699042080546492, Learning Rate: 0.09263500000000001\n",
      "Epoch: 1474, MSE: 0.26990202860766455, Learning Rate: 0.09263\n",
      "Epoch: 1475, MSE: 0.26989984911236686, Learning Rate: 0.09262500000000001\n",
      "Epoch: 1476, MSE: 0.26989766956875527, Learning Rate: 0.09262000000000001\n",
      "Epoch: 1477, MSE: 0.2698954899768284, Learning Rate: 0.092615\n",
      "Epoch: 1478, MSE: 0.2698933103365851, Learning Rate: 0.09261000000000001\n",
      "Epoch: 1479, MSE: 0.2698911306480256, Learning Rate: 0.092605\n",
      "Epoch: 1480, MSE: 0.26988895091114995, Learning Rate: 0.09260000000000002\n",
      "Epoch: 1481, MSE: 0.26988677112595544, Learning Rate: 0.09259500000000001\n",
      "Epoch: 1482, MSE: 0.26988459129244247, Learning Rate: 0.09259\n",
      "Epoch: 1483, MSE: 0.269882411410611, Learning Rate: 0.09258500000000001\n",
      "Epoch: 1484, MSE: 0.26988023148045914, Learning Rate: 0.09258\n",
      "Epoch: 1485, MSE: 0.26987805150198557, Learning Rate: 0.092575\n",
      "Epoch: 1486, MSE: 0.26987587147519165, Learning Rate: 0.09257\n",
      "Epoch: 1487, MSE: 0.26987369140007567, Learning Rate: 0.09256500000000001\n",
      "Epoch: 1488, MSE: 0.26987151127663633, Learning Rate: 0.09256\n",
      "Epoch: 1489, MSE: 0.2698693311048736, Learning Rate: 0.092555\n",
      "Epoch: 1490, MSE: 0.2698671508847857, Learning Rate: 0.09255000000000001\n",
      "Epoch: 1491, MSE: 0.2698649706163742, Learning Rate: 0.092545\n",
      "Epoch: 1492, MSE: 0.2698627902996358, Learning Rate: 0.09254000000000001\n",
      "Epoch: 1493, MSE: 0.2698606099345718, Learning Rate: 0.092535\n",
      "Epoch: 1494, MSE: 0.26985842952118, Learning Rate: 0.09253\n",
      "Epoch: 1495, MSE: 0.26985624905945976, Learning Rate: 0.09252500000000001\n",
      "Epoch: 1496, MSE: 0.2698540685494113, Learning Rate: 0.09252\n",
      "Epoch: 1497, MSE: 0.26985188799103366, Learning Rate: 0.09251500000000001\n",
      "Epoch: 1498, MSE: 0.2698497073843254, Learning Rate: 0.09251000000000001\n",
      "Epoch: 1499, MSE: 0.2698475267292865, Learning Rate: 0.092505\n",
      "Epoch: 1500, MSE: 0.26984534602591603, Learning Rate: 0.09250000000000001\n",
      "Epoch: 1501, MSE: 0.26984316527421354, Learning Rate: 0.092495\n",
      "Epoch: 1502, MSE: 0.26984098447417765, Learning Rate: 0.09249000000000002\n",
      "Epoch: 1503, MSE: 0.2698388036258072, Learning Rate: 0.092485\n",
      "Epoch: 1504, MSE: 0.26983662272910314, Learning Rate: 0.09248\n",
      "Epoch: 1505, MSE: 0.2698344417840638, Learning Rate: 0.092475\n",
      "Epoch: 1506, MSE: 0.26983226079068745, Learning Rate: 0.09247\n",
      "Epoch: 1507, MSE: 0.2698300797489752, Learning Rate: 0.092465\n",
      "Epoch: 1508, MSE: 0.26982789865892515, Learning Rate: 0.09246\n",
      "Epoch: 1509, MSE: 0.26982571752053675, Learning Rate: 0.09245500000000001\n",
      "Epoch: 1510, MSE: 0.2698235363338096, Learning Rate: 0.09245\n",
      "Epoch: 1511, MSE: 0.2698213550987423, Learning Rate: 0.092445\n",
      "Epoch: 1512, MSE: 0.26981917381533493, Learning Rate: 0.09244000000000001\n",
      "Epoch: 1513, MSE: 0.26981699248358615, Learning Rate: 0.092435\n",
      "Epoch: 1514, MSE: 0.2698148111034947, Learning Rate: 0.09243000000000001\n",
      "Epoch: 1515, MSE: 0.2698126296750613, Learning Rate: 0.09242500000000001\n",
      "Epoch: 1516, MSE: 0.2698104481982845, Learning Rate: 0.09242\n",
      "Epoch: 1517, MSE: 0.2698082666731628, Learning Rate: 0.09241500000000001\n",
      "Epoch: 1518, MSE: 0.26980608509969667, Learning Rate: 0.09241\n",
      "Epoch: 1519, MSE: 0.2698039034778841, Learning Rate: 0.09240500000000001\n",
      "Epoch: 1520, MSE: 0.26980172180772644, Learning Rate: 0.09240000000000001\n",
      "Epoch: 1521, MSE: 0.2697995400892201, Learning Rate: 0.092395\n",
      "Epoch: 1522, MSE: 0.26979735832236695, Learning Rate: 0.09239\n",
      "Epoch: 1523, MSE: 0.2697951765071634, Learning Rate: 0.09238500000000001\n",
      "Epoch: 1524, MSE: 0.2697929946436114, Learning Rate: 0.09238\n",
      "Epoch: 1525, MSE: 0.26979081273170885, Learning Rate: 0.092375\n",
      "Epoch: 1526, MSE: 0.2697886307714551, Learning Rate: 0.09237000000000001\n",
      "Epoch: 1527, MSE: 0.26978644876284985, Learning Rate: 0.092365\n",
      "Epoch: 1528, MSE: 0.26978426670589184, Learning Rate: 0.09236\n",
      "Epoch: 1529, MSE: 0.2697820846005815, Learning Rate: 0.092355\n",
      "Epoch: 1530, MSE: 0.26977990244691546, Learning Rate: 0.09235\n",
      "Epoch: 1531, MSE: 0.2697777202448951, Learning Rate: 0.09234500000000001\n",
      "Epoch: 1532, MSE: 0.26977553799451914, Learning Rate: 0.09234\n",
      "Epoch: 1533, MSE: 0.2697733556957874, Learning Rate: 0.092335\n",
      "Epoch: 1534, MSE: 0.2697711733486986, Learning Rate: 0.09233000000000001\n",
      "Epoch: 1535, MSE: 0.2697689909532511, Learning Rate: 0.092325\n",
      "Epoch: 1536, MSE: 0.269766808509445, Learning Rate: 0.09232000000000001\n",
      "Epoch: 1537, MSE: 0.26976462601728, Learning Rate: 0.09231500000000001\n",
      "Epoch: 1538, MSE: 0.2697624434767543, Learning Rate: 0.09231\n",
      "Epoch: 1539, MSE: 0.2697602608878687, Learning Rate: 0.09230500000000001\n",
      "Epoch: 1540, MSE: 0.26975807825062, Learning Rate: 0.09230000000000001\n",
      "Epoch: 1541, MSE: 0.2697558955650086, Learning Rate: 0.09229500000000002\n",
      "Epoch: 1542, MSE: 0.26975371283103533, Learning Rate: 0.09229000000000001\n",
      "Epoch: 1543, MSE: 0.26975153004869684, Learning Rate: 0.092285\n",
      "Epoch: 1544, MSE: 0.2697493472179942, Learning Rate: 0.09228\n",
      "Epoch: 1545, MSE: 0.269747164338926, Learning Rate: 0.092275\n",
      "Epoch: 1546, MSE: 0.26974498141149084, Learning Rate: 0.09227\n",
      "Epoch: 1547, MSE: 0.2697427984356879, Learning Rate: 0.092265\n",
      "Epoch: 1548, MSE: 0.26974061541151817, Learning Rate: 0.09226000000000001\n",
      "Epoch: 1549, MSE: 0.26973843233897915, Learning Rate: 0.092255\n",
      "Epoch: 1550, MSE: 0.26973624921807143, Learning Rate: 0.09225\n",
      "Epoch: 1551, MSE: 0.2697340660487928, Learning Rate: 0.09224500000000001\n",
      "Epoch: 1552, MSE: 0.2697318828311431, Learning Rate: 0.09224\n",
      "Epoch: 1553, MSE: 0.2697296995651224, Learning Rate: 0.09223500000000001\n",
      "Epoch: 1554, MSE: 0.2697275162507279, Learning Rate: 0.09223\n",
      "Epoch: 1555, MSE: 0.26972533288796, Learning Rate: 0.092225\n",
      "Epoch: 1556, MSE: 0.2697231494768186, Learning Rate: 0.09222000000000001\n",
      "Epoch: 1557, MSE: 0.2697209660173021, Learning Rate: 0.092215\n",
      "Epoch: 1558, MSE: 0.26971878250940917, Learning Rate: 0.09221000000000001\n",
      "Epoch: 1559, MSE: 0.2697165989531407, Learning Rate: 0.09220500000000001\n",
      "Epoch: 1560, MSE: 0.26971441534849466, Learning Rate: 0.0922\n",
      "Epoch: 1561, MSE: 0.26971223169546993, Learning Rate: 0.09219500000000001\n",
      "Epoch: 1562, MSE: 0.2697100479940665, Learning Rate: 0.09219\n",
      "Epoch: 1563, MSE: 0.26970786424428345, Learning Rate: 0.09218500000000002\n",
      "Epoch: 1564, MSE: 0.2697056804461198, Learning Rate: 0.09218\n",
      "Epoch: 1565, MSE: 0.26970349659957543, Learning Rate: 0.092175\n",
      "Epoch: 1566, MSE: 0.2697013127046483, Learning Rate: 0.09217\n",
      "Epoch: 1567, MSE: 0.2696991287613385, Learning Rate: 0.092165\n",
      "Epoch: 1568, MSE: 0.26969694476964584, Learning Rate: 0.09216\n",
      "Epoch: 1569, MSE: 0.2696947607295678, Learning Rate: 0.092155\n",
      "Epoch: 1570, MSE: 0.2696925766411048, Learning Rate: 0.09215000000000001\n",
      "Epoch: 1571, MSE: 0.2696903925042557, Learning Rate: 0.092145\n",
      "Epoch: 1572, MSE: 0.26968820831901935, Learning Rate: 0.09214\n",
      "Epoch: 1573, MSE: 0.26968602408539594, Learning Rate: 0.09213500000000001\n",
      "Epoch: 1574, MSE: 0.2696838398033839, Learning Rate: 0.09213\n",
      "Epoch: 1575, MSE: 0.2696816554729828, Learning Rate: 0.09212500000000001\n",
      "Epoch: 1576, MSE: 0.26967947109419116, Learning Rate: 0.09212000000000001\n",
      "Epoch: 1577, MSE: 0.2696772866670093, Learning Rate: 0.092115\n",
      "Epoch: 1578, MSE: 0.26967510219143537, Learning Rate: 0.09211000000000001\n",
      "Epoch: 1579, MSE: 0.26967291766746954, Learning Rate: 0.092105\n",
      "Epoch: 1580, MSE: 0.2696707330951109, Learning Rate: 0.09210000000000002\n",
      "Epoch: 1581, MSE: 0.26966854847435745, Learning Rate: 0.09209500000000001\n",
      "Epoch: 1582, MSE: 0.26966636380520853, Learning Rate: 0.09209\n",
      "Epoch: 1583, MSE: 0.2696641790876653, Learning Rate: 0.092085\n",
      "Epoch: 1584, MSE: 0.269661994321725, Learning Rate: 0.09208\n",
      "Epoch: 1585, MSE: 0.2696598095073877, Learning Rate: 0.092075\n",
      "Epoch: 1586, MSE: 0.2696576246446516, Learning Rate: 0.09207\n",
      "Epoch: 1587, MSE: 0.2696554397335179, Learning Rate: 0.09206500000000001\n",
      "Epoch: 1588, MSE: 0.2696532547739834, Learning Rate: 0.09206\n",
      "Epoch: 1589, MSE: 0.2696510697660489, Learning Rate: 0.092055\n",
      "Epoch: 1590, MSE: 0.26964888470971277, Learning Rate: 0.09205\n",
      "Epoch: 1591, MSE: 0.26964669960497484, Learning Rate: 0.092045\n",
      "Epoch: 1592, MSE: 0.26964451445183407, Learning Rate: 0.09204000000000001\n",
      "Epoch: 1593, MSE: 0.26964232925029, Learning Rate: 0.092035\n",
      "Epoch: 1594, MSE: 0.26964014400034125, Learning Rate: 0.09203\n",
      "Epoch: 1595, MSE: 0.26963795870198665, Learning Rate: 0.09202500000000001\n",
      "Epoch: 1596, MSE: 0.26963577335522626, Learning Rate: 0.09202\n",
      "Epoch: 1597, MSE: 0.269633587960059, Learning Rate: 0.09201500000000001\n",
      "Epoch: 1598, MSE: 0.26963140251648343, Learning Rate: 0.09201000000000001\n",
      "Epoch: 1599, MSE: 0.2696292170244999, Learning Rate: 0.092005\n",
      "Epoch: 1600, MSE: 0.2696270314841066, Learning Rate: 0.09200000000000001\n",
      "Epoch: 1601, MSE: 0.26962484589530356, Learning Rate: 0.09199500000000001\n",
      "Epoch: 1602, MSE: 0.2696226602580886, Learning Rate: 0.09199\n",
      "Epoch: 1603, MSE: 0.2696204745724627, Learning Rate: 0.09198500000000001\n",
      "Epoch: 1604, MSE: 0.2696182888384235, Learning Rate: 0.09198\n",
      "Epoch: 1605, MSE: 0.2696161030559707, Learning Rate: 0.091975\n",
      "Epoch: 1606, MSE: 0.26961391722510447, Learning Rate: 0.09197\n",
      "Epoch: 1607, MSE: 0.26961173134582217, Learning Rate: 0.091965\n",
      "Epoch: 1608, MSE: 0.26960954541812465, Learning Rate: 0.09196\n",
      "Epoch: 1609, MSE: 0.2696073594420104, Learning Rate: 0.09195500000000001\n",
      "Epoch: 1610, MSE: 0.2696051734174781, Learning Rate: 0.09195\n",
      "Epoch: 1611, MSE: 0.26960298734452715, Learning Rate: 0.091945\n",
      "Epoch: 1612, MSE: 0.269600801223157, Learning Rate: 0.09194000000000001\n",
      "Epoch: 1613, MSE: 0.2695986150533673, Learning Rate: 0.091935\n",
      "Epoch: 1614, MSE: 0.2695964288351568, Learning Rate: 0.09193000000000001\n",
      "Epoch: 1615, MSE: 0.2695942425685246, Learning Rate: 0.091925\n",
      "Epoch: 1616, MSE: 0.2695920562534691, Learning Rate: 0.09192\n",
      "Epoch: 1617, MSE: 0.2695898698899907, Learning Rate: 0.09191500000000001\n",
      "Epoch: 1618, MSE: 0.2695876834780884, Learning Rate: 0.09191\n",
      "Epoch: 1619, MSE: 0.2695854970177611, Learning Rate: 0.09190500000000001\n",
      "Epoch: 1620, MSE: 0.26958331050900747, Learning Rate: 0.09190000000000001\n",
      "Epoch: 1621, MSE: 0.26958112395182743, Learning Rate: 0.091895\n",
      "Epoch: 1622, MSE: 0.2695789373462199, Learning Rate: 0.09189000000000001\n",
      "Epoch: 1623, MSE: 0.2695767506921838, Learning Rate: 0.091885\n",
      "Epoch: 1624, MSE: 0.2695745639897185, Learning Rate: 0.09188000000000002\n",
      "Epoch: 1625, MSE: 0.26957237723882344, Learning Rate: 0.091875\n",
      "Epoch: 1626, MSE: 0.2695701904394983, Learning Rate: 0.09187000000000001\n",
      "Epoch: 1627, MSE: 0.2695680035917405, Learning Rate: 0.091865\n",
      "Epoch: 1628, MSE: 0.2695658166955501, Learning Rate: 0.09186\n",
      "Epoch: 1629, MSE: 0.2695636297509266, Learning Rate: 0.091855\n",
      "Epoch: 1630, MSE: 0.26956144275786886, Learning Rate: 0.09185\n",
      "Epoch: 1631, MSE: 0.269559255716377, Learning Rate: 0.09184500000000001\n",
      "Epoch: 1632, MSE: 0.2695570686264487, Learning Rate: 0.09184\n",
      "Epoch: 1633, MSE: 0.2695548814880833, Learning Rate: 0.091835\n",
      "Epoch: 1634, MSE: 0.2695526943012816, Learning Rate: 0.09183000000000001\n",
      "Epoch: 1635, MSE: 0.2695505070660408, Learning Rate: 0.091825\n",
      "Epoch: 1636, MSE: 0.26954831978236066, Learning Rate: 0.09182000000000001\n",
      "Epoch: 1637, MSE: 0.26954613245024034, Learning Rate: 0.09181500000000001\n",
      "Epoch: 1638, MSE: 0.2695439450696796, Learning Rate: 0.09181\n",
      "Epoch: 1639, MSE: 0.26954175764067745, Learning Rate: 0.09180500000000001\n",
      "Epoch: 1640, MSE: 0.2695395701632328, Learning Rate: 0.0918\n",
      "Epoch: 1641, MSE: 0.2695373826373443, Learning Rate: 0.09179500000000002\n",
      "Epoch: 1642, MSE: 0.269535195063012, Learning Rate: 0.09179\n",
      "Epoch: 1643, MSE: 0.26953300744023445, Learning Rate: 0.091785\n",
      "Epoch: 1644, MSE: 0.2695308197690109, Learning Rate: 0.09178\n",
      "Epoch: 1645, MSE: 0.2695286320493407, Learning Rate: 0.091775\n",
      "Epoch: 1646, MSE: 0.26952644428122247, Learning Rate: 0.09177\n",
      "Epoch: 1647, MSE: 0.26952425646465694, Learning Rate: 0.091765\n",
      "Epoch: 1648, MSE: 0.2695220685996417, Learning Rate: 0.09176000000000001\n",
      "Epoch: 1649, MSE: 0.26951988068617533, Learning Rate: 0.091755\n",
      "Epoch: 1650, MSE: 0.2695176927242595, Learning Rate: 0.09175\n",
      "Epoch: 1651, MSE: 0.2695155047138913, Learning Rate: 0.09174500000000001\n",
      "Epoch: 1652, MSE: 0.2695133166550704, Learning Rate: 0.09174\n",
      "Epoch: 1653, MSE: 0.26951112854779646, Learning Rate: 0.09173500000000001\n",
      "Epoch: 1654, MSE: 0.26950894039206785, Learning Rate: 0.09173\n",
      "Epoch: 1655, MSE: 0.269506752187884, Learning Rate: 0.091725\n",
      "Epoch: 1656, MSE: 0.2695045639352438, Learning Rate: 0.09172000000000001\n",
      "Epoch: 1657, MSE: 0.26950237563414753, Learning Rate: 0.091715\n",
      "Epoch: 1658, MSE: 0.26950018728459296, Learning Rate: 0.09171000000000001\n",
      "Epoch: 1659, MSE: 0.26949799888658005, Learning Rate: 0.09170500000000001\n",
      "Epoch: 1660, MSE: 0.2694958104401074, Learning Rate: 0.0917\n",
      "Epoch: 1661, MSE: 0.26949362194517446, Learning Rate: 0.09169500000000001\n",
      "Epoch: 1662, MSE: 0.2694914334017814, Learning Rate: 0.09169000000000001\n",
      "Epoch: 1663, MSE: 0.2694892448099252, Learning Rate: 0.091685\n",
      "Epoch: 1664, MSE: 0.26948705616960594, Learning Rate: 0.09168000000000001\n",
      "Epoch: 1665, MSE: 0.2694848674808247, Learning Rate: 0.091675\n",
      "Epoch: 1666, MSE: 0.2694826787435775, Learning Rate: 0.09167\n",
      "Epoch: 1667, MSE: 0.26948048995786567, Learning Rate: 0.091665\n",
      "Epoch: 1668, MSE: 0.26947830112368765, Learning Rate: 0.09166\n",
      "Epoch: 1669, MSE: 0.26947611224104073, Learning Rate: 0.091655\n",
      "Epoch: 1670, MSE: 0.26947392330992853, Learning Rate: 0.09165000000000001\n",
      "Epoch: 1671, MSE: 0.2694717343303456, Learning Rate: 0.091645\n",
      "Epoch: 1672, MSE: 0.2694695453022939, Learning Rate: 0.09164\n",
      "Epoch: 1673, MSE: 0.2694673562257713, Learning Rate: 0.09163500000000001\n",
      "Epoch: 1674, MSE: 0.26946516710077745, Learning Rate: 0.09163\n",
      "Epoch: 1675, MSE: 0.26946297792731144, Learning Rate: 0.09162500000000001\n",
      "Epoch: 1676, MSE: 0.2694607887053728, Learning Rate: 0.09162000000000001\n",
      "Epoch: 1677, MSE: 0.2694585994349593, Learning Rate: 0.091615\n",
      "Epoch: 1678, MSE: 0.26945641011607196, Learning Rate: 0.09161000000000001\n",
      "Epoch: 1679, MSE: 0.26945422074870823, Learning Rate: 0.091605\n",
      "Epoch: 1680, MSE: 0.2694520313328677, Learning Rate: 0.09160000000000001\n",
      "Epoch: 1681, MSE: 0.2694498418685505, Learning Rate: 0.09159500000000001\n",
      "Epoch: 1682, MSE: 0.26944765235575485, Learning Rate: 0.09159\n",
      "Epoch: 1683, MSE: 0.2694454627944809, Learning Rate: 0.09158500000000001\n",
      "Epoch: 1684, MSE: 0.2694432731847258, Learning Rate: 0.09158\n",
      "Epoch: 1685, MSE: 0.2694410835264904, Learning Rate: 0.091575\n",
      "Epoch: 1686, MSE: 0.26943889381977315, Learning Rate: 0.09157\n",
      "Epoch: 1687, MSE: 0.2694367040645737, Learning Rate: 0.09156500000000001\n",
      "Epoch: 1688, MSE: 0.2694345142608906, Learning Rate: 0.09156\n",
      "Epoch: 1689, MSE: 0.26943232440872333, Learning Rate: 0.091555\n",
      "Epoch: 1690, MSE: 0.2694301345080701, Learning Rate: 0.09155\n",
      "Epoch: 1691, MSE: 0.269427944558932, Learning Rate: 0.091545\n",
      "Epoch: 1692, MSE: 0.2694257545613064, Learning Rate: 0.09154000000000001\n",
      "Epoch: 1693, MSE: 0.26942356451519256, Learning Rate: 0.091535\n",
      "Epoch: 1694, MSE: 0.2694213744205911, Learning Rate: 0.09153\n",
      "Epoch: 1695, MSE: 0.2694191842775007, Learning Rate: 0.09152500000000001\n",
      "Epoch: 1696, MSE: 0.2694169940859186, Learning Rate: 0.09152\n",
      "Epoch: 1697, MSE: 0.2694148038458459, Learning Rate: 0.09151500000000001\n",
      "Epoch: 1698, MSE: 0.2694126135572811, Learning Rate: 0.09151000000000001\n",
      "Epoch: 1699, MSE: 0.2694104232202233, Learning Rate: 0.091505\n",
      "Epoch: 1700, MSE: 0.2694082328346723, Learning Rate: 0.09150000000000001\n",
      "Epoch: 1701, MSE: 0.26940604240062604, Learning Rate: 0.091495\n",
      "Epoch: 1702, MSE: 0.26940385191808414, Learning Rate: 0.09149000000000002\n",
      "Epoch: 1703, MSE: 0.26940166138704574, Learning Rate: 0.091485\n",
      "Epoch: 1704, MSE: 0.26939947080751, Learning Rate: 0.09148\n",
      "Epoch: 1705, MSE: 0.26939728017947734, Learning Rate: 0.091475\n",
      "Epoch: 1706, MSE: 0.26939508950294433, Learning Rate: 0.09147\n",
      "Epoch: 1707, MSE: 0.26939289877791206, Learning Rate: 0.091465\n",
      "Epoch: 1708, MSE: 0.2693907080043784, Learning Rate: 0.09146\n",
      "Epoch: 1709, MSE: 0.26938851718234313, Learning Rate: 0.09145500000000001\n",
      "Epoch: 1710, MSE: 0.26938632631180554, Learning Rate: 0.09145\n",
      "Epoch: 1711, MSE: 0.269384135392765, Learning Rate: 0.091445\n",
      "Epoch: 1712, MSE: 0.26938194442522045, Learning Rate: 0.09144000000000001\n",
      "Epoch: 1713, MSE: 0.26937975340916964, Learning Rate: 0.091435\n",
      "Epoch: 1714, MSE: 0.2693775623446139, Learning Rate: 0.09143000000000001\n",
      "Epoch: 1715, MSE: 0.26937537123155103, Learning Rate: 0.091425\n",
      "Epoch: 1716, MSE: 0.26937318006997973, Learning Rate: 0.09142\n",
      "Epoch: 1717, MSE: 0.2693709888599003, Learning Rate: 0.09141500000000001\n",
      "Epoch: 1718, MSE: 0.26936879760131155, Learning Rate: 0.09141\n",
      "Epoch: 1719, MSE: 0.26936660629421266, Learning Rate: 0.09140500000000001\n",
      "Epoch: 1720, MSE: 0.26936441493860114, Learning Rate: 0.09140000000000001\n",
      "Epoch: 1721, MSE: 0.26936222353447864, Learning Rate: 0.091395\n",
      "Epoch: 1722, MSE: 0.2693600320818435, Learning Rate: 0.09139000000000001\n",
      "Epoch: 1723, MSE: 0.2693578405806938, Learning Rate: 0.09138500000000001\n",
      "Epoch: 1724, MSE: 0.2693556490310295, Learning Rate: 0.09138\n",
      "Epoch: 1725, MSE: 0.269353457432849, Learning Rate: 0.09137500000000001\n",
      "Epoch: 1726, MSE: 0.2693512657861522, Learning Rate: 0.09137\n",
      "Epoch: 1727, MSE: 0.26934907409093894, Learning Rate: 0.091365\n",
      "Epoch: 1728, MSE: 0.2693468823472067, Learning Rate: 0.09136\n",
      "Epoch: 1729, MSE: 0.26934469055495525, Learning Rate: 0.091355\n",
      "Epoch: 1730, MSE: 0.26934249871418336, Learning Rate: 0.09135\n",
      "Epoch: 1731, MSE: 0.26934030682489113, Learning Rate: 0.09134500000000001\n",
      "Epoch: 1732, MSE: 0.269338114887077, Learning Rate: 0.09134\n",
      "Epoch: 1733, MSE: 0.26933592290074043, Learning Rate: 0.091335\n",
      "Epoch: 1734, MSE: 0.26933373086588014, Learning Rate: 0.09133000000000001\n",
      "Epoch: 1735, MSE: 0.26933153878249544, Learning Rate: 0.091325\n",
      "Epoch: 1736, MSE: 0.26932934665058533, Learning Rate: 0.09132000000000001\n",
      "Epoch: 1737, MSE: 0.2693271544701487, Learning Rate: 0.09131500000000001\n",
      "Epoch: 1738, MSE: 0.26932496224118524, Learning Rate: 0.09131\n",
      "Epoch: 1739, MSE: 0.26932276996369403, Learning Rate: 0.09130500000000001\n",
      "Epoch: 1740, MSE: 0.26932057763767275, Learning Rate: 0.0913\n",
      "Epoch: 1741, MSE: 0.269318385263123, Learning Rate: 0.09129500000000002\n",
      "Epoch: 1742, MSE: 0.26931619284004255, Learning Rate: 0.09129000000000001\n",
      "Epoch: 1743, MSE: 0.2693140003684307, Learning Rate: 0.091285\n",
      "Epoch: 1744, MSE: 0.2693118078482857, Learning Rate: 0.09128000000000001\n",
      "Epoch: 1745, MSE: 0.26930961527960817, Learning Rate: 0.091275\n",
      "Epoch: 1746, MSE: 0.269307422662396, Learning Rate: 0.09127\n",
      "Epoch: 1747, MSE: 0.2693052299966491, Learning Rate: 0.091265\n",
      "Epoch: 1748, MSE: 0.26930303728236615, Learning Rate: 0.09126000000000001\n",
      "Epoch: 1749, MSE: 0.2693008445195463, Learning Rate: 0.091255\n",
      "Epoch: 1750, MSE: 0.26929865170818906, Learning Rate: 0.09125\n",
      "Epoch: 1751, MSE: 0.2692964588482925, Learning Rate: 0.091245\n",
      "Epoch: 1752, MSE: 0.26929426593985634, Learning Rate: 0.09124\n",
      "Epoch: 1753, MSE: 0.2692920729828802, Learning Rate: 0.09123500000000001\n",
      "Epoch: 1754, MSE: 0.2692898799773632, Learning Rate: 0.09123\n",
      "Epoch: 1755, MSE: 0.269287686923304, Learning Rate: 0.091225\n",
      "Epoch: 1756, MSE: 0.269285493820701, Learning Rate: 0.09122000000000001\n",
      "Epoch: 1757, MSE: 0.26928330066955525, Learning Rate: 0.091215\n",
      "Epoch: 1758, MSE: 0.26928110746986317, Learning Rate: 0.09121000000000001\n",
      "Epoch: 1759, MSE: 0.2692789142216266, Learning Rate: 0.09120500000000001\n",
      "Epoch: 1760, MSE: 0.2692767209248425, Learning Rate: 0.0912\n",
      "Epoch: 1761, MSE: 0.269274527579512, Learning Rate: 0.09119500000000001\n",
      "Epoch: 1762, MSE: 0.26927233418563257, Learning Rate: 0.09119000000000001\n",
      "Epoch: 1763, MSE: 0.26927014074320343, Learning Rate: 0.09118500000000002\n",
      "Epoch: 1764, MSE: 0.2692679472522242, Learning Rate: 0.09118\n",
      "Epoch: 1765, MSE: 0.26926575371269396, Learning Rate: 0.091175\n",
      "Epoch: 1766, MSE: 0.26926356012461256, Learning Rate: 0.09117\n",
      "Epoch: 1767, MSE: 0.2692613664879781, Learning Rate: 0.091165\n",
      "Epoch: 1768, MSE: 0.269259172802789, Learning Rate: 0.09116\n",
      "Epoch: 1769, MSE: 0.26925697906904617, Learning Rate: 0.091155\n",
      "Epoch: 1770, MSE: 0.2692547852867473, Learning Rate: 0.09115000000000001\n",
      "Epoch: 1771, MSE: 0.26925259145589225, Learning Rate: 0.091145\n",
      "Epoch: 1772, MSE: 0.26925039757648, Learning Rate: 0.09114\n",
      "Epoch: 1773, MSE: 0.2692482036485089, Learning Rate: 0.09113500000000001\n",
      "Epoch: 1774, MSE: 0.26924600967197976, Learning Rate: 0.09113\n",
      "Epoch: 1775, MSE: 0.2692438156468893, Learning Rate: 0.09112500000000001\n",
      "Epoch: 1776, MSE: 0.2692416215732394, Learning Rate: 0.09112\n",
      "Epoch: 1777, MSE: 0.2692394274510263, Learning Rate: 0.091115\n",
      "Epoch: 1778, MSE: 0.2692372332802511, Learning Rate: 0.09111000000000001\n",
      "Epoch: 1779, MSE: 0.2692350390609126, Learning Rate: 0.091105\n",
      "Epoch: 1780, MSE: 0.2692328447930092, Learning Rate: 0.09110000000000001\n",
      "Epoch: 1781, MSE: 0.2692306504765405, Learning Rate: 0.09109500000000001\n",
      "Epoch: 1782, MSE: 0.26922845611150636, Learning Rate: 0.09109\n",
      "Epoch: 1783, MSE: 0.26922626169790465, Learning Rate: 0.09108500000000001\n",
      "Epoch: 1784, MSE: 0.2692240672357341, Learning Rate: 0.09108000000000001\n",
      "Epoch: 1785, MSE: 0.26922187272499504, Learning Rate: 0.091075\n",
      "Epoch: 1786, MSE: 0.2692196781656865, Learning Rate: 0.09107\n",
      "Epoch: 1787, MSE: 0.2692174835578066, Learning Rate: 0.09106500000000001\n",
      "Epoch: 1788, MSE: 0.2692152889013557, Learning Rate: 0.09106\n",
      "Epoch: 1789, MSE: 0.26921309419633194, Learning Rate: 0.091055\n",
      "Epoch: 1790, MSE: 0.2692108994427345, Learning Rate: 0.09105\n",
      "Epoch: 1791, MSE: 0.2692087046405628, Learning Rate: 0.091045\n",
      "Epoch: 1792, MSE: 0.26920650978981514, Learning Rate: 0.09104000000000001\n",
      "Epoch: 1793, MSE: 0.2692043148904927, Learning Rate: 0.091035\n",
      "Epoch: 1794, MSE: 0.26920211994259263, Learning Rate: 0.09103\n",
      "Epoch: 1795, MSE: 0.26919992494611417, Learning Rate: 0.09102500000000001\n",
      "Epoch: 1796, MSE: 0.2691977299010573, Learning Rate: 0.09102\n",
      "Epoch: 1797, MSE: 0.26919553480742076, Learning Rate: 0.09101500000000001\n",
      "Epoch: 1798, MSE: 0.2691933396652034, Learning Rate: 0.09101000000000001\n",
      "Epoch: 1799, MSE: 0.2691911444744049, Learning Rate: 0.091005\n",
      "Epoch: 1800, MSE: 0.2691889492350233, Learning Rate: 0.09100000000000001\n",
      "Epoch: 1801, MSE: 0.2691867539470582, Learning Rate: 0.090995\n",
      "Epoch: 1802, MSE: 0.2691845586105093, Learning Rate: 0.09099000000000002\n",
      "Epoch: 1803, MSE: 0.26918236322537525, Learning Rate: 0.09098500000000001\n",
      "Epoch: 1804, MSE: 0.2691801677916548, Learning Rate: 0.09098\n",
      "Epoch: 1805, MSE: 0.2691779723093477, Learning Rate: 0.09097500000000001\n",
      "Epoch: 1806, MSE: 0.26917577677845256, Learning Rate: 0.09097\n",
      "Epoch: 1807, MSE: 0.26917358119896806, Learning Rate: 0.090965\n",
      "Epoch: 1808, MSE: 0.26917138557089576, Learning Rate: 0.09096\n",
      "Epoch: 1809, MSE: 0.26916918989423166, Learning Rate: 0.09095500000000001\n",
      "Epoch: 1810, MSE: 0.26916699416897566, Learning Rate: 0.09095\n",
      "Epoch: 1811, MSE: 0.26916479839512786, Learning Rate: 0.090945\n",
      "Epoch: 1812, MSE: 0.2691626025726863, Learning Rate: 0.09094000000000001\n",
      "Epoch: 1813, MSE: 0.26916040670165087, Learning Rate: 0.090935\n",
      "Epoch: 1814, MSE: 0.2691582107820205, Learning Rate: 0.09093000000000001\n",
      "Epoch: 1815, MSE: 0.26915601481379353, Learning Rate: 0.090925\n",
      "Epoch: 1816, MSE: 0.2691538187969699, Learning Rate: 0.09092\n",
      "Epoch: 1817, MSE: 0.2691516227315487, Learning Rate: 0.09091500000000001\n",
      "Epoch: 1818, MSE: 0.26914942661752833, Learning Rate: 0.09091\n",
      "Epoch: 1819, MSE: 0.2691472304549087, Learning Rate: 0.09090500000000001\n",
      "Epoch: 1820, MSE: 0.26914503424368863, Learning Rate: 0.09090000000000001\n",
      "Epoch: 1821, MSE: 0.2691428379838664, Learning Rate: 0.090895\n",
      "Epoch: 1822, MSE: 0.269140641675442, Learning Rate: 0.09089000000000001\n",
      "Epoch: 1823, MSE: 0.2691384453184149, Learning Rate: 0.09088500000000001\n",
      "Epoch: 1824, MSE: 0.2691362489127835, Learning Rate: 0.09088000000000002\n",
      "Epoch: 1825, MSE: 0.269134052458547, Learning Rate: 0.090875\n",
      "Epoch: 1826, MSE: 0.2691318559557037, Learning Rate: 0.09087\n",
      "Epoch: 1827, MSE: 0.26912965940425465, Learning Rate: 0.090865\n",
      "Epoch: 1828, MSE: 0.269127462804197, Learning Rate: 0.09086\n",
      "Epoch: 1829, MSE: 0.269125266155531, Learning Rate: 0.090855\n",
      "Epoch: 1830, MSE: 0.2691230694582552, Learning Rate: 0.09085\n",
      "Epoch: 1831, MSE: 0.2691208727123693, Learning Rate: 0.09084500000000001\n",
      "Epoch: 1832, MSE: 0.2691186759178713, Learning Rate: 0.09084\n",
      "Epoch: 1833, MSE: 0.2691164790747616, Learning Rate: 0.090835\n",
      "Epoch: 1834, MSE: 0.26911428218303796, Learning Rate: 0.09083000000000001\n",
      "Epoch: 1835, MSE: 0.26911208524270036, Learning Rate: 0.090825\n",
      "Epoch: 1836, MSE: 0.2691098882537485, Learning Rate: 0.09082000000000001\n",
      "Epoch: 1837, MSE: 0.2691076912161795, Learning Rate: 0.090815\n",
      "Epoch: 1838, MSE: 0.269105494129994, Learning Rate: 0.09081\n",
      "Epoch: 1839, MSE: 0.26910329699519103, Learning Rate: 0.09080500000000001\n",
      "Epoch: 1840, MSE: 0.26910109981176844, Learning Rate: 0.0908\n",
      "Epoch: 1841, MSE: 0.2690989025797271, Learning Rate: 0.09079500000000001\n",
      "Epoch: 1842, MSE: 0.26909670529906454, Learning Rate: 0.09079000000000001\n",
      "Epoch: 1843, MSE: 0.2690945079697812, Learning Rate: 0.090785\n",
      "Epoch: 1844, MSE: 0.2690923105918746, Learning Rate: 0.09078\n",
      "Epoch: 1845, MSE: 0.2690901131653461, Learning Rate: 0.09077500000000001\n",
      "Epoch: 1846, MSE: 0.269087915690192, Learning Rate: 0.09077\n",
      "Epoch: 1847, MSE: 0.2690857181664136, Learning Rate: 0.090765\n",
      "Epoch: 1848, MSE: 0.26908352059400875, Learning Rate: 0.09076000000000001\n",
      "Epoch: 1849, MSE: 0.26908132297297727, Learning Rate: 0.090755\n",
      "Epoch: 1850, MSE: 0.26907912530331773, Learning Rate: 0.09075\n",
      "Epoch: 1851, MSE: 0.2690769275850298, Learning Rate: 0.090745\n",
      "Epoch: 1852, MSE: 0.26907472981811187, Learning Rate: 0.09074\n",
      "Epoch: 1853, MSE: 0.26907253200256315, Learning Rate: 0.09073500000000001\n",
      "Epoch: 1854, MSE: 0.2690703341383837, Learning Rate: 0.09073\n",
      "Epoch: 1855, MSE: 0.2690681362255709, Learning Rate: 0.090725\n",
      "Epoch: 1856, MSE: 0.269065938264126, Learning Rate: 0.09072000000000001\n",
      "Epoch: 1857, MSE: 0.26906374025404567, Learning Rate: 0.090715\n",
      "Epoch: 1858, MSE: 0.26906154219533046, Learning Rate: 0.09071000000000001\n",
      "Epoch: 1859, MSE: 0.2690593440879791, Learning Rate: 0.09070500000000001\n",
      "Epoch: 1860, MSE: 0.269057145931991, Learning Rate: 0.0907\n",
      "Epoch: 1861, MSE: 0.26905494772736516, Learning Rate: 0.09069500000000001\n",
      "Epoch: 1862, MSE: 0.2690527494741007, Learning Rate: 0.09069\n",
      "Epoch: 1863, MSE: 0.26905055117219545, Learning Rate: 0.09068500000000002\n",
      "Epoch: 1864, MSE: 0.26904835282165024, Learning Rate: 0.09068000000000001\n",
      "Epoch: 1865, MSE: 0.2690461544224629, Learning Rate: 0.090675\n",
      "Epoch: 1866, MSE: 0.2690439559746341, Learning Rate: 0.09067000000000001\n",
      "Epoch: 1867, MSE: 0.26904175747816117, Learning Rate: 0.090665\n",
      "Epoch: 1868, MSE: 0.2690395589330447, Learning Rate: 0.09066\n",
      "Epoch: 1869, MSE: 0.2690373603392817, Learning Rate: 0.090655\n",
      "Epoch: 1870, MSE: 0.26903516169687375, Learning Rate: 0.09065000000000001\n",
      "Epoch: 1871, MSE: 0.2690329630058186, Learning Rate: 0.090645\n",
      "Epoch: 1872, MSE: 0.2690307642661147, Learning Rate: 0.09064\n",
      "Epoch: 1873, MSE: 0.2690285654777629, Learning Rate: 0.09063500000000001\n",
      "Epoch: 1874, MSE: 0.2690263666407603, Learning Rate: 0.09063\n",
      "Epoch: 1875, MSE: 0.2690241677551077, Learning Rate: 0.09062500000000001\n",
      "Epoch: 1876, MSE: 0.26902196882080315, Learning Rate: 0.09062\n",
      "Epoch: 1877, MSE: 0.26901976983784537, Learning Rate: 0.090615\n",
      "Epoch: 1878, MSE: 0.26901757080623556, Learning Rate: 0.09061000000000001\n",
      "Epoch: 1879, MSE: 0.2690153717259703, Learning Rate: 0.090605\n",
      "Epoch: 1880, MSE: 0.26901317259705027, Learning Rate: 0.09060000000000001\n",
      "Epoch: 1881, MSE: 0.26901097341947366, Learning Rate: 0.09059500000000001\n",
      "Epoch: 1882, MSE: 0.26900877419323965, Learning Rate: 0.09059\n",
      "Epoch: 1883, MSE: 0.2690065749183487, Learning Rate: 0.09058500000000001\n",
      "Epoch: 1884, MSE: 0.2690043755947977, Learning Rate: 0.09058\n",
      "Epoch: 1885, MSE: 0.269002176222587, Learning Rate: 0.09057500000000002\n",
      "Epoch: 1886, MSE: 0.26899997680171583, Learning Rate: 0.09057\n",
      "Epoch: 1887, MSE: 0.2689977773321816, Learning Rate: 0.090565\n",
      "Epoch: 1888, MSE: 0.26899557781398636, Learning Rate: 0.09056\n",
      "Epoch: 1889, MSE: 0.2689933782471271, Learning Rate: 0.090555\n",
      "Epoch: 1890, MSE: 0.2689911786316027, Learning Rate: 0.09055\n",
      "Epoch: 1891, MSE: 0.2689889789674132, Learning Rate: 0.090545\n",
      "Epoch: 1892, MSE: 0.2689867792545574, Learning Rate: 0.09054000000000001\n",
      "Epoch: 1893, MSE: 0.2689845794930346, Learning Rate: 0.090535\n",
      "Epoch: 1894, MSE: 0.26898237968284294, Learning Rate: 0.09053\n",
      "Epoch: 1895, MSE: 0.26898017982398276, Learning Rate: 0.09052500000000001\n",
      "Epoch: 1896, MSE: 0.2689779799164524, Learning Rate: 0.09052\n",
      "Epoch: 1897, MSE: 0.2689757799602512, Learning Rate: 0.09051500000000001\n",
      "Epoch: 1898, MSE: 0.268973579955378, Learning Rate: 0.09051000000000001\n",
      "Epoch: 1899, MSE: 0.26897137990183195, Learning Rate: 0.090505\n",
      "Epoch: 1900, MSE: 0.26896917979961216, Learning Rate: 0.09050000000000001\n",
      "Epoch: 1901, MSE: 0.2689669796487176, Learning Rate: 0.090495\n",
      "Epoch: 1902, MSE: 0.2689647794491481, Learning Rate: 0.09049000000000001\n",
      "Epoch: 1903, MSE: 0.2689625792009017, Learning Rate: 0.09048500000000001\n",
      "Epoch: 1904, MSE: 0.26896037890397784, Learning Rate: 0.09048\n",
      "Epoch: 1905, MSE: 0.26895817855837567, Learning Rate: 0.090475\n",
      "Epoch: 1906, MSE: 0.2689559781640943, Learning Rate: 0.09047000000000001\n",
      "Epoch: 1907, MSE: 0.26895377772113244, Learning Rate: 0.090465\n",
      "Epoch: 1908, MSE: 0.26895157722949, Learning Rate: 0.09046\n",
      "Epoch: 1909, MSE: 0.26894937668916524, Learning Rate: 0.09045500000000001\n",
      "Epoch: 1910, MSE: 0.26894717610015795, Learning Rate: 0.09045\n",
      "Epoch: 1911, MSE: 0.26894497546246604, Learning Rate: 0.090445\n",
      "Epoch: 1912, MSE: 0.2689427747760902, Learning Rate: 0.09044\n",
      "Epoch: 1913, MSE: 0.2689405740410286, Learning Rate: 0.090435\n",
      "Epoch: 1914, MSE: 0.26893837325728004, Learning Rate: 0.09043000000000001\n",
      "Epoch: 1915, MSE: 0.2689361724248433, Learning Rate: 0.090425\n",
      "Epoch: 1916, MSE: 0.26893397154371884, Learning Rate: 0.09042\n",
      "Epoch: 1917, MSE: 0.26893177061390533, Learning Rate: 0.09041500000000001\n",
      "Epoch: 1918, MSE: 0.268929569635401, Learning Rate: 0.09041\n",
      "Epoch: 1919, MSE: 0.26892736860820543, Learning Rate: 0.09040500000000001\n",
      "Epoch: 1920, MSE: 0.26892516753231754, Learning Rate: 0.09040000000000001\n",
      "Epoch: 1921, MSE: 0.2689229664077371, Learning Rate: 0.090395\n",
      "Epoch: 1922, MSE: 0.2689207652344617, Learning Rate: 0.09039000000000001\n",
      "Epoch: 1923, MSE: 0.26891856401249187, Learning Rate: 0.09038500000000001\n",
      "Epoch: 1924, MSE: 0.2689163627418265, Learning Rate: 0.09038000000000002\n",
      "Epoch: 1925, MSE: 0.26891416142246416, Learning Rate: 0.09037500000000001\n",
      "Epoch: 1926, MSE: 0.2689119600544042, Learning Rate: 0.09037\n",
      "Epoch: 1927, MSE: 0.2689097586376453, Learning Rate: 0.090365\n",
      "Epoch: 1928, MSE: 0.2689075571721869, Learning Rate: 0.09036\n",
      "Epoch: 1929, MSE: 0.2689053556580283, Learning Rate: 0.090355\n",
      "Epoch: 1930, MSE: 0.2689031540951679, Learning Rate: 0.09035\n",
      "Epoch: 1931, MSE: 0.2689009524836054, Learning Rate: 0.09034500000000001\n",
      "Epoch: 1932, MSE: 0.2688987508233394, Learning Rate: 0.09034\n",
      "Epoch: 1933, MSE: 0.2688965491143699, Learning Rate: 0.090335\n",
      "Epoch: 1934, MSE: 0.26889434735669404, Learning Rate: 0.09033000000000001\n",
      "Epoch: 1935, MSE: 0.26889214555031365, Learning Rate: 0.090325\n",
      "Epoch: 1936, MSE: 0.26888994369522495, Learning Rate: 0.09032000000000001\n",
      "Epoch: 1937, MSE: 0.26888774179142905, Learning Rate: 0.090315\n",
      "Epoch: 1938, MSE: 0.2688855398389243, Learning Rate: 0.09031\n",
      "Epoch: 1939, MSE: 0.26888333783771, Learning Rate: 0.09030500000000001\n",
      "Epoch: 1940, MSE: 0.2688811357877845, Learning Rate: 0.0903\n",
      "Epoch: 1941, MSE: 0.2688789336891477, Learning Rate: 0.09029500000000001\n",
      "Epoch: 1942, MSE: 0.26887673154179886, Learning Rate: 0.09029000000000001\n",
      "Epoch: 1943, MSE: 0.26887452934573614, Learning Rate: 0.090285\n",
      "Epoch: 1944, MSE: 0.2688723271009587, Learning Rate: 0.09028000000000001\n",
      "Epoch: 1945, MSE: 0.2688701248074662, Learning Rate: 0.090275\n",
      "Epoch: 1946, MSE: 0.2688679224652573, Learning Rate: 0.09027000000000002\n",
      "Epoch: 1947, MSE: 0.2688657200743317, Learning Rate: 0.090265\n",
      "Epoch: 1948, MSE: 0.2688635176346874, Learning Rate: 0.09026\n",
      "Epoch: 1949, MSE: 0.2688613151463254, Learning Rate: 0.090255\n",
      "Epoch: 1950, MSE: 0.26885911260924256, Learning Rate: 0.09025\n",
      "Epoch: 1951, MSE: 0.2688569100234382, Learning Rate: 0.090245\n",
      "Epoch: 1952, MSE: 0.2688547073889132, Learning Rate: 0.09024\n",
      "Epoch: 1953, MSE: 0.2688525047056651, Learning Rate: 0.09023500000000001\n",
      "Epoch: 1954, MSE: 0.268850301973693, Learning Rate: 0.09023\n",
      "Epoch: 1955, MSE: 0.2688480991929965, Learning Rate: 0.090225\n",
      "Epoch: 1956, MSE: 0.2688458963635741, Learning Rate: 0.09022000000000001\n",
      "Epoch: 1957, MSE: 0.2688436934854263, Learning Rate: 0.090215\n",
      "Epoch: 1958, MSE: 0.2688414905585501, Learning Rate: 0.09021000000000001\n",
      "Epoch: 1959, MSE: 0.2688392875829469, Learning Rate: 0.09020500000000001\n",
      "Epoch: 1960, MSE: 0.2688370845586138, Learning Rate: 0.0902\n",
      "Epoch: 1961, MSE: 0.2688348814855507, Learning Rate: 0.09019500000000001\n",
      "Epoch: 1962, MSE: 0.2688326783637558, Learning Rate: 0.09019\n",
      "Epoch: 1963, MSE: 0.26883047519323, Learning Rate: 0.09018500000000002\n",
      "Epoch: 1964, MSE: 0.26882827197397025, Learning Rate: 0.09018000000000001\n",
      "Epoch: 1965, MSE: 0.2688260687059773, Learning Rate: 0.090175\n",
      "Epoch: 1966, MSE: 0.2688238653892495, Learning Rate: 0.09017\n",
      "Epoch: 1967, MSE: 0.26882166202378593, Learning Rate: 0.090165\n",
      "Epoch: 1968, MSE: 0.26881945860958617, Learning Rate: 0.09016\n",
      "Epoch: 1969, MSE: 0.2688172551466479, Learning Rate: 0.090155\n",
      "Epoch: 1970, MSE: 0.26881505163497155, Learning Rate: 0.09015000000000001\n",
      "Epoch: 1971, MSE: 0.2688128480745561, Learning Rate: 0.090145\n",
      "Epoch: 1972, MSE: 0.26881064446539926, Learning Rate: 0.09014\n",
      "Epoch: 1973, MSE: 0.2688084408075025, Learning Rate: 0.090135\n",
      "Epoch: 1974, MSE: 0.2688062371008637, Learning Rate: 0.09013\n",
      "Epoch: 1975, MSE: 0.2688040333454804, Learning Rate: 0.09012500000000001\n",
      "Epoch: 1976, MSE: 0.2688018295413533, Learning Rate: 0.09012\n",
      "Epoch: 1977, MSE: 0.268799625688482, Learning Rate: 0.090115\n",
      "Epoch: 1978, MSE: 0.2687974217868647, Learning Rate: 0.09011000000000001\n",
      "Epoch: 1979, MSE: 0.26879521783649973, Learning Rate: 0.090105\n",
      "Epoch: 1980, MSE: 0.2687930138373879, Learning Rate: 0.09010000000000001\n",
      "Epoch: 1981, MSE: 0.2687908097895269, Learning Rate: 0.09009500000000001\n",
      "Epoch: 1982, MSE: 0.2687886056929162, Learning Rate: 0.09009\n",
      "Epoch: 1983, MSE: 0.2687864015475551, Learning Rate: 0.09008500000000001\n",
      "Epoch: 1984, MSE: 0.26878419735344294, Learning Rate: 0.09008000000000001\n",
      "Epoch: 1985, MSE: 0.26878199311057754, Learning Rate: 0.090075\n",
      "Epoch: 1986, MSE: 0.26877978881895837, Learning Rate: 0.09007000000000001\n",
      "Epoch: 1987, MSE: 0.26877758447858646, Learning Rate: 0.090065\n",
      "Epoch: 1988, MSE: 0.26877538008945845, Learning Rate: 0.09006\n",
      "Epoch: 1989, MSE: 0.26877317565157455, Learning Rate: 0.090055\n",
      "Epoch: 1990, MSE: 0.2687709711649332, Learning Rate: 0.09005\n",
      "Epoch: 1991, MSE: 0.2687687666295338, Learning Rate: 0.090045\n",
      "Epoch: 1992, MSE: 0.2687665620453758, Learning Rate: 0.09004000000000001\n",
      "Epoch: 1993, MSE: 0.26876435741245785, Learning Rate: 0.090035\n",
      "Epoch: 1994, MSE: 0.2687621527307788, Learning Rate: 0.09003\n",
      "Epoch: 1995, MSE: 0.26875994800033837, Learning Rate: 0.09002500000000001\n",
      "Epoch: 1996, MSE: 0.2687577432211359, Learning Rate: 0.09002\n",
      "Epoch: 1997, MSE: 0.2687555383931684, Learning Rate: 0.09001500000000001\n",
      "Epoch: 1998, MSE: 0.2687533335164371, Learning Rate: 0.09001\n",
      "Epoch: 1999, MSE: 0.26875112859094014, Learning Rate: 0.090005\n",
      "Epoch: 2000, MSE: 0.26874892361667724, Learning Rate: 0.09000000000000001\n",
      "Epoch: 2001, MSE: 0.2687467185936469, Learning Rate: 0.089995\n",
      "Epoch: 2002, MSE: 0.26874451352184825, Learning Rate: 0.08999000000000001\n",
      "Epoch: 2003, MSE: 0.26874230840128077, Learning Rate: 0.08998500000000001\n",
      "Epoch: 2004, MSE: 0.26874010323194336, Learning Rate: 0.08998\n",
      "Epoch: 2005, MSE: 0.2687378980138342, Learning Rate: 0.08997500000000001\n",
      "Epoch: 2006, MSE: 0.2687356927469533, Learning Rate: 0.08997\n",
      "Epoch: 2007, MSE: 0.2687334874312995, Learning Rate: 0.08996500000000002\n",
      "Epoch: 2008, MSE: 0.268731282066872, Learning Rate: 0.08996\n",
      "Epoch: 2009, MSE: 0.26872907665366885, Learning Rate: 0.08995500000000001\n",
      "Epoch: 2010, MSE: 0.26872687119169175, Learning Rate: 0.08995\n",
      "Epoch: 2011, MSE: 0.2687246656809366, Learning Rate: 0.089945\n",
      "Epoch: 2012, MSE: 0.26872246012140444, Learning Rate: 0.08994\n",
      "Epoch: 2013, MSE: 0.268720254513093, Learning Rate: 0.089935\n",
      "Epoch: 2014, MSE: 0.26871804885600303, Learning Rate: 0.08993000000000001\n",
      "Epoch: 2015, MSE: 0.2687158431501328, Learning Rate: 0.089925\n",
      "Epoch: 2016, MSE: 0.268713637395481, Learning Rate: 0.08992\n",
      "Epoch: 2017, MSE: 0.2687114315920476, Learning Rate: 0.08991500000000001\n",
      "Epoch: 2018, MSE: 0.26870922573983025, Learning Rate: 0.08991\n",
      "Epoch: 2019, MSE: 0.26870701983882866, Learning Rate: 0.08990500000000001\n",
      "Epoch: 2020, MSE: 0.26870481388904244, Learning Rate: 0.08990000000000001\n",
      "Epoch: 2021, MSE: 0.26870260789047096, Learning Rate: 0.089895\n",
      "Epoch: 2022, MSE: 0.26870040184311217, Learning Rate: 0.08989000000000001\n",
      "Epoch: 2023, MSE: 0.26869819574696463, Learning Rate: 0.089885\n",
      "Epoch: 2024, MSE: 0.2686959896020297, Learning Rate: 0.08988000000000002\n",
      "Epoch: 2025, MSE: 0.2686937834083045, Learning Rate: 0.089875\n",
      "Epoch: 2026, MSE: 0.2686915771657887, Learning Rate: 0.08987\n",
      "Epoch: 2027, MSE: 0.2686893708744814, Learning Rate: 0.089865\n",
      "Epoch: 2028, MSE: 0.2686871645343816, Learning Rate: 0.08986\n",
      "Epoch: 2029, MSE: 0.26868495814548793, Learning Rate: 0.089855\n",
      "Epoch: 2030, MSE: 0.26868275170780065, Learning Rate: 0.08985\n",
      "Epoch: 2031, MSE: 0.2686805452213183, Learning Rate: 0.08984500000000001\n",
      "Epoch: 2032, MSE: 0.2686783386860394, Learning Rate: 0.08984\n",
      "Epoch: 2033, MSE: 0.26867613210196406, Learning Rate: 0.089835\n",
      "Epoch: 2034, MSE: 0.26867392546908986, Learning Rate: 0.08983000000000001\n",
      "Epoch: 2035, MSE: 0.26867171878741636, Learning Rate: 0.089825\n",
      "Epoch: 2036, MSE: 0.2686695120569438, Learning Rate: 0.08982000000000001\n",
      "Epoch: 2037, MSE: 0.2686673052776699, Learning Rate: 0.089815\n",
      "Epoch: 2038, MSE: 0.2686650984495946, Learning Rate: 0.08981\n",
      "Epoch: 2039, MSE: 0.268662891572716, Learning Rate: 0.08980500000000001\n",
      "Epoch: 2040, MSE: 0.26866068464703446, Learning Rate: 0.0898\n",
      "Epoch: 2041, MSE: 0.26865847767254797, Learning Rate: 0.08979500000000001\n",
      "Epoch: 2042, MSE: 0.2686562706492557, Learning Rate: 0.08979000000000001\n",
      "Epoch: 2043, MSE: 0.26865406357715776, Learning Rate: 0.089785\n",
      "Epoch: 2044, MSE: 0.2686518564562515, Learning Rate: 0.08978000000000001\n",
      "Epoch: 2045, MSE: 0.2686496492865376, Learning Rate: 0.08977500000000001\n",
      "Epoch: 2046, MSE: 0.26864744206801433, Learning Rate: 0.08977\n",
      "Epoch: 2047, MSE: 0.26864523480068114, Learning Rate: 0.08976500000000001\n",
      "Epoch: 2048, MSE: 0.26864302748453633, Learning Rate: 0.08976\n",
      "Epoch: 2049, MSE: 0.2686408201195796, Learning Rate: 0.089755\n",
      "Epoch: 2050, MSE: 0.2686386127058106, Learning Rate: 0.08975\n",
      "Epoch: 2051, MSE: 0.2686364052432274, Learning Rate: 0.089745\n",
      "Epoch: 2052, MSE: 0.26863419773182867, Learning Rate: 0.08974\n",
      "Epoch: 2053, MSE: 0.26863199017161477, Learning Rate: 0.08973500000000001\n",
      "Epoch: 2054, MSE: 0.26862978256258446, Learning Rate: 0.08973\n",
      "Epoch: 2055, MSE: 0.26862757490473543, Learning Rate: 0.089725\n",
      "Epoch: 2056, MSE: 0.26862536719806884, Learning Rate: 0.08972000000000001\n",
      "Epoch: 2057, MSE: 0.2686231594425823, Learning Rate: 0.089715\n",
      "Epoch: 2058, MSE: 0.2686209516382759, Learning Rate: 0.08971000000000001\n",
      "Epoch: 2059, MSE: 0.2686187437851477, Learning Rate: 0.08970500000000001\n",
      "Epoch: 2060, MSE: 0.26861653588319756, Learning Rate: 0.0897\n",
      "Epoch: 2061, MSE: 0.26861432793242346, Learning Rate: 0.08969500000000001\n",
      "Epoch: 2062, MSE: 0.2686121199328259, Learning Rate: 0.08969\n",
      "Epoch: 2063, MSE: 0.26860991188440325, Learning Rate: 0.08968500000000001\n",
      "Epoch: 2064, MSE: 0.26860770378715476, Learning Rate: 0.08968000000000001\n",
      "Epoch: 2065, MSE: 0.26860549564107816, Learning Rate: 0.089675\n",
      "Epoch: 2066, MSE: 0.26860328744617484, Learning Rate: 0.08967000000000001\n",
      "Epoch: 2067, MSE: 0.268601079202442, Learning Rate: 0.089665\n",
      "Epoch: 2068, MSE: 0.2685988709098796, Learning Rate: 0.08966\n",
      "Epoch: 2069, MSE: 0.2685966625684866, Learning Rate: 0.089655\n",
      "Epoch: 2070, MSE: 0.2685944541782629, Learning Rate: 0.08965000000000001\n",
      "Epoch: 2071, MSE: 0.26859224573920526, Learning Rate: 0.089645\n",
      "Epoch: 2072, MSE: 0.2685900372513146, Learning Rate: 0.08964\n",
      "Epoch: 2073, MSE: 0.26858782871458936, Learning Rate: 0.089635\n",
      "Epoch: 2074, MSE: 0.26858562012902953, Learning Rate: 0.08963\n",
      "Epoch: 2075, MSE: 0.2685834114946331, Learning Rate: 0.08962500000000001\n",
      "Epoch: 2076, MSE: 0.26858120281139924, Learning Rate: 0.08962\n",
      "Epoch: 2077, MSE: 0.2685789940793266, Learning Rate: 0.089615\n",
      "Epoch: 2078, MSE: 0.26857678529841594, Learning Rate: 0.08961000000000001\n",
      "Epoch: 2079, MSE: 0.2685745764686649, Learning Rate: 0.089605\n",
      "Epoch: 2080, MSE: 0.26857236759007275, Learning Rate: 0.08960000000000001\n",
      "Epoch: 2081, MSE: 0.2685701586626393, Learning Rate: 0.08959500000000001\n",
      "Epoch: 2082, MSE: 0.2685679496863623, Learning Rate: 0.08959\n",
      "Epoch: 2083, MSE: 0.268565740661242, Learning Rate: 0.08958500000000001\n",
      "Epoch: 2084, MSE: 0.26856353158727697, Learning Rate: 0.08958\n",
      "Epoch: 2085, MSE: 0.26856132246446673, Learning Rate: 0.08957500000000002\n",
      "Epoch: 2086, MSE: 0.268559113292809, Learning Rate: 0.08957\n",
      "Epoch: 2087, MSE: 0.268556904072305, Learning Rate: 0.089565\n",
      "Epoch: 2088, MSE: 0.26855469480295163, Learning Rate: 0.08956\n",
      "Epoch: 2089, MSE: 0.268552485484749, Learning Rate: 0.089555\n",
      "Epoch: 2090, MSE: 0.26855027611769644, Learning Rate: 0.08955\n",
      "Epoch: 2091, MSE: 0.26854806670179254, Learning Rate: 0.089545\n",
      "Epoch: 2092, MSE: 0.2685458572370368, Learning Rate: 0.08954000000000001\n",
      "Epoch: 2093, MSE: 0.268543647723428, Learning Rate: 0.089535\n",
      "Epoch: 2094, MSE: 0.2685414381609646, Learning Rate: 0.08953\n",
      "Epoch: 2095, MSE: 0.2685392285496471, Learning Rate: 0.08952500000000001\n",
      "Epoch: 2096, MSE: 0.268537018889473, Learning Rate: 0.08952\n",
      "Epoch: 2097, MSE: 0.2685348091804427, Learning Rate: 0.08951500000000001\n",
      "Epoch: 2098, MSE: 0.2685325994225542, Learning Rate: 0.08951\n",
      "Epoch: 2099, MSE: 0.2685303896158072, Learning Rate: 0.089505\n",
      "Epoch: 2100, MSE: 0.2685281797602006, Learning Rate: 0.08950000000000001\n",
      "Epoch: 2101, MSE: 0.2685259698557334, Learning Rate: 0.089495\n",
      "Epoch: 2102, MSE: 0.26852375990240496, Learning Rate: 0.08949000000000001\n",
      "Epoch: 2103, MSE: 0.268521549900214, Learning Rate: 0.08948500000000001\n",
      "Epoch: 2104, MSE: 0.26851933984916015, Learning Rate: 0.08948\n",
      "Epoch: 2105, MSE: 0.2685171297492405, Learning Rate: 0.08947500000000001\n",
      "Epoch: 2106, MSE: 0.26851491960045815, Learning Rate: 0.08947000000000001\n",
      "Epoch: 2107, MSE: 0.26851270940280736, Learning Rate: 0.089465\n",
      "Epoch: 2108, MSE: 0.2685104991562906, Learning Rate: 0.08946000000000001\n",
      "Epoch: 2109, MSE: 0.2685082888609052, Learning Rate: 0.089455\n",
      "Epoch: 2110, MSE: 0.268506078516652, Learning Rate: 0.08945\n",
      "Epoch: 2111, MSE: 0.2685038681235287, Learning Rate: 0.089445\n",
      "Epoch: 2112, MSE: 0.2685016576815337, Learning Rate: 0.08944\n",
      "Epoch: 2113, MSE: 0.26849944719066743, Learning Rate: 0.089435\n",
      "Epoch: 2114, MSE: 0.268497236650929, Learning Rate: 0.08943000000000001\n",
      "Epoch: 2115, MSE: 0.26849502606231657, Learning Rate: 0.089425\n",
      "Epoch: 2116, MSE: 0.2684928154248297, Learning Rate: 0.08942\n",
      "Epoch: 2117, MSE: 0.2684906047384672, Learning Rate: 0.08941500000000001\n",
      "Epoch: 2118, MSE: 0.26848839400322877, Learning Rate: 0.08941\n",
      "Epoch: 2119, MSE: 0.26848618321911333, Learning Rate: 0.08940500000000001\n",
      "Epoch: 2120, MSE: 0.2684839723861187, Learning Rate: 0.08940000000000001\n",
      "Epoch: 2121, MSE: 0.2684817615042448, Learning Rate: 0.089395\n",
      "Epoch: 2122, MSE: 0.26847955057349165, Learning Rate: 0.08939000000000001\n",
      "Epoch: 2123, MSE: 0.26847733959385744, Learning Rate: 0.089385\n",
      "Epoch: 2124, MSE: 0.2684751285653401, Learning Rate: 0.08938000000000001\n",
      "Epoch: 2125, MSE: 0.26847291748794105, Learning Rate: 0.08937500000000001\n",
      "Epoch: 2126, MSE: 0.26847070636165854, Learning Rate: 0.08937\n",
      "Epoch: 2127, MSE: 0.2684684951864902, Learning Rate: 0.08936500000000001\n",
      "Epoch: 2128, MSE: 0.26846628396243594, Learning Rate: 0.08936\n",
      "Epoch: 2129, MSE: 0.2684640726894959, Learning Rate: 0.089355\n",
      "Epoch: 2130, MSE: 0.2684618613676677, Learning Rate: 0.08935\n",
      "Epoch: 2131, MSE: 0.2684596499969519, Learning Rate: 0.08934500000000001\n",
      "Epoch: 2132, MSE: 0.26845743857734544, Learning Rate: 0.08934\n",
      "Epoch: 2133, MSE: 0.2684552271088498, Learning Rate: 0.089335\n",
      "Epoch: 2134, MSE: 0.2684530155914616, Learning Rate: 0.08933\n",
      "Epoch: 2135, MSE: 0.2684508040251824, Learning Rate: 0.089325\n",
      "Epoch: 2136, MSE: 0.26844859241000973, Learning Rate: 0.08932000000000001\n",
      "Epoch: 2137, MSE: 0.26844638074594274, Learning Rate: 0.089315\n",
      "Epoch: 2138, MSE: 0.2684441690329805, Learning Rate: 0.08931\n",
      "Epoch: 2139, MSE: 0.2684419572711227, Learning Rate: 0.08930500000000001\n",
      "Epoch: 2140, MSE: 0.2684397454603678, Learning Rate: 0.0893\n",
      "Epoch: 2141, MSE: 0.26843753360071515, Learning Rate: 0.08929500000000001\n",
      "Epoch: 2142, MSE: 0.268435321692164, Learning Rate: 0.08929000000000001\n",
      "Epoch: 2143, MSE: 0.2684331097347128, Learning Rate: 0.089285\n",
      "Epoch: 2144, MSE: 0.26843089772836115, Learning Rate: 0.08928000000000001\n",
      "Epoch: 2145, MSE: 0.26842868567310835, Learning Rate: 0.08927500000000001\n",
      "Epoch: 2146, MSE: 0.2684264735689527, Learning Rate: 0.08927000000000002\n",
      "Epoch: 2147, MSE: 0.2684242614158938, Learning Rate: 0.089265\n",
      "Epoch: 2148, MSE: 0.2684220492139305, Learning Rate: 0.08926\n",
      "Epoch: 2149, MSE: 0.2684198369630613, Learning Rate: 0.089255\n",
      "Epoch: 2150, MSE: 0.26841762466328667, Learning Rate: 0.08925\n",
      "Epoch: 2151, MSE: 0.26841541231460475, Learning Rate: 0.089245\n",
      "Epoch: 2152, MSE: 0.2684131999170142, Learning Rate: 0.08924\n",
      "Epoch: 2153, MSE: 0.2684109874705162, Learning Rate: 0.08923500000000001\n",
      "Epoch: 2154, MSE: 0.26840877497510696, Learning Rate: 0.08923\n",
      "Epoch: 2155, MSE: 0.2684065624307873, Learning Rate: 0.089225\n",
      "Epoch: 2156, MSE: 0.2684043498375551, Learning Rate: 0.08922000000000001\n",
      "Epoch: 2157, MSE: 0.2684021371954112, Learning Rate: 0.089215\n",
      "Epoch: 2158, MSE: 0.26839992450435307, Learning Rate: 0.08921000000000001\n",
      "Epoch: 2159, MSE: 0.26839771176438093, Learning Rate: 0.089205\n",
      "Epoch: 2160, MSE: 0.26839549897549325, Learning Rate: 0.0892\n",
      "Epoch: 2161, MSE: 0.26839328613768826, Learning Rate: 0.08919500000000001\n",
      "Epoch: 2162, MSE: 0.26839107325096645, Learning Rate: 0.08919\n",
      "Epoch: 2163, MSE: 0.26838886031532644, Learning Rate: 0.08918500000000001\n",
      "Epoch: 2164, MSE: 0.26838664733076656, Learning Rate: 0.08918000000000001\n",
      "Epoch: 2165, MSE: 0.26838443429728703, Learning Rate: 0.089175\n",
      "Epoch: 2166, MSE: 0.26838222121488686, Learning Rate: 0.08917000000000001\n",
      "Epoch: 2167, MSE: 0.2683800080835637, Learning Rate: 0.08916500000000001\n",
      "Epoch: 2168, MSE: 0.26837779490331826, Learning Rate: 0.08916\n",
      "Epoch: 2169, MSE: 0.2683755816741493, Learning Rate: 0.089155\n",
      "Epoch: 2170, MSE: 0.2683733683960543, Learning Rate: 0.08915000000000001\n",
      "Epoch: 2171, MSE: 0.26837115506903386, Learning Rate: 0.089145\n",
      "Epoch: 2172, MSE: 0.26836894169308767, Learning Rate: 0.08914\n",
      "Epoch: 2173, MSE: 0.26836672826821334, Learning Rate: 0.089135\n",
      "Epoch: 2174, MSE: 0.26836451479441054, Learning Rate: 0.08913\n",
      "Epoch: 2175, MSE: 0.2683623012716781, Learning Rate: 0.08912500000000001\n",
      "Epoch: 2176, MSE: 0.2683600877000152, Learning Rate: 0.08912\n",
      "Epoch: 2177, MSE: 0.26835787407942097, Learning Rate: 0.089115\n",
      "Epoch: 2178, MSE: 0.2683556604098951, Learning Rate: 0.08911000000000001\n",
      "Epoch: 2179, MSE: 0.26835344669143496, Learning Rate: 0.089105\n",
      "Epoch: 2180, MSE: 0.2683512329240418, Learning Rate: 0.08910000000000001\n",
      "Epoch: 2181, MSE: 0.2683490191077127, Learning Rate: 0.08909500000000001\n",
      "Epoch: 2182, MSE: 0.2683468052424476, Learning Rate: 0.08909\n",
      "Epoch: 2183, MSE: 0.26834459132824595, Learning Rate: 0.08908500000000001\n",
      "Epoch: 2184, MSE: 0.2683423773651069, Learning Rate: 0.08908\n",
      "Epoch: 2185, MSE: 0.26834016335302857, Learning Rate: 0.08907500000000002\n",
      "Epoch: 2186, MSE: 0.2683379492920111, Learning Rate: 0.08907000000000001\n",
      "Epoch: 2187, MSE: 0.26833573518205195, Learning Rate: 0.089065\n",
      "Epoch: 2188, MSE: 0.2683335210231519, Learning Rate: 0.08906000000000001\n",
      "Epoch: 2189, MSE: 0.2683313068153092, Learning Rate: 0.089055\n",
      "Epoch: 2190, MSE: 0.2683290925585235, Learning Rate: 0.08905\n",
      "Epoch: 2191, MSE: 0.26832687825279267, Learning Rate: 0.089045\n",
      "Epoch: 2192, MSE: 0.268324663898117, Learning Rate: 0.08904000000000001\n",
      "Epoch: 2193, MSE: 0.26832244949449535, Learning Rate: 0.089035\n",
      "Epoch: 2194, MSE: 0.26832023504192587, Learning Rate: 0.08903\n",
      "Epoch: 2195, MSE: 0.2683180205404087, Learning Rate: 0.089025\n",
      "Epoch: 2196, MSE: 0.2683158059899428, Learning Rate: 0.08902\n",
      "Epoch: 2197, MSE: 0.2683135913905271, Learning Rate: 0.08901500000000001\n",
      "Epoch: 2198, MSE: 0.2683113767421596, Learning Rate: 0.08901\n",
      "Epoch: 2199, MSE: 0.26830916204484084, Learning Rate: 0.089005\n",
      "Epoch: 2200, MSE: 0.26830694729856935, Learning Rate: 0.08900000000000001\n",
      "Epoch: 2201, MSE: 0.26830473250334463, Learning Rate: 0.088995\n",
      "Epoch: 2202, MSE: 0.2683025176591649, Learning Rate: 0.08899000000000001\n",
      "Epoch: 2203, MSE: 0.26830030276602973, Learning Rate: 0.08898500000000001\n",
      "Epoch: 2204, MSE: 0.2682980878239381, Learning Rate: 0.08898\n",
      "Epoch: 2205, MSE: 0.26829587283288897, Learning Rate: 0.08897500000000001\n",
      "Epoch: 2206, MSE: 0.2682936577928823, Learning Rate: 0.08897000000000001\n",
      "Epoch: 2207, MSE: 0.268291442703916, Learning Rate: 0.08896500000000002\n",
      "Epoch: 2208, MSE: 0.2682892275659895, Learning Rate: 0.08896\n",
      "Epoch: 2209, MSE: 0.26828701237910113, Learning Rate: 0.088955\n",
      "Epoch: 2210, MSE: 0.26828479714325154, Learning Rate: 0.08895\n",
      "Epoch: 2211, MSE: 0.26828258185843884, Learning Rate: 0.088945\n",
      "Epoch: 2212, MSE: 0.2682803665246625, Learning Rate: 0.08894\n",
      "Epoch: 2213, MSE: 0.2682781511419211, Learning Rate: 0.088935\n",
      "Epoch: 2214, MSE: 0.26827593571021424, Learning Rate: 0.08893000000000001\n",
      "Epoch: 2215, MSE: 0.2682737202295407, Learning Rate: 0.088925\n",
      "Epoch: 2216, MSE: 0.26827150469989935, Learning Rate: 0.08892\n",
      "Epoch: 2217, MSE: 0.26826928912128983, Learning Rate: 0.08891500000000001\n",
      "Epoch: 2218, MSE: 0.26826707349371093, Learning Rate: 0.08891\n",
      "Epoch: 2219, MSE: 0.26826485781716086, Learning Rate: 0.08890500000000001\n",
      "Epoch: 2220, MSE: 0.26826264209164047, Learning Rate: 0.0889\n",
      "Epoch: 2221, MSE: 0.2682604263171472, Learning Rate: 0.088895\n",
      "Epoch: 2222, MSE: 0.26825821049368087, Learning Rate: 0.08889000000000001\n",
      "Epoch: 2223, MSE: 0.2682559946212407, Learning Rate: 0.088885\n",
      "Epoch: 2224, MSE: 0.2682537786998257, Learning Rate: 0.08888000000000001\n",
      "Epoch: 2225, MSE: 0.26825156272943457, Learning Rate: 0.08887500000000001\n",
      "Epoch: 2226, MSE: 0.26824934671006684, Learning Rate: 0.08887\n",
      "Epoch: 2227, MSE: 0.26824713064172057, Learning Rate: 0.088865\n",
      "Epoch: 2228, MSE: 0.2682449145243957, Learning Rate: 0.08886000000000001\n",
      "Epoch: 2229, MSE: 0.26824269835809217, Learning Rate: 0.088855\n",
      "Epoch: 2230, MSE: 0.26824048214280743, Learning Rate: 0.08885\n",
      "Epoch: 2231, MSE: 0.26823826587854116, Learning Rate: 0.08884500000000001\n",
      "Epoch: 2232, MSE: 0.26823604956529246, Learning Rate: 0.08884\n",
      "Epoch: 2233, MSE: 0.2682338332030603, Learning Rate: 0.088835\n",
      "Epoch: 2234, MSE: 0.2682316167918446, Learning Rate: 0.08883\n",
      "Epoch: 2235, MSE: 0.2682294003316428, Learning Rate: 0.088825\n",
      "Epoch: 2236, MSE: 0.2682271838224549, Learning Rate: 0.08882000000000001\n",
      "Epoch: 2237, MSE: 0.26822496726428047, Learning Rate: 0.088815\n",
      "Epoch: 2238, MSE: 0.26822275065711826, Learning Rate: 0.08881\n",
      "Epoch: 2239, MSE: 0.26822053400096674, Learning Rate: 0.08880500000000001\n",
      "Epoch: 2240, MSE: 0.2682183172958252, Learning Rate: 0.0888\n",
      "Epoch: 2241, MSE: 0.2682161005416932, Learning Rate: 0.08879500000000001\n",
      "Epoch: 2242, MSE: 0.2682138837385693, Learning Rate: 0.08879000000000001\n",
      "Epoch: 2243, MSE: 0.26821166688645265, Learning Rate: 0.088785\n",
      "Epoch: 2244, MSE: 0.2682094499853429, Learning Rate: 0.08878000000000001\n",
      "Epoch: 2245, MSE: 0.2682072330352383, Learning Rate: 0.088775\n",
      "Epoch: 2246, MSE: 0.26820501603613894, Learning Rate: 0.08877000000000002\n",
      "Epoch: 2247, MSE: 0.26820279898804267, Learning Rate: 0.08876500000000001\n",
      "Epoch: 2248, MSE: 0.2682005818909495, Learning Rate: 0.08876\n",
      "Epoch: 2249, MSE: 0.2681983647448578, Learning Rate: 0.08875500000000001\n",
      "Epoch: 2250, MSE: 0.268196147549767, Learning Rate: 0.08875\n",
      "Epoch: 2251, MSE: 0.2681939303056768, Learning Rate: 0.088745\n",
      "Epoch: 2252, MSE: 0.2681917130125848, Learning Rate: 0.08874\n",
      "Epoch: 2253, MSE: 0.2681894956704917, Learning Rate: 0.08873500000000001\n",
      "Epoch: 2254, MSE: 0.2681872782793954, Learning Rate: 0.08873\n",
      "Epoch: 2255, MSE: 0.26818506083929544, Learning Rate: 0.088725\n",
      "Epoch: 2256, MSE: 0.268182843350191, Learning Rate: 0.08872000000000001\n",
      "Epoch: 2257, MSE: 0.2681806258120806, Learning Rate: 0.088715\n",
      "Epoch: 2258, MSE: 0.2681784082249635, Learning Rate: 0.08871000000000001\n",
      "Epoch: 2259, MSE: 0.2681761905888393, Learning Rate: 0.088705\n",
      "Epoch: 2260, MSE: 0.2681739729037072, Learning Rate: 0.0887\n",
      "Epoch: 2261, MSE: 0.26817175516956526, Learning Rate: 0.08869500000000001\n",
      "Epoch: 2262, MSE: 0.2681695373864137, Learning Rate: 0.08869\n",
      "Epoch: 2263, MSE: 0.2681673195542504, Learning Rate: 0.08868500000000001\n",
      "Epoch: 2264, MSE: 0.26816510167307533, Learning Rate: 0.08868000000000001\n",
      "Epoch: 2265, MSE: 0.2681628837428872, Learning Rate: 0.088675\n",
      "Epoch: 2266, MSE: 0.268160665763685, Learning Rate: 0.08867000000000001\n",
      "Epoch: 2267, MSE: 0.26815844773546804, Learning Rate: 0.088665\n",
      "Epoch: 2268, MSE: 0.26815622965823593, Learning Rate: 0.08866000000000002\n",
      "Epoch: 2269, MSE: 0.2681540115319871, Learning Rate: 0.088655\n",
      "Epoch: 2270, MSE: 0.2681517933567202, Learning Rate: 0.08865\n",
      "Epoch: 2271, MSE: 0.2681495751324345, Learning Rate: 0.088645\n",
      "Epoch: 2272, MSE: 0.26814735685913016, Learning Rate: 0.08864\n",
      "Epoch: 2273, MSE: 0.2681451385368051, Learning Rate: 0.088635\n",
      "Epoch: 2274, MSE: 0.2681429201654582, Learning Rate: 0.08863\n",
      "Epoch: 2275, MSE: 0.2681407017450892, Learning Rate: 0.08862500000000001\n",
      "Epoch: 2276, MSE: 0.26813848327569756, Learning Rate: 0.08862\n",
      "Epoch: 2277, MSE: 0.2681362647572822, Learning Rate: 0.088615\n",
      "Epoch: 2278, MSE: 0.26813404618984027, Learning Rate: 0.08861000000000001\n",
      "Epoch: 2279, MSE: 0.26813182757337406, Learning Rate: 0.088605\n",
      "Epoch: 2280, MSE: 0.2681296089078805, Learning Rate: 0.08860000000000001\n",
      "Epoch: 2281, MSE: 0.2681273901933593, Learning Rate: 0.08859500000000001\n",
      "Epoch: 2282, MSE: 0.2681251714298085, Learning Rate: 0.08859\n",
      "Epoch: 2283, MSE: 0.26812295261722957, Learning Rate: 0.08858500000000001\n",
      "Epoch: 2284, MSE: 0.26812073375561896, Learning Rate: 0.08858\n",
      "Epoch: 2285, MSE: 0.2681185148449772, Learning Rate: 0.08857500000000001\n",
      "Epoch: 2286, MSE: 0.2681162958853035, Learning Rate: 0.08857000000000001\n",
      "Epoch: 2287, MSE: 0.2681140768765963, Learning Rate: 0.088565\n",
      "Epoch: 2288, MSE: 0.2681118578188551, Learning Rate: 0.08856\n",
      "Epoch: 2289, MSE: 0.2681096387120778, Learning Rate: 0.08855500000000001\n",
      "Epoch: 2290, MSE: 0.2681074195562653, Learning Rate: 0.08855\n",
      "Epoch: 2291, MSE: 0.26810520035141533, Learning Rate: 0.088545\n",
      "Epoch: 2292, MSE: 0.2681029810975276, Learning Rate: 0.08854000000000001\n",
      "Epoch: 2293, MSE: 0.2681007617946009, Learning Rate: 0.088535\n",
      "Epoch: 2294, MSE: 0.2680985424426355, Learning Rate: 0.08853\n",
      "Epoch: 2295, MSE: 0.26809632304162806, Learning Rate: 0.088525\n",
      "Epoch: 2296, MSE: 0.26809410359157976, Learning Rate: 0.08852\n",
      "Epoch: 2297, MSE: 0.26809188409248874, Learning Rate: 0.08851500000000001\n",
      "Epoch: 2298, MSE: 0.2680896645443544, Learning Rate: 0.08851\n",
      "Epoch: 2299, MSE: 0.2680874449471755, Learning Rate: 0.088505\n",
      "Epoch: 2300, MSE: 0.2680852253009512, Learning Rate: 0.08850000000000001\n",
      "Epoch: 2301, MSE: 0.26808300560568105, Learning Rate: 0.088495\n",
      "Epoch: 2302, MSE: 0.26808078586136347, Learning Rate: 0.08849000000000001\n",
      "Epoch: 2303, MSE: 0.26807856606799785, Learning Rate: 0.08848500000000001\n",
      "Epoch: 2304, MSE: 0.2680763462255834, Learning Rate: 0.08848\n",
      "Epoch: 2305, MSE: 0.26807412633411887, Learning Rate: 0.08847500000000001\n",
      "Epoch: 2306, MSE: 0.26807190639360373, Learning Rate: 0.08847000000000001\n",
      "Epoch: 2307, MSE: 0.2680696864040372, Learning Rate: 0.08846500000000002\n",
      "Epoch: 2308, MSE: 0.2680674663654177, Learning Rate: 0.08846000000000001\n",
      "Epoch: 2309, MSE: 0.2680652462777442, Learning Rate: 0.088455\n",
      "Epoch: 2310, MSE: 0.268063026141016, Learning Rate: 0.08845\n",
      "Epoch: 2311, MSE: 0.2680608059552331, Learning Rate: 0.088445\n",
      "Epoch: 2312, MSE: 0.2680585857203942, Learning Rate: 0.08844\n",
      "Epoch: 2313, MSE: 0.2680563654364972, Learning Rate: 0.088435\n",
      "Epoch: 2314, MSE: 0.26805414510354264, Learning Rate: 0.08843000000000001\n",
      "Epoch: 2315, MSE: 0.26805192472152856, Learning Rate: 0.088425\n",
      "Epoch: 2316, MSE: 0.2680497042904548, Learning Rate: 0.08842\n",
      "Epoch: 2317, MSE: 0.26804748381032006, Learning Rate: 0.08841500000000001\n",
      "Epoch: 2318, MSE: 0.2680452632811229, Learning Rate: 0.08841\n",
      "Epoch: 2319, MSE: 0.26804304270286344, Learning Rate: 0.08840500000000001\n",
      "Epoch: 2320, MSE: 0.2680408220755405, Learning Rate: 0.0884\n",
      "Epoch: 2321, MSE: 0.2680386013991525, Learning Rate: 0.088395\n",
      "Epoch: 2322, MSE: 0.268036380673699, Learning Rate: 0.08839000000000001\n",
      "Epoch: 2323, MSE: 0.26803415989917856, Learning Rate: 0.088385\n",
      "Epoch: 2324, MSE: 0.268031939075592, Learning Rate: 0.08838000000000001\n",
      "Epoch: 2325, MSE: 0.26802971820293636, Learning Rate: 0.08837500000000001\n",
      "Epoch: 2326, MSE: 0.2680274972812117, Learning Rate: 0.08837\n",
      "Epoch: 2327, MSE: 0.2680252763104167, Learning Rate: 0.08836500000000001\n",
      "Epoch: 2328, MSE: 0.268023055290551, Learning Rate: 0.08836\n",
      "Epoch: 2329, MSE: 0.2680208342216129, Learning Rate: 0.08835500000000002\n",
      "Epoch: 2330, MSE: 0.2680186131036022, Learning Rate: 0.08835\n",
      "Epoch: 2331, MSE: 0.2680163919365182, Learning Rate: 0.088345\n",
      "Epoch: 2332, MSE: 0.2680141707203579, Learning Rate: 0.08834\n",
      "Epoch: 2333, MSE: 0.26801194945512297, Learning Rate: 0.088335\n",
      "Epoch: 2334, MSE: 0.2680097281408115, Learning Rate: 0.08833\n",
      "Epoch: 2335, MSE: 0.2680075067774221, Learning Rate: 0.088325\n",
      "Epoch: 2336, MSE: 0.26800528536495455, Learning Rate: 0.08832000000000001\n",
      "Epoch: 2337, MSE: 0.26800306390340833, Learning Rate: 0.088315\n",
      "Epoch: 2338, MSE: 0.26800084239278105, Learning Rate: 0.08831\n",
      "Epoch: 2339, MSE: 0.2679986208330729, Learning Rate: 0.08830500000000001\n",
      "Epoch: 2340, MSE: 0.2679963992242828, Learning Rate: 0.0883\n",
      "Epoch: 2341, MSE: 0.2679941775664091, Learning Rate: 0.08829500000000001\n",
      "Epoch: 2342, MSE: 0.2679919558594526, Learning Rate: 0.08829000000000001\n",
      "Epoch: 2343, MSE: 0.26798973410340954, Learning Rate: 0.088285\n",
      "Epoch: 2344, MSE: 0.2679875122982828, Learning Rate: 0.08828000000000001\n",
      "Epoch: 2345, MSE: 0.2679852904440678, Learning Rate: 0.088275\n",
      "Epoch: 2346, MSE: 0.26798306854076626, Learning Rate: 0.08827000000000002\n",
      "Epoch: 2347, MSE: 0.2679808465883759, Learning Rate: 0.08826500000000001\n",
      "Epoch: 2348, MSE: 0.2679786245868957, Learning Rate: 0.08826\n",
      "Epoch: 2349, MSE: 0.26797640253632626, Learning Rate: 0.088255\n",
      "Epoch: 2350, MSE: 0.26797418043666416, Learning Rate: 0.08825000000000001\n",
      "Epoch: 2351, MSE: 0.26797195828791065, Learning Rate: 0.088245\n",
      "Epoch: 2352, MSE: 0.2679697360900637, Learning Rate: 0.08824\n",
      "Epoch: 2353, MSE: 0.26796751384312323, Learning Rate: 0.08823500000000001\n",
      "Epoch: 2354, MSE: 0.2679652915470874, Learning Rate: 0.08823\n",
      "Epoch: 2355, MSE: 0.2679630692019556, Learning Rate: 0.088225\n",
      "Epoch: 2356, MSE: 0.2679608468077279, Learning Rate: 0.08822\n",
      "Epoch: 2357, MSE: 0.26795862436440177, Learning Rate: 0.088215\n",
      "Epoch: 2358, MSE: 0.26795640187197756, Learning Rate: 0.08821000000000001\n",
      "Epoch: 2359, MSE: 0.26795417933045335, Learning Rate: 0.088205\n",
      "Epoch: 2360, MSE: 0.2679519567398294, Learning Rate: 0.0882\n",
      "Epoch: 2361, MSE: 0.2679497341001036, Learning Rate: 0.08819500000000001\n",
      "Epoch: 2362, MSE: 0.26794751141127515, Learning Rate: 0.08819\n",
      "Epoch: 2363, MSE: 0.2679452886733444, Learning Rate: 0.08818500000000001\n",
      "Epoch: 2364, MSE: 0.26794306588630934, Learning Rate: 0.08818000000000001\n",
      "Epoch: 2365, MSE: 0.26794084305016974, Learning Rate: 0.088175\n",
      "Epoch: 2366, MSE: 0.2679386201649232, Learning Rate: 0.08817000000000001\n",
      "Epoch: 2367, MSE: 0.26793639723057044, Learning Rate: 0.08816500000000001\n",
      "Epoch: 2368, MSE: 0.26793417424710997, Learning Rate: 0.08816\n",
      "Epoch: 2369, MSE: 0.2679319512145405, Learning Rate: 0.08815500000000001\n",
      "Epoch: 2370, MSE: 0.26792972813286137, Learning Rate: 0.08815\n",
      "Epoch: 2371, MSE: 0.2679275050020725, Learning Rate: 0.088145\n",
      "Epoch: 2372, MSE: 0.267925281822172, Learning Rate: 0.08814\n",
      "Epoch: 2373, MSE: 0.2679230585931589, Learning Rate: 0.088135\n",
      "Epoch: 2374, MSE: 0.26792083531503286, Learning Rate: 0.08813\n",
      "Epoch: 2375, MSE: 0.2679186119877925, Learning Rate: 0.08812500000000001\n",
      "Epoch: 2376, MSE: 0.2679163886114376, Learning Rate: 0.08812\n",
      "Epoch: 2377, MSE: 0.2679141651859657, Learning Rate: 0.088115\n",
      "Epoch: 2378, MSE: 0.26791194171137767, Learning Rate: 0.08811000000000001\n",
      "Epoch: 2379, MSE: 0.2679097181876718, Learning Rate: 0.088105\n",
      "Epoch: 2380, MSE: 0.2679074946148475, Learning Rate: 0.08810000000000001\n",
      "Epoch: 2381, MSE: 0.2679052709929033, Learning Rate: 0.088095\n",
      "Epoch: 2382, MSE: 0.26790304732183856, Learning Rate: 0.08809\n",
      "Epoch: 2383, MSE: 0.26790082360165196, Learning Rate: 0.08808500000000001\n",
      "Epoch: 2384, MSE: 0.26789859983234365, Learning Rate: 0.08808\n",
      "Epoch: 2385, MSE: 0.26789637601391186, Learning Rate: 0.08807500000000001\n",
      "Epoch: 2386, MSE: 0.26789415214635554, Learning Rate: 0.08807000000000001\n",
      "Epoch: 2387, MSE: 0.2678919282296746, Learning Rate: 0.088065\n",
      "Epoch: 2388, MSE: 0.2678897042638674, Learning Rate: 0.08806000000000001\n",
      "Epoch: 2389, MSE: 0.26788748024893355, Learning Rate: 0.088055\n",
      "Epoch: 2390, MSE: 0.26788525618487113, Learning Rate: 0.08805000000000002\n",
      "Epoch: 2391, MSE: 0.26788303207168096, Learning Rate: 0.088045\n",
      "Epoch: 2392, MSE: 0.2678808079093603, Learning Rate: 0.08804000000000001\n",
      "Epoch: 2393, MSE: 0.2678785836979096, Learning Rate: 0.088035\n",
      "Epoch: 2394, MSE: 0.26787635943732785, Learning Rate: 0.08803\n",
      "Epoch: 2395, MSE: 0.26787413512761254, Learning Rate: 0.088025\n",
      "Epoch: 2396, MSE: 0.26787191076876493, Learning Rate: 0.08802\n",
      "Epoch: 2397, MSE: 0.2678696863607826, Learning Rate: 0.08801500000000001\n",
      "Epoch: 2398, MSE: 0.26786746190366484, Learning Rate: 0.08801\n",
      "Epoch: 2399, MSE: 0.26786523739741197, Learning Rate: 0.088005\n",
      "Epoch: 2400, MSE: 0.2678630128420209, Learning Rate: 0.08800000000000001\n",
      "Epoch: 2401, MSE: 0.26786078823749354, Learning Rate: 0.087995\n",
      "Epoch: 2402, MSE: 0.2678585635838271, Learning Rate: 0.08799000000000001\n",
      "Epoch: 2403, MSE: 0.26785633888102045, Learning Rate: 0.08798500000000001\n",
      "Epoch: 2404, MSE: 0.2678541141290721, Learning Rate: 0.08798\n",
      "Epoch: 2405, MSE: 0.26785188932798376, Learning Rate: 0.08797500000000001\n",
      "Epoch: 2406, MSE: 0.26784966447775316, Learning Rate: 0.08797\n",
      "Epoch: 2407, MSE: 0.26784743957837875, Learning Rate: 0.08796500000000002\n",
      "Epoch: 2408, MSE: 0.26784521462986033, Learning Rate: 0.08796000000000001\n",
      "Epoch: 2409, MSE: 0.2678429896321968, Learning Rate: 0.087955\n",
      "Epoch: 2410, MSE: 0.2678407645853866, Learning Rate: 0.08795\n",
      "Epoch: 2411, MSE: 0.2678385394894295, Learning Rate: 0.087945\n",
      "Epoch: 2412, MSE: 0.26783631434432525, Learning Rate: 0.08794\n",
      "Epoch: 2413, MSE: 0.267834089150072, Learning Rate: 0.087935\n",
      "Epoch: 2414, MSE: 0.2678318639066688, Learning Rate: 0.08793000000000001\n",
      "Epoch: 2415, MSE: 0.2678296386141153, Learning Rate: 0.087925\n",
      "Epoch: 2416, MSE: 0.2678274132724096, Learning Rate: 0.08792\n",
      "Epoch: 2417, MSE: 0.2678251878815527, Learning Rate: 0.08791500000000001\n",
      "Epoch: 2418, MSE: 0.267822962441541, Learning Rate: 0.08791\n",
      "Epoch: 2419, MSE: 0.2678207369523755, Learning Rate: 0.08790500000000001\n",
      "Epoch: 2420, MSE: 0.26781851141405555, Learning Rate: 0.0879\n",
      "Epoch: 2421, MSE: 0.26781628582657935, Learning Rate: 0.087895\n",
      "Epoch: 2422, MSE: 0.2678140601899455, Learning Rate: 0.08789000000000001\n",
      "Epoch: 2423, MSE: 0.26781183450415474, Learning Rate: 0.087885\n",
      "Epoch: 2424, MSE: 0.26780960876920523, Learning Rate: 0.08788000000000001\n",
      "Epoch: 2425, MSE: 0.2678073829850949, Learning Rate: 0.08787500000000001\n",
      "Epoch: 2426, MSE: 0.2678051571518247, Learning Rate: 0.08787\n",
      "Epoch: 2427, MSE: 0.26780293126939303, Learning Rate: 0.08786500000000001\n",
      "Epoch: 2428, MSE: 0.2678007053377981, Learning Rate: 0.08786000000000001\n",
      "Epoch: 2429, MSE: 0.26779847935704115, Learning Rate: 0.087855\n",
      "Epoch: 2430, MSE: 0.2677962533271195, Learning Rate: 0.08785000000000001\n",
      "Epoch: 2431, MSE: 0.2677940272480326, Learning Rate: 0.087845\n",
      "Epoch: 2432, MSE: 0.26779180111978, Learning Rate: 0.08784\n",
      "Epoch: 2433, MSE: 0.26778957494236033, Learning Rate: 0.087835\n",
      "Epoch: 2434, MSE: 0.2677873487157722, Learning Rate: 0.08783\n",
      "Epoch: 2435, MSE: 0.26778512244001607, Learning Rate: 0.087825\n",
      "Epoch: 2436, MSE: 0.26778289611509, Learning Rate: 0.08782000000000001\n",
      "Epoch: 2437, MSE: 0.26778066974099346, Learning Rate: 0.087815\n",
      "Epoch: 2438, MSE: 0.26777844331772493, Learning Rate: 0.08781\n",
      "Epoch: 2439, MSE: 0.26777621684528446, Learning Rate: 0.08780500000000001\n",
      "Epoch: 2440, MSE: 0.26777399032367083, Learning Rate: 0.0878\n",
      "Epoch: 2441, MSE: 0.2677717637528827, Learning Rate: 0.08779500000000001\n",
      "Epoch: 2442, MSE: 0.2677695371329196, Learning Rate: 0.08779\n",
      "Epoch: 2443, MSE: 0.26776731046378055, Learning Rate: 0.087785\n",
      "Epoch: 2444, MSE: 0.26776508374546437, Learning Rate: 0.08778000000000001\n",
      "Epoch: 2445, MSE: 0.2677628569779705, Learning Rate: 0.087775\n",
      "Epoch: 2446, MSE: 0.26776063016129814, Learning Rate: 0.08777000000000001\n",
      "Epoch: 2447, MSE: 0.2677584032954459, Learning Rate: 0.08776500000000001\n",
      "Epoch: 2448, MSE: 0.26775617638041277, Learning Rate: 0.08776\n",
      "Epoch: 2449, MSE: 0.2677539494161987, Learning Rate: 0.08775500000000001\n",
      "Epoch: 2450, MSE: 0.26775172240280204, Learning Rate: 0.08775\n",
      "Epoch: 2451, MSE: 0.26774949534022263, Learning Rate: 0.087745\n",
      "Epoch: 2452, MSE: 0.26774726822845873, Learning Rate: 0.08774\n",
      "Epoch: 2453, MSE: 0.26774504106750935, Learning Rate: 0.08773500000000001\n",
      "Epoch: 2454, MSE: 0.267742813857375, Learning Rate: 0.08773\n",
      "Epoch: 2455, MSE: 0.26774058659805344, Learning Rate: 0.087725\n",
      "Epoch: 2456, MSE: 0.267738359289543, Learning Rate: 0.08772\n",
      "Epoch: 2457, MSE: 0.26773613193184453, Learning Rate: 0.087715\n",
      "Epoch: 2458, MSE: 0.26773390452495743, Learning Rate: 0.08771000000000001\n",
      "Epoch: 2459, MSE: 0.2677316770688792, Learning Rate: 0.087705\n",
      "Epoch: 2460, MSE: 0.26772944956360895, Learning Rate: 0.0877\n",
      "Epoch: 2461, MSE: 0.26772722200914717, Learning Rate: 0.08769500000000001\n",
      "Epoch: 2462, MSE: 0.26772499440549163, Learning Rate: 0.08769\n",
      "Epoch: 2463, MSE: 0.2677227667526421, Learning Rate: 0.08768500000000001\n",
      "Epoch: 2464, MSE: 0.2677205390505978, Learning Rate: 0.08768000000000001\n",
      "Epoch: 2465, MSE: 0.2677183112993582, Learning Rate: 0.087675\n",
      "Epoch: 2466, MSE: 0.2677160834989211, Learning Rate: 0.08767000000000001\n",
      "Epoch: 2467, MSE: 0.26771385564928646, Learning Rate: 0.087665\n",
      "Epoch: 2468, MSE: 0.26771162775045243, Learning Rate: 0.08766000000000002\n",
      "Epoch: 2469, MSE: 0.2677093998024201, Learning Rate: 0.087655\n",
      "Epoch: 2470, MSE: 0.2677071718051866, Learning Rate: 0.08765\n",
      "Epoch: 2471, MSE: 0.2677049437587519, Learning Rate: 0.087645\n",
      "Epoch: 2472, MSE: 0.26770271566311504, Learning Rate: 0.08764\n",
      "Epoch: 2473, MSE: 0.2677004875182752, Learning Rate: 0.087635\n",
      "Epoch: 2474, MSE: 0.26769825932423064, Learning Rate: 0.08763\n",
      "Epoch: 2475, MSE: 0.2676960310809825, Learning Rate: 0.08762500000000001\n",
      "Epoch: 2476, MSE: 0.2676938027885278, Learning Rate: 0.08762\n",
      "Epoch: 2477, MSE: 0.2676915744468665, Learning Rate: 0.087615\n",
      "Epoch: 2478, MSE: 0.26768934605599715, Learning Rate: 0.08761000000000001\n",
      "Epoch: 2479, MSE: 0.2676871176159201, Learning Rate: 0.087605\n",
      "Epoch: 2480, MSE: 0.26768488912663196, Learning Rate: 0.08760000000000001\n",
      "Epoch: 2481, MSE: 0.267682660588135, Learning Rate: 0.087595\n",
      "Epoch: 2482, MSE: 0.26768043200042635, Learning Rate: 0.08759\n",
      "Epoch: 2483, MSE: 0.2676782033635055, Learning Rate: 0.08758500000000001\n",
      "Epoch: 2484, MSE: 0.267675974677372, Learning Rate: 0.08758\n",
      "Epoch: 2485, MSE: 0.2676737459420239, Learning Rate: 0.08757500000000001\n",
      "Epoch: 2486, MSE: 0.26767151715746157, Learning Rate: 0.08757000000000001\n",
      "Epoch: 2487, MSE: 0.2676692883236831, Learning Rate: 0.087565\n",
      "Epoch: 2488, MSE: 0.26766705944068836, Learning Rate: 0.08756000000000001\n",
      "Epoch: 2489, MSE: 0.2676648305084758, Learning Rate: 0.08755500000000001\n",
      "Epoch: 2490, MSE: 0.26766260152704496, Learning Rate: 0.08755\n",
      "Epoch: 2491, MSE: 0.26766037249639446, Learning Rate: 0.08754500000000001\n",
      "Epoch: 2492, MSE: 0.2676581434165244, Learning Rate: 0.08754\n",
      "Epoch: 2493, MSE: 0.2676559142874327, Learning Rate: 0.087535\n",
      "Epoch: 2494, MSE: 0.26765368510911886, Learning Rate: 0.08753\n",
      "Epoch: 2495, MSE: 0.2676514558815821, Learning Rate: 0.087525\n",
      "Epoch: 2496, MSE: 0.26764922660482193, Learning Rate: 0.08752\n",
      "Epoch: 2497, MSE: 0.2676469972788367, Learning Rate: 0.08751500000000001\n",
      "Epoch: 2498, MSE: 0.26764476790362607, Learning Rate: 0.08751\n",
      "Epoch: 2499, MSE: 0.26764253847918845, Learning Rate: 0.087505\n",
      "Epoch: 2500, MSE: 0.2676403090055242, Learning Rate: 0.08750000000000001\n",
      "Epoch: 2501, MSE: 0.26763807948263085, Learning Rate: 0.087495\n",
      "Epoch: 2502, MSE: 0.2676358499105088, Learning Rate: 0.08749000000000001\n",
      "Epoch: 2503, MSE: 0.2676336202891566, Learning Rate: 0.08748500000000001\n",
      "Epoch: 2504, MSE: 0.2676313906185726, Learning Rate: 0.08748\n",
      "Epoch: 2505, MSE: 0.2676291608987575, Learning Rate: 0.08747500000000001\n",
      "Epoch: 2506, MSE: 0.26762693112970937, Learning Rate: 0.08747\n",
      "Epoch: 2507, MSE: 0.2676247013114273, Learning Rate: 0.08746500000000001\n",
      "Epoch: 2508, MSE: 0.26762247144391105, Learning Rate: 0.08746000000000001\n",
      "Epoch: 2509, MSE: 0.26762024152715924, Learning Rate: 0.087455\n",
      "Epoch: 2510, MSE: 0.26761801156117127, Learning Rate: 0.08745000000000001\n",
      "Epoch: 2511, MSE: 0.2676157815459451, Learning Rate: 0.087445\n",
      "Epoch: 2512, MSE: 0.26761355148148136, Learning Rate: 0.08744000000000002\n",
      "Epoch: 2513, MSE: 0.26761132136777843, Learning Rate: 0.087435\n",
      "Epoch: 2514, MSE: 0.26760909120483634, Learning Rate: 0.08743000000000001\n",
      "Epoch: 2515, MSE: 0.2676068609926522, Learning Rate: 0.087425\n",
      "Epoch: 2516, MSE: 0.26760463073122653, Learning Rate: 0.08742\n",
      "Epoch: 2517, MSE: 0.26760240042055805, Learning Rate: 0.087415\n",
      "Epoch: 2518, MSE: 0.26760017006064674, Learning Rate: 0.08741\n",
      "Epoch: 2519, MSE: 0.26759793965148976, Learning Rate: 0.08740500000000001\n",
      "Epoch: 2520, MSE: 0.26759570919308906, Learning Rate: 0.0874\n",
      "Epoch: 2521, MSE: 0.26759347868544053, Learning Rate: 0.087395\n",
      "Epoch: 2522, MSE: 0.26759124812854523, Learning Rate: 0.08739000000000001\n",
      "Epoch: 2523, MSE: 0.26758901752240244, Learning Rate: 0.087385\n",
      "Epoch: 2524, MSE: 0.2675867868670105, Learning Rate: 0.08738000000000001\n",
      "Epoch: 2525, MSE: 0.2675845561623687, Learning Rate: 0.08737500000000001\n",
      "Epoch: 2526, MSE: 0.2675823254084762, Learning Rate: 0.08737\n",
      "Epoch: 2527, MSE: 0.2675800946053322, Learning Rate: 0.08736500000000001\n",
      "Epoch: 2528, MSE: 0.26757786375293546, Learning Rate: 0.08736\n",
      "Epoch: 2529, MSE: 0.26757563285128566, Learning Rate: 0.08735500000000002\n",
      "Epoch: 2530, MSE: 0.26757340190038, Learning Rate: 0.08735\n",
      "Epoch: 2531, MSE: 0.2675711709002211, Learning Rate: 0.087345\n",
      "Epoch: 2532, MSE: 0.2675689398508054, Learning Rate: 0.08734\n",
      "Epoch: 2533, MSE: 0.2675667087521325, Learning Rate: 0.087335\n",
      "Epoch: 2534, MSE: 0.267564477604202, Learning Rate: 0.08733\n",
      "Epoch: 2535, MSE: 0.26756224640701315, Learning Rate: 0.087325\n",
      "Epoch: 2536, MSE: 0.2675600151605643, Learning Rate: 0.08732000000000001\n",
      "Epoch: 2537, MSE: 0.2675577838648536, Learning Rate: 0.087315\n",
      "Epoch: 2538, MSE: 0.26755555251988294, Learning Rate: 0.08731\n",
      "Epoch: 2539, MSE: 0.2675533211256491, Learning Rate: 0.08730500000000001\n",
      "Epoch: 2540, MSE: 0.2675510896821526, Learning Rate: 0.0873\n",
      "Epoch: 2541, MSE: 0.26754885818939206, Learning Rate: 0.08729500000000001\n",
      "Epoch: 2542, MSE: 0.2675466266473664, Learning Rate: 0.08729\n",
      "Epoch: 2543, MSE: 0.2675443950560753, Learning Rate: 0.087285\n",
      "Epoch: 2544, MSE: 0.2675421634155159, Learning Rate: 0.08728000000000001\n",
      "Epoch: 2545, MSE: 0.26753993172568963, Learning Rate: 0.087275\n",
      "Epoch: 2546, MSE: 0.2675376999865953, Learning Rate: 0.08727000000000001\n",
      "Epoch: 2547, MSE: 0.2675354681982312, Learning Rate: 0.08726500000000001\n",
      "Epoch: 2548, MSE: 0.2675332363605967, Learning Rate: 0.08726\n",
      "Epoch: 2549, MSE: 0.26753100447369094, Learning Rate: 0.087255\n",
      "Epoch: 2550, MSE: 0.26752877253751234, Learning Rate: 0.08725000000000001\n",
      "Epoch: 2551, MSE: 0.2675265405520617, Learning Rate: 0.087245\n",
      "Epoch: 2552, MSE: 0.2675243085173357, Learning Rate: 0.08724000000000001\n",
      "Epoch: 2553, MSE: 0.26752207643333686, Learning Rate: 0.08723500000000001\n",
      "Epoch: 2554, MSE: 0.2675198443000609, Learning Rate: 0.08723\n",
      "Epoch: 2555, MSE: 0.2675176121175085, Learning Rate: 0.087225\n",
      "Epoch: 2556, MSE: 0.26751537988567864, Learning Rate: 0.08722\n",
      "Epoch: 2557, MSE: 0.267513147604571, Learning Rate: 0.087215\n",
      "Epoch: 2558, MSE: 0.26751091527418325, Learning Rate: 0.08721000000000001\n",
      "Epoch: 2559, MSE: 0.2675086828945158, Learning Rate: 0.087205\n",
      "Epoch: 2560, MSE: 0.2675064504655669, Learning Rate: 0.0872\n",
      "Epoch: 2561, MSE: 0.26750421798733676, Learning Rate: 0.08719500000000001\n",
      "Epoch: 2562, MSE: 0.26750198545982334, Learning Rate: 0.08719\n",
      "Epoch: 2563, MSE: 0.267499752883026, Learning Rate: 0.08718500000000001\n",
      "Epoch: 2564, MSE: 0.26749752025694423, Learning Rate: 0.08718000000000001\n",
      "Epoch: 2565, MSE: 0.26749528758157765, Learning Rate: 0.087175\n",
      "Epoch: 2566, MSE: 0.2674930548569242, Learning Rate: 0.08717000000000001\n",
      "Epoch: 2567, MSE: 0.26749082208298275, Learning Rate: 0.087165\n",
      "Epoch: 2568, MSE: 0.26748858925975355, Learning Rate: 0.08716000000000002\n",
      "Epoch: 2569, MSE: 0.2674863563872359, Learning Rate: 0.08715500000000001\n",
      "Epoch: 2570, MSE: 0.267484123465427, Learning Rate: 0.08715\n",
      "Epoch: 2571, MSE: 0.26748189049432874, Learning Rate: 0.08714500000000001\n",
      "Epoch: 2572, MSE: 0.2674796574739377, Learning Rate: 0.08714\n",
      "Epoch: 2573, MSE: 0.26747742440425454, Learning Rate: 0.08713500000000002\n",
      "Epoch: 2574, MSE: 0.26747519128527786, Learning Rate: 0.08713\n",
      "Epoch: 2575, MSE: 0.26747295811700705, Learning Rate: 0.08712500000000001\n",
      "Epoch: 2576, MSE: 0.26747072489944057, Learning Rate: 0.08712\n",
      "Epoch: 2577, MSE: 0.2674684916325778, Learning Rate: 0.087115\n",
      "Epoch: 2578, MSE: 0.2674662583164178, Learning Rate: 0.08711\n",
      "Epoch: 2579, MSE: 0.2674640249509608, Learning Rate: 0.087105\n",
      "Epoch: 2580, MSE: 0.2674617915362042, Learning Rate: 0.08710000000000001\n",
      "Epoch: 2581, MSE: 0.26745955807214783, Learning Rate: 0.087095\n",
      "Epoch: 2582, MSE: 0.26745732455879195, Learning Rate: 0.08709\n",
      "Epoch: 2583, MSE: 0.26745509099613335, Learning Rate: 0.08708500000000001\n",
      "Epoch: 2584, MSE: 0.26745285738417307, Learning Rate: 0.08708\n",
      "Epoch: 2585, MSE: 0.2674506237229089, Learning Rate: 0.08707500000000001\n",
      "Epoch: 2586, MSE: 0.26744839001234105, Learning Rate: 0.08707000000000001\n",
      "Epoch: 2587, MSE: 0.2674461562524679, Learning Rate: 0.087065\n",
      "Epoch: 2588, MSE: 0.26744392244328974, Learning Rate: 0.08706000000000001\n",
      "Epoch: 2589, MSE: 0.2674416885848037, Learning Rate: 0.087055\n",
      "Epoch: 2590, MSE: 0.26743945467701025, Learning Rate: 0.08705000000000002\n",
      "Epoch: 2591, MSE: 0.2674372207199081, Learning Rate: 0.087045\n",
      "Epoch: 2592, MSE: 0.2674349867134971, Learning Rate: 0.08704\n",
      "Epoch: 2593, MSE: 0.2674327526577759, Learning Rate: 0.087035\n",
      "Epoch: 2594, MSE: 0.2674305185527433, Learning Rate: 0.08703\n",
      "Epoch: 2595, MSE: 0.267428284398398, Learning Rate: 0.087025\n",
      "Epoch: 2596, MSE: 0.26742605019474003, Learning Rate: 0.08702\n",
      "Epoch: 2597, MSE: 0.2674238159417684, Learning Rate: 0.08701500000000001\n",
      "Epoch: 2598, MSE: 0.2674215816394817, Learning Rate: 0.08701\n",
      "Epoch: 2599, MSE: 0.26741934728787947, Learning Rate: 0.087005\n",
      "Epoch: 2600, MSE: 0.2674171128869606, Learning Rate: 0.08700000000000001\n",
      "Epoch: 2601, MSE: 0.26741487843672457, Learning Rate: 0.086995\n",
      "Epoch: 2602, MSE: 0.2674126439371708, Learning Rate: 0.08699000000000001\n",
      "Epoch: 2603, MSE: 0.2674104093882967, Learning Rate: 0.086985\n",
      "Epoch: 2604, MSE: 0.26740817479010276, Learning Rate: 0.08698\n",
      "Epoch: 2605, MSE: 0.2674059401425883, Learning Rate: 0.08697500000000001\n",
      "Epoch: 2606, MSE: 0.26740370544575204, Learning Rate: 0.08697\n",
      "Epoch: 2607, MSE: 0.26740147069959347, Learning Rate: 0.08696500000000001\n",
      "Epoch: 2608, MSE: 0.2673992359041105, Learning Rate: 0.08696000000000001\n",
      "Epoch: 2609, MSE: 0.26739700105930314, Learning Rate: 0.086955\n",
      "Epoch: 2610, MSE: 0.26739476616517066, Learning Rate: 0.08695\n",
      "Epoch: 2611, MSE: 0.2673925312217121, Learning Rate: 0.08694500000000001\n",
      "Epoch: 2612, MSE: 0.26739029622892635, Learning Rate: 0.08694\n",
      "Epoch: 2613, MSE: 0.26738806118681196, Learning Rate: 0.08693500000000001\n",
      "Epoch: 2614, MSE: 0.26738582609537015, Learning Rate: 0.08693000000000001\n",
      "Epoch: 2615, MSE: 0.2673835909545975, Learning Rate: 0.086925\n",
      "Epoch: 2616, MSE: 0.267381355764495, Learning Rate: 0.08692\n",
      "Epoch: 2617, MSE: 0.26737912052505997, Learning Rate: 0.086915\n",
      "Epoch: 2618, MSE: 0.2673768852362925, Learning Rate: 0.08691\n",
      "Epoch: 2619, MSE: 0.2673746498981922, Learning Rate: 0.08690500000000001\n",
      "Epoch: 2620, MSE: 0.2673724145107579, Learning Rate: 0.0869\n",
      "Epoch: 2621, MSE: 0.26737017907398886, Learning Rate: 0.086895\n",
      "Epoch: 2622, MSE: 0.26736794358788313, Learning Rate: 0.08689000000000001\n",
      "Epoch: 2623, MSE: 0.26736570805244103, Learning Rate: 0.086885\n",
      "Epoch: 2624, MSE: 0.2673634724676614, Learning Rate: 0.08688000000000001\n",
      "Epoch: 2625, MSE: 0.2673612368335431, Learning Rate: 0.08687500000000001\n",
      "Epoch: 2626, MSE: 0.26735900115008576, Learning Rate: 0.08687\n",
      "Epoch: 2627, MSE: 0.26735676541728687, Learning Rate: 0.08686500000000001\n",
      "Epoch: 2628, MSE: 0.267354529635147, Learning Rate: 0.08686\n",
      "Epoch: 2629, MSE: 0.2673522938036662, Learning Rate: 0.086855\n",
      "Epoch: 2630, MSE: 0.26735005792284183, Learning Rate: 0.08685000000000001\n",
      "Epoch: 2631, MSE: 0.2673478219926736, Learning Rate: 0.086845\n",
      "Epoch: 2632, MSE: 0.26734558601316005, Learning Rate: 0.08684000000000001\n",
      "Epoch: 2633, MSE: 0.2673433499843019, Learning Rate: 0.086835\n",
      "Epoch: 2634, MSE: 0.26734111390609716, Learning Rate: 0.08683\n",
      "Epoch: 2635, MSE: 0.26733887777854404, Learning Rate: 0.086825\n",
      "Epoch: 2636, MSE: 0.2673366416016448, Learning Rate: 0.08682000000000001\n",
      "Epoch: 2637, MSE: 0.26733440537539477, Learning Rate: 0.086815\n",
      "Epoch: 2638, MSE: 0.2673321690997947, Learning Rate: 0.08681\n",
      "Epoch: 2639, MSE: 0.26732993277484435, Learning Rate: 0.08680500000000001\n",
      "Epoch: 2640, MSE: 0.26732769640054277, Learning Rate: 0.0868\n",
      "Epoch: 2641, MSE: 0.26732545997688695, Learning Rate: 0.08679500000000001\n",
      "Epoch: 2642, MSE: 0.2673232235038787, Learning Rate: 0.08679\n",
      "Epoch: 2643, MSE: 0.26732098698151596, Learning Rate: 0.086785\n",
      "Epoch: 2644, MSE: 0.2673187504097981, Learning Rate: 0.08678000000000001\n",
      "Epoch: 2645, MSE: 0.26731651378872423, Learning Rate: 0.086775\n",
      "Epoch: 2646, MSE: 0.2673142771182932, Learning Rate: 0.08677000000000001\n",
      "Epoch: 2647, MSE: 0.26731204039850415, Learning Rate: 0.08676500000000001\n",
      "Epoch: 2648, MSE: 0.2673098036293567, Learning Rate: 0.08676\n",
      "Epoch: 2649, MSE: 0.267307566810849, Learning Rate: 0.08675500000000001\n",
      "Epoch: 2650, MSE: 0.2673053299429818, Learning Rate: 0.08675\n",
      "Epoch: 2651, MSE: 0.26730309302575245, Learning Rate: 0.08674500000000002\n",
      "Epoch: 2652, MSE: 0.2673008560591611, Learning Rate: 0.08674\n",
      "Epoch: 2653, MSE: 0.2672986190432061, Learning Rate: 0.086735\n",
      "Epoch: 2654, MSE: 0.26729638197788774, Learning Rate: 0.08673\n",
      "Epoch: 2655, MSE: 0.26729414486320446, Learning Rate: 0.086725\n",
      "Epoch: 2656, MSE: 0.2672919076991555, Learning Rate: 0.08672\n",
      "Epoch: 2657, MSE: 0.26728967048574015, Learning Rate: 0.086715\n",
      "Epoch: 2658, MSE: 0.2672874332229562, Learning Rate: 0.08671000000000001\n",
      "Epoch: 2659, MSE: 0.26728519591080485, Learning Rate: 0.086705\n",
      "Epoch: 2660, MSE: 0.2672829585492837, Learning Rate: 0.0867\n",
      "Epoch: 2661, MSE: 0.2672807211383924, Learning Rate: 0.08669500000000001\n",
      "Epoch: 2662, MSE: 0.2672784836781306, Learning Rate: 0.08669\n",
      "Epoch: 2663, MSE: 0.2672762461684966, Learning Rate: 0.08668500000000001\n",
      "Epoch: 2664, MSE: 0.26727400860949063, Learning Rate: 0.08668000000000001\n",
      "Epoch: 2665, MSE: 0.2672717710011097, Learning Rate: 0.086675\n",
      "Epoch: 2666, MSE: 0.2672695333433556, Learning Rate: 0.08667000000000001\n",
      "Epoch: 2667, MSE: 0.2672672956362251, Learning Rate: 0.086665\n",
      "Epoch: 2668, MSE: 0.2672650578797188, Learning Rate: 0.08666000000000001\n",
      "Epoch: 2669, MSE: 0.26726282007383523, Learning Rate: 0.086655\n",
      "Epoch: 2670, MSE: 0.26726058221857446, Learning Rate: 0.08665\n",
      "Epoch: 2671, MSE: 0.2672583443139343, Learning Rate: 0.086645\n",
      "Epoch: 2672, MSE: 0.26725610635991426, Learning Rate: 0.08664000000000001\n",
      "Epoch: 2673, MSE: 0.2672538683565135, Learning Rate: 0.086635\n",
      "Epoch: 2674, MSE: 0.2672516303037315, Learning Rate: 0.08663\n",
      "Epoch: 2675, MSE: 0.2672493922015673, Learning Rate: 0.08662500000000001\n",
      "Epoch: 2676, MSE: 0.26724715405001936, Learning Rate: 0.08662\n",
      "Epoch: 2677, MSE: 0.26724491584908766, Learning Rate: 0.086615\n",
      "Epoch: 2678, MSE: 0.26724267759877146, Learning Rate: 0.08661\n",
      "Epoch: 2679, MSE: 0.2672404392990686, Learning Rate: 0.086605\n",
      "Epoch: 2680, MSE: 0.2672382009499795, Learning Rate: 0.08660000000000001\n",
      "Epoch: 2681, MSE: 0.2672359625515034, Learning Rate: 0.086595\n",
      "Epoch: 2682, MSE: 0.26723372410363794, Learning Rate: 0.08659\n",
      "Epoch: 2683, MSE: 0.267231485606384, Learning Rate: 0.08658500000000001\n",
      "Epoch: 2684, MSE: 0.2672292470597391, Learning Rate: 0.08658\n",
      "Epoch: 2685, MSE: 0.267227008463704, Learning Rate: 0.08657500000000001\n",
      "Epoch: 2686, MSE: 0.2672247698182759, Learning Rate: 0.08657000000000001\n",
      "Epoch: 2687, MSE: 0.2672225311234555, Learning Rate: 0.086565\n",
      "Epoch: 2688, MSE: 0.2672202923792419, Learning Rate: 0.08656000000000001\n",
      "Epoch: 2689, MSE: 0.2672180535856328, Learning Rate: 0.086555\n",
      "Epoch: 2690, MSE: 0.2672158147426294, Learning Rate: 0.08655\n",
      "Epoch: 2691, MSE: 0.26721357585022937, Learning Rate: 0.08654500000000001\n",
      "Epoch: 2692, MSE: 0.2672113369084315, Learning Rate: 0.08654\n",
      "Epoch: 2693, MSE: 0.2672090979172372, Learning Rate: 0.08653500000000001\n",
      "Epoch: 2694, MSE: 0.26720685887664236, Learning Rate: 0.08653\n",
      "Epoch: 2695, MSE: 0.2672046197866482, Learning Rate: 0.086525\n",
      "Epoch: 2696, MSE: 0.26720238064725416, Learning Rate: 0.08652\n",
      "Epoch: 2697, MSE: 0.26720014145845783, Learning Rate: 0.08651500000000001\n",
      "Epoch: 2698, MSE: 0.2671979022202591, Learning Rate: 0.08651\n",
      "Epoch: 2699, MSE: 0.26719566293265823, Learning Rate: 0.086505\n",
      "Epoch: 2700, MSE: 0.26719342359565246, Learning Rate: 0.08650000000000001\n",
      "Epoch: 2701, MSE: 0.26719118420924204, Learning Rate: 0.086495\n",
      "Epoch: 2702, MSE: 0.26718894477342575, Learning Rate: 0.08649000000000001\n",
      "Epoch: 2703, MSE: 0.2671867052882028, Learning Rate: 0.086485\n",
      "Epoch: 2704, MSE: 0.267184465753572, Learning Rate: 0.08648\n",
      "Epoch: 2705, MSE: 0.2671822261695333, Learning Rate: 0.08647500000000001\n",
      "Epoch: 2706, MSE: 0.2671799865360853, Learning Rate: 0.08647\n",
      "Epoch: 2707, MSE: 0.2671777468532267, Learning Rate: 0.08646500000000001\n",
      "Epoch: 2708, MSE: 0.2671755071209577, Learning Rate: 0.08646000000000001\n",
      "Epoch: 2709, MSE: 0.2671732673392759, Learning Rate: 0.086455\n",
      "Epoch: 2710, MSE: 0.2671710275081822, Learning Rate: 0.08645000000000001\n",
      "Epoch: 2711, MSE: 0.26716878762767465, Learning Rate: 0.086445\n",
      "Epoch: 2712, MSE: 0.26716654769775244, Learning Rate: 0.08644000000000002\n",
      "Epoch: 2713, MSE: 0.26716430771841504, Learning Rate: 0.086435\n",
      "Epoch: 2714, MSE: 0.26716206768966133, Learning Rate: 0.08643\n",
      "Epoch: 2715, MSE: 0.2671598276114908, Learning Rate: 0.086425\n",
      "Epoch: 2716, MSE: 0.2671575874839023, Learning Rate: 0.08642\n",
      "Epoch: 2717, MSE: 0.26715534730689516, Learning Rate: 0.086415\n",
      "Epoch: 2718, MSE: 0.26715310708046774, Learning Rate: 0.08641\n",
      "Epoch: 2719, MSE: 0.26715086680462047, Learning Rate: 0.08640500000000001\n",
      "Epoch: 2720, MSE: 0.2671486264793515, Learning Rate: 0.0864\n",
      "Epoch: 2721, MSE: 0.2671463861046601, Learning Rate: 0.086395\n",
      "Epoch: 2722, MSE: 0.26714414568054545, Learning Rate: 0.08639000000000001\n",
      "Epoch: 2723, MSE: 0.2671419052070076, Learning Rate: 0.086385\n",
      "Epoch: 2724, MSE: 0.2671396646840441, Learning Rate: 0.08638000000000001\n",
      "Epoch: 2725, MSE: 0.2671374241116553, Learning Rate: 0.08637500000000001\n",
      "Epoch: 2726, MSE: 0.2671351834898402, Learning Rate: 0.08637\n",
      "Epoch: 2727, MSE: 0.2671329428185975, Learning Rate: 0.08636500000000001\n",
      "Epoch: 2728, MSE: 0.2671307020979262, Learning Rate: 0.08636\n",
      "Epoch: 2729, MSE: 0.26712846132782575, Learning Rate: 0.08635500000000002\n",
      "Epoch: 2730, MSE: 0.26712622050829476, Learning Rate: 0.08635\n",
      "Epoch: 2731, MSE: 0.2671239796393345, Learning Rate: 0.086345\n",
      "Epoch: 2732, MSE: 0.26712173872094086, Learning Rate: 0.08634\n",
      "Epoch: 2733, MSE: 0.26711949775311555, Learning Rate: 0.08633500000000001\n",
      "Epoch: 2734, MSE: 0.2671172567358564, Learning Rate: 0.08633\n",
      "Epoch: 2735, MSE: 0.2671150156691626, Learning Rate: 0.086325\n",
      "Epoch: 2736, MSE: 0.26711277455303467, Learning Rate: 0.08632000000000001\n",
      "Epoch: 2737, MSE: 0.26711053338747026, Learning Rate: 0.086315\n",
      "Epoch: 2738, MSE: 0.2671082921724686, Learning Rate: 0.08631\n",
      "Epoch: 2739, MSE: 0.2671060509080295, Learning Rate: 0.086305\n",
      "Epoch: 2740, MSE: 0.26710380959415114, Learning Rate: 0.0863\n",
      "Epoch: 2741, MSE: 0.2671015682308343, Learning Rate: 0.08629500000000001\n",
      "Epoch: 2742, MSE: 0.2670993268180763, Learning Rate: 0.08629\n",
      "Epoch: 2743, MSE: 0.26709708535587734, Learning Rate: 0.086285\n",
      "Epoch: 2744, MSE: 0.267094843844236, Learning Rate: 0.08628000000000001\n",
      "Epoch: 2745, MSE: 0.26709260228315235, Learning Rate: 0.086275\n",
      "Epoch: 2746, MSE: 0.267090360672624, Learning Rate: 0.08627000000000001\n",
      "Epoch: 2747, MSE: 0.267088119012652, Learning Rate: 0.08626500000000001\n",
      "Epoch: 2748, MSE: 0.26708587730323335, Learning Rate: 0.08626\n",
      "Epoch: 2749, MSE: 0.2670836355443698, Learning Rate: 0.08625500000000001\n",
      "Epoch: 2750, MSE: 0.26708139373605816, Learning Rate: 0.08625000000000001\n",
      "Epoch: 2751, MSE: 0.26707915187829856, Learning Rate: 0.086245\n",
      "Epoch: 2752, MSE: 0.26707690997108946, Learning Rate: 0.08624000000000001\n",
      "Epoch: 2753, MSE: 0.267074668014431, Learning Rate: 0.086235\n",
      "Epoch: 2754, MSE: 0.2670724260083213, Learning Rate: 0.08623000000000001\n",
      "Epoch: 2755, MSE: 0.267070183952761, Learning Rate: 0.086225\n",
      "Epoch: 2756, MSE: 0.26706794184774824, Learning Rate: 0.08622\n",
      "Epoch: 2757, MSE: 0.2670656996932818, Learning Rate: 0.086215\n",
      "Epoch: 2758, MSE: 0.26706345748936167, Learning Rate: 0.08621000000000001\n",
      "Epoch: 2759, MSE: 0.2670612152359862, Learning Rate: 0.086205\n",
      "Epoch: 2760, MSE: 0.2670589729331552, Learning Rate: 0.0862\n",
      "Epoch: 2761, MSE: 0.26705673058086804, Learning Rate: 0.08619500000000001\n",
      "Epoch: 2762, MSE: 0.2670544881791224, Learning Rate: 0.08619\n",
      "Epoch: 2763, MSE: 0.2670522457279182, Learning Rate: 0.08618500000000001\n",
      "Epoch: 2764, MSE: 0.2670500032272552, Learning Rate: 0.08618\n",
      "Epoch: 2765, MSE: 0.2670477606771321, Learning Rate: 0.086175\n",
      "Epoch: 2766, MSE: 0.26704551807754856, Learning Rate: 0.08617000000000001\n",
      "Epoch: 2767, MSE: 0.26704327542850204, Learning Rate: 0.086165\n",
      "Epoch: 2768, MSE: 0.2670410327299943, Learning Rate: 0.08616000000000001\n",
      "Epoch: 2769, MSE: 0.267038789982022, Learning Rate: 0.08615500000000001\n",
      "Epoch: 2770, MSE: 0.2670365471845851, Learning Rate: 0.08615\n",
      "Epoch: 2771, MSE: 0.26703430433768394, Learning Rate: 0.08614500000000001\n",
      "Epoch: 2772, MSE: 0.26703206144131675, Learning Rate: 0.08614\n",
      "Epoch: 2773, MSE: 0.2670298184954818, Learning Rate: 0.08613500000000002\n",
      "Epoch: 2774, MSE: 0.2670275755001793, Learning Rate: 0.08613\n",
      "Epoch: 2775, MSE: 0.2670253324554078, Learning Rate: 0.08612500000000001\n",
      "Epoch: 2776, MSE: 0.26702308936116714, Learning Rate: 0.08612\n",
      "Epoch: 2777, MSE: 0.2670208462174565, Learning Rate: 0.086115\n",
      "Epoch: 2778, MSE: 0.2670186030242749, Learning Rate: 0.08611\n",
      "Epoch: 2779, MSE: 0.26701635978162014, Learning Rate: 0.086105\n",
      "Epoch: 2780, MSE: 0.26701411648949247, Learning Rate: 0.08610000000000001\n",
      "Epoch: 2781, MSE: 0.26701187314789215, Learning Rate: 0.086095\n",
      "Epoch: 2782, MSE: 0.26700962975681647, Learning Rate: 0.08609\n",
      "Epoch: 2783, MSE: 0.2670073863162656, Learning Rate: 0.08608500000000001\n",
      "Epoch: 2784, MSE: 0.26700514282623744, Learning Rate: 0.08608\n",
      "Epoch: 2785, MSE: 0.26700289928673326, Learning Rate: 0.08607500000000001\n",
      "Epoch: 2786, MSE: 0.2670006556977507, Learning Rate: 0.08607000000000001\n",
      "Epoch: 2787, MSE: 0.26699841205928904, Learning Rate: 0.086065\n",
      "Epoch: 2788, MSE: 0.26699616837134776, Learning Rate: 0.08606000000000001\n",
      "Epoch: 2789, MSE: 0.26699392463392585, Learning Rate: 0.086055\n",
      "Epoch: 2790, MSE: 0.2669916808470222, Learning Rate: 0.08605000000000002\n",
      "Epoch: 2791, MSE: 0.26698943701063693, Learning Rate: 0.086045\n",
      "Epoch: 2792, MSE: 0.26698719312476815, Learning Rate: 0.08604\n",
      "Epoch: 2793, MSE: 0.26698494918941507, Learning Rate: 0.086035\n",
      "Epoch: 2794, MSE: 0.26698270520457734, Learning Rate: 0.08603000000000001\n",
      "Epoch: 2795, MSE: 0.26698046117025426, Learning Rate: 0.086025\n",
      "Epoch: 2796, MSE: 0.2669782170864443, Learning Rate: 0.08602\n",
      "Epoch: 2797, MSE: 0.2669759729531472, Learning Rate: 0.08601500000000001\n",
      "Epoch: 2798, MSE: 0.26697372877036096, Learning Rate: 0.08601\n",
      "Epoch: 2799, MSE: 0.266971484538087, Learning Rate: 0.086005\n",
      "Epoch: 2800, MSE: 0.2669692402563214, Learning Rate: 0.08600000000000001\n",
      "Epoch: 2801, MSE: 0.26696699592506656, Learning Rate: 0.085995\n",
      "Epoch: 2802, MSE: 0.2669647515443189, Learning Rate: 0.08599000000000001\n",
      "Epoch: 2803, MSE: 0.26696250711407987, Learning Rate: 0.085985\n",
      "Epoch: 2804, MSE: 0.26696026263434636, Learning Rate: 0.08598\n",
      "Epoch: 2805, MSE: 0.2669580181051195, Learning Rate: 0.08597500000000001\n",
      "Epoch: 2806, MSE: 0.2669557735263972, Learning Rate: 0.08597\n",
      "Epoch: 2807, MSE: 0.26695352889817897, Learning Rate: 0.08596500000000001\n",
      "Epoch: 2808, MSE: 0.266951284220464, Learning Rate: 0.08596000000000001\n",
      "Epoch: 2809, MSE: 0.26694903949325166, Learning Rate: 0.085955\n",
      "Epoch: 2810, MSE: 0.2669467947165405, Learning Rate: 0.08595\n",
      "Epoch: 2811, MSE: 0.2669445498903299, Learning Rate: 0.08594500000000001\n",
      "Epoch: 2812, MSE: 0.2669423050146192, Learning Rate: 0.08594\n",
      "Epoch: 2813, MSE: 0.2669400600894086, Learning Rate: 0.08593500000000001\n",
      "Epoch: 2814, MSE: 0.2669378151146945, Learning Rate: 0.08593\n",
      "Epoch: 2815, MSE: 0.2669355700904781, Learning Rate: 0.08592500000000002\n",
      "Epoch: 2816, MSE: 0.2669333250167584, Learning Rate: 0.08592\n",
      "Epoch: 2817, MSE: 0.2669310798935347, Learning Rate: 0.085915\n",
      "Epoch: 2818, MSE: 0.2669288347208055, Learning Rate: 0.08591\n",
      "Epoch: 2819, MSE: 0.26692658949856984, Learning Rate: 0.08590500000000001\n",
      "Epoch: 2820, MSE: 0.26692434422682837, Learning Rate: 0.0859\n",
      "Epoch: 2821, MSE: 0.2669220989055776, Learning Rate: 0.085895\n",
      "Epoch: 2822, MSE: 0.26691985353481945, Learning Rate: 0.08589000000000001\n",
      "Epoch: 2823, MSE: 0.26691760811455084, Learning Rate: 0.085885\n",
      "Epoch: 2824, MSE: 0.26691536264477284, Learning Rate: 0.08588000000000001\n",
      "Epoch: 2825, MSE: 0.26691311712548327, Learning Rate: 0.085875\n",
      "Epoch: 2826, MSE: 0.2669108715566809, Learning Rate: 0.08587\n",
      "Epoch: 2827, MSE: 0.2669086259383669, Learning Rate: 0.08586500000000001\n",
      "Epoch: 2828, MSE: 0.2669063802705391, Learning Rate: 0.08586\n",
      "Epoch: 2829, MSE: 0.26690413455319584, Learning Rate: 0.08585500000000001\n",
      "Epoch: 2830, MSE: 0.2669018887863374, Learning Rate: 0.08585000000000001\n",
      "Epoch: 2831, MSE: 0.26689964296996366, Learning Rate: 0.085845\n",
      "Epoch: 2832, MSE: 0.2668973971040717, Learning Rate: 0.08584000000000001\n",
      "Epoch: 2833, MSE: 0.2668951511886627, Learning Rate: 0.085835\n",
      "Epoch: 2834, MSE: 0.26689290522373393, Learning Rate: 0.08583000000000002\n",
      "Epoch: 2835, MSE: 0.26689065920928623, Learning Rate: 0.085825\n",
      "Epoch: 2836, MSE: 0.2668884131453181, Learning Rate: 0.08582000000000001\n",
      "Epoch: 2837, MSE: 0.266886167031829, Learning Rate: 0.085815\n",
      "Epoch: 2838, MSE: 0.26688392086881724, Learning Rate: 0.08581\n",
      "Epoch: 2839, MSE: 0.26688167465628243, Learning Rate: 0.085805\n",
      "Epoch: 2840, MSE: 0.2668794283942248, Learning Rate: 0.0858\n",
      "Epoch: 2841, MSE: 0.2668771820826409, Learning Rate: 0.08579500000000001\n",
      "Epoch: 2842, MSE: 0.26687493572153204, Learning Rate: 0.08579\n",
      "Epoch: 2843, MSE: 0.26687268931089736, Learning Rate: 0.085785\n",
      "Epoch: 2844, MSE: 0.2668704428507349, Learning Rate: 0.08578000000000001\n",
      "Epoch: 2845, MSE: 0.26686819634104436, Learning Rate: 0.085775\n",
      "Epoch: 2846, MSE: 0.26686594978182543, Learning Rate: 0.08577000000000001\n",
      "Epoch: 2847, MSE: 0.2668637031730766, Learning Rate: 0.08576500000000001\n",
      "Epoch: 2848, MSE: 0.26686145651479715, Learning Rate: 0.08576\n",
      "Epoch: 2849, MSE: 0.2668592098069862, Learning Rate: 0.08575500000000001\n",
      "Epoch: 2850, MSE: 0.2668569630496433, Learning Rate: 0.08575\n",
      "Epoch: 2851, MSE: 0.2668547162427668, Learning Rate: 0.08574500000000002\n",
      "Epoch: 2852, MSE: 0.2668524693863569, Learning Rate: 0.08574\n",
      "Epoch: 2853, MSE: 0.266850222480412, Learning Rate: 0.085735\n",
      "Epoch: 2854, MSE: 0.2668479755249313, Learning Rate: 0.08573\n",
      "Epoch: 2855, MSE: 0.26684572851991417, Learning Rate: 0.08572500000000001\n",
      "Epoch: 2856, MSE: 0.26684348146536024, Learning Rate: 0.08572\n",
      "Epoch: 2857, MSE: 0.2668412343612678, Learning Rate: 0.085715\n",
      "Epoch: 2858, MSE: 0.2668389872076367, Learning Rate: 0.08571000000000001\n",
      "Epoch: 2859, MSE: 0.26683674000446544, Learning Rate: 0.085705\n",
      "Epoch: 2860, MSE: 0.2668344927517531, Learning Rate: 0.0857\n",
      "Epoch: 2861, MSE: 0.2668322454494997, Learning Rate: 0.08569500000000001\n",
      "Epoch: 2862, MSE: 0.2668299980977039, Learning Rate: 0.08569\n",
      "Epoch: 2863, MSE: 0.266827750696365, Learning Rate: 0.08568500000000001\n",
      "Epoch: 2864, MSE: 0.2668255032454819, Learning Rate: 0.08568\n",
      "Epoch: 2865, MSE: 0.2668232557450544, Learning Rate: 0.085675\n",
      "Epoch: 2866, MSE: 0.26682100819508103, Learning Rate: 0.08567000000000001\n",
      "Epoch: 2867, MSE: 0.26681876059556064, Learning Rate: 0.085665\n",
      "Epoch: 2868, MSE: 0.2668165129464935, Learning Rate: 0.08566000000000001\n",
      "Epoch: 2869, MSE: 0.26681426524787805, Learning Rate: 0.08565500000000001\n",
      "Epoch: 2870, MSE: 0.26681201749971384, Learning Rate: 0.08565\n",
      "Epoch: 2871, MSE: 0.26680976970199854, Learning Rate: 0.085645\n",
      "Epoch: 2872, MSE: 0.2668075218547336, Learning Rate: 0.08564000000000001\n",
      "Epoch: 2873, MSE: 0.2668052739579166, Learning Rate: 0.085635\n",
      "Epoch: 2874, MSE: 0.26680302601154804, Learning Rate: 0.08563000000000001\n",
      "Epoch: 2875, MSE: 0.2668007780156251, Learning Rate: 0.085625\n",
      "Epoch: 2876, MSE: 0.26679852997014847, Learning Rate: 0.08562\n",
      "Epoch: 2877, MSE: 0.2667962818751173, Learning Rate: 0.085615\n",
      "Epoch: 2878, MSE: 0.26679403373052996, Learning Rate: 0.08561\n",
      "Epoch: 2879, MSE: 0.2667917855363863, Learning Rate: 0.085605\n",
      "Epoch: 2880, MSE: 0.26678953729268556, Learning Rate: 0.08560000000000001\n",
      "Epoch: 2881, MSE: 0.26678728899942566, Learning Rate: 0.085595\n",
      "Epoch: 2882, MSE: 0.26678504065660796, Learning Rate: 0.08559\n",
      "Epoch: 2883, MSE: 0.26678279226422935, Learning Rate: 0.08558500000000001\n",
      "Epoch: 2884, MSE: 0.2667805438222904, Learning Rate: 0.08558\n",
      "Epoch: 2885, MSE: 0.2667782953307896, Learning Rate: 0.08557500000000001\n",
      "Epoch: 2886, MSE: 0.26677604678972644, Learning Rate: 0.08557000000000001\n",
      "Epoch: 2887, MSE: 0.2667737981990999, Learning Rate: 0.085565\n",
      "Epoch: 2888, MSE: 0.26677154955891, Learning Rate: 0.08556000000000001\n",
      "Epoch: 2889, MSE: 0.26676930086915424, Learning Rate: 0.085555\n",
      "Epoch: 2890, MSE: 0.26676705212983276, Learning Rate: 0.08555000000000001\n",
      "Epoch: 2891, MSE: 0.2667648033409451, Learning Rate: 0.08554500000000001\n",
      "Epoch: 2892, MSE: 0.26676255450248954, Learning Rate: 0.08554\n",
      "Epoch: 2893, MSE: 0.26676030561446656, Learning Rate: 0.08553500000000001\n",
      "Epoch: 2894, MSE: 0.2667580566768736, Learning Rate: 0.08553\n",
      "Epoch: 2895, MSE: 0.2667558076897112, Learning Rate: 0.08552500000000002\n",
      "Epoch: 2896, MSE: 0.26675355865297834, Learning Rate: 0.08552\n",
      "Epoch: 2897, MSE: 0.2667513095666728, Learning Rate: 0.08551500000000001\n",
      "Epoch: 2898, MSE: 0.26674906043079594, Learning Rate: 0.08551\n",
      "Epoch: 2899, MSE: 0.2667468112453451, Learning Rate: 0.085505\n",
      "Epoch: 2900, MSE: 0.26674456201032054, Learning Rate: 0.0855\n",
      "Epoch: 2901, MSE: 0.2667423127257217, Learning Rate: 0.085495\n",
      "Epoch: 2902, MSE: 0.26674006339154593, Learning Rate: 0.08549000000000001\n",
      "Epoch: 2903, MSE: 0.2667378140077942, Learning Rate: 0.085485\n",
      "Epoch: 2904, MSE: 0.26673556457446496, Learning Rate: 0.08548\n",
      "Epoch: 2905, MSE: 0.26673331509155723, Learning Rate: 0.08547500000000001\n",
      "Epoch: 2906, MSE: 0.26673106555907033, Learning Rate: 0.08547\n",
      "Epoch: 2907, MSE: 0.26672881597700426, Learning Rate: 0.08546500000000001\n",
      "Epoch: 2908, MSE: 0.2667265663453567, Learning Rate: 0.08546000000000001\n",
      "Epoch: 2909, MSE: 0.26672431666412744, Learning Rate: 0.085455\n",
      "Epoch: 2910, MSE: 0.2667220669333162, Learning Rate: 0.08545000000000001\n",
      "Epoch: 2911, MSE: 0.2667198171529217, Learning Rate: 0.085445\n",
      "Epoch: 2912, MSE: 0.26671756732294305, Learning Rate: 0.08544000000000002\n",
      "Epoch: 2913, MSE: 0.26671531744337956, Learning Rate: 0.085435\n",
      "Epoch: 2914, MSE: 0.26671306751423063, Learning Rate: 0.08543\n",
      "Epoch: 2915, MSE: 0.26671081753549436, Learning Rate: 0.085425\n",
      "Epoch: 2916, MSE: 0.2667085675071719, Learning Rate: 0.08542\n",
      "Epoch: 2917, MSE: 0.26670631742926043, Learning Rate: 0.085415\n",
      "Epoch: 2918, MSE: 0.2667040673017595, Learning Rate: 0.08541\n",
      "Epoch: 2919, MSE: 0.2667018171246693, Learning Rate: 0.08540500000000001\n",
      "Epoch: 2920, MSE: 0.2666995668979885, Learning Rate: 0.0854\n",
      "Epoch: 2921, MSE: 0.2666973166217159, Learning Rate: 0.085395\n",
      "Epoch: 2922, MSE: 0.26669506629585105, Learning Rate: 0.08539000000000001\n",
      "Epoch: 2923, MSE: 0.2666928159203921, Learning Rate: 0.085385\n",
      "Epoch: 2924, MSE: 0.2666905654953406, Learning Rate: 0.08538000000000001\n",
      "Epoch: 2925, MSE: 0.2666883150206939, Learning Rate: 0.085375\n",
      "Epoch: 2926, MSE: 0.266686064496451, Learning Rate: 0.08537\n",
      "Epoch: 2927, MSE: 0.26668381392261203, Learning Rate: 0.08536500000000001\n",
      "Epoch: 2928, MSE: 0.2666815632991754, Learning Rate: 0.08536\n",
      "Epoch: 2929, MSE: 0.26667931262614086, Learning Rate: 0.08535500000000001\n",
      "Epoch: 2930, MSE: 0.26667706190350726, Learning Rate: 0.08535000000000001\n",
      "Epoch: 2931, MSE: 0.266674811131274, Learning Rate: 0.085345\n",
      "Epoch: 2932, MSE: 0.2666725603094402, Learning Rate: 0.08534\n",
      "Epoch: 2933, MSE: 0.26667030943800435, Learning Rate: 0.08533500000000001\n",
      "Epoch: 2934, MSE: 0.2666680585169672, Learning Rate: 0.08533\n",
      "Epoch: 2935, MSE: 0.2666658075463263, Learning Rate: 0.08532500000000001\n",
      "Epoch: 2936, MSE: 0.26666355652608165, Learning Rate: 0.08532000000000001\n",
      "Epoch: 2937, MSE: 0.2666613054562313, Learning Rate: 0.085315\n",
      "Epoch: 2938, MSE: 0.26665905433677667, Learning Rate: 0.08531\n",
      "Epoch: 2939, MSE: 0.2666568031677156, Learning Rate: 0.085305\n",
      "Epoch: 2940, MSE: 0.2666545519490462, Learning Rate: 0.0853\n",
      "Epoch: 2941, MSE: 0.26665230068076934, Learning Rate: 0.08529500000000001\n",
      "Epoch: 2942, MSE: 0.2666500493628837, Learning Rate: 0.08529\n",
      "Epoch: 2943, MSE: 0.26664779799538846, Learning Rate: 0.085285\n",
      "Epoch: 2944, MSE: 0.2666455465782828, Learning Rate: 0.08528000000000001\n",
      "Epoch: 2945, MSE: 0.2666432951115649, Learning Rate: 0.085275\n",
      "Epoch: 2946, MSE: 0.2666410435952355, Learning Rate: 0.08527000000000001\n",
      "Epoch: 2947, MSE: 0.2666387920292936, Learning Rate: 0.08526500000000001\n",
      "Epoch: 2948, MSE: 0.266636540413737, Learning Rate: 0.08526\n",
      "Epoch: 2949, MSE: 0.26663428874856543, Learning Rate: 0.08525500000000001\n",
      "Epoch: 2950, MSE: 0.2666320370337793, Learning Rate: 0.08525\n",
      "Epoch: 2951, MSE: 0.26662978526937686, Learning Rate: 0.08524500000000002\n",
      "Epoch: 2952, MSE: 0.2666275334553568, Learning Rate: 0.08524000000000001\n",
      "Epoch: 2953, MSE: 0.26662528159171917, Learning Rate: 0.085235\n",
      "Epoch: 2954, MSE: 0.2666230296784621, Learning Rate: 0.08523000000000001\n",
      "Epoch: 2955, MSE: 0.2666207777155859, Learning Rate: 0.085225\n",
      "Epoch: 2956, MSE: 0.2666185257030898, Learning Rate: 0.08522000000000002\n",
      "Epoch: 2957, MSE: 0.2666162736409721, Learning Rate: 0.085215\n",
      "Epoch: 2958, MSE: 0.26661402152923236, Learning Rate: 0.08521000000000001\n",
      "Epoch: 2959, MSE: 0.2666117693678696, Learning Rate: 0.085205\n",
      "Epoch: 2960, MSE: 0.2666095171568828, Learning Rate: 0.0852\n",
      "Epoch: 2961, MSE: 0.26660726489627196, Learning Rate: 0.085195\n",
      "Epoch: 2962, MSE: 0.2666050125860359, Learning Rate: 0.08519\n",
      "Epoch: 2963, MSE: 0.26660276022617346, Learning Rate: 0.08518500000000001\n",
      "Epoch: 2964, MSE: 0.2666005078166838, Learning Rate: 0.08518\n",
      "Epoch: 2965, MSE: 0.266598255357567, Learning Rate: 0.085175\n",
      "Epoch: 2966, MSE: 0.26659600284882096, Learning Rate: 0.08517000000000001\n",
      "Epoch: 2967, MSE: 0.2665937502904455, Learning Rate: 0.085165\n",
      "Epoch: 2968, MSE: 0.2665914976824404, Learning Rate: 0.08516000000000001\n",
      "Epoch: 2969, MSE: 0.2665892450248036, Learning Rate: 0.08515500000000001\n",
      "Epoch: 2970, MSE: 0.2665869923175347, Learning Rate: 0.08515\n",
      "Epoch: 2971, MSE: 0.26658473956063367, Learning Rate: 0.08514500000000001\n",
      "Epoch: 2972, MSE: 0.26658248675409835, Learning Rate: 0.08514\n",
      "Epoch: 2973, MSE: 0.26658023389792956, Learning Rate: 0.08513500000000002\n",
      "Epoch: 2974, MSE: 0.2665779809921258, Learning Rate: 0.08513\n",
      "Epoch: 2975, MSE: 0.266575728036685, Learning Rate: 0.085125\n",
      "Epoch: 2976, MSE: 0.26657347503160844, Learning Rate: 0.08512\n",
      "Epoch: 2977, MSE: 0.2665712219768933, Learning Rate: 0.085115\n",
      "Epoch: 2978, MSE: 0.26656896887254056, Learning Rate: 0.08511\n",
      "Epoch: 2979, MSE: 0.2665667157185476, Learning Rate: 0.085105\n",
      "Epoch: 2980, MSE: 0.2665644625149153, Learning Rate: 0.08510000000000001\n",
      "Epoch: 2981, MSE: 0.26656220926164215, Learning Rate: 0.085095\n",
      "Epoch: 2982, MSE: 0.26655995595872695, Learning Rate: 0.08509\n",
      "Epoch: 2983, MSE: 0.26655770260616984, Learning Rate: 0.08508500000000001\n",
      "Epoch: 2984, MSE: 0.26655544920396806, Learning Rate: 0.08508\n",
      "Epoch: 2985, MSE: 0.2665531957521232, Learning Rate: 0.08507500000000001\n",
      "Epoch: 2986, MSE: 0.2665509422506328, Learning Rate: 0.08507\n",
      "Epoch: 2987, MSE: 0.2665486886994977, Learning Rate: 0.085065\n",
      "Epoch: 2988, MSE: 0.26654643509871473, Learning Rate: 0.08506000000000001\n",
      "Epoch: 2989, MSE: 0.2665441814482848, Learning Rate: 0.085055\n",
      "Epoch: 2990, MSE: 0.26654192774820673, Learning Rate: 0.08505000000000001\n",
      "Epoch: 2991, MSE: 0.2665396739984791, Learning Rate: 0.08504500000000001\n",
      "Epoch: 2992, MSE: 0.2665374201991021, Learning Rate: 0.08504\n",
      "Epoch: 2993, MSE: 0.26653516635007457, Learning Rate: 0.085035\n",
      "Epoch: 2994, MSE: 0.26653291245139554, Learning Rate: 0.08503000000000001\n",
      "Epoch: 2995, MSE: 0.2665306585030642, Learning Rate: 0.085025\n",
      "Epoch: 2996, MSE: 0.2665284045050783, Learning Rate: 0.08502000000000001\n",
      "Epoch: 2997, MSE: 0.26652615045744016, Learning Rate: 0.08501500000000001\n",
      "Epoch: 2998, MSE: 0.26652389636014623, Learning Rate: 0.08501\n",
      "Epoch: 2999, MSE: 0.26652164221319696, Learning Rate: 0.085005\n",
      "Epoch: 3000, MSE: 0.26651938801659225, Learning Rate: 0.085\n",
      "Epoch: 3001, MSE: 0.2665171337703291, Learning Rate: 0.084995\n",
      "Epoch: 3002, MSE: 0.2665148794744085, Learning Rate: 0.08499000000000001\n",
      "Epoch: 3003, MSE: 0.2665126251288293, Learning Rate: 0.084985\n",
      "Epoch: 3004, MSE: 0.26651037073359, Learning Rate: 0.08498\n",
      "Epoch: 3005, MSE: 0.2665081162886907, Learning Rate: 0.08497500000000001\n",
      "Epoch: 3006, MSE: 0.2665058617941298, Learning Rate: 0.08497\n",
      "Epoch: 3007, MSE: 0.26650360724990635, Learning Rate: 0.08496500000000001\n",
      "Epoch: 3008, MSE: 0.2665013526560206, Learning Rate: 0.08496000000000001\n",
      "Epoch: 3009, MSE: 0.26649909801247135, Learning Rate: 0.084955\n",
      "Epoch: 3010, MSE: 0.26649684331925716, Learning Rate: 0.08495000000000001\n",
      "Epoch: 3011, MSE: 0.26649458857637837, Learning Rate: 0.084945\n",
      "Epoch: 3012, MSE: 0.26649233378383314, Learning Rate: 0.08494\n",
      "Epoch: 3013, MSE: 0.26649007894161997, Learning Rate: 0.08493500000000001\n",
      "Epoch: 3014, MSE: 0.26648782404973986, Learning Rate: 0.08493\n",
      "Epoch: 3015, MSE: 0.26648556910819127, Learning Rate: 0.08492500000000001\n",
      "Epoch: 3016, MSE: 0.26648331411697324, Learning Rate: 0.08492\n",
      "Epoch: 3017, MSE: 0.2664810590760842, Learning Rate: 0.084915\n",
      "Epoch: 3018, MSE: 0.2664788039855248, Learning Rate: 0.08491\n",
      "Epoch: 3019, MSE: 0.2664765488452941, Learning Rate: 0.08490500000000001\n",
      "Epoch: 3020, MSE: 0.2664742936553899, Learning Rate: 0.0849\n",
      "Epoch: 3021, MSE: 0.26647203841581346, Learning Rate: 0.084895\n",
      "Epoch: 3022, MSE: 0.26646978312656167, Learning Rate: 0.08489000000000001\n",
      "Epoch: 3023, MSE: 0.266467527787635, Learning Rate: 0.084885\n",
      "Epoch: 3024, MSE: 0.2664652723990329, Learning Rate: 0.08488000000000001\n",
      "Epoch: 3025, MSE: 0.26646301696075375, Learning Rate: 0.084875\n",
      "Epoch: 3026, MSE: 0.2664607614727974, Learning Rate: 0.08487\n",
      "Epoch: 3027, MSE: 0.26645850593516246, Learning Rate: 0.08486500000000001\n",
      "Epoch: 3028, MSE: 0.26645625034784864, Learning Rate: 0.08486\n",
      "Epoch: 3029, MSE: 0.2664539947108549, Learning Rate: 0.08485500000000001\n",
      "Epoch: 3030, MSE: 0.2664517390241806, Learning Rate: 0.08485000000000001\n",
      "Epoch: 3031, MSE: 0.2664494832878244, Learning Rate: 0.084845\n",
      "Epoch: 3032, MSE: 0.2664472275017858, Learning Rate: 0.08484000000000001\n",
      "Epoch: 3033, MSE: 0.2664449716660645, Learning Rate: 0.084835\n",
      "Epoch: 3034, MSE: 0.2664427157806595, Learning Rate: 0.08483000000000002\n",
      "Epoch: 3035, MSE: 0.266440459845569, Learning Rate: 0.084825\n",
      "Epoch: 3036, MSE: 0.26643820386079303, Learning Rate: 0.08482\n",
      "Epoch: 3037, MSE: 0.26643594782633123, Learning Rate: 0.084815\n",
      "Epoch: 3038, MSE: 0.266433691742182, Learning Rate: 0.08481\n",
      "Epoch: 3039, MSE: 0.26643143560834504, Learning Rate: 0.084805\n",
      "Epoch: 3040, MSE: 0.26642917942481925, Learning Rate: 0.0848\n",
      "Epoch: 3041, MSE: 0.26642692319160355, Learning Rate: 0.08479500000000001\n",
      "Epoch: 3042, MSE: 0.2664246669086973, Learning Rate: 0.08479\n",
      "Epoch: 3043, MSE: 0.2664224105761007, Learning Rate: 0.084785\n",
      "Epoch: 3044, MSE: 0.2664201541938112, Learning Rate: 0.08478000000000001\n",
      "Epoch: 3045, MSE: 0.26641789776182845, Learning Rate: 0.084775\n",
      "Epoch: 3046, MSE: 0.2664156412801537, Learning Rate: 0.08477000000000001\n",
      "Epoch: 3047, MSE: 0.266413384748783, Learning Rate: 0.08476500000000001\n",
      "Epoch: 3048, MSE: 0.2664111281677185, Learning Rate: 0.08476\n",
      "Epoch: 3049, MSE: 0.2664088715369575, Learning Rate: 0.08475500000000001\n",
      "Epoch: 3050, MSE: 0.26640661485649936, Learning Rate: 0.08475\n",
      "Epoch: 3051, MSE: 0.2664043581263437, Learning Rate: 0.08474500000000001\n",
      "Epoch: 3052, MSE: 0.2664021013464892, Learning Rate: 0.08474\n",
      "Epoch: 3053, MSE: 0.26639984451693566, Learning Rate: 0.084735\n",
      "Epoch: 3054, MSE: 0.26639758763768245, Learning Rate: 0.08473\n",
      "Epoch: 3055, MSE: 0.2663953307087282, Learning Rate: 0.08472500000000001\n",
      "Epoch: 3056, MSE: 0.2663930737300726, Learning Rate: 0.08472\n",
      "Epoch: 3057, MSE: 0.2663908167017146, Learning Rate: 0.084715\n",
      "Epoch: 3058, MSE: 0.2663885596236526, Learning Rate: 0.08471000000000001\n",
      "Epoch: 3059, MSE: 0.26638630249588696, Learning Rate: 0.084705\n",
      "Epoch: 3060, MSE: 0.2663840453184164, Learning Rate: 0.0847\n",
      "Epoch: 3061, MSE: 0.26638178809124063, Learning Rate: 0.084695\n",
      "Epoch: 3062, MSE: 0.2663795308143579, Learning Rate: 0.08469\n",
      "Epoch: 3063, MSE: 0.2663772734877675, Learning Rate: 0.08468500000000001\n",
      "Epoch: 3064, MSE: 0.26637501611146974, Learning Rate: 0.08468\n",
      "Epoch: 3065, MSE: 0.2663727586854631, Learning Rate: 0.084675\n",
      "Epoch: 3066, MSE: 0.2663705012097461, Learning Rate: 0.08467000000000001\n",
      "Epoch: 3067, MSE: 0.26636824368431955, Learning Rate: 0.084665\n",
      "Epoch: 3068, MSE: 0.2663659861091814, Learning Rate: 0.08466000000000001\n",
      "Epoch: 3069, MSE: 0.26636372848433115, Learning Rate: 0.08465500000000001\n",
      "Epoch: 3070, MSE: 0.2663614708097674, Learning Rate: 0.08465\n",
      "Epoch: 3071, MSE: 0.26635921308549104, Learning Rate: 0.08464500000000001\n",
      "Epoch: 3072, MSE: 0.26635695531150005, Learning Rate: 0.08464\n",
      "Epoch: 3073, MSE: 0.26635469748779356, Learning Rate: 0.084635\n",
      "Epoch: 3074, MSE: 0.2663524396143705, Learning Rate: 0.08463000000000001\n",
      "Epoch: 3075, MSE: 0.2663501816912312, Learning Rate: 0.084625\n",
      "Epoch: 3076, MSE: 0.26634792371837374, Learning Rate: 0.08462000000000001\n",
      "Epoch: 3077, MSE: 0.26634566569579826, Learning Rate: 0.084615\n",
      "Epoch: 3078, MSE: 0.26634340762350334, Learning Rate: 0.08461\n",
      "Epoch: 3079, MSE: 0.26634114950148846, Learning Rate: 0.084605\n",
      "Epoch: 3080, MSE: 0.2663388913297524, Learning Rate: 0.08460000000000001\n",
      "Epoch: 3081, MSE: 0.2663366331082946, Learning Rate: 0.084595\n",
      "Epoch: 3082, MSE: 0.26633437483711553, Learning Rate: 0.08459\n",
      "Epoch: 3083, MSE: 0.2663321165162118, Learning Rate: 0.08458500000000001\n",
      "Epoch: 3084, MSE: 0.2663298581455846, Learning Rate: 0.08458\n",
      "Epoch: 3085, MSE: 0.2663275997252325, Learning Rate: 0.08457500000000001\n",
      "Epoch: 3086, MSE: 0.26632534125515467, Learning Rate: 0.08457\n",
      "Epoch: 3087, MSE: 0.26632308273535016, Learning Rate: 0.084565\n",
      "Epoch: 3088, MSE: 0.2663208241658192, Learning Rate: 0.08456000000000001\n",
      "Epoch: 3089, MSE: 0.26631856554655964, Learning Rate: 0.084555\n",
      "Epoch: 3090, MSE: 0.26631630687757163, Learning Rate: 0.08455000000000001\n",
      "Epoch: 3091, MSE: 0.2663140481588535, Learning Rate: 0.08454500000000001\n",
      "Epoch: 3092, MSE: 0.26631178939040534, Learning Rate: 0.08454\n",
      "Epoch: 3093, MSE: 0.266309530572225, Learning Rate: 0.08453500000000001\n",
      "Epoch: 3094, MSE: 0.266307271704314, Learning Rate: 0.08453\n",
      "Epoch: 3095, MSE: 0.26630501278666957, Learning Rate: 0.08452500000000002\n",
      "Epoch: 3096, MSE: 0.266302753819292, Learning Rate: 0.08452\n",
      "Epoch: 3097, MSE: 0.2663004948021792, Learning Rate: 0.084515\n",
      "Epoch: 3098, MSE: 0.26629823573533146, Learning Rate: 0.08451\n",
      "Epoch: 3099, MSE: 0.2662959766187477, Learning Rate: 0.084505\n",
      "Epoch: 3100, MSE: 0.26629371745242764, Learning Rate: 0.0845\n",
      "Epoch: 3101, MSE: 0.26629145823636946, Learning Rate: 0.084495\n",
      "Epoch: 3102, MSE: 0.2662891989705735, Learning Rate: 0.08449000000000001\n",
      "Epoch: 3103, MSE: 0.266286939655038, Learning Rate: 0.084485\n",
      "Epoch: 3104, MSE: 0.2662846802897622, Learning Rate: 0.08448\n",
      "Epoch: 3105, MSE: 0.26628242087474585, Learning Rate: 0.08447500000000001\n",
      "Epoch: 3106, MSE: 0.2662801614099879, Learning Rate: 0.08447\n",
      "Epoch: 3107, MSE: 0.2662779018954878, Learning Rate: 0.08446500000000001\n",
      "Epoch: 3108, MSE: 0.26627564233124507, Learning Rate: 0.08446000000000001\n",
      "Epoch: 3109, MSE: 0.26627338271725726, Learning Rate: 0.084455\n",
      "Epoch: 3110, MSE: 0.2662711230535254, Learning Rate: 0.08445000000000001\n",
      "Epoch: 3111, MSE: 0.266268863340048, Learning Rate: 0.084445\n",
      "Epoch: 3112, MSE: 0.26626660357682436, Learning Rate: 0.08444000000000002\n",
      "Epoch: 3113, MSE: 0.26626434376385366, Learning Rate: 0.084435\n",
      "Epoch: 3114, MSE: 0.2662620839011347, Learning Rate: 0.08443\n",
      "Epoch: 3115, MSE: 0.2662598239886674, Learning Rate: 0.084425\n",
      "Epoch: 3116, MSE: 0.2662575640264511, Learning Rate: 0.08442000000000001\n",
      "Epoch: 3117, MSE: 0.26625530401448316, Learning Rate: 0.084415\n",
      "Epoch: 3118, MSE: 0.26625304395276506, Learning Rate: 0.08441\n",
      "Epoch: 3119, MSE: 0.2662507838412958, Learning Rate: 0.08440500000000001\n",
      "Epoch: 3120, MSE: 0.26624852368007285, Learning Rate: 0.0844\n",
      "Epoch: 3121, MSE: 0.2662462634690967, Learning Rate: 0.084395\n",
      "Epoch: 3122, MSE: 0.2662440032083665, Learning Rate: 0.08439\n",
      "Epoch: 3123, MSE: 0.2662417428978813, Learning Rate: 0.084385\n",
      "Epoch: 3124, MSE: 0.26623948253763974, Learning Rate: 0.08438000000000001\n",
      "Epoch: 3125, MSE: 0.2662372221276419, Learning Rate: 0.084375\n",
      "Epoch: 3126, MSE: 0.2662349616678873, Learning Rate: 0.08437\n",
      "Epoch: 3127, MSE: 0.2662327011583734, Learning Rate: 0.08436500000000001\n",
      "Epoch: 3128, MSE: 0.26623044059910217, Learning Rate: 0.08436\n",
      "Epoch: 3129, MSE: 0.2662281799900698, Learning Rate: 0.08435500000000001\n",
      "Epoch: 3130, MSE: 0.26622591933127765, Learning Rate: 0.08435000000000001\n",
      "Epoch: 3131, MSE: 0.26622365862272335, Learning Rate: 0.084345\n",
      "Epoch: 3132, MSE: 0.2662213978644076, Learning Rate: 0.08434000000000001\n",
      "Epoch: 3133, MSE: 0.26621913705632877, Learning Rate: 0.08433500000000001\n",
      "Epoch: 3134, MSE: 0.26621687619848655, Learning Rate: 0.08433\n",
      "Epoch: 3135, MSE: 0.26621461529087953, Learning Rate: 0.08432500000000001\n",
      "Epoch: 3136, MSE: 0.2662123543335074, Learning Rate: 0.08432\n",
      "Epoch: 3137, MSE: 0.2662100933263698, Learning Rate: 0.08431500000000001\n",
      "Epoch: 3138, MSE: 0.2662078322694642, Learning Rate: 0.08431\n",
      "Epoch: 3139, MSE: 0.26620557116279164, Learning Rate: 0.084305\n",
      "Epoch: 3140, MSE: 0.2662033100063503, Learning Rate: 0.0843\n",
      "Epoch: 3141, MSE: 0.26620104880014067, Learning Rate: 0.08429500000000001\n",
      "Epoch: 3142, MSE: 0.2661987875441599, Learning Rate: 0.08429\n",
      "Epoch: 3143, MSE: 0.26619652623840934, Learning Rate: 0.084285\n",
      "Epoch: 3144, MSE: 0.26619426488288644, Learning Rate: 0.08428000000000001\n",
      "Epoch: 3145, MSE: 0.26619200347759175, Learning Rate: 0.084275\n",
      "Epoch: 3146, MSE: 0.26618974202252427, Learning Rate: 0.08427000000000001\n",
      "Epoch: 3147, MSE: 0.2661874805176815, Learning Rate: 0.084265\n",
      "Epoch: 3148, MSE: 0.266185218963065, Learning Rate: 0.08426\n",
      "Epoch: 3149, MSE: 0.26618295735867326, Learning Rate: 0.08425500000000001\n",
      "Epoch: 3150, MSE: 0.26618069570450476, Learning Rate: 0.08425\n",
      "Epoch: 3151, MSE: 0.26617843400055946, Learning Rate: 0.08424500000000001\n",
      "Epoch: 3152, MSE: 0.2661761722468358, Learning Rate: 0.08424000000000001\n",
      "Epoch: 3153, MSE: 0.26617391044333455, Learning Rate: 0.084235\n",
      "Epoch: 3154, MSE: 0.2661716485900534, Learning Rate: 0.08423000000000001\n",
      "Epoch: 3155, MSE: 0.26616938668699175, Learning Rate: 0.084225\n",
      "Epoch: 3156, MSE: 0.26616712473414983, Learning Rate: 0.08422000000000002\n",
      "Epoch: 3157, MSE: 0.2661648627315262, Learning Rate: 0.084215\n",
      "Epoch: 3158, MSE: 0.266162600679119, Learning Rate: 0.08421000000000001\n",
      "Epoch: 3159, MSE: 0.2661603385769292, Learning Rate: 0.084205\n",
      "Epoch: 3160, MSE: 0.2661580764249547, Learning Rate: 0.0842\n",
      "Epoch: 3161, MSE: 0.2661558142231961, Learning Rate: 0.084195\n",
      "Epoch: 3162, MSE: 0.26615355197165175, Learning Rate: 0.08419\n",
      "Epoch: 3163, MSE: 0.26615128967032015, Learning Rate: 0.08418500000000001\n",
      "Epoch: 3164, MSE: 0.2661490273192022, Learning Rate: 0.08418\n",
      "Epoch: 3165, MSE: 0.26614676491829603, Learning Rate: 0.084175\n",
      "Epoch: 3166, MSE: 0.26614450246760085, Learning Rate: 0.08417000000000001\n",
      "Epoch: 3167, MSE: 0.26614223996711606, Learning Rate: 0.084165\n",
      "Epoch: 3168, MSE: 0.26613997741684137, Learning Rate: 0.08416000000000001\n",
      "Epoch: 3169, MSE: 0.2661377148167757, Learning Rate: 0.08415500000000001\n",
      "Epoch: 3170, MSE: 0.26613545216691753, Learning Rate: 0.08415\n",
      "Epoch: 3171, MSE: 0.2661331894672664, Learning Rate: 0.08414500000000001\n",
      "Epoch: 3172, MSE: 0.2661309267178225, Learning Rate: 0.08414\n",
      "Epoch: 3173, MSE: 0.26612866391858436, Learning Rate: 0.08413500000000002\n",
      "Epoch: 3174, MSE: 0.2661264010695509, Learning Rate: 0.08413\n",
      "Epoch: 3175, MSE: 0.26612413817072167, Learning Rate: 0.084125\n",
      "Epoch: 3176, MSE: 0.26612187522209574, Learning Rate: 0.08412\n",
      "Epoch: 3177, MSE: 0.2661196122236729, Learning Rate: 0.08411500000000001\n",
      "Epoch: 3178, MSE: 0.2661173491754508, Learning Rate: 0.08411\n",
      "Epoch: 3179, MSE: 0.2661150860774306, Learning Rate: 0.084105\n",
      "Epoch: 3180, MSE: 0.2661128229296112, Learning Rate: 0.08410000000000001\n",
      "Epoch: 3181, MSE: 0.2661105597319907, Learning Rate: 0.084095\n",
      "Epoch: 3182, MSE: 0.2661082964845689, Learning Rate: 0.08409\n",
      "Epoch: 3183, MSE: 0.26610603318734477, Learning Rate: 0.08408500000000001\n",
      "Epoch: 3184, MSE: 0.2661037698403184, Learning Rate: 0.08408\n",
      "Epoch: 3185, MSE: 0.2661015064434877, Learning Rate: 0.08407500000000001\n",
      "Epoch: 3186, MSE: 0.2660992429968537, Learning Rate: 0.08407\n",
      "Epoch: 3187, MSE: 0.2660969795004142, Learning Rate: 0.084065\n",
      "Epoch: 3188, MSE: 0.2660947159541683, Learning Rate: 0.08406000000000001\n",
      "Epoch: 3189, MSE: 0.26609245235811607, Learning Rate: 0.084055\n",
      "Epoch: 3190, MSE: 0.266090188712256, Learning Rate: 0.08405000000000001\n",
      "Epoch: 3191, MSE: 0.2660879250165877, Learning Rate: 0.08404500000000001\n",
      "Epoch: 3192, MSE: 0.26608566127111116, Learning Rate: 0.08404\n",
      "Epoch: 3193, MSE: 0.266083397475824, Learning Rate: 0.08403500000000001\n",
      "Epoch: 3194, MSE: 0.26608113363072616, Learning Rate: 0.08403000000000001\n",
      "Epoch: 3195, MSE: 0.2660788697358179, Learning Rate: 0.084025\n",
      "Epoch: 3196, MSE: 0.26607660579109693, Learning Rate: 0.08402000000000001\n",
      "Epoch: 3197, MSE: 0.26607434179656286, Learning Rate: 0.084015\n",
      "Epoch: 3198, MSE: 0.26607207775221514, Learning Rate: 0.08401000000000002\n",
      "Epoch: 3199, MSE: 0.2660698136580527, Learning Rate: 0.084005\n",
      "Epoch: 3200, MSE: 0.26606754951407563, Learning Rate: 0.084\n",
      "Epoch: 3201, MSE: 0.266065285320282, Learning Rate: 0.083995\n",
      "Epoch: 3202, MSE: 0.26606302107667196, Learning Rate: 0.08399000000000001\n",
      "Epoch: 3203, MSE: 0.2660607567832441, Learning Rate: 0.083985\n",
      "Epoch: 3204, MSE: 0.26605849243999846, Learning Rate: 0.08398\n",
      "Epoch: 3205, MSE: 0.266056228046933, Learning Rate: 0.08397500000000001\n",
      "Epoch: 3206, MSE: 0.26605396360404776, Learning Rate: 0.08397\n",
      "Epoch: 3207, MSE: 0.26605169911134247, Learning Rate: 0.08396500000000001\n",
      "Epoch: 3208, MSE: 0.2660494345688148, Learning Rate: 0.08396\n",
      "Epoch: 3209, MSE: 0.2660471699764654, Learning Rate: 0.083955\n",
      "Epoch: 3210, MSE: 0.26604490533429276, Learning Rate: 0.08395000000000001\n",
      "Epoch: 3211, MSE: 0.26604264064229743, Learning Rate: 0.083945\n",
      "Epoch: 3212, MSE: 0.26604037590047663, Learning Rate: 0.08394000000000001\n",
      "Epoch: 3213, MSE: 0.26603811110883147, Learning Rate: 0.08393500000000001\n",
      "Epoch: 3214, MSE: 0.26603584626735893, Learning Rate: 0.08393\n",
      "Epoch: 3215, MSE: 0.26603358137606037, Learning Rate: 0.08392500000000001\n",
      "Epoch: 3216, MSE: 0.2660313164349335, Learning Rate: 0.08392\n",
      "Epoch: 3217, MSE: 0.2660290514439787, Learning Rate: 0.08391500000000002\n",
      "Epoch: 3218, MSE: 0.26602678640319477, Learning Rate: 0.08391\n",
      "Epoch: 3219, MSE: 0.2660245213125812, Learning Rate: 0.08390500000000001\n",
      "Epoch: 3220, MSE: 0.26602225617213693, Learning Rate: 0.0839\n",
      "Epoch: 3221, MSE: 0.26601999098186074, Learning Rate: 0.083895\n",
      "Epoch: 3222, MSE: 0.26601772574175236, Learning Rate: 0.08389\n",
      "Epoch: 3223, MSE: 0.2660154604518111, Learning Rate: 0.083885\n",
      "Epoch: 3224, MSE: 0.2660131951120361, Learning Rate: 0.08388000000000001\n",
      "Epoch: 3225, MSE: 0.26601092972242696, Learning Rate: 0.083875\n",
      "Epoch: 3226, MSE: 0.2660086642829817, Learning Rate: 0.08387\n",
      "Epoch: 3227, MSE: 0.26600639879370086, Learning Rate: 0.08386500000000001\n",
      "Epoch: 3228, MSE: 0.2660041332545831, Learning Rate: 0.08386\n",
      "Epoch: 3229, MSE: 0.2660018676656277, Learning Rate: 0.08385500000000001\n",
      "Epoch: 3230, MSE: 0.2659996020268331, Learning Rate: 0.08385000000000001\n",
      "Epoch: 3231, MSE: 0.26599733633820094, Learning Rate: 0.083845\n",
      "Epoch: 3232, MSE: 0.26599507059972766, Learning Rate: 0.08384000000000001\n",
      "Epoch: 3233, MSE: 0.26599280481141385, Learning Rate: 0.083835\n",
      "Epoch: 3234, MSE: 0.2659905389732592, Learning Rate: 0.08383000000000002\n",
      "Epoch: 3235, MSE: 0.26598827308526163, Learning Rate: 0.083825\n",
      "Epoch: 3236, MSE: 0.2659860071474215, Learning Rate: 0.08382\n",
      "Epoch: 3237, MSE: 0.26598374115973805, Learning Rate: 0.083815\n",
      "Epoch: 3238, MSE: 0.2659814751222086, Learning Rate: 0.08381000000000001\n",
      "Epoch: 3239, MSE: 0.26597920903483496, Learning Rate: 0.083805\n",
      "Epoch: 3240, MSE: 0.26597694289761464, Learning Rate: 0.0838\n",
      "Epoch: 3241, MSE: 0.26597467671054803, Learning Rate: 0.08379500000000001\n",
      "Epoch: 3242, MSE: 0.26597241047363357, Learning Rate: 0.08379\n",
      "Epoch: 3243, MSE: 0.2659701441868714, Learning Rate: 0.083785\n",
      "Epoch: 3244, MSE: 0.2659678778502592, Learning Rate: 0.08378000000000001\n",
      "Epoch: 3245, MSE: 0.2659656114637975, Learning Rate: 0.083775\n",
      "Epoch: 3246, MSE: 0.2659633450274851, Learning Rate: 0.08377000000000001\n",
      "Epoch: 3247, MSE: 0.2659610785413217, Learning Rate: 0.083765\n",
      "Epoch: 3248, MSE: 0.2659588120053049, Learning Rate: 0.08376\n",
      "Epoch: 3249, MSE: 0.2659565454194354, Learning Rate: 0.08375500000000001\n",
      "Epoch: 3250, MSE: 0.2659542787837135, Learning Rate: 0.08375\n",
      "Epoch: 3251, MSE: 0.26595201209813585, Learning Rate: 0.08374500000000001\n",
      "Epoch: 3252, MSE: 0.26594974536270394, Learning Rate: 0.08374000000000001\n",
      "Epoch: 3253, MSE: 0.2659474785774147, Learning Rate: 0.083735\n",
      "Epoch: 3254, MSE: 0.26594521174226904, Learning Rate: 0.08373\n",
      "Epoch: 3255, MSE: 0.26594294485726666, Learning Rate: 0.08372500000000001\n",
      "Epoch: 3256, MSE: 0.2659406779224055, Learning Rate: 0.08372\n",
      "Epoch: 3257, MSE: 0.26593841093768533, Learning Rate: 0.08371500000000001\n",
      "Epoch: 3258, MSE: 0.2659361439031056, Learning Rate: 0.08371\n",
      "Epoch: 3259, MSE: 0.26593387681866393, Learning Rate: 0.083705\n",
      "Epoch: 3260, MSE: 0.26593160968436214, Learning Rate: 0.0837\n",
      "Epoch: 3261, MSE: 0.26592934250019823, Learning Rate: 0.083695\n",
      "Epoch: 3262, MSE: 0.2659270752661712, Learning Rate: 0.08369\n",
      "Epoch: 3263, MSE: 0.26592480798228013, Learning Rate: 0.08368500000000001\n",
      "Epoch: 3264, MSE: 0.26592254064852544, Learning Rate: 0.08368\n",
      "Epoch: 3265, MSE: 0.2659202732649053, Learning Rate: 0.083675\n",
      "Epoch: 3266, MSE: 0.2659180058314194, Learning Rate: 0.08367000000000001\n",
      "Epoch: 3267, MSE: 0.26591573834806553, Learning Rate: 0.083665\n",
      "Epoch: 3268, MSE: 0.26591347081484557, Learning Rate: 0.08366000000000001\n",
      "Epoch: 3269, MSE: 0.26591120323175754, Learning Rate: 0.08365500000000001\n",
      "Epoch: 3270, MSE: 0.26590893559879974, Learning Rate: 0.08365\n",
      "Epoch: 3271, MSE: 0.2659066679159726, Learning Rate: 0.08364500000000001\n",
      "Epoch: 3272, MSE: 0.26590440018327455, Learning Rate: 0.08364\n",
      "Epoch: 3273, MSE: 0.2659021324007052, Learning Rate: 0.08363500000000001\n",
      "Epoch: 3274, MSE: 0.26589986456826414, Learning Rate: 0.08363000000000001\n",
      "Epoch: 3275, MSE: 0.2658975966859502, Learning Rate: 0.083625\n",
      "Epoch: 3276, MSE: 0.2658953287537626, Learning Rate: 0.08362000000000001\n",
      "Epoch: 3277, MSE: 0.26589306077170144, Learning Rate: 0.083615\n",
      "Epoch: 3278, MSE: 0.26589079273976474, Learning Rate: 0.08361000000000002\n",
      "Epoch: 3279, MSE: 0.26588852465795243, Learning Rate: 0.083605\n",
      "Epoch: 3280, MSE: 0.2658862565262627, Learning Rate: 0.08360000000000001\n",
      "Epoch: 3281, MSE: 0.2658839883446965, Learning Rate: 0.083595\n",
      "Epoch: 3282, MSE: 0.26588172011325245, Learning Rate: 0.08359\n",
      "Epoch: 3283, MSE: 0.2658794518319286, Learning Rate: 0.083585\n",
      "Epoch: 3284, MSE: 0.26587718350072526, Learning Rate: 0.08358\n",
      "Epoch: 3285, MSE: 0.26587491511964206, Learning Rate: 0.08357500000000001\n",
      "Epoch: 3286, MSE: 0.2658726466886773, Learning Rate: 0.08357\n",
      "Epoch: 3287, MSE: 0.26587037820783144, Learning Rate: 0.083565\n",
      "Epoch: 3288, MSE: 0.26586810967710256, Learning Rate: 0.08356000000000001\n",
      "Epoch: 3289, MSE: 0.26586584109648936, Learning Rate: 0.083555\n",
      "Epoch: 3290, MSE: 0.2658635724659934, Learning Rate: 0.08355000000000001\n",
      "Epoch: 3291, MSE: 0.2658613037856112, Learning Rate: 0.08354500000000001\n",
      "Epoch: 3292, MSE: 0.2658590350553445, Learning Rate: 0.08354\n",
      "Epoch: 3293, MSE: 0.2658567662751909, Learning Rate: 0.08353500000000001\n",
      "Epoch: 3294, MSE: 0.2658544974451505, Learning Rate: 0.08353\n",
      "Epoch: 3295, MSE: 0.2658522285652216, Learning Rate: 0.08352500000000002\n",
      "Epoch: 3296, MSE: 0.26584995963540364, Learning Rate: 0.08352\n",
      "Epoch: 3297, MSE: 0.26584769065569713, Learning Rate: 0.083515\n",
      "Epoch: 3298, MSE: 0.26584542162610086, Learning Rate: 0.08351\n",
      "Epoch: 3299, MSE: 0.2658431525466126, Learning Rate: 0.083505\n",
      "Epoch: 3300, MSE: 0.2658408834172328, Learning Rate: 0.0835\n",
      "Epoch: 3301, MSE: 0.2658386142379609, Learning Rate: 0.083495\n",
      "Epoch: 3302, MSE: 0.26583634500879555, Learning Rate: 0.08349000000000001\n",
      "Epoch: 3303, MSE: 0.26583407572973633, Learning Rate: 0.083485\n",
      "Epoch: 3304, MSE: 0.2658318064007824, Learning Rate: 0.08348\n",
      "Epoch: 3305, MSE: 0.2658295370219319, Learning Rate: 0.08347500000000001\n",
      "Epoch: 3306, MSE: 0.26582726759318687, Learning Rate: 0.08347\n",
      "Epoch: 3307, MSE: 0.26582499811454363, Learning Rate: 0.08346500000000001\n",
      "Epoch: 3308, MSE: 0.2658227285860031, Learning Rate: 0.08346\n",
      "Epoch: 3309, MSE: 0.26582045900756474, Learning Rate: 0.083455\n",
      "Epoch: 3310, MSE: 0.2658181893792271, Learning Rate: 0.08345000000000001\n",
      "Epoch: 3311, MSE: 0.26581591970098833, Learning Rate: 0.083445\n",
      "Epoch: 3312, MSE: 0.2658136499728497, Learning Rate: 0.08344000000000001\n",
      "Epoch: 3313, MSE: 0.26581138019480915, Learning Rate: 0.08343500000000001\n",
      "Epoch: 3314, MSE: 0.2658091103668664, Learning Rate: 0.08343\n",
      "Epoch: 3315, MSE: 0.26580684048902026, Learning Rate: 0.083425\n",
      "Epoch: 3316, MSE: 0.2658045705612718, Learning Rate: 0.08342000000000001\n",
      "Epoch: 3317, MSE: 0.2658023005836177, Learning Rate: 0.083415\n",
      "Epoch: 3318, MSE: 0.2658000305560583, Learning Rate: 0.08341000000000001\n",
      "Epoch: 3319, MSE: 0.2657977604785931, Learning Rate: 0.083405\n",
      "Epoch: 3320, MSE: 0.26579549035122085, Learning Rate: 0.0834\n",
      "Epoch: 3321, MSE: 0.2657932201739418, Learning Rate: 0.083395\n",
      "Epoch: 3322, MSE: 0.26579094994675323, Learning Rate: 0.08339\n",
      "Epoch: 3323, MSE: 0.2657886796696569, Learning Rate: 0.083385\n",
      "Epoch: 3324, MSE: 0.26578640934265046, Learning Rate: 0.08338000000000001\n",
      "Epoch: 3325, MSE: 0.2657841389657332, Learning Rate: 0.083375\n",
      "Epoch: 3326, MSE: 0.2657818685389054, Learning Rate: 0.08337\n",
      "Epoch: 3327, MSE: 0.26577959806216467, Learning Rate: 0.08336500000000001\n",
      "Epoch: 3328, MSE: 0.2657773275355122, Learning Rate: 0.08336\n",
      "Epoch: 3329, MSE: 0.2657750569589447, Learning Rate: 0.08335500000000001\n",
      "Epoch: 3330, MSE: 0.26577278633246354, Learning Rate: 0.08335000000000001\n",
      "Epoch: 3331, MSE: 0.2657705156560684, Learning Rate: 0.083345\n",
      "Epoch: 3332, MSE: 0.2657682449297567, Learning Rate: 0.08334000000000001\n",
      "Epoch: 3333, MSE: 0.2657659741535287, Learning Rate: 0.083335\n",
      "Epoch: 3334, MSE: 0.2657637033273835, Learning Rate: 0.08333000000000002\n",
      "Epoch: 3335, MSE: 0.26576143245132006, Learning Rate: 0.08332500000000001\n",
      "Epoch: 3336, MSE: 0.2657591615253386, Learning Rate: 0.08332\n",
      "Epoch: 3337, MSE: 0.26575689054943696, Learning Rate: 0.08331500000000001\n",
      "Epoch: 3338, MSE: 0.2657546195236145, Learning Rate: 0.08331\n",
      "Epoch: 3339, MSE: 0.2657523484478725, Learning Rate: 0.08330500000000002\n",
      "Epoch: 3340, MSE: 0.2657500773222078, Learning Rate: 0.0833\n",
      "Epoch: 3341, MSE: 0.2657478061466203, Learning Rate: 0.08329500000000001\n",
      "Epoch: 3342, MSE: 0.26574553492111025, Learning Rate: 0.08329\n",
      "Epoch: 3343, MSE: 0.2657432636456763, Learning Rate: 0.083285\n",
      "Epoch: 3344, MSE: 0.26574099232031756, Learning Rate: 0.08328\n",
      "Epoch: 3345, MSE: 0.2657387209450331, Learning Rate: 0.083275\n",
      "Epoch: 3346, MSE: 0.26573644951982245, Learning Rate: 0.08327000000000001\n",
      "Epoch: 3347, MSE: 0.26573417804468524, Learning Rate: 0.083265\n",
      "Epoch: 3348, MSE: 0.2657319065196198, Learning Rate: 0.08326\n",
      "Epoch: 3349, MSE: 0.26572963494462626, Learning Rate: 0.08325500000000001\n",
      "Epoch: 3350, MSE: 0.26572736331970326, Learning Rate: 0.08325\n",
      "Epoch: 3351, MSE: 0.2657250916448507, Learning Rate: 0.08324500000000001\n",
      "Epoch: 3352, MSE: 0.26572281992006724, Learning Rate: 0.08324000000000001\n",
      "Epoch: 3353, MSE: 0.26572054814535234, Learning Rate: 0.083235\n",
      "Epoch: 3354, MSE: 0.26571827632070466, Learning Rate: 0.08323000000000001\n",
      "Epoch: 3355, MSE: 0.2657160044461261, Learning Rate: 0.083225\n",
      "Epoch: 3356, MSE: 0.26571373252161185, Learning Rate: 0.08322000000000002\n",
      "Epoch: 3357, MSE: 0.2657114605471636, Learning Rate: 0.083215\n",
      "Epoch: 3358, MSE: 0.2657091885227809, Learning Rate: 0.08321\n",
      "Epoch: 3359, MSE: 0.26570691644846184, Learning Rate: 0.083205\n",
      "Epoch: 3360, MSE: 0.26570464432420654, Learning Rate: 0.0832\n",
      "Epoch: 3361, MSE: 0.2657023721500136, Learning Rate: 0.083195\n",
      "Epoch: 3362, MSE: 0.26570009992588206, Learning Rate: 0.08319\n",
      "Epoch: 3363, MSE: 0.2656978276518122, Learning Rate: 0.08318500000000001\n",
      "Epoch: 3364, MSE: 0.265695555327803, Learning Rate: 0.08318\n",
      "Epoch: 3365, MSE: 0.26569328295385286, Learning Rate: 0.083175\n",
      "Epoch: 3366, MSE: 0.2656910105299625, Learning Rate: 0.08317000000000001\n",
      "Epoch: 3367, MSE: 0.265688738056129, Learning Rate: 0.083165\n",
      "Epoch: 3368, MSE: 0.26568646553235403, Learning Rate: 0.08316000000000001\n",
      "Epoch: 3369, MSE: 0.26568419295863593, Learning Rate: 0.083155\n",
      "Epoch: 3370, MSE: 0.2656819203349736, Learning Rate: 0.08315\n",
      "Epoch: 3371, MSE: 0.2656796476613657, Learning Rate: 0.08314500000000001\n",
      "Epoch: 3372, MSE: 0.2656773749378129, Learning Rate: 0.08314\n",
      "Epoch: 3373, MSE: 0.265675102164314, Learning Rate: 0.08313500000000001\n",
      "Epoch: 3374, MSE: 0.2656728293408674, Learning Rate: 0.08313000000000001\n",
      "Epoch: 3375, MSE: 0.26567055646747395, Learning Rate: 0.083125\n",
      "Epoch: 3376, MSE: 0.2656682835441318, Learning Rate: 0.08312\n",
      "Epoch: 3377, MSE: 0.2656660105708396, Learning Rate: 0.08311500000000001\n",
      "Epoch: 3378, MSE: 0.26566373754759864, Learning Rate: 0.08311\n",
      "Epoch: 3379, MSE: 0.26566146447440614, Learning Rate: 0.08310500000000001\n",
      "Epoch: 3380, MSE: 0.26565919135126265, Learning Rate: 0.08310000000000001\n",
      "Epoch: 3381, MSE: 0.26565691817816706, Learning Rate: 0.083095\n",
      "Epoch: 3382, MSE: 0.2656546449551183, Learning Rate: 0.08309\n",
      "Epoch: 3383, MSE: 0.2656523716821158, Learning Rate: 0.083085\n",
      "Epoch: 3384, MSE: 0.26565009835915887, Learning Rate: 0.08308\n",
      "Epoch: 3385, MSE: 0.26564782498624767, Learning Rate: 0.08307500000000001\n",
      "Epoch: 3386, MSE: 0.26564555156338004, Learning Rate: 0.08307\n",
      "Epoch: 3387, MSE: 0.2656432780905557, Learning Rate: 0.083065\n",
      "Epoch: 3388, MSE: 0.26564100456777373, Learning Rate: 0.08306000000000001\n",
      "Epoch: 3389, MSE: 0.26563873099503454, Learning Rate: 0.083055\n",
      "Epoch: 3390, MSE: 0.265636457372336, Learning Rate: 0.08305000000000001\n",
      "Epoch: 3391, MSE: 0.26563418369967784, Learning Rate: 0.08304500000000001\n",
      "Epoch: 3392, MSE: 0.2656319099770605, Learning Rate: 0.08304\n",
      "Epoch: 3393, MSE: 0.26562963620448066, Learning Rate: 0.08303500000000001\n",
      "Epoch: 3394, MSE: 0.26562736238193974, Learning Rate: 0.08303\n",
      "Epoch: 3395, MSE: 0.26562508850943617, Learning Rate: 0.083025\n",
      "Epoch: 3396, MSE: 0.265622814586969, Learning Rate: 0.08302000000000001\n",
      "Epoch: 3397, MSE: 0.26562054061453844, Learning Rate: 0.083015\n",
      "Epoch: 3398, MSE: 0.26561826659214327, Learning Rate: 0.08301000000000001\n",
      "Epoch: 3399, MSE: 0.2656159925197824, Learning Rate: 0.083005\n",
      "Epoch: 3400, MSE: 0.2656137183974554, Learning Rate: 0.083\n",
      "Epoch: 3401, MSE: 0.265611444225162, Learning Rate: 0.082995\n",
      "Epoch: 3402, MSE: 0.26560917000289963, Learning Rate: 0.08299000000000001\n",
      "Epoch: 3403, MSE: 0.26560689573067053, Learning Rate: 0.082985\n",
      "Epoch: 3404, MSE: 0.26560462140847163, Learning Rate: 0.08298\n",
      "Epoch: 3405, MSE: 0.2656023470363026, Learning Rate: 0.08297500000000001\n",
      "Epoch: 3406, MSE: 0.26560007261416385, Learning Rate: 0.08297\n",
      "Epoch: 3407, MSE: 0.26559779814205337, Learning Rate: 0.08296500000000001\n",
      "Epoch: 3408, MSE: 0.26559552361997035, Learning Rate: 0.08296\n",
      "Epoch: 3409, MSE: 0.26559324904791554, Learning Rate: 0.082955\n",
      "Epoch: 3410, MSE: 0.2655909744258866, Learning Rate: 0.08295000000000001\n",
      "Epoch: 3411, MSE: 0.2655886997538835, Learning Rate: 0.082945\n",
      "Epoch: 3412, MSE: 0.2655864250319055, Learning Rate: 0.08294000000000001\n",
      "Epoch: 3413, MSE: 0.26558415025995186, Learning Rate: 0.08293500000000001\n",
      "Epoch: 3414, MSE: 0.2655818754380218, Learning Rate: 0.08293\n",
      "Epoch: 3415, MSE: 0.26557960056611424, Learning Rate: 0.08292500000000001\n",
      "Epoch: 3416, MSE: 0.265577325644229, Learning Rate: 0.08292\n",
      "Epoch: 3417, MSE: 0.26557505067236614, Learning Rate: 0.08291500000000002\n",
      "Epoch: 3418, MSE: 0.26557277565052306, Learning Rate: 0.08291\n",
      "Epoch: 3419, MSE: 0.2655705005787001, Learning Rate: 0.082905\n",
      "Epoch: 3420, MSE: 0.26556822545689573, Learning Rate: 0.0829\n",
      "Epoch: 3421, MSE: 0.2655659502851104, Learning Rate: 0.082895\n",
      "Epoch: 3422, MSE: 0.2655636750633421, Learning Rate: 0.08289\n",
      "Epoch: 3423, MSE: 0.26556139979159243, Learning Rate: 0.082885\n",
      "Epoch: 3424, MSE: 0.26555912446985735, Learning Rate: 0.08288000000000001\n",
      "Epoch: 3425, MSE: 0.26555684909813837, Learning Rate: 0.082875\n",
      "Epoch: 3426, MSE: 0.2655545736764342, Learning Rate: 0.08287\n",
      "Epoch: 3427, MSE: 0.265552298204745, Learning Rate: 0.08286500000000001\n",
      "Epoch: 3428, MSE: 0.26555002268306854, Learning Rate: 0.08286\n",
      "Epoch: 3429, MSE: 0.2655477471114037, Learning Rate: 0.08285500000000001\n",
      "Epoch: 3430, MSE: 0.2655454714897522, Learning Rate: 0.08285000000000001\n",
      "Epoch: 3431, MSE: 0.2655431958181114, Learning Rate: 0.082845\n",
      "Epoch: 3432, MSE: 0.26554092009648106, Learning Rate: 0.08284000000000001\n",
      "Epoch: 3433, MSE: 0.2655386443248606, Learning Rate: 0.082835\n",
      "Epoch: 3434, MSE: 0.265536368503249, Learning Rate: 0.08283000000000001\n",
      "Epoch: 3435, MSE: 0.2655340926316455, Learning Rate: 0.082825\n",
      "Epoch: 3436, MSE: 0.2655318167100499, Learning Rate: 0.08282\n",
      "Epoch: 3437, MSE: 0.2655295407384604, Learning Rate: 0.082815\n",
      "Epoch: 3438, MSE: 0.26552726471687804, Learning Rate: 0.08281000000000001\n",
      "Epoch: 3439, MSE: 0.2655249886453003, Learning Rate: 0.082805\n",
      "Epoch: 3440, MSE: 0.26552271252372706, Learning Rate: 0.08280000000000001\n",
      "Epoch: 3441, MSE: 0.26552043635215844, Learning Rate: 0.08279500000000001\n",
      "Epoch: 3442, MSE: 0.2655181601305921, Learning Rate: 0.08279\n",
      "Epoch: 3443, MSE: 0.26551588385902886, Learning Rate: 0.082785\n",
      "Epoch: 3444, MSE: 0.26551360753746756, Learning Rate: 0.08278\n",
      "Epoch: 3445, MSE: 0.2655113311659074, Learning Rate: 0.082775\n",
      "Epoch: 3446, MSE: 0.26550905474434716, Learning Rate: 0.08277000000000001\n",
      "Epoch: 3447, MSE: 0.2655067782727863, Learning Rate: 0.082765\n",
      "Epoch: 3448, MSE: 0.26550450175122386, Learning Rate: 0.08276\n",
      "Epoch: 3449, MSE: 0.26550222517966027, Learning Rate: 0.08275500000000001\n",
      "Epoch: 3450, MSE: 0.2654999485580942, Learning Rate: 0.08275\n",
      "Epoch: 3451, MSE: 0.2654976718865245, Learning Rate: 0.08274500000000001\n",
      "Epoch: 3452, MSE: 0.2654953951649498, Learning Rate: 0.08274000000000001\n",
      "Epoch: 3453, MSE: 0.265493118393372, Learning Rate: 0.082735\n",
      "Epoch: 3454, MSE: 0.26549084157178765, Learning Rate: 0.08273000000000001\n",
      "Epoch: 3455, MSE: 0.26548856470019755, Learning Rate: 0.082725\n",
      "Epoch: 3456, MSE: 0.2654862877786002, Learning Rate: 0.08272\n",
      "Epoch: 3457, MSE: 0.26548401080699563, Learning Rate: 0.08271500000000001\n",
      "Epoch: 3458, MSE: 0.2654817337853822, Learning Rate: 0.08271\n",
      "Epoch: 3459, MSE: 0.26547945671375967, Learning Rate: 0.08270500000000001\n",
      "Epoch: 3460, MSE: 0.2654771795921274, Learning Rate: 0.0827\n",
      "Epoch: 3461, MSE: 0.2654749024204848, Learning Rate: 0.082695\n",
      "Epoch: 3462, MSE: 0.2654726251988305, Learning Rate: 0.08269\n",
      "Epoch: 3463, MSE: 0.2654703479271646, Learning Rate: 0.08268500000000001\n",
      "Epoch: 3464, MSE: 0.26546807060548516, Learning Rate: 0.08268\n",
      "Epoch: 3465, MSE: 0.26546579323379327, Learning Rate: 0.082675\n",
      "Epoch: 3466, MSE: 0.26546351581208644, Learning Rate: 0.08267000000000001\n",
      "Epoch: 3467, MSE: 0.26546123834036506, Learning Rate: 0.082665\n",
      "Epoch: 3468, MSE: 0.2654589608186284, Learning Rate: 0.08266000000000001\n",
      "Epoch: 3469, MSE: 0.2654566832468755, Learning Rate: 0.082655\n",
      "Epoch: 3470, MSE: 0.2654544056251051, Learning Rate: 0.08265\n",
      "Epoch: 3471, MSE: 0.2654521279533163, Learning Rate: 0.08264500000000001\n",
      "Epoch: 3472, MSE: 0.2654498502315102, Learning Rate: 0.08264\n",
      "Epoch: 3473, MSE: 0.2654475724596844, Learning Rate: 0.08263500000000001\n",
      "Epoch: 3474, MSE: 0.2654452946378386, Learning Rate: 0.08263000000000001\n",
      "Epoch: 3475, MSE: 0.2654430167659722, Learning Rate: 0.082625\n",
      "Epoch: 3476, MSE: 0.2654407388440847, Learning Rate: 0.08262000000000001\n",
      "Epoch: 3477, MSE: 0.26543846087217493, Learning Rate: 0.082615\n",
      "Epoch: 3478, MSE: 0.26543618285024245, Learning Rate: 0.08261000000000002\n",
      "Epoch: 3479, MSE: 0.2654339047782861, Learning Rate: 0.082605\n",
      "Epoch: 3480, MSE: 0.26543162665630576, Learning Rate: 0.0826\n",
      "Epoch: 3481, MSE: 0.2654293484843003, Learning Rate: 0.082595\n",
      "Epoch: 3482, MSE: 0.2654270702622693, Learning Rate: 0.08259\n",
      "Epoch: 3483, MSE: 0.265424791990212, Learning Rate: 0.082585\n",
      "Epoch: 3484, MSE: 0.26542251366812775, Learning Rate: 0.08258\n",
      "Epoch: 3485, MSE: 0.26542023529601544, Learning Rate: 0.08257500000000001\n",
      "Epoch: 3486, MSE: 0.2654179568738745, Learning Rate: 0.08257\n",
      "Epoch: 3487, MSE: 0.26541567840170477, Learning Rate: 0.082565\n",
      "Epoch: 3488, MSE: 0.2654133998795051, Learning Rate: 0.08256000000000001\n",
      "Epoch: 3489, MSE: 0.2654111213072735, Learning Rate: 0.082555\n",
      "Epoch: 3490, MSE: 0.2654088426850118, Learning Rate: 0.08255000000000001\n",
      "Epoch: 3491, MSE: 0.26540656401271767, Learning Rate: 0.08254500000000001\n",
      "Epoch: 3492, MSE: 0.26540428529039095, Learning Rate: 0.08254\n",
      "Epoch: 3493, MSE: 0.2654020065180295, Learning Rate: 0.08253500000000001\n",
      "Epoch: 3494, MSE: 0.2653997276956342, Learning Rate: 0.08253\n",
      "Epoch: 3495, MSE: 0.265397448823205, Learning Rate: 0.08252500000000002\n",
      "Epoch: 3496, MSE: 0.2653951699007395, Learning Rate: 0.08252\n",
      "Epoch: 3497, MSE: 0.2653928909282369, Learning Rate: 0.082515\n",
      "Epoch: 3498, MSE: 0.2653906119056981, Learning Rate: 0.08251\n",
      "Epoch: 3499, MSE: 0.2653883328331215, Learning Rate: 0.08250500000000001\n",
      "Epoch: 3500, MSE: 0.26538605371050583, Learning Rate: 0.0825\n",
      "Epoch: 3501, MSE: 0.26538377453785034, Learning Rate: 0.082495\n",
      "Epoch: 3502, MSE: 0.2653814953151562, Learning Rate: 0.08249000000000001\n",
      "Epoch: 3503, MSE: 0.26537921604242015, Learning Rate: 0.082485\n",
      "Epoch: 3504, MSE: 0.2653769367196436, Learning Rate: 0.08248\n",
      "Epoch: 3505, MSE: 0.26537465734682497, Learning Rate: 0.082475\n",
      "Epoch: 3506, MSE: 0.2653723779239631, Learning Rate: 0.08247\n",
      "Epoch: 3507, MSE: 0.2653700984510576, Learning Rate: 0.08246500000000001\n",
      "Epoch: 3508, MSE: 0.2653678189281084, Learning Rate: 0.08246\n",
      "Epoch: 3509, MSE: 0.26536553935511353, Learning Rate: 0.082455\n",
      "Epoch: 3510, MSE: 0.2653632597320732, Learning Rate: 0.08245000000000001\n",
      "Epoch: 3511, MSE: 0.26536098005898734, Learning Rate: 0.082445\n",
      "Epoch: 3512, MSE: 0.26535870033585324, Learning Rate: 0.08244000000000001\n",
      "Epoch: 3513, MSE: 0.265356420562672, Learning Rate: 0.08243500000000001\n",
      "Epoch: 3514, MSE: 0.26535414073944175, Learning Rate: 0.08243\n",
      "Epoch: 3515, MSE: 0.26535186086616264, Learning Rate: 0.08242500000000001\n",
      "Epoch: 3516, MSE: 0.2653495809428332, Learning Rate: 0.08242000000000001\n",
      "Epoch: 3517, MSE: 0.26534730096945336, Learning Rate: 0.082415\n",
      "Epoch: 3518, MSE: 0.2653450209460223, Learning Rate: 0.08241000000000001\n",
      "Epoch: 3519, MSE: 0.2653427408725388, Learning Rate: 0.082405\n",
      "Epoch: 3520, MSE: 0.2653404607490029, Learning Rate: 0.08240000000000001\n",
      "Epoch: 3521, MSE: 0.26533818057541314, Learning Rate: 0.082395\n",
      "Epoch: 3522, MSE: 0.2653359003517699, Learning Rate: 0.08239\n",
      "Epoch: 3523, MSE: 0.26533362007807093, Learning Rate: 0.082385\n",
      "Epoch: 3524, MSE: 0.26533133975431616, Learning Rate: 0.08238000000000001\n",
      "Epoch: 3525, MSE: 0.2653290593805057, Learning Rate: 0.082375\n",
      "Epoch: 3526, MSE: 0.2653267789566385, Learning Rate: 0.08237\n",
      "Epoch: 3527, MSE: 0.2653244984827132, Learning Rate: 0.08236500000000001\n",
      "Epoch: 3528, MSE: 0.26532221795872907, Learning Rate: 0.08236\n",
      "Epoch: 3529, MSE: 0.2653199373846863, Learning Rate: 0.08235500000000001\n",
      "Epoch: 3530, MSE: 0.2653176567605836, Learning Rate: 0.08235\n",
      "Epoch: 3531, MSE: 0.2653153760864198, Learning Rate: 0.082345\n",
      "Epoch: 3532, MSE: 0.2653130953621949, Learning Rate: 0.08234000000000001\n",
      "Epoch: 3533, MSE: 0.26531081458790917, Learning Rate: 0.082335\n",
      "Epoch: 3534, MSE: 0.26530853376355956, Learning Rate: 0.08233000000000001\n",
      "Epoch: 3535, MSE: 0.2653062528891462, Learning Rate: 0.08232500000000001\n",
      "Epoch: 3536, MSE: 0.2653039719646687, Learning Rate: 0.08232\n",
      "Epoch: 3537, MSE: 0.2653016909901284, Learning Rate: 0.08231500000000001\n",
      "Epoch: 3538, MSE: 0.2652994099655206, Learning Rate: 0.08231\n",
      "Epoch: 3539, MSE: 0.26529712889084717, Learning Rate: 0.08230500000000002\n",
      "Epoch: 3540, MSE: 0.2652948477661074, Learning Rate: 0.0823\n",
      "Epoch: 3541, MSE: 0.26529256659129863, Learning Rate: 0.08229500000000001\n",
      "Epoch: 3542, MSE: 0.2652902853664234, Learning Rate: 0.08229\n",
      "Epoch: 3543, MSE: 0.2652880040914774, Learning Rate: 0.082285\n",
      "Epoch: 3544, MSE: 0.2652857227664624, Learning Rate: 0.08228\n",
      "Epoch: 3545, MSE: 0.2652834413913766, Learning Rate: 0.082275\n",
      "Epoch: 3546, MSE: 0.2652811599662201, Learning Rate: 0.08227000000000001\n",
      "Epoch: 3547, MSE: 0.2652788784909911, Learning Rate: 0.082265\n",
      "Epoch: 3548, MSE: 0.2652765969656904, Learning Rate: 0.08226\n",
      "Epoch: 3549, MSE: 0.26527431539031615, Learning Rate: 0.08225500000000001\n",
      "Epoch: 3550, MSE: 0.26527203376486846, Learning Rate: 0.08225\n",
      "Epoch: 3551, MSE: 0.2652697520893445, Learning Rate: 0.08224500000000001\n",
      "Epoch: 3552, MSE: 0.26526747036374637, Learning Rate: 0.08224000000000001\n",
      "Epoch: 3553, MSE: 0.2652651885880721, Learning Rate: 0.082235\n",
      "Epoch: 3554, MSE: 0.26526290676232056, Learning Rate: 0.08223000000000001\n",
      "Epoch: 3555, MSE: 0.2652606248864924, Learning Rate: 0.082225\n",
      "Epoch: 3556, MSE: 0.26525834296058487, Learning Rate: 0.08222000000000002\n",
      "Epoch: 3557, MSE: 0.26525606098459925, Learning Rate: 0.082215\n",
      "Epoch: 3558, MSE: 0.26525377895853347, Learning Rate: 0.08221\n",
      "Epoch: 3559, MSE: 0.26525149688238747, Learning Rate: 0.082205\n",
      "Epoch: 3560, MSE: 0.2652492147561612, Learning Rate: 0.08220000000000001\n",
      "Epoch: 3561, MSE: 0.26524693257985366, Learning Rate: 0.082195\n",
      "Epoch: 3562, MSE: 0.2652446503534628, Learning Rate: 0.08219\n",
      "Epoch: 3563, MSE: 0.2652423680769884, Learning Rate: 0.08218500000000001\n",
      "Epoch: 3564, MSE: 0.2652400857504309, Learning Rate: 0.08218\n",
      "Epoch: 3565, MSE: 0.26523780337378877, Learning Rate: 0.082175\n",
      "Epoch: 3566, MSE: 0.2652355209470613, Learning Rate: 0.08217\n",
      "Epoch: 3567, MSE: 0.2652332384702477, Learning Rate: 0.082165\n",
      "Epoch: 3568, MSE: 0.2652309559433479, Learning Rate: 0.08216000000000001\n",
      "Epoch: 3569, MSE: 0.2652286733663613, Learning Rate: 0.082155\n",
      "Epoch: 3570, MSE: 0.26522639073928617, Learning Rate: 0.08215\n",
      "Epoch: 3571, MSE: 0.26522410806212215, Learning Rate: 0.08214500000000001\n",
      "Epoch: 3572, MSE: 0.26522182533486915, Learning Rate: 0.08214\n",
      "Epoch: 3573, MSE: 0.26521954255752617, Learning Rate: 0.08213500000000001\n",
      "Epoch: 3574, MSE: 0.2652172597300916, Learning Rate: 0.08213000000000001\n",
      "Epoch: 3575, MSE: 0.2652149768525663, Learning Rate: 0.082125\n",
      "Epoch: 3576, MSE: 0.26521269392494856, Learning Rate: 0.08212000000000001\n",
      "Epoch: 3577, MSE: 0.26521041094723796, Learning Rate: 0.08211500000000001\n",
      "Epoch: 3578, MSE: 0.26520812791943393, Learning Rate: 0.08211\n",
      "Epoch: 3579, MSE: 0.2652058448415353, Learning Rate: 0.08210500000000001\n",
      "Epoch: 3580, MSE: 0.2652035617135418, Learning Rate: 0.0821\n",
      "Epoch: 3581, MSE: 0.26520127853545233, Learning Rate: 0.08209500000000002\n",
      "Epoch: 3582, MSE: 0.2651989953072671, Learning Rate: 0.08209\n",
      "Epoch: 3583, MSE: 0.2651967120289845, Learning Rate: 0.082085\n",
      "Epoch: 3584, MSE: 0.26519442870060433, Learning Rate: 0.08208\n",
      "Epoch: 3585, MSE: 0.2651921453221253, Learning Rate: 0.08207500000000001\n",
      "Epoch: 3586, MSE: 0.2651898618935476, Learning Rate: 0.08207\n",
      "Epoch: 3587, MSE: 0.2651875784148704, Learning Rate: 0.082065\n",
      "Epoch: 3588, MSE: 0.26518529488609194, Learning Rate: 0.08206000000000001\n",
      "Epoch: 3589, MSE: 0.26518301130721217, Learning Rate: 0.082055\n",
      "Epoch: 3590, MSE: 0.2651807276782309, Learning Rate: 0.08205000000000001\n",
      "Epoch: 3591, MSE: 0.2651784439991469, Learning Rate: 0.082045\n",
      "Epoch: 3592, MSE: 0.26517616026996005, Learning Rate: 0.08204\n",
      "Epoch: 3593, MSE: 0.26517387649066865, Learning Rate: 0.08203500000000001\n",
      "Epoch: 3594, MSE: 0.26517159266127266, Learning Rate: 0.08203\n",
      "Epoch: 3595, MSE: 0.26516930878177086, Learning Rate: 0.08202500000000001\n",
      "Epoch: 3596, MSE: 0.26516702485216326, Learning Rate: 0.08202000000000001\n",
      "Epoch: 3597, MSE: 0.26516474087244885, Learning Rate: 0.082015\n",
      "Epoch: 3598, MSE: 0.2651624568426273, Learning Rate: 0.08201000000000001\n",
      "Epoch: 3599, MSE: 0.26516017276269715, Learning Rate: 0.082005\n",
      "Epoch: 3600, MSE: 0.2651578886326584, Learning Rate: 0.08200000000000002\n",
      "Epoch: 3601, MSE: 0.2651556044525098, Learning Rate: 0.081995\n",
      "Epoch: 3602, MSE: 0.26515332022225135, Learning Rate: 0.08199000000000001\n",
      "Epoch: 3603, MSE: 0.2651510359418818, Learning Rate: 0.081985\n",
      "Epoch: 3604, MSE: 0.2651487516114007, Learning Rate: 0.08198\n",
      "Epoch: 3605, MSE: 0.26514646723080726, Learning Rate: 0.081975\n",
      "Epoch: 3606, MSE: 0.2651441828000998, Learning Rate: 0.08197\n",
      "Epoch: 3607, MSE: 0.26514189831927953, Learning Rate: 0.08196500000000001\n",
      "Epoch: 3608, MSE: 0.265139613788345, Learning Rate: 0.08196\n",
      "Epoch: 3609, MSE: 0.26513732920729527, Learning Rate: 0.081955\n",
      "Epoch: 3610, MSE: 0.26513504457612963, Learning Rate: 0.08195000000000001\n",
      "Epoch: 3611, MSE: 0.2651327598948478, Learning Rate: 0.081945\n",
      "Epoch: 3612, MSE: 0.26513047516344856, Learning Rate: 0.08194000000000001\n",
      "Epoch: 3613, MSE: 0.2651281903819315, Learning Rate: 0.08193500000000001\n",
      "Epoch: 3614, MSE: 0.2651259055502958, Learning Rate: 0.08193\n",
      "Epoch: 3615, MSE: 0.2651236206685411, Learning Rate: 0.08192500000000001\n",
      "Epoch: 3616, MSE: 0.2651213357366662, Learning Rate: 0.08192\n",
      "Epoch: 3617, MSE: 0.26511905075467107, Learning Rate: 0.08191500000000002\n",
      "Epoch: 3618, MSE: 0.2651167657225541, Learning Rate: 0.08191\n",
      "Epoch: 3619, MSE: 0.26511448064031573, Learning Rate: 0.081905\n",
      "Epoch: 3620, MSE: 0.2651121955079541, Learning Rate: 0.0819\n",
      "Epoch: 3621, MSE: 0.2651099103254699, Learning Rate: 0.08189500000000001\n",
      "Epoch: 3622, MSE: 0.2651076250928603, Learning Rate: 0.08189\n",
      "Epoch: 3623, MSE: 0.26510533981012735, Learning Rate: 0.081885\n",
      "Epoch: 3624, MSE: 0.2651030544772684, Learning Rate: 0.08188000000000001\n",
      "Epoch: 3625, MSE: 0.2651007690942834, Learning Rate: 0.081875\n",
      "Epoch: 3626, MSE: 0.2650984836611713, Learning Rate: 0.08187\n",
      "Epoch: 3627, MSE: 0.265096198177932, Learning Rate: 0.08186500000000001\n",
      "Epoch: 3628, MSE: 0.265093912644564, Learning Rate: 0.08186\n",
      "Epoch: 3629, MSE: 0.2650916270610683, Learning Rate: 0.08185500000000001\n",
      "Epoch: 3630, MSE: 0.2650893414274418, Learning Rate: 0.08185\n",
      "Epoch: 3631, MSE: 0.2650870557436856, Learning Rate: 0.081845\n",
      "Epoch: 3632, MSE: 0.26508477000979885, Learning Rate: 0.08184000000000001\n",
      "Epoch: 3633, MSE: 0.2650824842257803, Learning Rate: 0.081835\n",
      "Epoch: 3634, MSE: 0.265080198391629, Learning Rate: 0.08183000000000001\n",
      "Epoch: 3635, MSE: 0.2650779125073452, Learning Rate: 0.08182500000000001\n",
      "Epoch: 3636, MSE: 0.2650756265729274, Learning Rate: 0.08182\n",
      "Epoch: 3637, MSE: 0.2650733405883753, Learning Rate: 0.081815\n",
      "Epoch: 3638, MSE: 0.26507105455368857, Learning Rate: 0.08181000000000001\n",
      "Epoch: 3639, MSE: 0.2650687684688661, Learning Rate: 0.081805\n",
      "Epoch: 3640, MSE: 0.26506648233390623, Learning Rate: 0.08180000000000001\n",
      "Epoch: 3641, MSE: 0.2650641961488102, Learning Rate: 0.081795\n",
      "Epoch: 3642, MSE: 0.26506190991357614, Learning Rate: 0.08179\n",
      "Epoch: 3643, MSE: 0.2650596236282032, Learning Rate: 0.081785\n",
      "Epoch: 3644, MSE: 0.2650573372926923, Learning Rate: 0.08178\n",
      "Epoch: 3645, MSE: 0.2650550509070407, Learning Rate: 0.081775\n",
      "Epoch: 3646, MSE: 0.2650527644712494, Learning Rate: 0.08177000000000001\n",
      "Epoch: 3647, MSE: 0.2650504779853156, Learning Rate: 0.081765\n",
      "Epoch: 3648, MSE: 0.2650481914492408, Learning Rate: 0.08176\n",
      "Epoch: 3649, MSE: 0.2650459048630233, Learning Rate: 0.08175500000000001\n",
      "Epoch: 3650, MSE: 0.26504361822666195, Learning Rate: 0.08175\n",
      "Epoch: 3651, MSE: 0.2650413315401576, Learning Rate: 0.08174500000000001\n",
      "Epoch: 3652, MSE: 0.26503904480350793, Learning Rate: 0.08174000000000001\n",
      "Epoch: 3653, MSE: 0.2650367580167138, Learning Rate: 0.081735\n",
      "Epoch: 3654, MSE: 0.26503447117977263, Learning Rate: 0.08173000000000001\n",
      "Epoch: 3655, MSE: 0.2650321842926857, Learning Rate: 0.081725\n",
      "Epoch: 3656, MSE: 0.265029897355451, Learning Rate: 0.08172000000000001\n",
      "Epoch: 3657, MSE: 0.2650276103680683, Learning Rate: 0.08171500000000001\n",
      "Epoch: 3658, MSE: 0.2650253233305376, Learning Rate: 0.08171\n",
      "Epoch: 3659, MSE: 0.26502303624285656, Learning Rate: 0.08170500000000001\n",
      "Epoch: 3660, MSE: 0.265020749105026, Learning Rate: 0.0817\n",
      "Epoch: 3661, MSE: 0.26501846191704437, Learning Rate: 0.08169500000000002\n",
      "Epoch: 3662, MSE: 0.2650161746789125, Learning Rate: 0.08169\n",
      "Epoch: 3663, MSE: 0.26501388739062753, Learning Rate: 0.08168500000000001\n",
      "Epoch: 3664, MSE: 0.2650116000521898, Learning Rate: 0.08168\n",
      "Epoch: 3665, MSE: 0.26500931266359856, Learning Rate: 0.081675\n",
      "Epoch: 3666, MSE: 0.2650070252248528, Learning Rate: 0.08167\n",
      "Epoch: 3667, MSE: 0.2650047377359532, Learning Rate: 0.081665\n",
      "Epoch: 3668, MSE: 0.26500245019689816, Learning Rate: 0.08166000000000001\n",
      "Epoch: 3669, MSE: 0.2650001626076863, Learning Rate: 0.081655\n",
      "Epoch: 3670, MSE: 0.264997874968318, Learning Rate: 0.08165\n",
      "Epoch: 3671, MSE: 0.2649955872787919, Learning Rate: 0.08164500000000001\n",
      "Epoch: 3672, MSE: 0.2649932995391075, Learning Rate: 0.08164\n",
      "Epoch: 3673, MSE: 0.2649910117492645, Learning Rate: 0.08163500000000001\n",
      "Epoch: 3674, MSE: 0.2649887239092618, Learning Rate: 0.08163000000000001\n",
      "Epoch: 3675, MSE: 0.26498643601909944, Learning Rate: 0.081625\n",
      "Epoch: 3676, MSE: 0.26498414807877557, Learning Rate: 0.08162000000000001\n",
      "Epoch: 3677, MSE: 0.2649818600882902, Learning Rate: 0.081615\n",
      "Epoch: 3678, MSE: 0.26497957204764344, Learning Rate: 0.08161000000000002\n",
      "Epoch: 3679, MSE: 0.26497728395683234, Learning Rate: 0.081605\n",
      "Epoch: 3680, MSE: 0.26497499581585776, Learning Rate: 0.0816\n",
      "Epoch: 3681, MSE: 0.26497270762471986, Learning Rate: 0.081595\n",
      "Epoch: 3682, MSE: 0.26497041938341676, Learning Rate: 0.08159\n",
      "Epoch: 3683, MSE: 0.2649681310919471, Learning Rate: 0.081585\n",
      "Epoch: 3684, MSE: 0.2649658427503119, Learning Rate: 0.08158\n",
      "Epoch: 3685, MSE: 0.26496355435851, Learning Rate: 0.08157500000000001\n",
      "Epoch: 3686, MSE: 0.26496126591653973, Learning Rate: 0.08157\n",
      "Epoch: 3687, MSE: 0.2649589774244019, Learning Rate: 0.081565\n",
      "Epoch: 3688, MSE: 0.2649566888820951, Learning Rate: 0.08156000000000001\n",
      "Epoch: 3689, MSE: 0.2649544002896181, Learning Rate: 0.081555\n",
      "Epoch: 3690, MSE: 0.26495211164697047, Learning Rate: 0.08155000000000001\n",
      "Epoch: 3691, MSE: 0.2649498229541521, Learning Rate: 0.081545\n",
      "Epoch: 3692, MSE: 0.26494753421116196, Learning Rate: 0.08154\n",
      "Epoch: 3693, MSE: 0.2649452454180002, Learning Rate: 0.08153500000000001\n",
      "Epoch: 3694, MSE: 0.2649429565746645, Learning Rate: 0.08153\n",
      "Epoch: 3695, MSE: 0.26494066768115554, Learning Rate: 0.08152500000000001\n",
      "Epoch: 3696, MSE: 0.2649383787374719, Learning Rate: 0.08152000000000001\n",
      "Epoch: 3697, MSE: 0.2649360897436131, Learning Rate: 0.081515\n",
      "Epoch: 3698, MSE: 0.26493380069957934, Learning Rate: 0.08151\n",
      "Epoch: 3699, MSE: 0.2649315116053682, Learning Rate: 0.08150500000000001\n",
      "Epoch: 3700, MSE: 0.26492922246098083, Learning Rate: 0.0815\n",
      "Epoch: 3701, MSE: 0.26492693326641553, Learning Rate: 0.08149500000000001\n",
      "Epoch: 3702, MSE: 0.26492464402167143, Learning Rate: 0.08149\n",
      "Epoch: 3703, MSE: 0.26492235472674835, Learning Rate: 0.081485\n",
      "Epoch: 3704, MSE: 0.2649200653816459, Learning Rate: 0.08148\n",
      "Epoch: 3705, MSE: 0.26491777598636257, Learning Rate: 0.081475\n",
      "Epoch: 3706, MSE: 0.2649154865408983, Learning Rate: 0.08147\n",
      "Epoch: 3707, MSE: 0.264913197045252, Learning Rate: 0.08146500000000001\n",
      "Epoch: 3708, MSE: 0.26491090749942336, Learning Rate: 0.08146\n",
      "Epoch: 3709, MSE: 0.2649086179034118, Learning Rate: 0.081455\n",
      "Epoch: 3710, MSE: 0.2649063282572155, Learning Rate: 0.08145000000000001\n",
      "Epoch: 3711, MSE: 0.26490403856083605, Learning Rate: 0.081445\n",
      "Epoch: 3712, MSE: 0.2649017488142708, Learning Rate: 0.08144000000000001\n",
      "Epoch: 3713, MSE: 0.2648994590175209, Learning Rate: 0.08143500000000001\n",
      "Epoch: 3714, MSE: 0.26489716917058287, Learning Rate: 0.08143\n",
      "Epoch: 3715, MSE: 0.26489487927345917, Learning Rate: 0.08142500000000001\n",
      "Epoch: 3716, MSE: 0.26489258932614645, Learning Rate: 0.08142\n",
      "Epoch: 3717, MSE: 0.264890299328646, Learning Rate: 0.08141500000000002\n",
      "Epoch: 3718, MSE: 0.26488800928095624, Learning Rate: 0.08141000000000001\n",
      "Epoch: 3719, MSE: 0.26488571918307724, Learning Rate: 0.081405\n",
      "Epoch: 3720, MSE: 0.2648834290350067, Learning Rate: 0.08140000000000001\n",
      "Epoch: 3721, MSE: 0.26488113883674524, Learning Rate: 0.081395\n",
      "Epoch: 3722, MSE: 0.26487884858829275, Learning Rate: 0.08139000000000002\n",
      "Epoch: 3723, MSE: 0.2648765582896475, Learning Rate: 0.081385\n",
      "Epoch: 3724, MSE: 0.26487426794080854, Learning Rate: 0.08138000000000001\n",
      "Epoch: 3725, MSE: 0.2648719775417768, Learning Rate: 0.081375\n",
      "Epoch: 3726, MSE: 0.26486968709254943, Learning Rate: 0.08137\n",
      "Epoch: 3727, MSE: 0.26486739659312786, Learning Rate: 0.081365\n",
      "Epoch: 3728, MSE: 0.26486510604350993, Learning Rate: 0.08136\n",
      "Epoch: 3729, MSE: 0.26486281544369533, Learning Rate: 0.08135500000000001\n",
      "Epoch: 3730, MSE: 0.2648605247936846, Learning Rate: 0.08135\n",
      "Epoch: 3731, MSE: 0.26485823409347564, Learning Rate: 0.081345\n",
      "Epoch: 3732, MSE: 0.2648559433430681, Learning Rate: 0.08134000000000001\n",
      "Epoch: 3733, MSE: 0.2648536525424611, Learning Rate: 0.081335\n",
      "Epoch: 3734, MSE: 0.264851361691654, Learning Rate: 0.08133000000000001\n",
      "Epoch: 3735, MSE: 0.26484907079064723, Learning Rate: 0.08132500000000001\n",
      "Epoch: 3736, MSE: 0.2648467798394398, Learning Rate: 0.08132\n",
      "Epoch: 3737, MSE: 0.2648444888380298, Learning Rate: 0.08131500000000001\n",
      "Epoch: 3738, MSE: 0.26484219778641793, Learning Rate: 0.08131\n",
      "Epoch: 3739, MSE: 0.26483990668460206, Learning Rate: 0.08130500000000002\n",
      "Epoch: 3740, MSE: 0.26483761553258295, Learning Rate: 0.0813\n",
      "Epoch: 3741, MSE: 0.2648353243303595, Learning Rate: 0.081295\n",
      "Epoch: 3742, MSE: 0.2648330330779304, Learning Rate: 0.08129\n",
      "Epoch: 3743, MSE: 0.2648307417752967, Learning Rate: 0.081285\n",
      "Epoch: 3744, MSE: 0.26482845042245573, Learning Rate: 0.08128\n",
      "Epoch: 3745, MSE: 0.26482615901940787, Learning Rate: 0.081275\n",
      "Epoch: 3746, MSE: 0.2648238675661521, Learning Rate: 0.08127000000000001\n",
      "Epoch: 3747, MSE: 0.2648215760626887, Learning Rate: 0.081265\n",
      "Epoch: 3748, MSE: 0.26481928450901504, Learning Rate: 0.08126\n",
      "Epoch: 3749, MSE: 0.2648169929051321, Learning Rate: 0.08125500000000001\n",
      "Epoch: 3750, MSE: 0.26481470125103895, Learning Rate: 0.08125\n",
      "Epoch: 3751, MSE: 0.2648124095467351, Learning Rate: 0.08124500000000001\n",
      "Epoch: 3752, MSE: 0.2648101177922191, Learning Rate: 0.08124\n",
      "Epoch: 3753, MSE: 0.2648078259874906, Learning Rate: 0.081235\n",
      "Epoch: 3754, MSE: 0.2648055341325489, Learning Rate: 0.08123000000000001\n",
      "Epoch: 3755, MSE: 0.2648032422273943, Learning Rate: 0.081225\n",
      "Epoch: 3756, MSE: 0.26480095027202444, Learning Rate: 0.08122000000000001\n",
      "Epoch: 3757, MSE: 0.2647986582664399, Learning Rate: 0.08121500000000001\n",
      "Epoch: 3758, MSE: 0.2647963662106401, Learning Rate: 0.08121\n",
      "Epoch: 3759, MSE: 0.2647940741046239, Learning Rate: 0.081205\n",
      "Epoch: 3760, MSE: 0.26479178194839087, Learning Rate: 0.08120000000000001\n",
      "Epoch: 3761, MSE: 0.2647894897419394, Learning Rate: 0.081195\n",
      "Epoch: 3762, MSE: 0.26478719748526997, Learning Rate: 0.08119000000000001\n",
      "Epoch: 3763, MSE: 0.2647849051783819, Learning Rate: 0.08118500000000001\n",
      "Epoch: 3764, MSE: 0.2647826128212742, Learning Rate: 0.08118\n",
      "Epoch: 3765, MSE: 0.26478032041394584, Learning Rate: 0.081175\n",
      "Epoch: 3766, MSE: 0.2647780279563973, Learning Rate: 0.08117\n",
      "Epoch: 3767, MSE: 0.26477573544862626, Learning Rate: 0.081165\n",
      "Epoch: 3768, MSE: 0.2647734428906337, Learning Rate: 0.08116000000000001\n",
      "Epoch: 3769, MSE: 0.2647711502824176, Learning Rate: 0.081155\n",
      "Epoch: 3770, MSE: 0.26476885762397817, Learning Rate: 0.08115\n",
      "Epoch: 3771, MSE: 0.26476656491531464, Learning Rate: 0.08114500000000001\n",
      "Epoch: 3772, MSE: 0.2647642721564265, Learning Rate: 0.08114\n",
      "Epoch: 3773, MSE: 0.2647619793473119, Learning Rate: 0.08113500000000001\n",
      "Epoch: 3774, MSE: 0.26475968648797166, Learning Rate: 0.08113000000000001\n",
      "Epoch: 3775, MSE: 0.26475739357840494, Learning Rate: 0.081125\n",
      "Epoch: 3776, MSE: 0.26475510061861024, Learning Rate: 0.08112000000000001\n",
      "Epoch: 3777, MSE: 0.2647528076085874, Learning Rate: 0.081115\n",
      "Epoch: 3778, MSE: 0.26475051454833637, Learning Rate: 0.08111\n",
      "Epoch: 3779, MSE: 0.26474822143785515, Learning Rate: 0.08110500000000001\n",
      "Epoch: 3780, MSE: 0.2647459282771442, Learning Rate: 0.0811\n",
      "Epoch: 3781, MSE: 0.26474363506620247, Learning Rate: 0.08109500000000001\n",
      "Epoch: 3782, MSE: 0.2647413418050292, Learning Rate: 0.08109\n",
      "Epoch: 3783, MSE: 0.26473904849362406, Learning Rate: 0.081085\n",
      "Epoch: 3784, MSE: 0.2647367551319859, Learning Rate: 0.08108\n",
      "Epoch: 3785, MSE: 0.26473446172011433, Learning Rate: 0.08107500000000001\n",
      "Epoch: 3786, MSE: 0.26473216825800894, Learning Rate: 0.08107\n",
      "Epoch: 3787, MSE: 0.264729874745669, Learning Rate: 0.081065\n",
      "Epoch: 3788, MSE: 0.26472758118309403, Learning Rate: 0.08106000000000001\n",
      "Epoch: 3789, MSE: 0.2647252875702822, Learning Rate: 0.081055\n",
      "Epoch: 3790, MSE: 0.2647229939072344, Learning Rate: 0.08105000000000001\n",
      "Epoch: 3791, MSE: 0.2647207001939484, Learning Rate: 0.081045\n",
      "Epoch: 3792, MSE: 0.26471840643042505, Learning Rate: 0.08104\n",
      "Epoch: 3793, MSE: 0.26471611261666345, Learning Rate: 0.08103500000000001\n",
      "Epoch: 3794, MSE: 0.2647138187526624, Learning Rate: 0.08103\n",
      "Epoch: 3795, MSE: 0.2647115248384212, Learning Rate: 0.08102500000000001\n",
      "Epoch: 3796, MSE: 0.2647092308739393, Learning Rate: 0.08102000000000001\n",
      "Epoch: 3797, MSE: 0.2647069368592164, Learning Rate: 0.081015\n",
      "Epoch: 3798, MSE: 0.2647046427942511, Learning Rate: 0.08101000000000001\n",
      "Epoch: 3799, MSE: 0.26470234867904496, Learning Rate: 0.081005\n",
      "Epoch: 3800, MSE: 0.2647000545135941, Learning Rate: 0.08100000000000002\n",
      "Epoch: 3801, MSE: 0.2646977602979002, Learning Rate: 0.080995\n",
      "Epoch: 3802, MSE: 0.26469546603196104, Learning Rate: 0.08099\n",
      "Epoch: 3803, MSE: 0.2646931717157778, Learning Rate: 0.080985\n",
      "Epoch: 3804, MSE: 0.26469087734934776, Learning Rate: 0.08098\n",
      "Epoch: 3805, MSE: 0.2646885829326717, Learning Rate: 0.080975\n",
      "Epoch: 3806, MSE: 0.26468628846574865, Learning Rate: 0.08097\n",
      "Epoch: 3807, MSE: 0.26468399394857817, Learning Rate: 0.08096500000000001\n",
      "Epoch: 3808, MSE: 0.2646816993811593, Learning Rate: 0.08096\n",
      "Epoch: 3809, MSE: 0.26467940476349117, Learning Rate: 0.080955\n",
      "Epoch: 3810, MSE: 0.26467711009557393, Learning Rate: 0.08095000000000001\n",
      "Epoch: 3811, MSE: 0.2646748153774057, Learning Rate: 0.080945\n",
      "Epoch: 3812, MSE: 0.2646725206089866, Learning Rate: 0.08094000000000001\n",
      "Epoch: 3813, MSE: 0.2646702257903167, Learning Rate: 0.080935\n",
      "Epoch: 3814, MSE: 0.26466793092139346, Learning Rate: 0.08093\n",
      "Epoch: 3815, MSE: 0.26466563600221815, Learning Rate: 0.08092500000000001\n",
      "Epoch: 3816, MSE: 0.26466334103278893, Learning Rate: 0.08092\n",
      "Epoch: 3817, MSE: 0.2646610460131054, Learning Rate: 0.08091500000000001\n",
      "Epoch: 3818, MSE: 0.26465875094316715, Learning Rate: 0.08091000000000001\n",
      "Epoch: 3819, MSE: 0.264656455822973, Learning Rate: 0.080905\n",
      "Epoch: 3820, MSE: 0.26465416065252373, Learning Rate: 0.0809\n",
      "Epoch: 3821, MSE: 0.26465186543181707, Learning Rate: 0.08089500000000001\n",
      "Epoch: 3822, MSE: 0.26464957016085355, Learning Rate: 0.08089\n",
      "Epoch: 3823, MSE: 0.26464727483963146, Learning Rate: 0.08088500000000001\n",
      "Epoch: 3824, MSE: 0.26464497946815035, Learning Rate: 0.08088000000000001\n",
      "Epoch: 3825, MSE: 0.2646426840464112, Learning Rate: 0.080875\n",
      "Epoch: 3826, MSE: 0.2646403885744108, Learning Rate: 0.08087\n",
      "Epoch: 3827, MSE: 0.2646380930521507, Learning Rate: 0.080865\n",
      "Epoch: 3828, MSE: 0.26463579747962857, Learning Rate: 0.08086\n",
      "Epoch: 3829, MSE: 0.2646335018568447, Learning Rate: 0.08085500000000001\n",
      "Epoch: 3830, MSE: 0.2646312061837983, Learning Rate: 0.08085\n",
      "Epoch: 3831, MSE: 0.2646289104604879, Learning Rate: 0.080845\n",
      "Epoch: 3832, MSE: 0.264626614686915, Learning Rate: 0.08084000000000001\n",
      "Epoch: 3833, MSE: 0.26462431886307686, Learning Rate: 0.080835\n",
      "Epoch: 3834, MSE: 0.2646220229889745, Learning Rate: 0.08083000000000001\n",
      "Epoch: 3835, MSE: 0.2646197270646054, Learning Rate: 0.08082500000000001\n",
      "Epoch: 3836, MSE: 0.26461743108996993, Learning Rate: 0.08082\n",
      "Epoch: 3837, MSE: 0.26461513506506795, Learning Rate: 0.08081500000000001\n",
      "Epoch: 3838, MSE: 0.26461283898989785, Learning Rate: 0.08081\n",
      "Epoch: 3839, MSE: 0.26461054286445956, Learning Rate: 0.080805\n",
      "Epoch: 3840, MSE: 0.26460824668875244, Learning Rate: 0.08080000000000001\n",
      "Epoch: 3841, MSE: 0.26460595046277474, Learning Rate: 0.080795\n",
      "Epoch: 3842, MSE: 0.264603654186528, Learning Rate: 0.08079000000000001\n",
      "Epoch: 3843, MSE: 0.26460135786000927, Learning Rate: 0.080785\n",
      "Epoch: 3844, MSE: 0.26459906148321943, Learning Rate: 0.08078\n",
      "Epoch: 3845, MSE: 0.26459676505615787, Learning Rate: 0.080775\n",
      "Epoch: 3846, MSE: 0.26459446857882285, Learning Rate: 0.08077000000000001\n",
      "Epoch: 3847, MSE: 0.2645921720512147, Learning Rate: 0.080765\n",
      "Epoch: 3848, MSE: 0.26458987547333246, Learning Rate: 0.08076\n",
      "Epoch: 3849, MSE: 0.26458757884517553, Learning Rate: 0.08075500000000001\n",
      "Epoch: 3850, MSE: 0.26458528216674304, Learning Rate: 0.08075\n",
      "Epoch: 3851, MSE: 0.26458298543803443, Learning Rate: 0.08074500000000001\n",
      "Epoch: 3852, MSE: 0.26458068865904966, Learning Rate: 0.08074\n",
      "Epoch: 3853, MSE: 0.26457839182978704, Learning Rate: 0.080735\n",
      "Epoch: 3854, MSE: 0.2645760949502462, Learning Rate: 0.08073000000000001\n",
      "Epoch: 3855, MSE: 0.26457379802042785, Learning Rate: 0.080725\n",
      "Epoch: 3856, MSE: 0.2645715010403295, Learning Rate: 0.08072000000000001\n",
      "Epoch: 3857, MSE: 0.2645692040099509, Learning Rate: 0.08071500000000001\n",
      "Epoch: 3858, MSE: 0.26456690692929247, Learning Rate: 0.08071\n",
      "Epoch: 3859, MSE: 0.26456460979835333, Learning Rate: 0.08070500000000001\n",
      "Epoch: 3860, MSE: 0.26456231261713187, Learning Rate: 0.0807\n",
      "Epoch: 3861, MSE: 0.2645600153856277, Learning Rate: 0.08069500000000002\n",
      "Epoch: 3862, MSE: 0.2645577181038401, Learning Rate: 0.08069\n",
      "Epoch: 3863, MSE: 0.26455542077176986, Learning Rate: 0.080685\n",
      "Epoch: 3864, MSE: 0.26455312338941517, Learning Rate: 0.08068\n",
      "Epoch: 3865, MSE: 0.26455082595677565, Learning Rate: 0.080675\n",
      "Epoch: 3866, MSE: 0.26454852847384974, Learning Rate: 0.08067\n",
      "Epoch: 3867, MSE: 0.2645462309406379, Learning Rate: 0.080665\n",
      "Epoch: 3868, MSE: 0.264543933357139, Learning Rate: 0.08066000000000001\n",
      "Epoch: 3869, MSE: 0.2645416357233535, Learning Rate: 0.080655\n",
      "Epoch: 3870, MSE: 0.2645393380392791, Learning Rate: 0.08065\n",
      "Epoch: 3871, MSE: 0.26453704030491587, Learning Rate: 0.08064500000000001\n",
      "Epoch: 3872, MSE: 0.2645347425202637, Learning Rate: 0.08064\n",
      "Epoch: 3873, MSE: 0.2645324446853212, Learning Rate: 0.08063500000000001\n",
      "Epoch: 3874, MSE: 0.2645301468000879, Learning Rate: 0.08063000000000001\n",
      "Epoch: 3875, MSE: 0.2645278488645644, Learning Rate: 0.080625\n",
      "Epoch: 3876, MSE: 0.2645255508787474, Learning Rate: 0.08062000000000001\n",
      "Epoch: 3877, MSE: 0.2645232528426387, Learning Rate: 0.080615\n",
      "Epoch: 3878, MSE: 0.2645209547562364, Learning Rate: 0.08061000000000001\n",
      "Epoch: 3879, MSE: 0.2645186566195409, Learning Rate: 0.080605\n",
      "Epoch: 3880, MSE: 0.2645163584325505, Learning Rate: 0.0806\n",
      "Epoch: 3881, MSE: 0.26451406019526474, Learning Rate: 0.080595\n",
      "Epoch: 3882, MSE: 0.264511761907684, Learning Rate: 0.08059000000000001\n",
      "Epoch: 3883, MSE: 0.2645094635698062, Learning Rate: 0.080585\n",
      "Epoch: 3884, MSE: 0.26450716518163125, Learning Rate: 0.08058\n",
      "Epoch: 3885, MSE: 0.2645048667431589, Learning Rate: 0.08057500000000001\n",
      "Epoch: 3886, MSE: 0.26450256825438795, Learning Rate: 0.08057\n",
      "Epoch: 3887, MSE: 0.2645002697153191, Learning Rate: 0.080565\n",
      "Epoch: 3888, MSE: 0.2644979711259502, Learning Rate: 0.08056\n",
      "Epoch: 3889, MSE: 0.2644956724862813, Learning Rate: 0.080555\n",
      "Epoch: 3890, MSE: 0.26449337379631127, Learning Rate: 0.08055000000000001\n",
      "Epoch: 3891, MSE: 0.2644910750560401, Learning Rate: 0.080545\n",
      "Epoch: 3892, MSE: 0.2644887762654669, Learning Rate: 0.08054\n",
      "Epoch: 3893, MSE: 0.2644864774245908, Learning Rate: 0.08053500000000001\n",
      "Epoch: 3894, MSE: 0.2644841785334114, Learning Rate: 0.08053\n",
      "Epoch: 3895, MSE: 0.26448187959192776, Learning Rate: 0.08052500000000001\n",
      "Epoch: 3896, MSE: 0.2644795806001403, Learning Rate: 0.08052000000000001\n",
      "Epoch: 3897, MSE: 0.2644772815580478, Learning Rate: 0.080515\n",
      "Epoch: 3898, MSE: 0.2644749824656481, Learning Rate: 0.08051000000000001\n",
      "Epoch: 3899, MSE: 0.2644726833229428, Learning Rate: 0.08050500000000001\n",
      "Epoch: 3900, MSE: 0.26447038412993135, Learning Rate: 0.0805\n",
      "Epoch: 3901, MSE: 0.2644680848866107, Learning Rate: 0.08049500000000001\n",
      "Epoch: 3902, MSE: 0.2644657855929821, Learning Rate: 0.08049\n",
      "Epoch: 3903, MSE: 0.2644634862490446, Learning Rate: 0.08048500000000001\n",
      "Epoch: 3904, MSE: 0.26446118685479814, Learning Rate: 0.08048\n",
      "Epoch: 3905, MSE: 0.26445888741024054, Learning Rate: 0.080475\n",
      "Epoch: 3906, MSE: 0.2644565879153726, Learning Rate: 0.08047\n",
      "Epoch: 3907, MSE: 0.26445428837019325, Learning Rate: 0.08046500000000001\n",
      "Epoch: 3908, MSE: 0.2644519887747014, Learning Rate: 0.08046\n",
      "Epoch: 3909, MSE: 0.2644496891288973, Learning Rate: 0.080455\n",
      "Epoch: 3910, MSE: 0.26444738943277935, Learning Rate: 0.08045000000000001\n",
      "Epoch: 3911, MSE: 0.26444508968634794, Learning Rate: 0.080445\n",
      "Epoch: 3912, MSE: 0.26444278988960174, Learning Rate: 0.08044000000000001\n",
      "Epoch: 3913, MSE: 0.2644404900425399, Learning Rate: 0.080435\n",
      "Epoch: 3914, MSE: 0.26443819014516246, Learning Rate: 0.08043\n",
      "Epoch: 3915, MSE: 0.2644358901974689, Learning Rate: 0.08042500000000001\n",
      "Epoch: 3916, MSE: 0.26443359019945795, Learning Rate: 0.08042\n",
      "Epoch: 3917, MSE: 0.2644312901511294, Learning Rate: 0.08041500000000001\n",
      "Epoch: 3918, MSE: 0.2644289900524826, Learning Rate: 0.08041000000000001\n",
      "Epoch: 3919, MSE: 0.26442668990351575, Learning Rate: 0.080405\n",
      "Epoch: 3920, MSE: 0.26442438970423077, Learning Rate: 0.08040000000000001\n",
      "Epoch: 3921, MSE: 0.2644220894546246, Learning Rate: 0.080395\n",
      "Epoch: 3922, MSE: 0.264419789154698, Learning Rate: 0.08039000000000002\n",
      "Epoch: 3923, MSE: 0.2644174888044491, Learning Rate: 0.080385\n",
      "Epoch: 3924, MSE: 0.26441518840387934, Learning Rate: 0.08038000000000001\n",
      "Epoch: 3925, MSE: 0.26441288795298673, Learning Rate: 0.080375\n",
      "Epoch: 3926, MSE: 0.2644105874517702, Learning Rate: 0.08037\n",
      "Epoch: 3927, MSE: 0.2644082869002298, Learning Rate: 0.080365\n",
      "Epoch: 3928, MSE: 0.26440598629836454, Learning Rate: 0.08036\n",
      "Epoch: 3929, MSE: 0.26440368564617445, Learning Rate: 0.08035500000000001\n",
      "Epoch: 3930, MSE: 0.264401384943659, Learning Rate: 0.08035\n",
      "Epoch: 3931, MSE: 0.26439908419081637, Learning Rate: 0.080345\n",
      "Epoch: 3932, MSE: 0.2643967833876469, Learning Rate: 0.08034000000000001\n",
      "Epoch: 3933, MSE: 0.2643944825341493, Learning Rate: 0.080335\n",
      "Epoch: 3934, MSE: 0.2643921816303242, Learning Rate: 0.08033000000000001\n",
      "Epoch: 3935, MSE: 0.26438988067616964, Learning Rate: 0.08032500000000001\n",
      "Epoch: 3936, MSE: 0.26438757967168597, Learning Rate: 0.08032\n",
      "Epoch: 3937, MSE: 0.26438527861687144, Learning Rate: 0.08031500000000001\n",
      "Epoch: 3938, MSE: 0.2643829775117267, Learning Rate: 0.08031\n",
      "Epoch: 3939, MSE: 0.26438067635625007, Learning Rate: 0.08030500000000002\n",
      "Epoch: 3940, MSE: 0.26437837515044094, Learning Rate: 0.0803\n",
      "Epoch: 3941, MSE: 0.26437607389430035, Learning Rate: 0.080295\n",
      "Epoch: 3942, MSE: 0.2643737725878253, Learning Rate: 0.08029\n",
      "Epoch: 3943, MSE: 0.2643714712310177, Learning Rate: 0.08028500000000001\n",
      "Epoch: 3944, MSE: 0.26436916982387487, Learning Rate: 0.08028\n",
      "Epoch: 3945, MSE: 0.2643668683663964, Learning Rate: 0.080275\n",
      "Epoch: 3946, MSE: 0.2643645668585829, Learning Rate: 0.08027000000000001\n",
      "Epoch: 3947, MSE: 0.2643622653004333, Learning Rate: 0.080265\n",
      "Epoch: 3948, MSE: 0.2643599636919457, Learning Rate: 0.08026\n",
      "Epoch: 3949, MSE: 0.264357662033121, Learning Rate: 0.080255\n",
      "Epoch: 3950, MSE: 0.26435536032395857, Learning Rate: 0.08025\n",
      "Epoch: 3951, MSE: 0.2643530585644566, Learning Rate: 0.08024500000000001\n",
      "Epoch: 3952, MSE: 0.26435075675461567, Learning Rate: 0.08024\n",
      "Epoch: 3953, MSE: 0.2643484548944341, Learning Rate: 0.080235\n",
      "Epoch: 3954, MSE: 0.26434615298391223, Learning Rate: 0.08023000000000001\n",
      "Epoch: 3955, MSE: 0.26434385102304936, Learning Rate: 0.080225\n",
      "Epoch: 3956, MSE: 0.2643415490118434, Learning Rate: 0.08022000000000001\n",
      "Epoch: 3957, MSE: 0.2643392469502957, Learning Rate: 0.08021500000000001\n",
      "Epoch: 3958, MSE: 0.2643369448384051, Learning Rate: 0.08021\n",
      "Epoch: 3959, MSE: 0.2643346426761704, Learning Rate: 0.08020500000000001\n",
      "Epoch: 3960, MSE: 0.2643323404635912, Learning Rate: 0.08020000000000001\n",
      "Epoch: 3961, MSE: 0.2643300382006667, Learning Rate: 0.080195\n",
      "Epoch: 3962, MSE: 0.2643277358873974, Learning Rate: 0.08019000000000001\n",
      "Epoch: 3963, MSE: 0.2643254335237819, Learning Rate: 0.080185\n",
      "Epoch: 3964, MSE: 0.2643231311098188, Learning Rate: 0.08018000000000002\n",
      "Epoch: 3965, MSE: 0.26432082864550854, Learning Rate: 0.080175\n",
      "Epoch: 3966, MSE: 0.2643185261308502, Learning Rate: 0.08017\n",
      "Epoch: 3967, MSE: 0.26431622356584283, Learning Rate: 0.080165\n",
      "Epoch: 3968, MSE: 0.2643139209504865, Learning Rate: 0.08016000000000001\n",
      "Epoch: 3969, MSE: 0.2643116182847805, Learning Rate: 0.080155\n",
      "Epoch: 3970, MSE: 0.26430931556872345, Learning Rate: 0.08015\n",
      "Epoch: 3971, MSE: 0.2643070128023155, Learning Rate: 0.08014500000000001\n",
      "Epoch: 3972, MSE: 0.2643047099855559, Learning Rate: 0.08014\n",
      "Epoch: 3973, MSE: 0.264302407118444, Learning Rate: 0.08013500000000001\n",
      "Epoch: 3974, MSE: 0.2643001042009788, Learning Rate: 0.08013\n",
      "Epoch: 3975, MSE: 0.26429780123316027, Learning Rate: 0.080125\n",
      "Epoch: 3976, MSE: 0.2642954982149874, Learning Rate: 0.08012000000000001\n",
      "Epoch: 3977, MSE: 0.2642931951464601, Learning Rate: 0.080115\n",
      "Epoch: 3978, MSE: 0.2642908920275773, Learning Rate: 0.08011000000000001\n",
      "Epoch: 3979, MSE: 0.26428858885833756, Learning Rate: 0.08010500000000001\n",
      "Epoch: 3980, MSE: 0.26428628563874207, Learning Rate: 0.0801\n",
      "Epoch: 3981, MSE: 0.26428398236878936, Learning Rate: 0.08009500000000001\n",
      "Epoch: 3982, MSE: 0.26428167904847755, Learning Rate: 0.08009\n",
      "Epoch: 3983, MSE: 0.26427937567780874, Learning Rate: 0.08008500000000002\n",
      "Epoch: 3984, MSE: 0.2642770722567809, Learning Rate: 0.08008\n",
      "Epoch: 3985, MSE: 0.26427476878539247, Learning Rate: 0.08007500000000001\n",
      "Epoch: 3986, MSE: 0.2642724652636433, Learning Rate: 0.08007\n",
      "Epoch: 3987, MSE: 0.264270161691534, Learning Rate: 0.080065\n",
      "Epoch: 3988, MSE: 0.26426785806906383, Learning Rate: 0.08006\n",
      "Epoch: 3989, MSE: 0.2642655543962303, Learning Rate: 0.080055\n",
      "Epoch: 3990, MSE: 0.26426325067303463, Learning Rate: 0.08005000000000001\n",
      "Epoch: 3991, MSE: 0.264260946899475, Learning Rate: 0.080045\n",
      "Epoch: 3992, MSE: 0.2642586430755525, Learning Rate: 0.08004\n",
      "Epoch: 3993, MSE: 0.2642563392012646, Learning Rate: 0.08003500000000001\n",
      "Epoch: 3994, MSE: 0.2642540352766115, Learning Rate: 0.08003\n",
      "Epoch: 3995, MSE: 0.26425173130159313, Learning Rate: 0.08002500000000001\n",
      "Epoch: 3996, MSE: 0.2642494272762075, Learning Rate: 0.08002000000000001\n",
      "Epoch: 3997, MSE: 0.2642471232004559, Learning Rate: 0.080015\n",
      "Epoch: 3998, MSE: 0.2642448190743361, Learning Rate: 0.08001000000000001\n",
      "Epoch: 3999, MSE: 0.26424251489784834, Learning Rate: 0.080005\n",
      "Epoch: 4000, MSE: 0.2642402106709916, Learning Rate: 0.08000000000000002\n",
      "Epoch: 4001, MSE: 0.2642379063937653, Learning Rate: 0.079995\n",
      "Epoch: 4002, MSE: 0.26423560206616936, Learning Rate: 0.07999\n",
      "Epoch: 4003, MSE: 0.26423329768820214, Learning Rate: 0.079985\n",
      "Epoch: 4004, MSE: 0.26423099325986465, Learning Rate: 0.07998000000000001\n",
      "Epoch: 4005, MSE: 0.26422868878115435, Learning Rate: 0.079975\n",
      "Epoch: 4006, MSE: 0.26422638425207157, Learning Rate: 0.07997\n",
      "Epoch: 4007, MSE: 0.26422407967261663, Learning Rate: 0.07996500000000001\n",
      "Epoch: 4008, MSE: 0.2642217750427875, Learning Rate: 0.07996\n",
      "Epoch: 4009, MSE: 0.264219470362584, Learning Rate: 0.079955\n",
      "Epoch: 4010, MSE: 0.26421716563200576, Learning Rate: 0.07995000000000001\n",
      "Epoch: 4011, MSE: 0.26421486085105245, Learning Rate: 0.079945\n",
      "Epoch: 4012, MSE: 0.26421255601972293, Learning Rate: 0.07994000000000001\n",
      "Epoch: 4013, MSE: 0.26421025113801655, Learning Rate: 0.079935\n",
      "Epoch: 4014, MSE: 0.26420794620593213, Learning Rate: 0.07993\n",
      "Epoch: 4015, MSE: 0.2642056412234701, Learning Rate: 0.07992500000000001\n",
      "Epoch: 4016, MSE: 0.26420333619063047, Learning Rate: 0.07992\n",
      "Epoch: 4017, MSE: 0.26420103110741094, Learning Rate: 0.07991500000000001\n",
      "Epoch: 4018, MSE: 0.26419872597381233, Learning Rate: 0.07991000000000001\n",
      "Epoch: 4019, MSE: 0.2641964207898325, Learning Rate: 0.079905\n",
      "Epoch: 4020, MSE: 0.2641941155554734, Learning Rate: 0.0799\n",
      "Epoch: 4021, MSE: 0.2641918102707309, Learning Rate: 0.07989500000000001\n",
      "Epoch: 4022, MSE: 0.26418950493560706, Learning Rate: 0.07989\n",
      "Epoch: 4023, MSE: 0.26418719955010084, Learning Rate: 0.07988500000000001\n",
      "Epoch: 4024, MSE: 0.2641848941142106, Learning Rate: 0.07988\n",
      "Epoch: 4025, MSE: 0.2641825886279368, Learning Rate: 0.079875\n",
      "Epoch: 4026, MSE: 0.2641802830912785, Learning Rate: 0.07987\n",
      "Epoch: 4027, MSE: 0.2641779775042356, Learning Rate: 0.079865\n",
      "Epoch: 4028, MSE: 0.26417567186680585, Learning Rate: 0.07986\n",
      "Epoch: 4029, MSE: 0.26417336617899073, Learning Rate: 0.07985500000000001\n",
      "Epoch: 4030, MSE: 0.264171060440789, Learning Rate: 0.07985\n",
      "Epoch: 4031, MSE: 0.26416875465219936, Learning Rate: 0.079845\n",
      "Epoch: 4032, MSE: 0.2641664488132213, Learning Rate: 0.07984000000000001\n",
      "Epoch: 4033, MSE: 0.26416414292385454, Learning Rate: 0.079835\n",
      "Epoch: 4034, MSE: 0.26416183698409845, Learning Rate: 0.07983000000000001\n",
      "Epoch: 4035, MSE: 0.2641595309939526, Learning Rate: 0.07982500000000001\n",
      "Epoch: 4036, MSE: 0.2641572249534166, Learning Rate: 0.07982\n",
      "Epoch: 4037, MSE: 0.264154918862489, Learning Rate: 0.07981500000000001\n",
      "Epoch: 4038, MSE: 0.26415261272116947, Learning Rate: 0.07981\n",
      "Epoch: 4039, MSE: 0.26415030652945737, Learning Rate: 0.07980500000000001\n",
      "Epoch: 4040, MSE: 0.2641480002873535, Learning Rate: 0.07980000000000001\n",
      "Epoch: 4041, MSE: 0.26414569399485593, Learning Rate: 0.079795\n",
      "Epoch: 4042, MSE: 0.2641433876519635, Learning Rate: 0.07979000000000001\n",
      "Epoch: 4043, MSE: 0.26414108125867686, Learning Rate: 0.079785\n",
      "Epoch: 4044, MSE: 0.264138774814995, Learning Rate: 0.07978000000000002\n",
      "Epoch: 4045, MSE: 0.2641364683209173, Learning Rate: 0.079775\n",
      "Epoch: 4046, MSE: 0.26413416177644317, Learning Rate: 0.07977000000000001\n",
      "Epoch: 4047, MSE: 0.26413185518157145, Learning Rate: 0.079765\n",
      "Epoch: 4048, MSE: 0.2641295485363018, Learning Rate: 0.07976\n",
      "Epoch: 4049, MSE: 0.26412724184063524, Learning Rate: 0.079755\n",
      "Epoch: 4050, MSE: 0.2641249350945691, Learning Rate: 0.07975\n",
      "Epoch: 4051, MSE: 0.26412262829810346, Learning Rate: 0.07974500000000001\n",
      "Epoch: 4052, MSE: 0.26412032145123737, Learning Rate: 0.07974\n",
      "Epoch: 4053, MSE: 0.2641180145539705, Learning Rate: 0.079735\n",
      "Epoch: 4054, MSE: 0.26411570760630354, Learning Rate: 0.07973000000000001\n",
      "Epoch: 4055, MSE: 0.2641134006082334, Learning Rate: 0.079725\n",
      "Epoch: 4056, MSE: 0.26411109355976176, Learning Rate: 0.07972000000000001\n",
      "Epoch: 4057, MSE: 0.2641087864608874, Learning Rate: 0.07971500000000001\n",
      "Epoch: 4058, MSE: 0.26410647931160813, Learning Rate: 0.07971\n",
      "Epoch: 4059, MSE: 0.2641041721119257, Learning Rate: 0.07970500000000001\n",
      "Epoch: 4060, MSE: 0.264101864861838, Learning Rate: 0.0797\n",
      "Epoch: 4061, MSE: 0.2640995575613451, Learning Rate: 0.07969500000000002\n",
      "Epoch: 4062, MSE: 0.2640972502104462, Learning Rate: 0.07969\n",
      "Epoch: 4063, MSE: 0.26409494280914014, Learning Rate: 0.079685\n",
      "Epoch: 4064, MSE: 0.264092635357428, Learning Rate: 0.07968\n",
      "Epoch: 4065, MSE: 0.2640903278553074, Learning Rate: 0.07967500000000001\n",
      "Epoch: 4066, MSE: 0.26408802030277906, Learning Rate: 0.07967\n",
      "Epoch: 4067, MSE: 0.2640857126998407, Learning Rate: 0.079665\n",
      "Epoch: 4068, MSE: 0.26408340504649325, Learning Rate: 0.07966000000000001\n",
      "Epoch: 4069, MSE: 0.2640810973427359, Learning Rate: 0.079655\n",
      "Epoch: 4070, MSE: 0.26407878958856745, Learning Rate: 0.07965\n",
      "Epoch: 4071, MSE: 0.2640764817839881, Learning Rate: 0.07964500000000001\n",
      "Epoch: 4072, MSE: 0.264074173928997, Learning Rate: 0.07964\n",
      "Epoch: 4073, MSE: 0.2640718660235924, Learning Rate: 0.07963500000000001\n",
      "Epoch: 4074, MSE: 0.2640695580677748, Learning Rate: 0.07963\n",
      "Epoch: 4075, MSE: 0.2640672500615446, Learning Rate: 0.079625\n",
      "Epoch: 4076, MSE: 0.2640649420048998, Learning Rate: 0.07962000000000001\n",
      "Epoch: 4077, MSE: 0.2640626338978401, Learning Rate: 0.079615\n",
      "Epoch: 4078, MSE: 0.2640603257403653, Learning Rate: 0.07961000000000001\n",
      "Epoch: 4079, MSE: 0.2640580175324739, Learning Rate: 0.07960500000000001\n",
      "Epoch: 4080, MSE: 0.2640557092741655, Learning Rate: 0.0796\n",
      "Epoch: 4081, MSE: 0.26405340096544033, Learning Rate: 0.079595\n",
      "Epoch: 4082, MSE: 0.2640510926062975, Learning Rate: 0.07959000000000001\n",
      "Epoch: 4083, MSE: 0.26404878419673594, Learning Rate: 0.079585\n",
      "Epoch: 4084, MSE: 0.2640464757367558, Learning Rate: 0.07958000000000001\n",
      "Epoch: 4085, MSE: 0.2640441672263556, Learning Rate: 0.079575\n",
      "Epoch: 4086, MSE: 0.2640418586655359, Learning Rate: 0.07957\n",
      "Epoch: 4087, MSE: 0.2640395500542949, Learning Rate: 0.079565\n",
      "Epoch: 4088, MSE: 0.26403724139263285, Learning Rate: 0.07956\n",
      "Epoch: 4089, MSE: 0.26403493268054923, Learning Rate: 0.079555\n",
      "Epoch: 4090, MSE: 0.26403262391804244, Learning Rate: 0.07955000000000001\n",
      "Epoch: 4091, MSE: 0.2640303151051125, Learning Rate: 0.079545\n",
      "Epoch: 4092, MSE: 0.2640280062417595, Learning Rate: 0.07954\n",
      "Epoch: 4093, MSE: 0.2640256973279817, Learning Rate: 0.07953500000000001\n",
      "Epoch: 4094, MSE: 0.2640233883637796, Learning Rate: 0.07953\n",
      "Epoch: 4095, MSE: 0.264021079349152, Learning Rate: 0.07952500000000001\n",
      "Epoch: 4096, MSE: 0.2640187702840976, Learning Rate: 0.07952000000000001\n",
      "Epoch: 4097, MSE: 0.264016461168618, Learning Rate: 0.079515\n",
      "Epoch: 4098, MSE: 0.2640141520027099, Learning Rate: 0.07951000000000001\n",
      "Epoch: 4099, MSE: 0.2640118427863746, Learning Rate: 0.079505\n",
      "Epoch: 4100, MSE: 0.26400953351961065, Learning Rate: 0.07950000000000002\n",
      "Epoch: 4101, MSE: 0.2640072242024183, Learning Rate: 0.07949500000000001\n",
      "Epoch: 4102, MSE: 0.2640049148347963, Learning Rate: 0.07949\n",
      "Epoch: 4103, MSE: 0.26400260541674414, Learning Rate: 0.07948500000000001\n",
      "Epoch: 4104, MSE: 0.26400029594826085, Learning Rate: 0.07948\n",
      "Epoch: 4105, MSE: 0.26399798642934674, Learning Rate: 0.07947500000000002\n",
      "Epoch: 4106, MSE: 0.26399567686000036, Learning Rate: 0.07947\n",
      "Epoch: 4107, MSE: 0.26399336724022193, Learning Rate: 0.07946500000000001\n",
      "Epoch: 4108, MSE: 0.26399105757001023, Learning Rate: 0.07946\n",
      "Epoch: 4109, MSE: 0.26398874784936543, Learning Rate: 0.079455\n",
      "Epoch: 4110, MSE: 0.26398643807828626, Learning Rate: 0.07945\n",
      "Epoch: 4111, MSE: 0.2639841282567717, Learning Rate: 0.079445\n",
      "Epoch: 4112, MSE: 0.26398181838482243, Learning Rate: 0.07944000000000001\n",
      "Epoch: 4113, MSE: 0.26397950846243723, Learning Rate: 0.079435\n",
      "Epoch: 4114, MSE: 0.2639771984896151, Learning Rate: 0.07943\n",
      "Epoch: 4115, MSE: 0.2639748884663561, Learning Rate: 0.07942500000000001\n",
      "Epoch: 4116, MSE: 0.2639725783926594, Learning Rate: 0.07942\n",
      "Epoch: 4117, MSE: 0.2639702682685249, Learning Rate: 0.07941500000000001\n",
      "Epoch: 4118, MSE: 0.26396795809395024, Learning Rate: 0.07941000000000001\n",
      "Epoch: 4119, MSE: 0.2639656478689378, Learning Rate: 0.079405\n",
      "Epoch: 4120, MSE: 0.2639633375934847, Learning Rate: 0.07940000000000001\n",
      "Epoch: 4121, MSE: 0.26396102726759146, Learning Rate: 0.079395\n",
      "Epoch: 4122, MSE: 0.2639587168912564, Learning Rate: 0.07939000000000002\n",
      "Epoch: 4123, MSE: 0.2639564064644795, Learning Rate: 0.079385\n",
      "Epoch: 4124, MSE: 0.26395409598726016, Learning Rate: 0.07938\n",
      "Epoch: 4125, MSE: 0.26395178545959846, Learning Rate: 0.079375\n",
      "Epoch: 4126, MSE: 0.26394947488149373, Learning Rate: 0.07937\n",
      "Epoch: 4127, MSE: 0.26394716425294407, Learning Rate: 0.079365\n",
      "Epoch: 4128, MSE: 0.2639448535739506, Learning Rate: 0.07936\n",
      "Epoch: 4129, MSE: 0.2639425428445118, Learning Rate: 0.07935500000000001\n",
      "Epoch: 4130, MSE: 0.2639402320646265, Learning Rate: 0.07935\n",
      "Epoch: 4131, MSE: 0.2639379212342959, Learning Rate: 0.079345\n",
      "Epoch: 4132, MSE: 0.2639356103535173, Learning Rate: 0.07934000000000001\n",
      "Epoch: 4133, MSE: 0.2639332994222912, Learning Rate: 0.079335\n",
      "Epoch: 4134, MSE: 0.2639309884406181, Learning Rate: 0.07933000000000001\n",
      "Epoch: 4135, MSE: 0.2639286774084955, Learning Rate: 0.079325\n",
      "Epoch: 4136, MSE: 0.26392636632592353, Learning Rate: 0.07932\n",
      "Epoch: 4137, MSE: 0.2639240551929025, Learning Rate: 0.07931500000000001\n",
      "Epoch: 4138, MSE: 0.26392174400943086, Learning Rate: 0.07931\n",
      "Epoch: 4139, MSE: 0.26391943277550794, Learning Rate: 0.07930500000000001\n",
      "Epoch: 4140, MSE: 0.26391712149113344, Learning Rate: 0.07930000000000001\n",
      "Epoch: 4141, MSE: 0.263914810156307, Learning Rate: 0.079295\n",
      "Epoch: 4142, MSE: 0.26391249877102785, Learning Rate: 0.07929\n",
      "Epoch: 4143, MSE: 0.2639101873352959, Learning Rate: 0.07928500000000001\n",
      "Epoch: 4144, MSE: 0.2639078758491092, Learning Rate: 0.07928\n",
      "Epoch: 4145, MSE: 0.2639055643124687, Learning Rate: 0.07927500000000001\n",
      "Epoch: 4146, MSE: 0.2639032527253735, Learning Rate: 0.07927000000000001\n",
      "Epoch: 4147, MSE: 0.263900941087822, Learning Rate: 0.079265\n",
      "Epoch: 4148, MSE: 0.2638986293998152, Learning Rate: 0.07926\n",
      "Epoch: 4149, MSE: 0.2638963176613504, Learning Rate: 0.079255\n",
      "Epoch: 4150, MSE: 0.26389400587242917, Learning Rate: 0.07925\n",
      "Epoch: 4151, MSE: 0.26389169403305035, Learning Rate: 0.07924500000000001\n",
      "Epoch: 4152, MSE: 0.26388938214321284, Learning Rate: 0.07924\n",
      "Epoch: 4153, MSE: 0.2638870702029156, Learning Rate: 0.079235\n",
      "Epoch: 4154, MSE: 0.2638847582121598, Learning Rate: 0.07923000000000001\n",
      "Epoch: 4155, MSE: 0.2638824461709441, Learning Rate: 0.079225\n",
      "Epoch: 4156, MSE: 0.26388013407926625, Learning Rate: 0.07922000000000001\n",
      "Epoch: 4157, MSE: 0.2638778219371284, Learning Rate: 0.07921500000000001\n",
      "Epoch: 4158, MSE: 0.26387550974452834, Learning Rate: 0.07921\n",
      "Epoch: 4159, MSE: 0.26387319750146576, Learning Rate: 0.07920500000000001\n",
      "Epoch: 4160, MSE: 0.26387088520794, Learning Rate: 0.0792\n",
      "Epoch: 4161, MSE: 0.26386857286395105, Learning Rate: 0.079195\n",
      "Epoch: 4162, MSE: 0.2638662604694977, Learning Rate: 0.07919000000000001\n",
      "Epoch: 4163, MSE: 0.26386394802457996, Learning Rate: 0.079185\n",
      "Epoch: 4164, MSE: 0.2638616355291965, Learning Rate: 0.07918000000000001\n",
      "Epoch: 4165, MSE: 0.2638593229833473, Learning Rate: 0.079175\n",
      "Epoch: 4166, MSE: 0.2638570103870316, Learning Rate: 0.07917\n",
      "Epoch: 4167, MSE: 0.2638546977402497, Learning Rate: 0.079165\n",
      "Epoch: 4168, MSE: 0.2638523850429994, Learning Rate: 0.07916000000000001\n",
      "Epoch: 4169, MSE: 0.2638500722952812, Learning Rate: 0.079155\n",
      "Epoch: 4170, MSE: 0.2638477594970939, Learning Rate: 0.07915\n",
      "Epoch: 4171, MSE: 0.2638454466484384, Learning Rate: 0.07914500000000001\n",
      "Epoch: 4172, MSE: 0.2638431337493119, Learning Rate: 0.07914\n",
      "Epoch: 4173, MSE: 0.26384082079971616, Learning Rate: 0.07913500000000001\n",
      "Epoch: 4174, MSE: 0.2638385077996485, Learning Rate: 0.07913\n",
      "Epoch: 4175, MSE: 0.2638361947491098, Learning Rate: 0.079125\n",
      "Epoch: 4176, MSE: 0.26383388164809907, Learning Rate: 0.07912000000000001\n",
      "Epoch: 4177, MSE: 0.2638315684966152, Learning Rate: 0.079115\n",
      "Epoch: 4178, MSE: 0.26382925529465806, Learning Rate: 0.07911000000000001\n",
      "Epoch: 4179, MSE: 0.2638269420422273, Learning Rate: 0.07910500000000001\n",
      "Epoch: 4180, MSE: 0.2638246287393232, Learning Rate: 0.0791\n",
      "Epoch: 4181, MSE: 0.26382231538594236, Learning Rate: 0.07909500000000001\n",
      "Epoch: 4182, MSE: 0.2638200019820871, Learning Rate: 0.07909\n",
      "Epoch: 4183, MSE: 0.2638176885277559, Learning Rate: 0.07908500000000002\n",
      "Epoch: 4184, MSE: 0.263815375022948, Learning Rate: 0.07908\n",
      "Epoch: 4185, MSE: 0.26381306146766237, Learning Rate: 0.079075\n",
      "Epoch: 4186, MSE: 0.263810747861899, Learning Rate: 0.07907\n",
      "Epoch: 4187, MSE: 0.2638084342056574, Learning Rate: 0.079065\n",
      "Epoch: 4188, MSE: 0.263806120498938, Learning Rate: 0.07906\n",
      "Epoch: 4189, MSE: 0.26380380674173814, Learning Rate: 0.079055\n",
      "Epoch: 4190, MSE: 0.2638014929340578, Learning Rate: 0.07905000000000001\n",
      "Epoch: 4191, MSE: 0.26379917907589795, Learning Rate: 0.079045\n",
      "Epoch: 4192, MSE: 0.26379686516725626, Learning Rate: 0.07904\n",
      "Epoch: 4193, MSE: 0.26379455120813305, Learning Rate: 0.07903500000000001\n",
      "Epoch: 4194, MSE: 0.2637922371985276, Learning Rate: 0.07903\n",
      "Epoch: 4195, MSE: 0.26378992313843913, Learning Rate: 0.07902500000000001\n",
      "Epoch: 4196, MSE: 0.26378760902786774, Learning Rate: 0.07902\n",
      "Epoch: 4197, MSE: 0.26378529486681224, Learning Rate: 0.079015\n",
      "Epoch: 4198, MSE: 0.26378298065527206, Learning Rate: 0.07901000000000001\n",
      "Epoch: 4199, MSE: 0.263780666393247, Learning Rate: 0.079005\n",
      "Epoch: 4200, MSE: 0.2637783520807362, Learning Rate: 0.07900000000000001\n",
      "Epoch: 4201, MSE: 0.263776037717739, Learning Rate: 0.07899500000000001\n",
      "Epoch: 4202, MSE: 0.26377372330425464, Learning Rate: 0.07899\n",
      "Epoch: 4203, MSE: 0.26377140884028405, Learning Rate: 0.078985\n",
      "Epoch: 4204, MSE: 0.2637690943258249, Learning Rate: 0.07898000000000001\n",
      "Epoch: 4205, MSE: 0.26376677976087726, Learning Rate: 0.078975\n",
      "Epoch: 4206, MSE: 0.2637644651454408, Learning Rate: 0.07897000000000001\n",
      "Epoch: 4207, MSE: 0.26376215047951473, Learning Rate: 0.07896500000000001\n",
      "Epoch: 4208, MSE: 0.2637598357630986, Learning Rate: 0.07896\n",
      "Epoch: 4209, MSE: 0.2637575209961918, Learning Rate: 0.078955\n",
      "Epoch: 4210, MSE: 0.2637552061787942, Learning Rate: 0.07895\n",
      "Epoch: 4211, MSE: 0.2637528913109042, Learning Rate: 0.078945\n",
      "Epoch: 4212, MSE: 0.2637505763925215, Learning Rate: 0.07894000000000001\n",
      "Epoch: 4213, MSE: 0.2637482614236463, Learning Rate: 0.078935\n",
      "Epoch: 4214, MSE: 0.26374594640427745, Learning Rate: 0.07893\n",
      "Epoch: 4215, MSE: 0.2637436313344153, Learning Rate: 0.07892500000000001\n",
      "Epoch: 4216, MSE: 0.2637413162140574, Learning Rate: 0.07892\n",
      "Epoch: 4217, MSE: 0.2637390010432052, Learning Rate: 0.07891500000000001\n",
      "Epoch: 4218, MSE: 0.2637366858218566, Learning Rate: 0.07891000000000001\n",
      "Epoch: 4219, MSE: 0.26373437055001253, Learning Rate: 0.078905\n",
      "Epoch: 4220, MSE: 0.2637320552276711, Learning Rate: 0.07890000000000001\n",
      "Epoch: 4221, MSE: 0.263729739854832, Learning Rate: 0.078895\n",
      "Epoch: 4222, MSE: 0.2637274244314956, Learning Rate: 0.07889\n",
      "Epoch: 4223, MSE: 0.26372510895766094, Learning Rate: 0.07888500000000001\n",
      "Epoch: 4224, MSE: 0.26372279343332644, Learning Rate: 0.07888\n",
      "Epoch: 4225, MSE: 0.26372047785849245, Learning Rate: 0.07887500000000001\n",
      "Epoch: 4226, MSE: 0.26371816223315864, Learning Rate: 0.07887\n",
      "Epoch: 4227, MSE: 0.2637158465573237, Learning Rate: 0.078865\n",
      "Epoch: 4228, MSE: 0.26371353083098864, Learning Rate: 0.07886\n",
      "Epoch: 4229, MSE: 0.2637112150541498, Learning Rate: 0.07885500000000001\n",
      "Epoch: 4230, MSE: 0.2637088992268094, Learning Rate: 0.07885\n",
      "Epoch: 4231, MSE: 0.2637065833489671, Learning Rate: 0.078845\n",
      "Epoch: 4232, MSE: 0.26370426742062075, Learning Rate: 0.07884000000000001\n",
      "Epoch: 4233, MSE: 0.2637019514417699, Learning Rate: 0.078835\n",
      "Epoch: 4234, MSE: 0.2636996354124144, Learning Rate: 0.07883000000000001\n",
      "Epoch: 4235, MSE: 0.2636973193325544, Learning Rate: 0.078825\n",
      "Epoch: 4236, MSE: 0.26369500320218764, Learning Rate: 0.07882\n",
      "Epoch: 4237, MSE: 0.2636926870213157, Learning Rate: 0.07881500000000001\n",
      "Epoch: 4238, MSE: 0.2636903707899363, Learning Rate: 0.07881\n",
      "Epoch: 4239, MSE: 0.2636880545080496, Learning Rate: 0.07880500000000001\n",
      "Epoch: 4240, MSE: 0.2636857381756551, Learning Rate: 0.07880000000000001\n",
      "Epoch: 4241, MSE: 0.26368342179275156, Learning Rate: 0.078795\n",
      "Epoch: 4242, MSE: 0.2636811053593405, Learning Rate: 0.07879000000000001\n",
      "Epoch: 4243, MSE: 0.2636787888754187, Learning Rate: 0.078785\n",
      "Epoch: 4244, MSE: 0.26367647234098673, Learning Rate: 0.07878000000000002\n",
      "Epoch: 4245, MSE: 0.26367415575604414, Learning Rate: 0.078775\n",
      "Epoch: 4246, MSE: 0.2636718391205908, Learning Rate: 0.07877\n",
      "Epoch: 4247, MSE: 0.26366952243462544, Learning Rate: 0.078765\n",
      "Epoch: 4248, MSE: 0.26366720569814744, Learning Rate: 0.07876\n",
      "Epoch: 4249, MSE: 0.2636648889111566, Learning Rate: 0.078755\n",
      "Epoch: 4250, MSE: 0.2636625720736528, Learning Rate: 0.07875\n",
      "Epoch: 4251, MSE: 0.2636602551856353, Learning Rate: 0.07874500000000001\n",
      "Epoch: 4252, MSE: 0.2636579382471017, Learning Rate: 0.07874\n",
      "Epoch: 4253, MSE: 0.26365562125805425, Learning Rate: 0.078735\n",
      "Epoch: 4254, MSE: 0.26365330421849154, Learning Rate: 0.07873000000000001\n",
      "Epoch: 4255, MSE: 0.2636509871284113, Learning Rate: 0.078725\n",
      "Epoch: 4256, MSE: 0.26364866998781505, Learning Rate: 0.07872000000000001\n",
      "Epoch: 4257, MSE: 0.2636463527967016, Learning Rate: 0.07871500000000001\n",
      "Epoch: 4258, MSE: 0.2636440355550704, Learning Rate: 0.07871\n",
      "Epoch: 4259, MSE: 0.2636417182629203, Learning Rate: 0.07870500000000001\n",
      "Epoch: 4260, MSE: 0.2636394009202518, Learning Rate: 0.0787\n",
      "Epoch: 4261, MSE: 0.26363708352706366, Learning Rate: 0.07869500000000001\n",
      "Epoch: 4262, MSE: 0.2636347660833557, Learning Rate: 0.07869\n",
      "Epoch: 4263, MSE: 0.26363244858912677, Learning Rate: 0.078685\n",
      "Epoch: 4264, MSE: 0.26363013104437677, Learning Rate: 0.07868\n",
      "Epoch: 4265, MSE: 0.2636278134491051, Learning Rate: 0.07867500000000001\n",
      "Epoch: 4266, MSE: 0.26362549580331146, Learning Rate: 0.07867\n",
      "Epoch: 4267, MSE: 0.2636231781069949, Learning Rate: 0.078665\n",
      "Epoch: 4268, MSE: 0.26362086036015575, Learning Rate: 0.07866000000000001\n",
      "Epoch: 4269, MSE: 0.2636185425627912, Learning Rate: 0.078655\n",
      "Epoch: 4270, MSE: 0.26361622471490376, Learning Rate: 0.07865\n",
      "Epoch: 4271, MSE: 0.26361390681649066, Learning Rate: 0.078645\n",
      "Epoch: 4272, MSE: 0.2636115888675527, Learning Rate: 0.07864\n",
      "Epoch: 4273, MSE: 0.2636092708680877, Learning Rate: 0.07863500000000001\n",
      "Epoch: 4274, MSE: 0.26360695281809626, Learning Rate: 0.07863\n",
      "Epoch: 4275, MSE: 0.2636046347175781, Learning Rate: 0.078625\n",
      "Epoch: 4276, MSE: 0.26360231656653305, Learning Rate: 0.07862000000000001\n",
      "Epoch: 4277, MSE: 0.26359999836495773, Learning Rate: 0.078615\n",
      "Epoch: 4278, MSE: 0.2635976801128558, Learning Rate: 0.07861000000000001\n",
      "Epoch: 4279, MSE: 0.2635953618102235, Learning Rate: 0.07860500000000001\n",
      "Epoch: 4280, MSE: 0.26359304345706147, Learning Rate: 0.0786\n",
      "Epoch: 4281, MSE: 0.26359072505336917, Learning Rate: 0.07859500000000001\n",
      "Epoch: 4282, MSE: 0.26358840659914606, Learning Rate: 0.07859000000000001\n",
      "Epoch: 4283, MSE: 0.26358608809439127, Learning Rate: 0.078585\n",
      "Epoch: 4284, MSE: 0.2635837695391046, Learning Rate: 0.07858000000000001\n",
      "Epoch: 4285, MSE: 0.26358145093328506, Learning Rate: 0.078575\n",
      "Epoch: 4286, MSE: 0.2635791322769325, Learning Rate: 0.07857000000000001\n",
      "Epoch: 4287, MSE: 0.26357681357004675, Learning Rate: 0.078565\n",
      "Epoch: 4288, MSE: 0.2635744948126268, Learning Rate: 0.07856\n",
      "Epoch: 4289, MSE: 0.26357217600467203, Learning Rate: 0.078555\n",
      "Epoch: 4290, MSE: 0.2635698571461816, Learning Rate: 0.07855000000000001\n",
      "Epoch: 4291, MSE: 0.26356753823715556, Learning Rate: 0.078545\n",
      "Epoch: 4292, MSE: 0.2635652192775928, Learning Rate: 0.07854\n",
      "Epoch: 4293, MSE: 0.2635629002674939, Learning Rate: 0.07853500000000001\n",
      "Epoch: 4294, MSE: 0.2635605812068574, Learning Rate: 0.07853\n",
      "Epoch: 4295, MSE: 0.26355826209568245, Learning Rate: 0.07852500000000001\n",
      "Epoch: 4296, MSE: 0.2635559429339695, Learning Rate: 0.07852\n",
      "Epoch: 4297, MSE: 0.2635536237217173, Learning Rate: 0.078515\n",
      "Epoch: 4298, MSE: 0.2635513044589262, Learning Rate: 0.07851000000000001\n",
      "Epoch: 4299, MSE: 0.26354898514559366, Learning Rate: 0.078505\n",
      "Epoch: 4300, MSE: 0.26354666578172176, Learning Rate: 0.07850000000000001\n",
      "Epoch: 4301, MSE: 0.263544346367308, Learning Rate: 0.07849500000000001\n",
      "Epoch: 4302, MSE: 0.2635420269023527, Learning Rate: 0.07849\n",
      "Epoch: 4303, MSE: 0.26353970738685406, Learning Rate: 0.07848500000000001\n",
      "Epoch: 4304, MSE: 0.26353738782081365, Learning Rate: 0.07848\n",
      "Epoch: 4305, MSE: 0.26353506820422945, Learning Rate: 0.07847500000000002\n",
      "Epoch: 4306, MSE: 0.2635327485371021, Learning Rate: 0.07847\n",
      "Epoch: 4307, MSE: 0.26353042881942945, Learning Rate: 0.07846500000000001\n",
      "Epoch: 4308, MSE: 0.26352810905121304, Learning Rate: 0.07846\n",
      "Epoch: 4309, MSE: 0.2635257892324502, Learning Rate: 0.078455\n",
      "Epoch: 4310, MSE: 0.2635234693631413, Learning Rate: 0.07845\n",
      "Epoch: 4311, MSE: 0.2635211494432867, Learning Rate: 0.078445\n",
      "Epoch: 4312, MSE: 0.26351882947288346, Learning Rate: 0.07844000000000001\n",
      "Epoch: 4313, MSE: 0.26351650945193417, Learning Rate: 0.078435\n",
      "Epoch: 4314, MSE: 0.26351418938043525, Learning Rate: 0.07843\n",
      "Epoch: 4315, MSE: 0.26351186925838804, Learning Rate: 0.07842500000000001\n",
      "Epoch: 4316, MSE: 0.2635095490857926, Learning Rate: 0.07842\n",
      "Epoch: 4317, MSE: 0.2635072288626466, Learning Rate: 0.07841500000000001\n",
      "Epoch: 4318, MSE: 0.26350490858894965, Learning Rate: 0.07841000000000001\n",
      "Epoch: 4319, MSE: 0.2635025882647034, Learning Rate: 0.078405\n",
      "Epoch: 4320, MSE: 0.26350026788990444, Learning Rate: 0.07840000000000001\n",
      "Epoch: 4321, MSE: 0.26349794746455435, Learning Rate: 0.078395\n",
      "Epoch: 4322, MSE: 0.2634956269886514, Learning Rate: 0.07839000000000002\n",
      "Epoch: 4323, MSE: 0.2634933064621955, Learning Rate: 0.078385\n",
      "Epoch: 4324, MSE: 0.263490985885186, Learning Rate: 0.07838\n",
      "Epoch: 4325, MSE: 0.26348866525762316, Learning Rate: 0.078375\n",
      "Epoch: 4326, MSE: 0.26348634457950476, Learning Rate: 0.07837000000000001\n",
      "Epoch: 4327, MSE: 0.2634840238508317, Learning Rate: 0.078365\n",
      "Epoch: 4328, MSE: 0.2634817030716027, Learning Rate: 0.07836\n",
      "Epoch: 4329, MSE: 0.26347938224181766, Learning Rate: 0.07835500000000001\n",
      "Epoch: 4330, MSE: 0.2634770613614758, Learning Rate: 0.07835\n",
      "Epoch: 4331, MSE: 0.26347474043057706, Learning Rate: 0.078345\n",
      "Epoch: 4332, MSE: 0.2634724194491205, Learning Rate: 0.07834\n",
      "Epoch: 4333, MSE: 0.26347009841710506, Learning Rate: 0.078335\n",
      "Epoch: 4334, MSE: 0.2634677773345315, Learning Rate: 0.07833000000000001\n",
      "Epoch: 4335, MSE: 0.2634654562013983, Learning Rate: 0.078325\n",
      "Epoch: 4336, MSE: 0.2634631350177049, Learning Rate: 0.07832\n",
      "Epoch: 4337, MSE: 0.2634608137834511, Learning Rate: 0.07831500000000001\n",
      "Epoch: 4338, MSE: 0.2634584924986366, Learning Rate: 0.07831\n",
      "Epoch: 4339, MSE: 0.26345617116326026, Learning Rate: 0.07830500000000001\n",
      "Epoch: 4340, MSE: 0.26345384977732245, Learning Rate: 0.07830000000000001\n",
      "Epoch: 4341, MSE: 0.26345152834082225, Learning Rate: 0.078295\n",
      "Epoch: 4342, MSE: 0.2634492068537584, Learning Rate: 0.07829000000000001\n",
      "Epoch: 4343, MSE: 0.26344688531613064, Learning Rate: 0.07828500000000001\n",
      "Epoch: 4344, MSE: 0.26344456372793934, Learning Rate: 0.07828\n",
      "Epoch: 4345, MSE: 0.2634422420891829, Learning Rate: 0.07827500000000001\n",
      "Epoch: 4346, MSE: 0.26343992039986125, Learning Rate: 0.07827\n",
      "Epoch: 4347, MSE: 0.2634375986599752, Learning Rate: 0.07826500000000002\n",
      "Epoch: 4348, MSE: 0.2634352768695217, Learning Rate: 0.07826\n",
      "Epoch: 4349, MSE: 0.26343295502850095, Learning Rate: 0.078255\n",
      "Epoch: 4350, MSE: 0.26343063313691367, Learning Rate: 0.07825\n",
      "Epoch: 4351, MSE: 0.26342831119475857, Learning Rate: 0.07824500000000001\n",
      "Epoch: 4352, MSE: 0.26342598920203536, Learning Rate: 0.07824\n",
      "Epoch: 4353, MSE: 0.2634236671587425, Learning Rate: 0.078235\n",
      "Epoch: 4354, MSE: 0.26342134506488035, Learning Rate: 0.07823000000000001\n",
      "Epoch: 4355, MSE: 0.26341902292044894, Learning Rate: 0.078225\n",
      "Epoch: 4356, MSE: 0.2634167007254465, Learning Rate: 0.07822000000000001\n",
      "Epoch: 4357, MSE: 0.2634143784798738, Learning Rate: 0.078215\n",
      "Epoch: 4358, MSE: 0.26341205618372887, Learning Rate: 0.07821\n",
      "Epoch: 4359, MSE: 0.26340973383701144, Learning Rate: 0.07820500000000001\n",
      "Epoch: 4360, MSE: 0.2634074114397225, Learning Rate: 0.0782\n",
      "Epoch: 4361, MSE: 0.26340508899185994, Learning Rate: 0.07819500000000001\n",
      "Epoch: 4362, MSE: 0.263402766493424, Learning Rate: 0.07819000000000001\n",
      "Epoch: 4363, MSE: 0.2634004439444137, Learning Rate: 0.078185\n",
      "Epoch: 4364, MSE: 0.2633981213448278, Learning Rate: 0.07818000000000001\n",
      "Epoch: 4365, MSE: 0.26339579869466834, Learning Rate: 0.078175\n",
      "Epoch: 4366, MSE: 0.26339347599393276, Learning Rate: 0.07817000000000002\n",
      "Epoch: 4367, MSE: 0.2633911532426209, Learning Rate: 0.078165\n",
      "Epoch: 4368, MSE: 0.26338883044073147, Learning Rate: 0.07816000000000001\n",
      "Epoch: 4369, MSE: 0.2633865075882655, Learning Rate: 0.078155\n",
      "Epoch: 4370, MSE: 0.2633841846852217, Learning Rate: 0.07815\n",
      "Epoch: 4371, MSE: 0.2633818617315997, Learning Rate: 0.078145\n",
      "Epoch: 4372, MSE: 0.26337953872739844, Learning Rate: 0.07814\n",
      "Epoch: 4373, MSE: 0.26337721567261807, Learning Rate: 0.07813500000000001\n",
      "Epoch: 4374, MSE: 0.26337489256725805, Learning Rate: 0.07813\n",
      "Epoch: 4375, MSE: 0.2633725694113172, Learning Rate: 0.078125\n",
      "Epoch: 4376, MSE: 0.2633702462047951, Learning Rate: 0.07812000000000001\n",
      "Epoch: 4377, MSE: 0.2633679229476921, Learning Rate: 0.078115\n",
      "Epoch: 4378, MSE: 0.26336559964000744, Learning Rate: 0.07811000000000001\n",
      "Epoch: 4379, MSE: 0.2633632762817399, Learning Rate: 0.07810500000000001\n",
      "Epoch: 4380, MSE: 0.2633609528728886, Learning Rate: 0.0781\n",
      "Epoch: 4381, MSE: 0.26335862941345445, Learning Rate: 0.07809500000000001\n",
      "Epoch: 4382, MSE: 0.26335630590343617, Learning Rate: 0.07809\n",
      "Epoch: 4383, MSE: 0.26335398234283386, Learning Rate: 0.07808500000000002\n",
      "Epoch: 4384, MSE: 0.263351658731646, Learning Rate: 0.07808\n",
      "Epoch: 4385, MSE: 0.2633493350698722, Learning Rate: 0.078075\n",
      "Epoch: 4386, MSE: 0.2633470113575127, Learning Rate: 0.07807\n",
      "Epoch: 4387, MSE: 0.2633446875945667, Learning Rate: 0.07806500000000001\n",
      "Epoch: 4388, MSE: 0.2633423637810332, Learning Rate: 0.07806\n",
      "Epoch: 4389, MSE: 0.26334003991691235, Learning Rate: 0.078055\n",
      "Epoch: 4390, MSE: 0.2633377160022027, Learning Rate: 0.07805000000000001\n",
      "Epoch: 4391, MSE: 0.2633353920369041, Learning Rate: 0.078045\n",
      "Epoch: 4392, MSE: 0.263333068021017, Learning Rate: 0.07804\n",
      "Epoch: 4393, MSE: 0.26333074395454015, Learning Rate: 0.07803500000000001\n",
      "Epoch: 4394, MSE: 0.26332841983747307, Learning Rate: 0.07803\n",
      "Epoch: 4395, MSE: 0.2633260956698149, Learning Rate: 0.07802500000000001\n",
      "Epoch: 4396, MSE: 0.26332377145156505, Learning Rate: 0.07802\n",
      "Epoch: 4397, MSE: 0.2633214471827241, Learning Rate: 0.078015\n",
      "Epoch: 4398, MSE: 0.26331912286329034, Learning Rate: 0.07801000000000001\n",
      "Epoch: 4399, MSE: 0.2633167984932642, Learning Rate: 0.078005\n",
      "Epoch: 4400, MSE: 0.26331447407264413, Learning Rate: 0.07800000000000001\n",
      "Epoch: 4401, MSE: 0.2633121496014304, Learning Rate: 0.07799500000000001\n",
      "Epoch: 4402, MSE: 0.26330982507962214, Learning Rate: 0.07799\n",
      "Epoch: 4403, MSE: 0.26330750050721935, Learning Rate: 0.077985\n",
      "Epoch: 4404, MSE: 0.26330517588422103, Learning Rate: 0.07798000000000001\n",
      "Epoch: 4405, MSE: 0.2633028512106268, Learning Rate: 0.077975\n",
      "Epoch: 4406, MSE: 0.26330052648643537, Learning Rate: 0.07797000000000001\n",
      "Epoch: 4407, MSE: 0.2632982017116477, Learning Rate: 0.077965\n",
      "Epoch: 4408, MSE: 0.26329587688626266, Learning Rate: 0.07796\n",
      "Epoch: 4409, MSE: 0.26329355201027904, Learning Rate: 0.077955\n",
      "Epoch: 4410, MSE: 0.2632912270836973, Learning Rate: 0.07795\n",
      "Epoch: 4411, MSE: 0.263288902106516, Learning Rate: 0.077945\n",
      "Epoch: 4412, MSE: 0.26328657707873604, Learning Rate: 0.07794000000000001\n",
      "Epoch: 4413, MSE: 0.2632842520003557, Learning Rate: 0.077935\n",
      "Epoch: 4414, MSE: 0.26328192687137447, Learning Rate: 0.07793\n",
      "Epoch: 4415, MSE: 0.2632796016917924, Learning Rate: 0.07792500000000001\n",
      "Epoch: 4416, MSE: 0.2632772764616088, Learning Rate: 0.07792\n",
      "Epoch: 4417, MSE: 0.2632749511808229, Learning Rate: 0.07791500000000001\n",
      "Epoch: 4418, MSE: 0.26327262584943417, Learning Rate: 0.07791000000000001\n",
      "Epoch: 4419, MSE: 0.26327030046744254, Learning Rate: 0.077905\n",
      "Epoch: 4420, MSE: 0.26326797503484756, Learning Rate: 0.07790000000000001\n",
      "Epoch: 4421, MSE: 0.2632656495516482, Learning Rate: 0.077895\n",
      "Epoch: 4422, MSE: 0.2632633240178441, Learning Rate: 0.07789000000000001\n",
      "Epoch: 4423, MSE: 0.2632609984334355, Learning Rate: 0.07788500000000001\n",
      "Epoch: 4424, MSE: 0.2632586727984208, Learning Rate: 0.07788\n",
      "Epoch: 4425, MSE: 0.2632563471127995, Learning Rate: 0.07787500000000001\n",
      "Epoch: 4426, MSE: 0.2632540213765718, Learning Rate: 0.07787\n",
      "Epoch: 4427, MSE: 0.2632516955897369, Learning Rate: 0.07786500000000002\n",
      "Epoch: 4428, MSE: 0.26324936975229407, Learning Rate: 0.07786\n",
      "Epoch: 4429, MSE: 0.2632470438642431, Learning Rate: 0.07785500000000001\n",
      "Epoch: 4430, MSE: 0.26324471792558385, Learning Rate: 0.07785\n",
      "Epoch: 4431, MSE: 0.26324239193631477, Learning Rate: 0.077845\n",
      "Epoch: 4432, MSE: 0.2632400658964362, Learning Rate: 0.07784\n",
      "Epoch: 4433, MSE: 0.26323773980594706, Learning Rate: 0.077835\n",
      "Epoch: 4434, MSE: 0.26323541366484765, Learning Rate: 0.07783000000000001\n",
      "Epoch: 4435, MSE: 0.26323308747313684, Learning Rate: 0.077825\n",
      "Epoch: 4436, MSE: 0.26323076123081446, Learning Rate: 0.07782\n",
      "Epoch: 4437, MSE: 0.2632284349378796, Learning Rate: 0.07781500000000001\n",
      "Epoch: 4438, MSE: 0.26322610859433193, Learning Rate: 0.07781\n",
      "Epoch: 4439, MSE: 0.2632237822001705, Learning Rate: 0.07780500000000001\n",
      "Epoch: 4440, MSE: 0.263221455755396, Learning Rate: 0.07780000000000001\n",
      "Epoch: 4441, MSE: 0.26321912926000657, Learning Rate: 0.077795\n",
      "Epoch: 4442, MSE: 0.26321680271400244, Learning Rate: 0.07779000000000001\n",
      "Epoch: 4443, MSE: 0.2632144761173831, Learning Rate: 0.077785\n",
      "Epoch: 4444, MSE: 0.2632121494701487, Learning Rate: 0.07778000000000002\n",
      "Epoch: 4445, MSE: 0.26320982277229693, Learning Rate: 0.077775\n",
      "Epoch: 4446, MSE: 0.2632074960238287, Learning Rate: 0.07777\n",
      "Epoch: 4447, MSE: 0.263205169224743, Learning Rate: 0.077765\n",
      "Epoch: 4448, MSE: 0.26320284237503977, Learning Rate: 0.07776000000000001\n",
      "Epoch: 4449, MSE: 0.263200515474718, Learning Rate: 0.077755\n",
      "Epoch: 4450, MSE: 0.26319818852377724, Learning Rate: 0.07775\n",
      "Epoch: 4451, MSE: 0.26319586152221774, Learning Rate: 0.07774500000000001\n",
      "Epoch: 4452, MSE: 0.2631935344700375, Learning Rate: 0.07774\n",
      "Epoch: 4453, MSE: 0.2631912073672377, Learning Rate: 0.077735\n",
      "Epoch: 4454, MSE: 0.26318888021381615, Learning Rate: 0.07773000000000001\n",
      "Epoch: 4455, MSE: 0.2631865530097739, Learning Rate: 0.077725\n",
      "Epoch: 4456, MSE: 0.2631842257551092, Learning Rate: 0.07772000000000001\n",
      "Epoch: 4457, MSE: 0.2631818984498231, Learning Rate: 0.077715\n",
      "Epoch: 4458, MSE: 0.26317957109391277, Learning Rate: 0.07771\n",
      "Epoch: 4459, MSE: 0.26317724368738, Learning Rate: 0.07770500000000001\n",
      "Epoch: 4460, MSE: 0.2631749162302229, Learning Rate: 0.0777\n",
      "Epoch: 4461, MSE: 0.26317258872244237, Learning Rate: 0.07769500000000001\n",
      "Epoch: 4462, MSE: 0.2631702611640366, Learning Rate: 0.07769000000000001\n",
      "Epoch: 4463, MSE: 0.2631679335550049, Learning Rate: 0.077685\n",
      "Epoch: 4464, MSE: 0.26316560589534743, Learning Rate: 0.07768\n",
      "Epoch: 4465, MSE: 0.26316327818506363, Learning Rate: 0.07767500000000001\n",
      "Epoch: 4466, MSE: 0.2631609504241531, Learning Rate: 0.07767\n",
      "Epoch: 4467, MSE: 0.26315862261261547, Learning Rate: 0.07766500000000001\n",
      "Epoch: 4468, MSE: 0.2631562947504491, Learning Rate: 0.07766\n",
      "Epoch: 4469, MSE: 0.2631539668376549, Learning Rate: 0.077655\n",
      "Epoch: 4470, MSE: 0.26315163887423215, Learning Rate: 0.07765\n",
      "Epoch: 4471, MSE: 0.2631493108601797, Learning Rate: 0.077645\n",
      "Epoch: 4472, MSE: 0.2631469827954969, Learning Rate: 0.07764\n",
      "Epoch: 4473, MSE: 0.26314465468018394, Learning Rate: 0.07763500000000001\n",
      "Epoch: 4474, MSE: 0.263142326514241, Learning Rate: 0.07763\n",
      "Epoch: 4475, MSE: 0.26313999829766593, Learning Rate: 0.077625\n",
      "Epoch: 4476, MSE: 0.26313767003045885, Learning Rate: 0.07762000000000001\n",
      "Epoch: 4477, MSE: 0.2631353417126188, Learning Rate: 0.077615\n",
      "Epoch: 4478, MSE: 0.2631330133441471, Learning Rate: 0.07761000000000001\n",
      "Epoch: 4479, MSE: 0.26313068492504205, Learning Rate: 0.07760500000000001\n",
      "Epoch: 4480, MSE: 0.26312835645530297, Learning Rate: 0.0776\n",
      "Epoch: 4481, MSE: 0.2631260279349291, Learning Rate: 0.07759500000000001\n",
      "Epoch: 4482, MSE: 0.2631236993639204, Learning Rate: 0.07759\n",
      "Epoch: 4483, MSE: 0.26312137074227643, Learning Rate: 0.07758500000000002\n",
      "Epoch: 4484, MSE: 0.26311904206999687, Learning Rate: 0.07758000000000001\n",
      "Epoch: 4485, MSE: 0.26311671334708114, Learning Rate: 0.077575\n",
      "Epoch: 4486, MSE: 0.2631143845735281, Learning Rate: 0.07757000000000001\n",
      "Epoch: 4487, MSE: 0.26311205574933816, Learning Rate: 0.077565\n",
      "Epoch: 4488, MSE: 0.2631097268745103, Learning Rate: 0.07756000000000002\n",
      "Epoch: 4489, MSE: 0.2631073979490437, Learning Rate: 0.077555\n",
      "Epoch: 4490, MSE: 0.263105068972938, Learning Rate: 0.07755000000000001\n",
      "Epoch: 4491, MSE: 0.263102739946194, Learning Rate: 0.077545\n",
      "Epoch: 4492, MSE: 0.26310041086880925, Learning Rate: 0.07754\n",
      "Epoch: 4493, MSE: 0.2630980817407847, Learning Rate: 0.077535\n",
      "Epoch: 4494, MSE: 0.26309575256211953, Learning Rate: 0.07753\n",
      "Epoch: 4495, MSE: 0.2630934233328129, Learning Rate: 0.07752500000000001\n",
      "Epoch: 4496, MSE: 0.2630910940528645, Learning Rate: 0.07752\n",
      "Epoch: 4497, MSE: 0.2630887647222739, Learning Rate: 0.077515\n",
      "Epoch: 4498, MSE: 0.2630864353410405, Learning Rate: 0.07751000000000001\n",
      "Epoch: 4499, MSE: 0.26308410590916387, Learning Rate: 0.077505\n",
      "Epoch: 4500, MSE: 0.26308177642664377, Learning Rate: 0.07750000000000001\n",
      "Epoch: 4501, MSE: 0.26307944689347873, Learning Rate: 0.07749500000000001\n",
      "Epoch: 4502, MSE: 0.26307711730966893, Learning Rate: 0.07749\n",
      "Epoch: 4503, MSE: 0.26307478767521425, Learning Rate: 0.07748500000000001\n",
      "Epoch: 4504, MSE: 0.26307245799011475, Learning Rate: 0.07748\n",
      "Epoch: 4505, MSE: 0.26307012825436743, Learning Rate: 0.07747500000000002\n",
      "Epoch: 4506, MSE: 0.26306779846797446, Learning Rate: 0.07747\n",
      "Epoch: 4507, MSE: 0.2630654686309344, Learning Rate: 0.077465\n",
      "Epoch: 4508, MSE: 0.26306313874324627, Learning Rate: 0.07746\n",
      "Epoch: 4509, MSE: 0.26306080880491045, Learning Rate: 0.077455\n",
      "Epoch: 4510, MSE: 0.26305847881592526, Learning Rate: 0.07745\n",
      "Epoch: 4511, MSE: 0.2630561487762914, Learning Rate: 0.077445\n",
      "Epoch: 4512, MSE: 0.2630538186860075, Learning Rate: 0.07744000000000001\n",
      "Epoch: 4513, MSE: 0.2630514885450737, Learning Rate: 0.077435\n",
      "Epoch: 4514, MSE: 0.26304915835348935, Learning Rate: 0.07743\n",
      "Epoch: 4515, MSE: 0.26304682811125396, Learning Rate: 0.07742500000000001\n",
      "Epoch: 4516, MSE: 0.263044497818367, Learning Rate: 0.07742\n",
      "Epoch: 4517, MSE: 0.263042167474828, Learning Rate: 0.07741500000000001\n",
      "Epoch: 4518, MSE: 0.2630398370806363, Learning Rate: 0.07741\n",
      "Epoch: 4519, MSE: 0.26303750663579145, Learning Rate: 0.077405\n",
      "Epoch: 4520, MSE: 0.26303517614029354, Learning Rate: 0.07740000000000001\n",
      "Epoch: 4521, MSE: 0.2630328455941416, Learning Rate: 0.077395\n",
      "Epoch: 4522, MSE: 0.2630305149973349, Learning Rate: 0.07739000000000001\n",
      "Epoch: 4523, MSE: 0.2630281843498729, Learning Rate: 0.07738500000000001\n",
      "Epoch: 4524, MSE: 0.26302585365175585, Learning Rate: 0.07738\n",
      "Epoch: 4525, MSE: 0.2630235229029822, Learning Rate: 0.077375\n",
      "Epoch: 4526, MSE: 0.2630211921035523, Learning Rate: 0.07737000000000001\n",
      "Epoch: 4527, MSE: 0.2630188612534659, Learning Rate: 0.077365\n",
      "Epoch: 4528, MSE: 0.26301653035272227, Learning Rate: 0.07736000000000001\n",
      "Epoch: 4529, MSE: 0.26301419940132004, Learning Rate: 0.07735500000000001\n",
      "Epoch: 4530, MSE: 0.26301186839925983, Learning Rate: 0.07735\n",
      "Epoch: 4531, MSE: 0.2630095373465403, Learning Rate: 0.077345\n",
      "Epoch: 4532, MSE: 0.263007206243162, Learning Rate: 0.07734\n",
      "Epoch: 4533, MSE: 0.2630048750891237, Learning Rate: 0.077335\n",
      "Epoch: 4534, MSE: 0.26300254388442457, Learning Rate: 0.07733000000000001\n",
      "Epoch: 4535, MSE: 0.2630002126290658, Learning Rate: 0.077325\n",
      "Epoch: 4536, MSE: 0.26299788132304447, Learning Rate: 0.07732\n",
      "Epoch: 4537, MSE: 0.26299554996636165, Learning Rate: 0.07731500000000001\n",
      "Epoch: 4538, MSE: 0.26299321855901797, Learning Rate: 0.07731\n",
      "Epoch: 4539, MSE: 0.2629908871010099, Learning Rate: 0.07730500000000001\n",
      "Epoch: 4540, MSE: 0.2629885555923388, Learning Rate: 0.07730000000000001\n",
      "Epoch: 4541, MSE: 0.26298622403300476, Learning Rate: 0.077295\n",
      "Epoch: 4542, MSE: 0.26298389242300574, Learning Rate: 0.07729000000000001\n",
      "Epoch: 4543, MSE: 0.26298156076234236, Learning Rate: 0.077285\n",
      "Epoch: 4544, MSE: 0.26297922905101384, Learning Rate: 0.07728\n",
      "Epoch: 4545, MSE: 0.26297689728901996, Learning Rate: 0.07727500000000001\n",
      "Epoch: 4546, MSE: 0.262974565476359, Learning Rate: 0.07727\n",
      "Epoch: 4547, MSE: 0.2629722336130326, Learning Rate: 0.07726500000000001\n",
      "Epoch: 4548, MSE: 0.26296990169903833, Learning Rate: 0.07726\n",
      "Epoch: 4549, MSE: 0.2629675697343768, Learning Rate: 0.077255\n",
      "Epoch: 4550, MSE: 0.26296523771904734, Learning Rate: 0.07725\n",
      "Epoch: 4551, MSE: 0.26296290565304936, Learning Rate: 0.07724500000000001\n",
      "Epoch: 4552, MSE: 0.26296057353638225, Learning Rate: 0.07724\n",
      "Epoch: 4553, MSE: 0.26295824136904505, Learning Rate: 0.077235\n",
      "Epoch: 4554, MSE: 0.26295590915103934, Learning Rate: 0.07723000000000001\n",
      "Epoch: 4555, MSE: 0.2629535768823623, Learning Rate: 0.077225\n",
      "Epoch: 4556, MSE: 0.2629512445630142, Learning Rate: 0.07722000000000001\n",
      "Epoch: 4557, MSE: 0.26294891219299554, Learning Rate: 0.077215\n",
      "Epoch: 4558, MSE: 0.262946579772304, Learning Rate: 0.07721\n",
      "Epoch: 4559, MSE: 0.26294424730094057, Learning Rate: 0.07720500000000001\n",
      "Epoch: 4560, MSE: 0.26294191477890466, Learning Rate: 0.0772\n",
      "Epoch: 4561, MSE: 0.26293958220619496, Learning Rate: 0.07719500000000001\n",
      "Epoch: 4562, MSE: 0.26293724958281156, Learning Rate: 0.07719000000000001\n",
      "Epoch: 4563, MSE: 0.2629349169087542, Learning Rate: 0.077185\n",
      "Epoch: 4564, MSE: 0.2629325841840214, Learning Rate: 0.07718000000000001\n",
      "Epoch: 4565, MSE: 0.26293025140861437, Learning Rate: 0.077175\n",
      "Epoch: 4566, MSE: 0.2629279185825304, Learning Rate: 0.07717000000000002\n",
      "Epoch: 4567, MSE: 0.26292558570577146, Learning Rate: 0.077165\n",
      "Epoch: 4568, MSE: 0.26292325277833534, Learning Rate: 0.07716\n",
      "Epoch: 4569, MSE: 0.26292091980022203, Learning Rate: 0.077155\n",
      "Epoch: 4570, MSE: 0.26291858677143104, Learning Rate: 0.07715\n",
      "Epoch: 4571, MSE: 0.2629162536919625, Learning Rate: 0.077145\n",
      "Epoch: 4572, MSE: 0.2629139205618152, Learning Rate: 0.07714\n",
      "Epoch: 4573, MSE: 0.2629115873809893, Learning Rate: 0.07713500000000001\n",
      "Epoch: 4574, MSE: 0.26290925414948224, Learning Rate: 0.07713\n",
      "Epoch: 4575, MSE: 0.26290692086729683, Learning Rate: 0.077125\n",
      "Epoch: 4576, MSE: 0.2629045875344306, Learning Rate: 0.07712000000000001\n",
      "Epoch: 4577, MSE: 0.26290225415088375, Learning Rate: 0.077115\n",
      "Epoch: 4578, MSE: 0.26289992071665524, Learning Rate: 0.07711000000000001\n",
      "Epoch: 4579, MSE: 0.26289758723174494, Learning Rate: 0.077105\n",
      "Epoch: 4580, MSE: 0.2628952536961525, Learning Rate: 0.0771\n",
      "Epoch: 4581, MSE: 0.26289292010987686, Learning Rate: 0.07709500000000001\n",
      "Epoch: 4582, MSE: 0.2628905864729173, Learning Rate: 0.07709\n",
      "Epoch: 4583, MSE: 0.2628882527852746, Learning Rate: 0.07708500000000001\n",
      "Epoch: 4584, MSE: 0.2628859190469483, Learning Rate: 0.07708000000000001\n",
      "Epoch: 4585, MSE: 0.26288358525793726, Learning Rate: 0.077075\n",
      "Epoch: 4586, MSE: 0.26288125141824065, Learning Rate: 0.07707\n",
      "Epoch: 4587, MSE: 0.2628789175278586, Learning Rate: 0.07706500000000001\n",
      "Epoch: 4588, MSE: 0.26287658358679006, Learning Rate: 0.07706\n",
      "Epoch: 4589, MSE: 0.2628742495950354, Learning Rate: 0.07705500000000001\n",
      "Epoch: 4590, MSE: 0.26287191555259326, Learning Rate: 0.07705000000000001\n",
      "Epoch: 4591, MSE: 0.2628695814594636, Learning Rate: 0.077045\n",
      "Epoch: 4592, MSE: 0.26286724731564676, Learning Rate: 0.07704\n",
      "Epoch: 4593, MSE: 0.26286491312114, Learning Rate: 0.077035\n",
      "Epoch: 4594, MSE: 0.26286257887594594, Learning Rate: 0.07703\n",
      "Epoch: 4595, MSE: 0.26286024458006146, Learning Rate: 0.07702500000000001\n",
      "Epoch: 4596, MSE: 0.26285791023348704, Learning Rate: 0.07702\n",
      "Epoch: 4597, MSE: 0.26285557583622327, Learning Rate: 0.077015\n",
      "Epoch: 4598, MSE: 0.26285324138826793, Learning Rate: 0.07701000000000001\n",
      "Epoch: 4599, MSE: 0.26285090688962154, Learning Rate: 0.077005\n",
      "Epoch: 4600, MSE: 0.262848572340283, Learning Rate: 0.07700000000000001\n",
      "Epoch: 4601, MSE: 0.2628462377402526, Learning Rate: 0.07699500000000001\n",
      "Epoch: 4602, MSE: 0.2628439030895301, Learning Rate: 0.07699\n",
      "Epoch: 4603, MSE: 0.2628415683881141, Learning Rate: 0.07698500000000001\n",
      "Epoch: 4604, MSE: 0.26283923363600414, Learning Rate: 0.07698\n",
      "Epoch: 4605, MSE: 0.2628368988332001, Learning Rate: 0.076975\n",
      "Epoch: 4606, MSE: 0.26283456397970206, Learning Rate: 0.07697000000000001\n",
      "Epoch: 4607, MSE: 0.26283222907550885, Learning Rate: 0.076965\n",
      "Epoch: 4608, MSE: 0.2628298941206199, Learning Rate: 0.07696000000000001\n",
      "Epoch: 4609, MSE: 0.262827559115035, Learning Rate: 0.076955\n",
      "Epoch: 4610, MSE: 0.2628252240587536, Learning Rate: 0.07695\n",
      "Epoch: 4611, MSE: 0.26282288895177514, Learning Rate: 0.076945\n",
      "Epoch: 4612, MSE: 0.2628205537941005, Learning Rate: 0.07694000000000001\n",
      "Epoch: 4613, MSE: 0.26281821858572707, Learning Rate: 0.076935\n",
      "Epoch: 4614, MSE: 0.2628158833266556, Learning Rate: 0.07693\n",
      "Epoch: 4615, MSE: 0.2628135480168858, Learning Rate: 0.07692500000000001\n",
      "Epoch: 4616, MSE: 0.2628112126564165, Learning Rate: 0.07692\n",
      "Epoch: 4617, MSE: 0.262808877245247, Learning Rate: 0.07691500000000001\n",
      "Epoch: 4618, MSE: 0.2628065417833783, Learning Rate: 0.07691\n",
      "Epoch: 4619, MSE: 0.2628042062708086, Learning Rate: 0.076905\n",
      "Epoch: 4620, MSE: 0.26280187070753736, Learning Rate: 0.07690000000000001\n",
      "Epoch: 4621, MSE: 0.2627995350935658, Learning Rate: 0.076895\n",
      "Epoch: 4622, MSE: 0.26279719942889185, Learning Rate: 0.07689000000000001\n",
      "Epoch: 4623, MSE: 0.2627948637135151, Learning Rate: 0.07688500000000001\n",
      "Epoch: 4624, MSE: 0.2627925279474353, Learning Rate: 0.07688\n",
      "Epoch: 4625, MSE: 0.2627901921306521, Learning Rate: 0.07687500000000001\n",
      "Epoch: 4626, MSE: 0.2627878562631662, Learning Rate: 0.07687\n",
      "Epoch: 4627, MSE: 0.26278552034497554, Learning Rate: 0.07686500000000002\n",
      "Epoch: 4628, MSE: 0.26278318437607856, Learning Rate: 0.07686\n",
      "Epoch: 4629, MSE: 0.26278084835647925, Learning Rate: 0.076855\n",
      "Epoch: 4630, MSE: 0.2627785122861721, Learning Rate: 0.07685\n",
      "Epoch: 4631, MSE: 0.2627761761651592, Learning Rate: 0.076845\n",
      "Epoch: 4632, MSE: 0.2627738399934404, Learning Rate: 0.07684\n",
      "Epoch: 4633, MSE: 0.2627715037710139, Learning Rate: 0.076835\n",
      "Epoch: 4634, MSE: 0.26276916749788015, Learning Rate: 0.07683000000000001\n",
      "Epoch: 4635, MSE: 0.2627668311740387, Learning Rate: 0.076825\n",
      "Epoch: 4636, MSE: 0.2627644947994884, Learning Rate: 0.07682\n",
      "Epoch: 4637, MSE: 0.2627621583742296, Learning Rate: 0.07681500000000001\n",
      "Epoch: 4638, MSE: 0.26275982189826036, Learning Rate: 0.07681\n",
      "Epoch: 4639, MSE: 0.26275748537158305, Learning Rate: 0.07680500000000001\n",
      "Epoch: 4640, MSE: 0.2627551487941946, Learning Rate: 0.07680000000000001\n",
      "Epoch: 4641, MSE: 0.26275281216609564, Learning Rate: 0.076795\n",
      "Epoch: 4642, MSE: 0.2627504754872851, Learning Rate: 0.07679000000000001\n",
      "Epoch: 4643, MSE: 0.26274813875776326, Learning Rate: 0.076785\n",
      "Epoch: 4644, MSE: 0.2627458019775293, Learning Rate: 0.07678000000000001\n",
      "Epoch: 4645, MSE: 0.2627434651465826, Learning Rate: 0.076775\n",
      "Epoch: 4646, MSE: 0.26274112826492313, Learning Rate: 0.07677\n",
      "Epoch: 4647, MSE: 0.26273879133255046, Learning Rate: 0.076765\n",
      "Epoch: 4648, MSE: 0.2627364543494634, Learning Rate: 0.07676000000000001\n",
      "Epoch: 4649, MSE: 0.2627341173156621, Learning Rate: 0.076755\n",
      "Epoch: 4650, MSE: 0.2627317802311461, Learning Rate: 0.07675\n",
      "Epoch: 4651, MSE: 0.2627294430959146, Learning Rate: 0.07674500000000001\n",
      "Epoch: 4652, MSE: 0.2627271059099675, Learning Rate: 0.07674\n",
      "Epoch: 4653, MSE: 0.26272476867330424, Learning Rate: 0.076735\n",
      "Epoch: 4654, MSE: 0.2627224313859245, Learning Rate: 0.07673\n",
      "Epoch: 4655, MSE: 0.26272009404782737, Learning Rate: 0.076725\n",
      "Epoch: 4656, MSE: 0.2627177566590136, Learning Rate: 0.07672000000000001\n",
      "Epoch: 4657, MSE: 0.26271541921947994, Learning Rate: 0.076715\n",
      "Epoch: 4658, MSE: 0.26271308172922925, Learning Rate: 0.07671\n",
      "Epoch: 4659, MSE: 0.2627107441882596, Learning Rate: 0.07670500000000001\n",
      "Epoch: 4660, MSE: 0.26270840659657063, Learning Rate: 0.0767\n",
      "Epoch: 4661, MSE: 0.26270606895416176, Learning Rate: 0.07669500000000001\n",
      "Epoch: 4662, MSE: 0.26270373126103197, Learning Rate: 0.07669000000000001\n",
      "Epoch: 4663, MSE: 0.2627013935171815, Learning Rate: 0.076685\n",
      "Epoch: 4664, MSE: 0.26269905572261054, Learning Rate: 0.07668000000000001\n",
      "Epoch: 4665, MSE: 0.2626967178773175, Learning Rate: 0.07667500000000001\n",
      "Epoch: 4666, MSE: 0.26269437998130263, Learning Rate: 0.07667\n",
      "Epoch: 4667, MSE: 0.26269204203456464, Learning Rate: 0.07666500000000001\n",
      "Epoch: 4668, MSE: 0.26268970403710457, Learning Rate: 0.07666\n",
      "Epoch: 4669, MSE: 0.26268736598892023, Learning Rate: 0.07665500000000001\n",
      "Epoch: 4670, MSE: 0.2626850278900127, Learning Rate: 0.07665\n",
      "Epoch: 4671, MSE: 0.26268268974038056, Learning Rate: 0.076645\n",
      "Epoch: 4672, MSE: 0.2626803515400242, Learning Rate: 0.07664\n",
      "Epoch: 4673, MSE: 0.262678013288941, Learning Rate: 0.07663500000000001\n",
      "Epoch: 4674, MSE: 0.26267567498713323, Learning Rate: 0.07663\n",
      "Epoch: 4675, MSE: 0.26267333663459963, Learning Rate: 0.076625\n",
      "Epoch: 4676, MSE: 0.2626709982313389, Learning Rate: 0.07662000000000001\n",
      "Epoch: 4677, MSE: 0.262668659777351, Learning Rate: 0.076615\n",
      "Epoch: 4678, MSE: 0.2626663212726364, Learning Rate: 0.07661000000000001\n",
      "Epoch: 4679, MSE: 0.2626639827171932, Learning Rate: 0.076605\n",
      "Epoch: 4680, MSE: 0.2626616441110216, Learning Rate: 0.0766\n",
      "Epoch: 4681, MSE: 0.26265930545412147, Learning Rate: 0.07659500000000001\n",
      "Epoch: 4682, MSE: 0.262656966746492, Learning Rate: 0.07659\n",
      "Epoch: 4683, MSE: 0.26265462798813294, Learning Rate: 0.07658500000000001\n",
      "Epoch: 4684, MSE: 0.26265228917904343, Learning Rate: 0.07658000000000001\n",
      "Epoch: 4685, MSE: 0.2626499503192235, Learning Rate: 0.076575\n",
      "Epoch: 4686, MSE: 0.2626476114086725, Learning Rate: 0.07657000000000001\n",
      "Epoch: 4687, MSE: 0.2626452724473895, Learning Rate: 0.076565\n",
      "Epoch: 4688, MSE: 0.26264293343537537, Learning Rate: 0.07656000000000002\n",
      "Epoch: 4689, MSE: 0.2626405943726281, Learning Rate: 0.076555\n",
      "Epoch: 4690, MSE: 0.26263825525914813, Learning Rate: 0.07655\n",
      "Epoch: 4691, MSE: 0.26263591609493514, Learning Rate: 0.076545\n",
      "Epoch: 4692, MSE: 0.2626335768799881, Learning Rate: 0.07654\n",
      "Epoch: 4693, MSE: 0.262631237614307, Learning Rate: 0.076535\n",
      "Epoch: 4694, MSE: 0.2626288982978913, Learning Rate: 0.07653\n",
      "Epoch: 4695, MSE: 0.2626265589307403, Learning Rate: 0.07652500000000001\n",
      "Epoch: 4696, MSE: 0.26262421951285425, Learning Rate: 0.07652\n",
      "Epoch: 4697, MSE: 0.2626218800442317, Learning Rate: 0.076515\n",
      "Epoch: 4698, MSE: 0.26261954052487296, Learning Rate: 0.07651000000000001\n",
      "Epoch: 4699, MSE: 0.2626172009547776, Learning Rate: 0.076505\n",
      "Epoch: 4700, MSE: 0.26261486133394496, Learning Rate: 0.07650000000000001\n",
      "Epoch: 4701, MSE: 0.2626125216623743, Learning Rate: 0.07649500000000001\n",
      "Epoch: 4702, MSE: 0.26261018194006575, Learning Rate: 0.07649\n",
      "Epoch: 4703, MSE: 0.26260784216701827, Learning Rate: 0.07648500000000001\n",
      "Epoch: 4704, MSE: 0.26260550234323154, Learning Rate: 0.07648\n",
      "Epoch: 4705, MSE: 0.26260316246870624, Learning Rate: 0.07647500000000002\n",
      "Epoch: 4706, MSE: 0.26260082254343936, Learning Rate: 0.07647\n",
      "Epoch: 4707, MSE: 0.26259848256743334, Learning Rate: 0.076465\n",
      "Epoch: 4708, MSE: 0.2625961425406863, Learning Rate: 0.07646\n",
      "Epoch: 4709, MSE: 0.26259380246319847, Learning Rate: 0.07645500000000001\n",
      "Epoch: 4710, MSE: 0.2625914623349674, Learning Rate: 0.07645\n",
      "Epoch: 4711, MSE: 0.26258912215599506, Learning Rate: 0.076445\n",
      "Epoch: 4712, MSE: 0.2625867819262806, Learning Rate: 0.07644000000000001\n",
      "Epoch: 4713, MSE: 0.26258444164582245, Learning Rate: 0.076435\n",
      "Epoch: 4714, MSE: 0.26258210131462095, Learning Rate: 0.07643\n",
      "Epoch: 4715, MSE: 0.26257976093267565, Learning Rate: 0.076425\n",
      "Epoch: 4716, MSE: 0.2625774204999858, Learning Rate: 0.07642\n",
      "Epoch: 4717, MSE: 0.2625750800165512, Learning Rate: 0.07641500000000001\n",
      "Epoch: 4718, MSE: 0.26257273948237175, Learning Rate: 0.07641\n",
      "Epoch: 4719, MSE: 0.262570398897446, Learning Rate: 0.076405\n",
      "Epoch: 4720, MSE: 0.2625680582617746, Learning Rate: 0.07640000000000001\n",
      "Epoch: 4721, MSE: 0.26256571757535613, Learning Rate: 0.076395\n",
      "Epoch: 4722, MSE: 0.2625633768381907, Learning Rate: 0.07639000000000001\n",
      "Epoch: 4723, MSE: 0.2625610360502787, Learning Rate: 0.07638500000000001\n",
      "Epoch: 4724, MSE: 0.26255869521161834, Learning Rate: 0.07638\n",
      "Epoch: 4725, MSE: 0.26255635432220903, Learning Rate: 0.07637500000000001\n",
      "Epoch: 4726, MSE: 0.2625540133820523, Learning Rate: 0.07637000000000001\n",
      "Epoch: 4727, MSE: 0.26255167239114546, Learning Rate: 0.076365\n",
      "Epoch: 4728, MSE: 0.26254933134948943, Learning Rate: 0.07636000000000001\n",
      "Epoch: 4729, MSE: 0.26254699025708284, Learning Rate: 0.076355\n",
      "Epoch: 4730, MSE: 0.2625446491139255, Learning Rate: 0.07635000000000002\n",
      "Epoch: 4731, MSE: 0.2625423079200188, Learning Rate: 0.076345\n",
      "Epoch: 4732, MSE: 0.26253996667535945, Learning Rate: 0.07634\n",
      "Epoch: 4733, MSE: 0.26253762537994874, Learning Rate: 0.076335\n",
      "Epoch: 4734, MSE: 0.2625352840337854, Learning Rate: 0.07633000000000001\n",
      "Epoch: 4735, MSE: 0.2625329426368693, Learning Rate: 0.076325\n",
      "Epoch: 4736, MSE: 0.2625306011892006, Learning Rate: 0.07632\n",
      "Epoch: 4737, MSE: 0.2625282596907779, Learning Rate: 0.07631500000000001\n",
      "Epoch: 4738, MSE: 0.26252591814160153, Learning Rate: 0.07631\n",
      "Epoch: 4739, MSE: 0.2625235765416708, Learning Rate: 0.07630500000000001\n",
      "Epoch: 4740, MSE: 0.262521234890985, Learning Rate: 0.0763\n",
      "Epoch: 4741, MSE: 0.26251889318954474, Learning Rate: 0.076295\n",
      "Epoch: 4742, MSE: 0.26251655143734764, Learning Rate: 0.07629000000000001\n",
      "Epoch: 4743, MSE: 0.2625142096343951, Learning Rate: 0.076285\n",
      "Epoch: 4744, MSE: 0.26251186778068575, Learning Rate: 0.07628000000000001\n",
      "Epoch: 4745, MSE: 0.2625095258762196, Learning Rate: 0.07627500000000001\n",
      "Epoch: 4746, MSE: 0.2625071839209951, Learning Rate: 0.07627\n",
      "Epoch: 4747, MSE: 0.26250484191501405, Learning Rate: 0.07626500000000001\n",
      "Epoch: 4748, MSE: 0.262502499858274, Learning Rate: 0.07626\n",
      "Epoch: 4749, MSE: 0.26250015775077545, Learning Rate: 0.07625500000000002\n",
      "Epoch: 4750, MSE: 0.2624978155925171, Learning Rate: 0.07625\n",
      "Epoch: 4751, MSE: 0.26249547338350004, Learning Rate: 0.07624500000000001\n",
      "Epoch: 4752, MSE: 0.2624931311237234, Learning Rate: 0.07624\n",
      "Epoch: 4753, MSE: 0.262490788813185, Learning Rate: 0.076235\n",
      "Epoch: 4754, MSE: 0.2624884464518858, Learning Rate: 0.07623\n",
      "Epoch: 4755, MSE: 0.26248610403982603, Learning Rate: 0.076225\n",
      "Epoch: 4756, MSE: 0.26248376157700415, Learning Rate: 0.07622000000000001\n",
      "Epoch: 4757, MSE: 0.2624814190634203, Learning Rate: 0.076215\n",
      "Epoch: 4758, MSE: 0.2624790764990738, Learning Rate: 0.07621\n",
      "Epoch: 4759, MSE: 0.2624767338839639, Learning Rate: 0.07620500000000001\n",
      "Epoch: 4760, MSE: 0.2624743912180913, Learning Rate: 0.0762\n",
      "Epoch: 4761, MSE: 0.2624720485014538, Learning Rate: 0.07619500000000001\n",
      "Epoch: 4762, MSE: 0.262469705734053, Learning Rate: 0.07619000000000001\n",
      "Epoch: 4763, MSE: 0.2624673629158875, Learning Rate: 0.076185\n",
      "Epoch: 4764, MSE: 0.2624650200469559, Learning Rate: 0.07618000000000001\n",
      "Epoch: 4765, MSE: 0.26246267712725946, Learning Rate: 0.076175\n",
      "Epoch: 4766, MSE: 0.2624603341567961, Learning Rate: 0.07617000000000002\n",
      "Epoch: 4767, MSE: 0.262457991135567, Learning Rate: 0.076165\n",
      "Epoch: 4768, MSE: 0.2624556480635713, Learning Rate: 0.07616\n",
      "Epoch: 4769, MSE: 0.2624533049408075, Learning Rate: 0.076155\n",
      "Epoch: 4770, MSE: 0.26245096176727645, Learning Rate: 0.07615000000000001\n",
      "Epoch: 4771, MSE: 0.26244861854297724, Learning Rate: 0.076145\n",
      "Epoch: 4772, MSE: 0.26244627526790903, Learning Rate: 0.07614\n",
      "Epoch: 4773, MSE: 0.2624439319420721, Learning Rate: 0.07613500000000001\n",
      "Epoch: 4774, MSE: 0.262441588565466, Learning Rate: 0.07613\n",
      "Epoch: 4775, MSE: 0.2624392451380901, Learning Rate: 0.076125\n",
      "Epoch: 4776, MSE: 0.2624369016599426, Learning Rate: 0.07612000000000001\n",
      "Epoch: 4777, MSE: 0.26243455813102606, Learning Rate: 0.076115\n",
      "Epoch: 4778, MSE: 0.2624322145513377, Learning Rate: 0.07611000000000001\n",
      "Epoch: 4779, MSE: 0.2624298709208776, Learning Rate: 0.076105\n",
      "Epoch: 4780, MSE: 0.2624275272396461, Learning Rate: 0.0761\n",
      "Epoch: 4781, MSE: 0.26242518350764216, Learning Rate: 0.07609500000000001\n",
      "Epoch: 4782, MSE: 0.26242283972486474, Learning Rate: 0.07609\n",
      "Epoch: 4783, MSE: 0.2624204958913145, Learning Rate: 0.07608500000000001\n",
      "Epoch: 4784, MSE: 0.2624181520069908, Learning Rate: 0.07608000000000001\n",
      "Epoch: 4785, MSE: 0.2624158080718923, Learning Rate: 0.076075\n",
      "Epoch: 4786, MSE: 0.26241346408602023, Learning Rate: 0.07607\n",
      "Epoch: 4787, MSE: 0.2624111200493726, Learning Rate: 0.07606500000000001\n",
      "Epoch: 4788, MSE: 0.26240877596194945, Learning Rate: 0.07606\n",
      "Epoch: 4789, MSE: 0.2624064318237511, Learning Rate: 0.07605500000000001\n",
      "Epoch: 4790, MSE: 0.2624040876347759, Learning Rate: 0.07605\n",
      "Epoch: 4791, MSE: 0.26240174339502476, Learning Rate: 0.076045\n",
      "Epoch: 4792, MSE: 0.26239939910449606, Learning Rate: 0.07604\n",
      "Epoch: 4793, MSE: 0.262397054763191, Learning Rate: 0.076035\n",
      "Epoch: 4794, MSE: 0.2623947103711068, Learning Rate: 0.07603\n",
      "Epoch: 4795, MSE: 0.26239236592824444, Learning Rate: 0.07602500000000001\n",
      "Epoch: 4796, MSE: 0.2623900214346032, Learning Rate: 0.07602\n",
      "Epoch: 4797, MSE: 0.26238767689018333, Learning Rate: 0.076015\n",
      "Epoch: 4798, MSE: 0.262385332294984, Learning Rate: 0.07601000000000001\n",
      "Epoch: 4799, MSE: 0.2623829876490047, Learning Rate: 0.076005\n",
      "Epoch: 4800, MSE: 0.2623806429522439, Learning Rate: 0.07600000000000001\n",
      "Epoch: 4801, MSE: 0.2623782982047034, Learning Rate: 0.07599500000000001\n",
      "Epoch: 4802, MSE: 0.26237595340638187, Learning Rate: 0.07599\n",
      "Epoch: 4803, MSE: 0.26237360855727804, Learning Rate: 0.07598500000000001\n",
      "Epoch: 4804, MSE: 0.26237126365739205, Learning Rate: 0.07598\n",
      "Epoch: 4805, MSE: 0.262368918706724, Learning Rate: 0.07597500000000001\n",
      "Epoch: 4806, MSE: 0.26236657370527255, Learning Rate: 0.07597000000000001\n",
      "Epoch: 4807, MSE: 0.26236422865303877, Learning Rate: 0.075965\n",
      "Epoch: 4808, MSE: 0.26236188355002, Learning Rate: 0.07596000000000001\n",
      "Epoch: 4809, MSE: 0.26235953839621745, Learning Rate: 0.075955\n",
      "Epoch: 4810, MSE: 0.26235719319163137, Learning Rate: 0.07595000000000002\n",
      "Epoch: 4811, MSE: 0.262354847936259, Learning Rate: 0.075945\n",
      "Epoch: 4812, MSE: 0.26235250263010224, Learning Rate: 0.07594000000000001\n",
      "Epoch: 4813, MSE: 0.2623501572731589, Learning Rate: 0.075935\n",
      "Epoch: 4814, MSE: 0.26234781186542927, Learning Rate: 0.07593\n",
      "Epoch: 4815, MSE: 0.2623454664069136, Learning Rate: 0.075925\n",
      "Epoch: 4816, MSE: 0.2623431208976109, Learning Rate: 0.07592\n",
      "Epoch: 4817, MSE: 0.26234077533752, Learning Rate: 0.07591500000000001\n",
      "Epoch: 4818, MSE: 0.2623384297266418, Learning Rate: 0.07591\n",
      "Epoch: 4819, MSE: 0.26233608406497466, Learning Rate: 0.075905\n",
      "Epoch: 4820, MSE: 0.26233373835251955, Learning Rate: 0.07590000000000001\n",
      "Epoch: 4821, MSE: 0.2623313925892753, Learning Rate: 0.075895\n",
      "Epoch: 4822, MSE: 0.262329046775241, Learning Rate: 0.07589000000000001\n",
      "Epoch: 4823, MSE: 0.2623267009104165, Learning Rate: 0.07588500000000001\n",
      "Epoch: 4824, MSE: 0.2623243549948022, Learning Rate: 0.07588\n",
      "Epoch: 4825, MSE: 0.2623220090283969, Learning Rate: 0.07587500000000001\n",
      "Epoch: 4826, MSE: 0.2623196630112007, Learning Rate: 0.07587\n",
      "Epoch: 4827, MSE: 0.26231731694321325, Learning Rate: 0.07586500000000002\n",
      "Epoch: 4828, MSE: 0.26231497082443267, Learning Rate: 0.07586\n",
      "Epoch: 4829, MSE: 0.2623126246548605, Learning Rate: 0.075855\n",
      "Epoch: 4830, MSE: 0.26231027843449495, Learning Rate: 0.07585\n",
      "Epoch: 4831, MSE: 0.26230793216333664, Learning Rate: 0.07584500000000001\n",
      "Epoch: 4832, MSE: 0.2623055858413839, Learning Rate: 0.07584\n",
      "Epoch: 4833, MSE: 0.26230323946863804, Learning Rate: 0.075835\n",
      "Epoch: 4834, MSE: 0.2623008930450969, Learning Rate: 0.07583000000000001\n",
      "Epoch: 4835, MSE: 0.2622985465707612, Learning Rate: 0.075825\n",
      "Epoch: 4836, MSE: 0.26229620004563114, Learning Rate: 0.07582\n",
      "Epoch: 4837, MSE: 0.2622938534697037, Learning Rate: 0.07581500000000001\n",
      "Epoch: 4838, MSE: 0.26229150684298125, Learning Rate: 0.07581\n",
      "Epoch: 4839, MSE: 0.2622891601654621, Learning Rate: 0.07580500000000001\n",
      "Epoch: 4840, MSE: 0.2622868134371458, Learning Rate: 0.0758\n",
      "Epoch: 4841, MSE: 0.2622844666580323, Learning Rate: 0.075795\n",
      "Epoch: 4842, MSE: 0.2622821198281207, Learning Rate: 0.07579000000000001\n",
      "Epoch: 4843, MSE: 0.2622797729474113, Learning Rate: 0.075785\n",
      "Epoch: 4844, MSE: 0.26227742601590387, Learning Rate: 0.07578000000000001\n",
      "Epoch: 4845, MSE: 0.2622750790335965, Learning Rate: 0.07577500000000001\n",
      "Epoch: 4846, MSE: 0.26227273200048984, Learning Rate: 0.07577\n",
      "Epoch: 4847, MSE: 0.26227038491658355, Learning Rate: 0.075765\n",
      "Epoch: 4848, MSE: 0.26226803778187713, Learning Rate: 0.07576000000000001\n",
      "Epoch: 4849, MSE: 0.2622656905963699, Learning Rate: 0.075755\n",
      "Epoch: 4850, MSE: 0.2622633433600623, Learning Rate: 0.07575000000000001\n",
      "Epoch: 4851, MSE: 0.2622609960729527, Learning Rate: 0.075745\n",
      "Epoch: 4852, MSE: 0.26225864873504173, Learning Rate: 0.07574\n",
      "Epoch: 4853, MSE: 0.26225630134632866, Learning Rate: 0.075735\n",
      "Epoch: 4854, MSE: 0.26225395390681233, Learning Rate: 0.07573\n",
      "Epoch: 4855, MSE: 0.26225160641649303, Learning Rate: 0.075725\n",
      "Epoch: 4856, MSE: 0.2622492588753701, Learning Rate: 0.07572000000000001\n",
      "Epoch: 4857, MSE: 0.2622469112834444, Learning Rate: 0.075715\n",
      "Epoch: 4858, MSE: 0.26224456364071325, Learning Rate: 0.07571\n",
      "Epoch: 4859, MSE: 0.2622422159471786, Learning Rate: 0.07570500000000001\n",
      "Epoch: 4860, MSE: 0.2622398682028378, Learning Rate: 0.0757\n",
      "Epoch: 4861, MSE: 0.2622375204076919, Learning Rate: 0.07569500000000001\n",
      "Epoch: 4862, MSE: 0.2622351725617403, Learning Rate: 0.07569000000000001\n",
      "Epoch: 4863, MSE: 0.2622328246649828, Learning Rate: 0.075685\n",
      "Epoch: 4864, MSE: 0.2622304767174177, Learning Rate: 0.07568000000000001\n",
      "Epoch: 4865, MSE: 0.26222812871904627, Learning Rate: 0.075675\n",
      "Epoch: 4866, MSE: 0.2622257806698681, Learning Rate: 0.07567000000000002\n",
      "Epoch: 4867, MSE: 0.2622234325698805, Learning Rate: 0.07566500000000001\n",
      "Epoch: 4868, MSE: 0.2622210844190854, Learning Rate: 0.07566\n",
      "Epoch: 4869, MSE: 0.26221873621748126, Learning Rate: 0.07565500000000001\n",
      "Epoch: 4870, MSE: 0.26221638796506763, Learning Rate: 0.07565\n",
      "Epoch: 4871, MSE: 0.26221403966184575, Learning Rate: 0.07564500000000002\n",
      "Epoch: 4872, MSE: 0.26221169130781313, Learning Rate: 0.07564\n",
      "Epoch: 4873, MSE: 0.26220934290297065, Learning Rate: 0.07563500000000001\n",
      "Epoch: 4874, MSE: 0.26220699444731743, Learning Rate: 0.07563\n",
      "Epoch: 4875, MSE: 0.2622046459408533, Learning Rate: 0.075625\n",
      "Epoch: 4876, MSE: 0.2622022973835768, Learning Rate: 0.07562\n",
      "Epoch: 4877, MSE: 0.26219994877548997, Learning Rate: 0.075615\n",
      "Epoch: 4878, MSE: 0.26219760011658966, Learning Rate: 0.07561000000000001\n",
      "Epoch: 4879, MSE: 0.26219525140687694, Learning Rate: 0.075605\n",
      "Epoch: 4880, MSE: 0.26219290264635164, Learning Rate: 0.0756\n",
      "Epoch: 4881, MSE: 0.26219055383501216, Learning Rate: 0.07559500000000001\n",
      "Epoch: 4882, MSE: 0.26218820497285905, Learning Rate: 0.07559\n",
      "Epoch: 4883, MSE: 0.26218585605989186, Learning Rate: 0.07558500000000001\n",
      "Epoch: 4884, MSE: 0.2621835070961101, Learning Rate: 0.07558000000000001\n",
      "Epoch: 4885, MSE: 0.2621811580815127, Learning Rate: 0.075575\n",
      "Epoch: 4886, MSE: 0.2621788090161002, Learning Rate: 0.07557000000000001\n",
      "Epoch: 4887, MSE: 0.262176459899872, Learning Rate: 0.075565\n",
      "Epoch: 4888, MSE: 0.26217411073282765, Learning Rate: 0.07556000000000002\n",
      "Epoch: 4889, MSE: 0.26217176151496624, Learning Rate: 0.075555\n",
      "Epoch: 4890, MSE: 0.2621694122462884, Learning Rate: 0.07555\n",
      "Epoch: 4891, MSE: 0.26216706292679254, Learning Rate: 0.075545\n",
      "Epoch: 4892, MSE: 0.2621647135564789, Learning Rate: 0.07554\n",
      "Epoch: 4893, MSE: 0.2621623641353472, Learning Rate: 0.075535\n",
      "Epoch: 4894, MSE: 0.2621600146633967, Learning Rate: 0.07553\n",
      "Epoch: 4895, MSE: 0.26215766514062705, Learning Rate: 0.07552500000000001\n",
      "Epoch: 4896, MSE: 0.26215531556703814, Learning Rate: 0.07552\n",
      "Epoch: 4897, MSE: 0.2621529659426305, Learning Rate: 0.075515\n",
      "Epoch: 4898, MSE: 0.26215061626740127, Learning Rate: 0.07551000000000001\n",
      "Epoch: 4899, MSE: 0.262148266541352, Learning Rate: 0.075505\n",
      "Epoch: 4900, MSE: 0.26214591676448157, Learning Rate: 0.07550000000000001\n",
      "Epoch: 4901, MSE: 0.26214356693678975, Learning Rate: 0.075495\n",
      "Epoch: 4902, MSE: 0.2621412170582762, Learning Rate: 0.07549\n",
      "Epoch: 4903, MSE: 0.26213886712894097, Learning Rate: 0.07548500000000001\n",
      "Epoch: 4904, MSE: 0.262136517148783, Learning Rate: 0.07548\n",
      "Epoch: 4905, MSE: 0.26213416711780174, Learning Rate: 0.07547500000000001\n",
      "Epoch: 4906, MSE: 0.26213181703599736, Learning Rate: 0.07547000000000001\n",
      "Epoch: 4907, MSE: 0.2621294669033689, Learning Rate: 0.075465\n",
      "Epoch: 4908, MSE: 0.26212711671991623, Learning Rate: 0.07546\n",
      "Epoch: 4909, MSE: 0.26212476648564004, Learning Rate: 0.07545500000000001\n",
      "Epoch: 4910, MSE: 0.2621224162005378, Learning Rate: 0.07545\n",
      "Epoch: 4911, MSE: 0.26212006586461123, Learning Rate: 0.07544500000000001\n",
      "Epoch: 4912, MSE: 0.26211771547785856, Learning Rate: 0.07544000000000001\n",
      "Epoch: 4913, MSE: 0.26211536504027955, Learning Rate: 0.075435\n",
      "Epoch: 4914, MSE: 0.2621130145518745, Learning Rate: 0.07543\n",
      "Epoch: 4915, MSE: 0.2621106640126429, Learning Rate: 0.075425\n",
      "Epoch: 4916, MSE: 0.2621083134225834, Learning Rate: 0.07542\n",
      "Epoch: 4917, MSE: 0.2621059627816964, Learning Rate: 0.07541500000000001\n",
      "Epoch: 4918, MSE: 0.2621036120899811, Learning Rate: 0.07541\n",
      "Epoch: 4919, MSE: 0.26210126134743805, Learning Rate: 0.075405\n",
      "Epoch: 4920, MSE: 0.2620989105540662, Learning Rate: 0.07540000000000001\n",
      "Epoch: 4921, MSE: 0.2620965597098645, Learning Rate: 0.075395\n",
      "Epoch: 4922, MSE: 0.26209420881483353, Learning Rate: 0.07539000000000001\n",
      "Epoch: 4923, MSE: 0.2620918578689729, Learning Rate: 0.07538500000000001\n",
      "Epoch: 4924, MSE: 0.26208950687228194, Learning Rate: 0.07538\n",
      "Epoch: 4925, MSE: 0.26208715582476044, Learning Rate: 0.07537500000000001\n",
      "Epoch: 4926, MSE: 0.2620848047264068, Learning Rate: 0.07537\n",
      "Epoch: 4927, MSE: 0.26208245357722226, Learning Rate: 0.075365\n",
      "Epoch: 4928, MSE: 0.26208010237720564, Learning Rate: 0.07536000000000001\n",
      "Epoch: 4929, MSE: 0.2620777511263573, Learning Rate: 0.075355\n",
      "Epoch: 4930, MSE: 0.26207539982467526, Learning Rate: 0.07535000000000001\n",
      "Epoch: 4931, MSE: 0.26207304847216106, Learning Rate: 0.075345\n",
      "Epoch: 4932, MSE: 0.2620706970688142, Learning Rate: 0.07534\n",
      "Epoch: 4933, MSE: 0.2620683456146325, Learning Rate: 0.075335\n",
      "Epoch: 4934, MSE: 0.26206599410961656, Learning Rate: 0.07533000000000001\n",
      "Epoch: 4935, MSE: 0.2620636425537663, Learning Rate: 0.075325\n",
      "Epoch: 4936, MSE: 0.26206129094708125, Learning Rate: 0.07532\n",
      "Epoch: 4937, MSE: 0.2620589392895599, Learning Rate: 0.07531500000000001\n",
      "Epoch: 4938, MSE: 0.26205658758120387, Learning Rate: 0.07531\n",
      "Epoch: 4939, MSE: 0.2620542358220108, Learning Rate: 0.07530500000000001\n",
      "Epoch: 4940, MSE: 0.26205188401198176, Learning Rate: 0.0753\n",
      "Epoch: 4941, MSE: 0.262049532151116, Learning Rate: 0.075295\n",
      "Epoch: 4942, MSE: 0.2620471802394129, Learning Rate: 0.07529000000000001\n",
      "Epoch: 4943, MSE: 0.2620448282768721, Learning Rate: 0.075285\n",
      "Epoch: 4944, MSE: 0.2620424762634927, Learning Rate: 0.07528000000000001\n",
      "Epoch: 4945, MSE: 0.262040124199276, Learning Rate: 0.07527500000000001\n",
      "Epoch: 4946, MSE: 0.2620377720842201, Learning Rate: 0.07527\n",
      "Epoch: 4947, MSE: 0.26203541991832485, Learning Rate: 0.07526500000000001\n",
      "Epoch: 4948, MSE: 0.2620330677015898, Learning Rate: 0.07526\n",
      "Epoch: 4949, MSE: 0.2620307154340146, Learning Rate: 0.07525500000000002\n",
      "Epoch: 4950, MSE: 0.26202836311560007, Learning Rate: 0.07525\n",
      "Epoch: 4951, MSE: 0.2620260107463442, Learning Rate: 0.075245\n",
      "Epoch: 4952, MSE: 0.26202365832624713, Learning Rate: 0.07524\n",
      "Epoch: 4953, MSE: 0.262021305855309, Learning Rate: 0.075235\n",
      "Epoch: 4954, MSE: 0.2620189533335289, Learning Rate: 0.07523\n",
      "Epoch: 4955, MSE: 0.2620166007609064, Learning Rate: 0.075225\n",
      "Epoch: 4956, MSE: 0.2620142481374417, Learning Rate: 0.07522000000000001\n",
      "Epoch: 4957, MSE: 0.2620118954631338, Learning Rate: 0.075215\n",
      "Epoch: 4958, MSE: 0.2620095427379828, Learning Rate: 0.07521\n",
      "Epoch: 4959, MSE: 0.2620071899619877, Learning Rate: 0.07520500000000001\n",
      "Epoch: 4960, MSE: 0.2620048371351491, Learning Rate: 0.0752\n",
      "Epoch: 4961, MSE: 0.26200248425746564, Learning Rate: 0.07519500000000001\n",
      "Epoch: 4962, MSE: 0.2620001313289368, Learning Rate: 0.07519\n",
      "Epoch: 4963, MSE: 0.2619977783495638, Learning Rate: 0.075185\n",
      "Epoch: 4964, MSE: 0.2619954253193441, Learning Rate: 0.07518000000000001\n",
      "Epoch: 4965, MSE: 0.2619930722382791, Learning Rate: 0.075175\n",
      "Epoch: 4966, MSE: 0.2619907191063678, Learning Rate: 0.07517000000000001\n",
      "Epoch: 4967, MSE: 0.26198836592360925, Learning Rate: 0.07516500000000001\n",
      "Epoch: 4968, MSE: 0.2619860126900043, Learning Rate: 0.07516\n",
      "Epoch: 4969, MSE: 0.26198365940555063, Learning Rate: 0.075155\n",
      "Epoch: 4970, MSE: 0.2619813060702504, Learning Rate: 0.07515000000000001\n",
      "Epoch: 4971, MSE: 0.2619789526841011, Learning Rate: 0.075145\n",
      "Epoch: 4972, MSE: 0.26197659924710337, Learning Rate: 0.07514000000000001\n",
      "Epoch: 4973, MSE: 0.26197424575925715, Learning Rate: 0.07513500000000001\n",
      "Epoch: 4974, MSE: 0.26197189222056083, Learning Rate: 0.07513\n",
      "Epoch: 4975, MSE: 0.26196953863101485, Learning Rate: 0.075125\n",
      "Epoch: 4976, MSE: 0.26196718499061916, Learning Rate: 0.07512\n",
      "Epoch: 4977, MSE: 0.2619648312993734, Learning Rate: 0.075115\n",
      "Epoch: 4978, MSE: 0.2619624775572757, Learning Rate: 0.07511000000000001\n",
      "Epoch: 4979, MSE: 0.26196012376432726, Learning Rate: 0.075105\n",
      "Epoch: 4980, MSE: 0.26195776992052683, Learning Rate: 0.0751\n",
      "Epoch: 4981, MSE: 0.2619554160258756, Learning Rate: 0.07509500000000001\n",
      "Epoch: 4982, MSE: 0.2619530620803714, Learning Rate: 0.07509\n",
      "Epoch: 4983, MSE: 0.2619507080840142, Learning Rate: 0.07508500000000001\n",
      "Epoch: 4984, MSE: 0.2619483540368044, Learning Rate: 0.07508000000000001\n",
      "Epoch: 4985, MSE: 0.26194599993874024, Learning Rate: 0.075075\n",
      "Epoch: 4986, MSE: 0.2619436457898228, Learning Rate: 0.07507000000000001\n",
      "Epoch: 4987, MSE: 0.2619412915900512, Learning Rate: 0.075065\n",
      "Epoch: 4988, MSE: 0.26193893733942464, Learning Rate: 0.07506\n",
      "Epoch: 4989, MSE: 0.26193658303794337, Learning Rate: 0.07505500000000001\n",
      "Epoch: 4990, MSE: 0.2619342286856069, Learning Rate: 0.07505\n",
      "Epoch: 4991, MSE: 0.26193187428241554, Learning Rate: 0.07504500000000001\n",
      "Epoch: 4992, MSE: 0.2619295198283674, Learning Rate: 0.07504\n",
      "Epoch: 4993, MSE: 0.26192716532346233, Learning Rate: 0.075035\n",
      "Epoch: 4994, MSE: 0.26192481076770086, Learning Rate: 0.07503\n",
      "Epoch: 4995, MSE: 0.26192245616108245, Learning Rate: 0.07502500000000001\n",
      "Epoch: 4996, MSE: 0.26192010150360645, Learning Rate: 0.07502\n",
      "Epoch: 4997, MSE: 0.26191774679527247, Learning Rate: 0.075015\n",
      "Epoch: 4998, MSE: 0.26191539203608016, Learning Rate: 0.07501000000000001\n",
      "Epoch: 4999, MSE: 0.2619130372260293, Learning Rate: 0.075005\n",
      "Epoch: 5000, MSE: 0.26191068236511905, Learning Rate: 0.07500000000000001\n",
      "Epoch: 5001, MSE: 0.2619083274533498, Learning Rate: 0.074995\n",
      "Epoch: 5002, MSE: 0.26190597249072056, Learning Rate: 0.07499\n",
      "Epoch: 5003, MSE: 0.2619036174772321, Learning Rate: 0.07498500000000001\n",
      "Epoch: 5004, MSE: 0.2619012624128826, Learning Rate: 0.07498\n",
      "Epoch: 5005, MSE: 0.26189890729767207, Learning Rate: 0.074975\n",
      "Epoch: 5006, MSE: 0.26189655213160035, Learning Rate: 0.07497000000000001\n",
      "Epoch: 5007, MSE: 0.2618941969146674, Learning Rate: 0.07496499999999999\n",
      "Epoch: 5008, MSE: 0.2618918416468725, Learning Rate: 0.07496000000000001\n",
      "Epoch: 5009, MSE: 0.261889486328215, Learning Rate: 0.074955\n",
      "Epoch: 5010, MSE: 0.26188713095869526, Learning Rate: 0.07495\n",
      "Epoch: 5011, MSE: 0.2618847755383115, Learning Rate: 0.074945\n",
      "Epoch: 5012, MSE: 0.2618824200670657, Learning Rate: 0.07494\n",
      "Epoch: 5013, MSE: 0.2618800645449552, Learning Rate: 0.074935\n",
      "Epoch: 5014, MSE: 0.2618777089719812, Learning Rate: 0.07493000000000001\n",
      "Epoch: 5015, MSE: 0.26187535334814227, Learning Rate: 0.074925\n",
      "Epoch: 5016, MSE: 0.2618729976734381, Learning Rate: 0.07492\n",
      "Epoch: 5017, MSE: 0.26187064194786996, Learning Rate: 0.074915\n",
      "Epoch: 5018, MSE: 0.2618682861714358, Learning Rate: 0.07491\n",
      "Epoch: 5019, MSE: 0.26186593034413524, Learning Rate: 0.074905\n",
      "Epoch: 5020, MSE: 0.2618635744659688, Learning Rate: 0.07490000000000001\n",
      "Epoch: 5021, MSE: 0.2618612185369356, Learning Rate: 0.074895\n",
      "Epoch: 5022, MSE: 0.26185886255703544, Learning Rate: 0.07489\n",
      "Epoch: 5023, MSE: 0.2618565065262678, Learning Rate: 0.07488500000000001\n",
      "Epoch: 5024, MSE: 0.26185415044463217, Learning Rate: 0.07488\n",
      "Epoch: 5025, MSE: 0.26185179431212835, Learning Rate: 0.07487500000000001\n",
      "Epoch: 5026, MSE: 0.261849438128757, Learning Rate: 0.07486999999999999\n",
      "Epoch: 5027, MSE: 0.26184708189451583, Learning Rate: 0.074865\n",
      "Epoch: 5028, MSE: 0.2618447256094065, Learning Rate: 0.07486\n",
      "Epoch: 5029, MSE: 0.2618423692734269, Learning Rate: 0.074855\n",
      "Epoch: 5030, MSE: 0.26184001288657793, Learning Rate: 0.07485\n",
      "Epoch: 5031, MSE: 0.261837656448858, Learning Rate: 0.07484500000000001\n",
      "Epoch: 5032, MSE: 0.26183529996026805, Learning Rate: 0.07484\n",
      "Epoch: 5033, MSE: 0.2618329434208069, Learning Rate: 0.07483500000000001\n",
      "Epoch: 5034, MSE: 0.2618305868304743, Learning Rate: 0.07483\n",
      "Epoch: 5035, MSE: 0.2618282301892703, Learning Rate: 0.07482500000000002\n",
      "Epoch: 5036, MSE: 0.26182587349719383, Learning Rate: 0.07482\n",
      "Epoch: 5037, MSE: 0.2618235167542447, Learning Rate: 0.074815\n",
      "Epoch: 5038, MSE: 0.2618211599604244, Learning Rate: 0.07481\n",
      "Epoch: 5039, MSE: 0.26181880311572936, Learning Rate: 0.074805\n",
      "Epoch: 5040, MSE: 0.26181644622016126, Learning Rate: 0.0748\n",
      "Epoch: 5041, MSE: 0.2618140892737191, Learning Rate: 0.074795\n",
      "Epoch: 5042, MSE: 0.26181173227640364, Learning Rate: 0.07479000000000001\n",
      "Epoch: 5043, MSE: 0.2618093752282134, Learning Rate: 0.074785\n",
      "Epoch: 5044, MSE: 0.26180701812914736, Learning Rate: 0.07478\n",
      "Epoch: 5045, MSE: 0.26180466097920707, Learning Rate: 0.07477500000000001\n",
      "Epoch: 5046, MSE: 0.261802303778391, Learning Rate: 0.07477\n",
      "Epoch: 5047, MSE: 0.26179994652669836, Learning Rate: 0.074765\n",
      "Epoch: 5048, MSE: 0.26179758922412966, Learning Rate: 0.07476000000000001\n",
      "Epoch: 5049, MSE: 0.261795231870685, Learning Rate: 0.074755\n",
      "Epoch: 5050, MSE: 0.2617928744663625, Learning Rate: 0.07475000000000001\n",
      "Epoch: 5051, MSE: 0.2617905170111625, Learning Rate: 0.07474499999999999\n",
      "Epoch: 5052, MSE: 0.2617881595050851, Learning Rate: 0.07474000000000001\n",
      "Epoch: 5053, MSE: 0.26178580194812967, Learning Rate: 0.074735\n",
      "Epoch: 5054, MSE: 0.261783444340296, Learning Rate: 0.07473\n",
      "Epoch: 5055, MSE: 0.2617810866815833, Learning Rate: 0.074725\n",
      "Epoch: 5056, MSE: 0.2617787289719914, Learning Rate: 0.07472\n",
      "Epoch: 5057, MSE: 0.2617763712115198, Learning Rate: 0.074715\n",
      "Epoch: 5058, MSE: 0.26177401340016904, Learning Rate: 0.07471\n",
      "Epoch: 5059, MSE: 0.2617716555379373, Learning Rate: 0.07470500000000001\n",
      "Epoch: 5060, MSE: 0.2617692976248253, Learning Rate: 0.0747\n",
      "Epoch: 5061, MSE: 0.26176693966083214, Learning Rate: 0.074695\n",
      "Epoch: 5062, MSE: 0.2617645816459579, Learning Rate: 0.07469\n",
      "Epoch: 5063, MSE: 0.2617622235802027, Learning Rate: 0.074685\n",
      "Epoch: 5064, MSE: 0.2617598654635646, Learning Rate: 0.07468000000000001\n",
      "Epoch: 5065, MSE: 0.26175750729604474, Learning Rate: 0.074675\n",
      "Epoch: 5066, MSE: 0.26175514907764175, Learning Rate: 0.07467\n",
      "Epoch: 5067, MSE: 0.26175279080835695, Learning Rate: 0.07466500000000001\n",
      "Epoch: 5068, MSE: 0.26175043248818797, Learning Rate: 0.07465999999999999\n",
      "Epoch: 5069, MSE: 0.26174807411713447, Learning Rate: 0.07465500000000001\n",
      "Epoch: 5070, MSE: 0.26174571569519833, Learning Rate: 0.07465\n",
      "Epoch: 5071, MSE: 0.261743357222377, Learning Rate: 0.074645\n",
      "Epoch: 5072, MSE: 0.26174099869867085, Learning Rate: 0.07464\n",
      "Epoch: 5073, MSE: 0.2617386401240793, Learning Rate: 0.074635\n",
      "Epoch: 5074, MSE: 0.2617362814986032, Learning Rate: 0.07463\n",
      "Epoch: 5075, MSE: 0.261733922822241, Learning Rate: 0.07462500000000001\n",
      "Epoch: 5076, MSE: 0.26173156409499204, Learning Rate: 0.07462\n",
      "Epoch: 5077, MSE: 0.26172920531685756, Learning Rate: 0.074615\n",
      "Epoch: 5078, MSE: 0.26172684648783606, Learning Rate: 0.07461\n",
      "Epoch: 5079, MSE: 0.26172448760792727, Learning Rate: 0.074605\n",
      "Epoch: 5080, MSE: 0.2617221286771306, Learning Rate: 0.0746\n",
      "Epoch: 5081, MSE: 0.2617197696954459, Learning Rate: 0.07459500000000001\n",
      "Epoch: 5082, MSE: 0.26171741066287324, Learning Rate: 0.07459\n",
      "Epoch: 5083, MSE: 0.2617150515794128, Learning Rate: 0.074585\n",
      "Epoch: 5084, MSE: 0.26171269244506246, Learning Rate: 0.07458000000000001\n",
      "Epoch: 5085, MSE: 0.26171033325982357, Learning Rate: 0.074575\n",
      "Epoch: 5086, MSE: 0.2617079740236943, Learning Rate: 0.07457000000000001\n",
      "Epoch: 5087, MSE: 0.26170561473667514, Learning Rate: 0.07456499999999999\n",
      "Epoch: 5088, MSE: 0.26170325539876615, Learning Rate: 0.07456\n",
      "Epoch: 5089, MSE: 0.26170089600996665, Learning Rate: 0.074555\n",
      "Epoch: 5090, MSE: 0.2616985365702753, Learning Rate: 0.07455\n",
      "Epoch: 5091, MSE: 0.26169617707969445, Learning Rate: 0.074545\n",
      "Epoch: 5092, MSE: 0.2616938175382201, Learning Rate: 0.07454000000000001\n",
      "Epoch: 5093, MSE: 0.26169145794585447, Learning Rate: 0.074535\n",
      "Epoch: 5094, MSE: 0.2616890983025965, Learning Rate: 0.07453000000000001\n",
      "Epoch: 5095, MSE: 0.2616867386084454, Learning Rate: 0.074525\n",
      "Epoch: 5096, MSE: 0.2616843788634019, Learning Rate: 0.07452\n",
      "Epoch: 5097, MSE: 0.2616820190674643, Learning Rate: 0.074515\n",
      "Epoch: 5098, MSE: 0.2616796592206338, Learning Rate: 0.07451\n",
      "Epoch: 5099, MSE: 0.2616772993229095, Learning Rate: 0.074505\n",
      "Epoch: 5100, MSE: 0.2616749393742896, Learning Rate: 0.0745\n",
      "Epoch: 5101, MSE: 0.2616725793747755, Learning Rate: 0.074495\n",
      "Epoch: 5102, MSE: 0.2616702193243667, Learning Rate: 0.07449\n",
      "Epoch: 5103, MSE: 0.26166785922306207, Learning Rate: 0.07448500000000001\n",
      "Epoch: 5104, MSE: 0.261665499070862, Learning Rate: 0.07448\n",
      "Epoch: 5105, MSE: 0.2616631388677651, Learning Rate: 0.074475\n",
      "Epoch: 5106, MSE: 0.2616607786137722, Learning Rate: 0.07447\n",
      "Epoch: 5107, MSE: 0.2616584183088827, Learning Rate: 0.074465\n",
      "Epoch: 5108, MSE: 0.2616560579530958, Learning Rate: 0.07446\n",
      "Epoch: 5109, MSE: 0.2616536975464123, Learning Rate: 0.07445500000000001\n",
      "Epoch: 5110, MSE: 0.26165133708883026, Learning Rate: 0.07445\n",
      "Epoch: 5111, MSE: 0.26164897658034975, Learning Rate: 0.07444500000000001\n",
      "Epoch: 5112, MSE: 0.2616466160209712, Learning Rate: 0.07443999999999999\n",
      "Epoch: 5113, MSE: 0.26164425541069475, Learning Rate: 0.07443500000000002\n",
      "Epoch: 5114, MSE: 0.26164189474951766, Learning Rate: 0.07443\n",
      "Epoch: 5115, MSE: 0.26163953403744156, Learning Rate: 0.074425\n",
      "Epoch: 5116, MSE: 0.26163717327446595, Learning Rate: 0.07442\n",
      "Epoch: 5117, MSE: 0.26163481246058934, Learning Rate: 0.074415\n",
      "Epoch: 5118, MSE: 0.2616324515958138, Learning Rate: 0.07441\n",
      "Epoch: 5119, MSE: 0.26163009068013665, Learning Rate: 0.074405\n",
      "Epoch: 5120, MSE: 0.2616277297135581, Learning Rate: 0.07440000000000001\n",
      "Epoch: 5121, MSE: 0.26162536869607805, Learning Rate: 0.074395\n",
      "Epoch: 5122, MSE: 0.2616230076276964, Learning Rate: 0.07439\n",
      "Epoch: 5123, MSE: 0.2616206465084129, Learning Rate: 0.074385\n",
      "Epoch: 5124, MSE: 0.2616182853382264, Learning Rate: 0.07438\n",
      "Epoch: 5125, MSE: 0.26161592411713713, Learning Rate: 0.07437500000000001\n",
      "Epoch: 5126, MSE: 0.26161356284514403, Learning Rate: 0.07437\n",
      "Epoch: 5127, MSE: 0.26161120152224876, Learning Rate: 0.074365\n",
      "Epoch: 5128, MSE: 0.2616088401484491, Learning Rate: 0.07436000000000001\n",
      "Epoch: 5129, MSE: 0.26160647872374587, Learning Rate: 0.07435499999999999\n",
      "Epoch: 5130, MSE: 0.2616041172481375, Learning Rate: 0.07435000000000001\n",
      "Epoch: 5131, MSE: 0.2616017557216239, Learning Rate: 0.074345\n",
      "Epoch: 5132, MSE: 0.2615993941442056, Learning Rate: 0.07434\n",
      "Epoch: 5133, MSE: 0.2615970325158823, Learning Rate: 0.074335\n",
      "Epoch: 5134, MSE: 0.26159467083665183, Learning Rate: 0.07433000000000001\n",
      "Epoch: 5135, MSE: 0.261592309106517, Learning Rate: 0.074325\n",
      "Epoch: 5136, MSE: 0.2615899473254742, Learning Rate: 0.07432000000000001\n",
      "Epoch: 5137, MSE: 0.26158758549352523, Learning Rate: 0.074315\n",
      "Epoch: 5138, MSE: 0.26158522361066927, Learning Rate: 0.07431\n",
      "Epoch: 5139, MSE: 0.2615828616769055, Learning Rate: 0.074305\n",
      "Epoch: 5140, MSE: 0.2615804996922341, Learning Rate: 0.0743\n",
      "Epoch: 5141, MSE: 0.2615781376566543, Learning Rate: 0.074295\n",
      "Epoch: 5142, MSE: 0.26157577557016654, Learning Rate: 0.07429000000000001\n",
      "Epoch: 5143, MSE: 0.26157341343276913, Learning Rate: 0.074285\n",
      "Epoch: 5144, MSE: 0.2615710512444631, Learning Rate: 0.07428\n",
      "Epoch: 5145, MSE: 0.2615686890052478, Learning Rate: 0.07427500000000001\n",
      "Epoch: 5146, MSE: 0.2615663267151225, Learning Rate: 0.07427\n",
      "Epoch: 5147, MSE: 0.2615639643740865, Learning Rate: 0.07426500000000001\n",
      "Epoch: 5148, MSE: 0.26156160198214096, Learning Rate: 0.07425999999999999\n",
      "Epoch: 5149, MSE: 0.26155923953928456, Learning Rate: 0.074255\n",
      "Epoch: 5150, MSE: 0.2615568770455169, Learning Rate: 0.07425\n",
      "Epoch: 5151, MSE: 0.2615545145008377, Learning Rate: 0.074245\n",
      "Epoch: 5152, MSE: 0.2615521519052473, Learning Rate: 0.07424\n",
      "Epoch: 5153, MSE: 0.26154978925874406, Learning Rate: 0.07423500000000001\n",
      "Epoch: 5154, MSE: 0.26154742656132857, Learning Rate: 0.07423\n",
      "Epoch: 5155, MSE: 0.2615450638130005, Learning Rate: 0.07422500000000001\n",
      "Epoch: 5156, MSE: 0.26154270101375976, Learning Rate: 0.07422\n",
      "Epoch: 5157, MSE: 0.26154033816360506, Learning Rate: 0.074215\n",
      "Epoch: 5158, MSE: 0.2615379752625367, Learning Rate: 0.07421\n",
      "Epoch: 5159, MSE: 0.2615356123105544, Learning Rate: 0.07420500000000001\n",
      "Epoch: 5160, MSE: 0.26153324930765853, Learning Rate: 0.0742\n",
      "Epoch: 5161, MSE: 0.261530886253847, Learning Rate: 0.074195\n",
      "Epoch: 5162, MSE: 0.26152852314912073, Learning Rate: 0.07419\n",
      "Epoch: 5163, MSE: 0.26152615999347945, Learning Rate: 0.074185\n",
      "Epoch: 5164, MSE: 0.2615237967869221, Learning Rate: 0.07418000000000001\n",
      "Epoch: 5165, MSE: 0.2615214335294483, Learning Rate: 0.074175\n",
      "Epoch: 5166, MSE: 0.26151907022105914, Learning Rate: 0.07417\n",
      "Epoch: 5167, MSE: 0.2615167068617537, Learning Rate: 0.074165\n",
      "Epoch: 5168, MSE: 0.26151434345153035, Learning Rate: 0.07416\n",
      "Epoch: 5169, MSE: 0.2615119799903896, Learning Rate: 0.074155\n",
      "Epoch: 5170, MSE: 0.26150961647833115, Learning Rate: 0.07415000000000001\n",
      "Epoch: 5171, MSE: 0.2615072529153564, Learning Rate: 0.074145\n",
      "Epoch: 5172, MSE: 0.26150488930146254, Learning Rate: 0.07414000000000001\n",
      "Epoch: 5173, MSE: 0.26150252563664955, Learning Rate: 0.07413499999999999\n",
      "Epoch: 5174, MSE: 0.26150016192091796, Learning Rate: 0.07413000000000002\n",
      "Epoch: 5175, MSE: 0.2614977981542672, Learning Rate: 0.074125\n",
      "Epoch: 5176, MSE: 0.26149543433669753, Learning Rate: 0.07412\n",
      "Epoch: 5177, MSE: 0.261493070468208, Learning Rate: 0.074115\n",
      "Epoch: 5178, MSE: 0.26149070654879747, Learning Rate: 0.07411\n",
      "Epoch: 5179, MSE: 0.2614883425784667, Learning Rate: 0.074105\n",
      "Epoch: 5180, MSE: 0.26148597855721556, Learning Rate: 0.0741\n",
      "Epoch: 5181, MSE: 0.2614836144850428, Learning Rate: 0.07409500000000001\n",
      "Epoch: 5182, MSE: 0.26148125036194925, Learning Rate: 0.07409\n",
      "Epoch: 5183, MSE: 0.26147888618793363, Learning Rate: 0.074085\n",
      "Epoch: 5184, MSE: 0.2614765219629958, Learning Rate: 0.07408000000000001\n",
      "Epoch: 5185, MSE: 0.26147415768713583, Learning Rate: 0.074075\n",
      "Epoch: 5186, MSE: 0.2614717933603526, Learning Rate: 0.07407000000000001\n",
      "Epoch: 5187, MSE: 0.2614694289826473, Learning Rate: 0.074065\n",
      "Epoch: 5188, MSE: 0.26146706455401764, Learning Rate: 0.07406\n",
      "Epoch: 5189, MSE: 0.26146470007446493, Learning Rate: 0.07405500000000001\n",
      "Epoch: 5190, MSE: 0.2614623355439884, Learning Rate: 0.07404999999999999\n",
      "Epoch: 5191, MSE: 0.2614599709625872, Learning Rate: 0.07404500000000001\n",
      "Epoch: 5192, MSE: 0.26145760633026177, Learning Rate: 0.07404\n",
      "Epoch: 5193, MSE: 0.26145524164701095, Learning Rate: 0.074035\n",
      "Epoch: 5194, MSE: 0.26145287691283514, Learning Rate: 0.07403\n",
      "Epoch: 5195, MSE: 0.261450512127734, Learning Rate: 0.07402500000000001\n",
      "Epoch: 5196, MSE: 0.2614481472917068, Learning Rate: 0.07402\n",
      "Epoch: 5197, MSE: 0.2614457824047535, Learning Rate: 0.074015\n",
      "Epoch: 5198, MSE: 0.2614434174668735, Learning Rate: 0.07401\n",
      "Epoch: 5199, MSE: 0.2614410524780672, Learning Rate: 0.074005\n",
      "Epoch: 5200, MSE: 0.2614386874383335, Learning Rate: 0.074\n",
      "Epoch: 5201, MSE: 0.26143632234767206, Learning Rate: 0.073995\n",
      "Epoch: 5202, MSE: 0.2614339572060831, Learning Rate: 0.07399\n",
      "Epoch: 5203, MSE: 0.26143159201356636, Learning Rate: 0.07398500000000001\n",
      "Epoch: 5204, MSE: 0.26142922677012076, Learning Rate: 0.07398\n",
      "Epoch: 5205, MSE: 0.26142686147574695, Learning Rate: 0.073975\n",
      "Epoch: 5206, MSE: 0.26142449613044433, Learning Rate: 0.07397000000000001\n",
      "Epoch: 5207, MSE: 0.26142213073421183, Learning Rate: 0.07396499999999999\n",
      "Epoch: 5208, MSE: 0.2614197652870499, Learning Rate: 0.07396000000000001\n",
      "Epoch: 5209, MSE: 0.2614173997889579, Learning Rate: 0.07395499999999999\n",
      "Epoch: 5210, MSE: 0.2614150342399355, Learning Rate: 0.07395\n",
      "Epoch: 5211, MSE: 0.2614126686399829, Learning Rate: 0.073945\n",
      "Epoch: 5212, MSE: 0.26141030298909923, Learning Rate: 0.07394\n",
      "Epoch: 5213, MSE: 0.26140793728728495, Learning Rate: 0.073935\n",
      "Epoch: 5214, MSE: 0.2614055715345385, Learning Rate: 0.07393000000000001\n",
      "Epoch: 5215, MSE: 0.26140320573086057, Learning Rate: 0.073925\n",
      "Epoch: 5216, MSE: 0.26140083987625096, Learning Rate: 0.07392000000000001\n",
      "Epoch: 5217, MSE: 0.26139847397070815, Learning Rate: 0.073915\n",
      "Epoch: 5218, MSE: 0.2613961080142333, Learning Rate: 0.07391\n",
      "Epoch: 5219, MSE: 0.2613937420068251, Learning Rate: 0.073905\n",
      "Epoch: 5220, MSE: 0.2613913759484838, Learning Rate: 0.07390000000000001\n",
      "Epoch: 5221, MSE: 0.2613890098392077, Learning Rate: 0.073895\n",
      "Epoch: 5222, MSE: 0.2613866436789993, Learning Rate: 0.07389\n",
      "Epoch: 5223, MSE: 0.2613842774678558, Learning Rate: 0.073885\n",
      "Epoch: 5224, MSE: 0.2613819112057779, Learning Rate: 0.07388\n",
      "Epoch: 5225, MSE: 0.26137954489276477, Learning Rate: 0.07387500000000001\n",
      "Epoch: 5226, MSE: 0.2613771785288168, Learning Rate: 0.07387\n",
      "Epoch: 5227, MSE: 0.2613748121139339, Learning Rate: 0.073865\n",
      "Epoch: 5228, MSE: 0.2613724456481143, Learning Rate: 0.07386\n",
      "Epoch: 5229, MSE: 0.2613700791313589, Learning Rate: 0.073855\n",
      "Epoch: 5230, MSE: 0.2613677125636671, Learning Rate: 0.07385\n",
      "Epoch: 5231, MSE: 0.26136534594503835, Learning Rate: 0.07384500000000001\n",
      "Epoch: 5232, MSE: 0.2613629792754728, Learning Rate: 0.07384\n",
      "Epoch: 5233, MSE: 0.26136061255497006, Learning Rate: 0.07383500000000001\n",
      "Epoch: 5234, MSE: 0.2613582457835296, Learning Rate: 0.07382999999999999\n",
      "Epoch: 5235, MSE: 0.2613558789611515, Learning Rate: 0.07382500000000002\n",
      "Epoch: 5236, MSE: 0.26135351208783547, Learning Rate: 0.07382\n",
      "Epoch: 5237, MSE: 0.2613511451635798, Learning Rate: 0.073815\n",
      "Epoch: 5238, MSE: 0.26134877818838637, Learning Rate: 0.07381\n",
      "Epoch: 5239, MSE: 0.2613464111622531, Learning Rate: 0.073805\n",
      "Epoch: 5240, MSE: 0.2613440440851801, Learning Rate: 0.0738\n",
      "Epoch: 5241, MSE: 0.2613416769571686, Learning Rate: 0.073795\n",
      "Epoch: 5242, MSE: 0.2613393097782154, Learning Rate: 0.07379000000000001\n",
      "Epoch: 5243, MSE: 0.2613369425483232, Learning Rate: 0.073785\n",
      "Epoch: 5244, MSE: 0.26133457526748943, Learning Rate: 0.07378\n",
      "Epoch: 5245, MSE: 0.26133220793571554, Learning Rate: 0.07377500000000001\n",
      "Epoch: 5246, MSE: 0.261329840553, Learning Rate: 0.07377\n",
      "Epoch: 5247, MSE: 0.2613274731193435, Learning Rate: 0.073765\n",
      "Epoch: 5248, MSE: 0.26132510563474465, Learning Rate: 0.07376\n",
      "Epoch: 5249, MSE: 0.26132273809920337, Learning Rate: 0.073755\n",
      "Epoch: 5250, MSE: 0.26132037051271967, Learning Rate: 0.07375000000000001\n",
      "Epoch: 5251, MSE: 0.2613180028752933, Learning Rate: 0.07374499999999999\n",
      "Epoch: 5252, MSE: 0.2613156351869244, Learning Rate: 0.07374000000000001\n",
      "Epoch: 5253, MSE: 0.2613132674476117, Learning Rate: 0.073735\n",
      "Epoch: 5254, MSE: 0.261310899657355, Learning Rate: 0.07373\n",
      "Epoch: 5255, MSE: 0.261308531816155, Learning Rate: 0.073725\n",
      "Epoch: 5256, MSE: 0.26130616392401035, Learning Rate: 0.07372000000000001\n",
      "Epoch: 5257, MSE: 0.26130379598092074, Learning Rate: 0.073715\n",
      "Epoch: 5258, MSE: 0.2613014279868874, Learning Rate: 0.07371\n",
      "Epoch: 5259, MSE: 0.26129905994190833, Learning Rate: 0.073705\n",
      "Epoch: 5260, MSE: 0.2612966918459836, Learning Rate: 0.0737\n",
      "Epoch: 5261, MSE: 0.261294323699114, Learning Rate: 0.073695\n",
      "Epoch: 5262, MSE: 0.2612919555012972, Learning Rate: 0.07369\n",
      "Epoch: 5263, MSE: 0.2612895872525344, Learning Rate: 0.073685\n",
      "Epoch: 5264, MSE: 0.2612872189528257, Learning Rate: 0.07368000000000001\n",
      "Epoch: 5265, MSE: 0.2612848506021695, Learning Rate: 0.073675\n",
      "Epoch: 5266, MSE: 0.2612824822005661, Learning Rate: 0.07367\n",
      "Epoch: 5267, MSE: 0.26128011374801646, Learning Rate: 0.07366500000000001\n",
      "Epoch: 5268, MSE: 0.2612777452445171, Learning Rate: 0.07365999999999999\n",
      "Epoch: 5269, MSE: 0.2612753766900703, Learning Rate: 0.07365500000000001\n",
      "Epoch: 5270, MSE: 0.26127300808467463, Learning Rate: 0.07365\n",
      "Epoch: 5271, MSE: 0.2612706394283312, Learning Rate: 0.073645\n",
      "Epoch: 5272, MSE: 0.26126827072103814, Learning Rate: 0.07364\n",
      "Epoch: 5273, MSE: 0.2612659019627966, Learning Rate: 0.073635\n",
      "Epoch: 5274, MSE: 0.261263533153605, Learning Rate: 0.07363\n",
      "Epoch: 5275, MSE: 0.2612611642934633, Learning Rate: 0.07362500000000001\n",
      "Epoch: 5276, MSE: 0.26125879538237146, Learning Rate: 0.07362\n",
      "Epoch: 5277, MSE: 0.2612564264203294, Learning Rate: 0.07361500000000001\n",
      "Epoch: 5278, MSE: 0.26125405740733676, Learning Rate: 0.07361\n",
      "Epoch: 5279, MSE: 0.26125168834339246, Learning Rate: 0.073605\n",
      "Epoch: 5280, MSE: 0.2612493192284966, Learning Rate: 0.0736\n",
      "Epoch: 5281, MSE: 0.26124695006265, Learning Rate: 0.07359500000000001\n",
      "Epoch: 5282, MSE: 0.26124458084585106, Learning Rate: 0.07359\n",
      "Epoch: 5283, MSE: 0.2612422115781008, Learning Rate: 0.073585\n",
      "Epoch: 5284, MSE: 0.2612398422593975, Learning Rate: 0.07358\n",
      "Epoch: 5285, MSE: 0.2612374728897409, Learning Rate: 0.073575\n",
      "Epoch: 5286, MSE: 0.2612351034691315, Learning Rate: 0.07357000000000001\n",
      "Epoch: 5287, MSE: 0.2612327339975694, Learning Rate: 0.073565\n",
      "Epoch: 5288, MSE: 0.2612303644750525, Learning Rate: 0.07356\n",
      "Epoch: 5289, MSE: 0.26122799490158244, Learning Rate: 0.073555\n",
      "Epoch: 5290, MSE: 0.2612256252771582, Learning Rate: 0.07355\n",
      "Epoch: 5291, MSE: 0.26122325560177934, Learning Rate: 0.073545\n",
      "Epoch: 5292, MSE: 0.26122088587544584, Learning Rate: 0.07354000000000001\n",
      "Epoch: 5293, MSE: 0.26121851609815633, Learning Rate: 0.073535\n",
      "Epoch: 5294, MSE: 0.2612161462699123, Learning Rate: 0.07353000000000001\n",
      "Epoch: 5295, MSE: 0.26121377639071225, Learning Rate: 0.073525\n",
      "Epoch: 5296, MSE: 0.2612114064605566, Learning Rate: 0.07352000000000002\n",
      "Epoch: 5297, MSE: 0.2612090364794439, Learning Rate: 0.073515\n",
      "Epoch: 5298, MSE: 0.2612066664473755, Learning Rate: 0.07351\n",
      "Epoch: 5299, MSE: 0.2612042963643507, Learning Rate: 0.073505\n",
      "Epoch: 5300, MSE: 0.26120192623036814, Learning Rate: 0.0735\n",
      "Epoch: 5301, MSE: 0.2611995560454274, Learning Rate: 0.073495\n",
      "Epoch: 5302, MSE: 0.26119718580953083, Learning Rate: 0.07349\n",
      "Epoch: 5303, MSE: 0.2611948155226748, Learning Rate: 0.07348500000000001\n",
      "Epoch: 5304, MSE: 0.2611924451848611, Learning Rate: 0.07348\n",
      "Epoch: 5305, MSE: 0.2611900747960885, Learning Rate: 0.073475\n",
      "Epoch: 5306, MSE: 0.2611877043563576, Learning Rate: 0.07347000000000001\n",
      "Epoch: 5307, MSE: 0.26118533386566767, Learning Rate: 0.073465\n",
      "Epoch: 5308, MSE: 0.26118296332401836, Learning Rate: 0.07346\n",
      "Epoch: 5309, MSE: 0.26118059273140853, Learning Rate: 0.073455\n",
      "Epoch: 5310, MSE: 0.26117822208783875, Learning Rate: 0.07345\n",
      "Epoch: 5311, MSE: 0.2611758513933101, Learning Rate: 0.07344500000000001\n",
      "Epoch: 5312, MSE: 0.26117348064782037, Learning Rate: 0.07343999999999999\n",
      "Epoch: 5313, MSE: 0.26117110985136915, Learning Rate: 0.07343500000000001\n",
      "Epoch: 5314, MSE: 0.26116873900395726, Learning Rate: 0.07343\n",
      "Epoch: 5315, MSE: 0.26116636810558397, Learning Rate: 0.073425\n",
      "Epoch: 5316, MSE: 0.26116399715624916, Learning Rate: 0.07342\n",
      "Epoch: 5317, MSE: 0.2611616261559524, Learning Rate: 0.07341500000000001\n",
      "Epoch: 5318, MSE: 0.2611592551046937, Learning Rate: 0.07341\n",
      "Epoch: 5319, MSE: 0.26115688400247294, Learning Rate: 0.073405\n",
      "Epoch: 5320, MSE: 0.2611545128492885, Learning Rate: 0.0734\n",
      "Epoch: 5321, MSE: 0.261152141645141, Learning Rate: 0.073395\n",
      "Epoch: 5322, MSE: 0.2611497703900308, Learning Rate: 0.07339\n",
      "Epoch: 5323, MSE: 0.2611473990839562, Learning Rate: 0.073385\n",
      "Epoch: 5324, MSE: 0.261145027726918, Learning Rate: 0.07338\n",
      "Epoch: 5325, MSE: 0.26114265631891576, Learning Rate: 0.07337500000000001\n",
      "Epoch: 5326, MSE: 0.26114028485994895, Learning Rate: 0.07337\n",
      "Epoch: 5327, MSE: 0.2611379133500187, Learning Rate: 0.073365\n",
      "Epoch: 5328, MSE: 0.26113554178912224, Learning Rate: 0.07336000000000001\n",
      "Epoch: 5329, MSE: 0.26113317017726023, Learning Rate: 0.07335499999999999\n",
      "Epoch: 5330, MSE: 0.2611307985144331, Learning Rate: 0.07335000000000001\n",
      "Epoch: 5331, MSE: 0.2611284268006404, Learning Rate: 0.073345\n",
      "Epoch: 5332, MSE: 0.26112605503588104, Learning Rate: 0.07334\n",
      "Epoch: 5333, MSE: 0.2611236832201558, Learning Rate: 0.073335\n",
      "Epoch: 5334, MSE: 0.2611213113534635, Learning Rate: 0.07333\n",
      "Epoch: 5335, MSE: 0.2611189394358046, Learning Rate: 0.073325\n",
      "Epoch: 5336, MSE: 0.2611165674671778, Learning Rate: 0.07332000000000001\n",
      "Epoch: 5337, MSE: 0.2611141954475845, Learning Rate: 0.073315\n",
      "Epoch: 5338, MSE: 0.2611118233770226, Learning Rate: 0.07331\n",
      "Epoch: 5339, MSE: 0.2611094512554931, Learning Rate: 0.073305\n",
      "Epoch: 5340, MSE: 0.26110707908299496, Learning Rate: 0.0733\n",
      "Epoch: 5341, MSE: 0.2611047068595291, Learning Rate: 0.073295\n",
      "Epoch: 5342, MSE: 0.2611023345850935, Learning Rate: 0.07329000000000001\n",
      "Epoch: 5343, MSE: 0.2610999622596888, Learning Rate: 0.073285\n",
      "Epoch: 5344, MSE: 0.2610975898833155, Learning Rate: 0.07328\n",
      "Epoch: 5345, MSE: 0.26109521745597136, Learning Rate: 0.073275\n",
      "Epoch: 5346, MSE: 0.2610928449776586, Learning Rate: 0.07327\n",
      "Epoch: 5347, MSE: 0.2610904724483742, Learning Rate: 0.07326500000000001\n",
      "Epoch: 5348, MSE: 0.26108809986812004, Learning Rate: 0.07325999999999999\n",
      "Epoch: 5349, MSE: 0.261085727236895, Learning Rate: 0.073255\n",
      "Epoch: 5350, MSE: 0.26108335455469933, Learning Rate: 0.07325\n",
      "Epoch: 5351, MSE: 0.26108098182153155, Learning Rate: 0.073245\n",
      "Epoch: 5352, MSE: 0.2610786090373924, Learning Rate: 0.07324\n",
      "Epoch: 5353, MSE: 0.261076236202282, Learning Rate: 0.07323500000000001\n",
      "Epoch: 5354, MSE: 0.2610738633161991, Learning Rate: 0.07323\n",
      "Epoch: 5355, MSE: 0.26107149037914373, Learning Rate: 0.07322500000000001\n",
      "Epoch: 5356, MSE: 0.2610691173911158, Learning Rate: 0.07322\n",
      "Epoch: 5357, MSE: 0.2610667443521147, Learning Rate: 0.07321500000000002\n",
      "Epoch: 5358, MSE: 0.26106437126214027, Learning Rate: 0.07321\n",
      "Epoch: 5359, MSE: 0.26106199812119246, Learning Rate: 0.073205\n",
      "Epoch: 5360, MSE: 0.26105962492927137, Learning Rate: 0.0732\n",
      "Epoch: 5361, MSE: 0.26105725168637567, Learning Rate: 0.073195\n",
      "Epoch: 5362, MSE: 0.2610548783925059, Learning Rate: 0.07319\n",
      "Epoch: 5363, MSE: 0.2610525050476622, Learning Rate: 0.073185\n",
      "Epoch: 5364, MSE: 0.26105013165184277, Learning Rate: 0.07318000000000001\n",
      "Epoch: 5365, MSE: 0.261047758205049, Learning Rate: 0.073175\n",
      "Epoch: 5366, MSE: 0.26104538470727867, Learning Rate: 0.07317\n",
      "Epoch: 5367, MSE: 0.2610430111585338, Learning Rate: 0.07316500000000001\n",
      "Epoch: 5368, MSE: 0.2610406375588125, Learning Rate: 0.07316\n",
      "Epoch: 5369, MSE: 0.26103826390811513, Learning Rate: 0.073155\n",
      "Epoch: 5370, MSE: 0.26103589020644175, Learning Rate: 0.07315\n",
      "Epoch: 5371, MSE: 0.26103351645379164, Learning Rate: 0.073145\n",
      "Epoch: 5372, MSE: 0.2610311426501644, Learning Rate: 0.07314000000000001\n",
      "Epoch: 5373, MSE: 0.26102876879555975, Learning Rate: 0.07313499999999999\n",
      "Epoch: 5374, MSE: 0.26102639488997775, Learning Rate: 0.07313000000000001\n",
      "Epoch: 5375, MSE: 0.2610240209334177, Learning Rate: 0.073125\n",
      "Epoch: 5376, MSE: 0.2610216469258802, Learning Rate: 0.07312\n",
      "Epoch: 5377, MSE: 0.2610192728673634, Learning Rate: 0.073115\n",
      "Epoch: 5378, MSE: 0.2610168987578696, Learning Rate: 0.07311000000000001\n",
      "Epoch: 5379, MSE: 0.26101452459739577, Learning Rate: 0.073105\n",
      "Epoch: 5380, MSE: 0.2610121503859431, Learning Rate: 0.0731\n",
      "Epoch: 5381, MSE: 0.2610097761235118, Learning Rate: 0.07309500000000001\n",
      "Epoch: 5382, MSE: 0.26100740181009957, Learning Rate: 0.07309\n",
      "Epoch: 5383, MSE: 0.2610050274457089, Learning Rate: 0.073085\n",
      "Epoch: 5384, MSE: 0.2610026530303371, Learning Rate: 0.07308\n",
      "Epoch: 5385, MSE: 0.2610002785639859, Learning Rate: 0.073075\n",
      "Epoch: 5386, MSE: 0.26099790404665335, Learning Rate: 0.07307000000000001\n",
      "Epoch: 5387, MSE: 0.2609955294783399, Learning Rate: 0.073065\n",
      "Epoch: 5388, MSE: 0.26099315485904506, Learning Rate: 0.07306\n",
      "Epoch: 5389, MSE: 0.2609907801887692, Learning Rate: 0.07305500000000001\n",
      "Epoch: 5390, MSE: 0.26098840546751184, Learning Rate: 0.07304999999999999\n",
      "Epoch: 5391, MSE: 0.2609860306952718, Learning Rate: 0.07304500000000001\n",
      "Epoch: 5392, MSE: 0.2609836558720499, Learning Rate: 0.07304\n",
      "Epoch: 5393, MSE: 0.2609812809978455, Learning Rate: 0.073035\n",
      "Epoch: 5394, MSE: 0.26097890607265867, Learning Rate: 0.07303\n",
      "Epoch: 5395, MSE: 0.26097653109648883, Learning Rate: 0.073025\n",
      "Epoch: 5396, MSE: 0.2609741560693355, Learning Rate: 0.07302\n",
      "Epoch: 5397, MSE: 0.2609717809911989, Learning Rate: 0.07301500000000001\n",
      "Epoch: 5398, MSE: 0.2609694058620778, Learning Rate: 0.07301\n",
      "Epoch: 5399, MSE: 0.2609670306819733, Learning Rate: 0.073005\n",
      "Epoch: 5400, MSE: 0.2609646554508846, Learning Rate: 0.073\n",
      "Epoch: 5401, MSE: 0.2609622801688115, Learning Rate: 0.072995\n",
      "Epoch: 5402, MSE: 0.26095990483575293, Learning Rate: 0.07299\n",
      "Epoch: 5403, MSE: 0.2609575294517097, Learning Rate: 0.07298500000000001\n",
      "Epoch: 5404, MSE: 0.26095515401668146, Learning Rate: 0.07298\n",
      "Epoch: 5405, MSE: 0.26095277853066695, Learning Rate: 0.072975\n",
      "Epoch: 5406, MSE: 0.26095040299366695, Learning Rate: 0.07297000000000001\n",
      "Epoch: 5407, MSE: 0.2609480274056812, Learning Rate: 0.072965\n",
      "Epoch: 5408, MSE: 0.2609456517667086, Learning Rate: 0.07296000000000001\n",
      "Epoch: 5409, MSE: 0.26094327607674994, Learning Rate: 0.07295499999999999\n",
      "Epoch: 5410, MSE: 0.2609409003358033, Learning Rate: 0.07295\n",
      "Epoch: 5411, MSE: 0.2609385245438706, Learning Rate: 0.072945\n",
      "Epoch: 5412, MSE: 0.26093614870095017, Learning Rate: 0.07294\n",
      "Epoch: 5413, MSE: 0.2609337728070429, Learning Rate: 0.072935\n",
      "Epoch: 5414, MSE: 0.26093139686214667, Learning Rate: 0.07293000000000001\n",
      "Epoch: 5415, MSE: 0.26092902086626335, Learning Rate: 0.072925\n",
      "Epoch: 5416, MSE: 0.26092664481939065, Learning Rate: 0.07292000000000001\n",
      "Epoch: 5417, MSE: 0.26092426872152924, Learning Rate: 0.072915\n",
      "Epoch: 5418, MSE: 0.2609218925726806, Learning Rate: 0.07291000000000002\n",
      "Epoch: 5419, MSE: 0.2609195163728414, Learning Rate: 0.072905\n",
      "Epoch: 5420, MSE: 0.26091714012201334, Learning Rate: 0.0729\n",
      "Epoch: 5421, MSE: 0.26091476382019463, Learning Rate: 0.072895\n",
      "Epoch: 5422, MSE: 0.2609123874673872, Learning Rate: 0.07289\n",
      "Epoch: 5423, MSE: 0.2609100110635894, Learning Rate: 0.072885\n",
      "Epoch: 5424, MSE: 0.26090763460880095, Learning Rate: 0.07288\n",
      "Epoch: 5425, MSE: 0.26090525810302234, Learning Rate: 0.07287500000000001\n",
      "Epoch: 5426, MSE: 0.2609028815462527, Learning Rate: 0.07287\n",
      "Epoch: 5427, MSE: 0.2609005049384914, Learning Rate: 0.072865\n",
      "Epoch: 5428, MSE: 0.26089812827973896, Learning Rate: 0.07286000000000001\n",
      "Epoch: 5429, MSE: 0.2608957515699953, Learning Rate: 0.072855\n",
      "Epoch: 5430, MSE: 0.26089337480925945, Learning Rate: 0.07285\n",
      "Epoch: 5431, MSE: 0.2608909979975316, Learning Rate: 0.07284500000000001\n",
      "Epoch: 5432, MSE: 0.26088862113481115, Learning Rate: 0.07284\n",
      "Epoch: 5433, MSE: 0.26088624422109785, Learning Rate: 0.07283500000000001\n",
      "Epoch: 5434, MSE: 0.260883867256392, Learning Rate: 0.07282999999999999\n",
      "Epoch: 5435, MSE: 0.26088149024069274, Learning Rate: 0.07282500000000001\n",
      "Epoch: 5436, MSE: 0.2608791131740009, Learning Rate: 0.07282\n",
      "Epoch: 5437, MSE: 0.26087673605631484, Learning Rate: 0.072815\n",
      "Epoch: 5438, MSE: 0.2608743588876353, Learning Rate: 0.07281\n",
      "Epoch: 5439, MSE: 0.26087198166796166, Learning Rate: 0.072805\n",
      "Epoch: 5440, MSE: 0.2608696043972922, Learning Rate: 0.0728\n",
      "Epoch: 5441, MSE: 0.26086722707562937, Learning Rate: 0.072795\n",
      "Epoch: 5442, MSE: 0.26086484970297236, Learning Rate: 0.07279000000000001\n",
      "Epoch: 5443, MSE: 0.260862472279319, Learning Rate: 0.072785\n",
      "Epoch: 5444, MSE: 0.2608600948046713, Learning Rate: 0.07278\n",
      "Epoch: 5445, MSE: 0.2608577172790274, Learning Rate: 0.072775\n",
      "Epoch: 5446, MSE: 0.2608553397023878, Learning Rate: 0.07277\n",
      "Epoch: 5447, MSE: 0.26085296207475184, Learning Rate: 0.07276500000000001\n",
      "Epoch: 5448, MSE: 0.26085058439611986, Learning Rate: 0.07276\n",
      "Epoch: 5449, MSE: 0.26084820666649144, Learning Rate: 0.072755\n",
      "Epoch: 5450, MSE: 0.26084582888586566, Learning Rate: 0.07275000000000001\n",
      "Epoch: 5451, MSE: 0.2608434510542436, Learning Rate: 0.07274499999999999\n",
      "Epoch: 5452, MSE: 0.2608410731716236, Learning Rate: 0.07274000000000001\n",
      "Epoch: 5453, MSE: 0.2608386952380065, Learning Rate: 0.072735\n",
      "Epoch: 5454, MSE: 0.2608363172533916, Learning Rate: 0.07273\n",
      "Epoch: 5455, MSE: 0.2608339392177781, Learning Rate: 0.072725\n",
      "Epoch: 5456, MSE: 0.2608315611311669, Learning Rate: 0.07272\n",
      "Epoch: 5457, MSE: 0.2608291829935572, Learning Rate: 0.072715\n",
      "Epoch: 5458, MSE: 0.26082680480494885, Learning Rate: 0.07271000000000001\n",
      "Epoch: 5459, MSE: 0.2608244265653412, Learning Rate: 0.072705\n",
      "Epoch: 5460, MSE: 0.26082204827473415, Learning Rate: 0.0727\n",
      "Epoch: 5461, MSE: 0.2608196699331279, Learning Rate: 0.072695\n",
      "Epoch: 5462, MSE: 0.2608172915405221, Learning Rate: 0.07269\n",
      "Epoch: 5463, MSE: 0.2608149130969164, Learning Rate: 0.072685\n",
      "Epoch: 5464, MSE: 0.2608125346023104, Learning Rate: 0.07268000000000001\n",
      "Epoch: 5465, MSE: 0.26081015605670355, Learning Rate: 0.072675\n",
      "Epoch: 5466, MSE: 0.26080777746009703, Learning Rate: 0.07267\n",
      "Epoch: 5467, MSE: 0.2608053988124883, Learning Rate: 0.07266500000000001\n",
      "Epoch: 5468, MSE: 0.26080302011387946, Learning Rate: 0.07266\n",
      "Epoch: 5469, MSE: 0.26080064136426884, Learning Rate: 0.07265500000000001\n",
      "Epoch: 5470, MSE: 0.26079826256365646, Learning Rate: 0.07264999999999999\n",
      "Epoch: 5471, MSE: 0.26079588371204243, Learning Rate: 0.072645\n",
      "Epoch: 5472, MSE: 0.260793504809427, Learning Rate: 0.07264\n",
      "Epoch: 5473, MSE: 0.26079112585580766, Learning Rate: 0.072635\n",
      "Epoch: 5474, MSE: 0.2607887468511873, Learning Rate: 0.07263\n",
      "Epoch: 5475, MSE: 0.2607863677955632, Learning Rate: 0.07262500000000001\n",
      "Epoch: 5476, MSE: 0.2607839886889363, Learning Rate: 0.07262\n",
      "Epoch: 5477, MSE: 0.26078160953130647, Learning Rate: 0.07261500000000001\n",
      "Epoch: 5478, MSE: 0.260779230322673, Learning Rate: 0.07261\n",
      "Epoch: 5479, MSE: 0.26077685106303555, Learning Rate: 0.072605\n",
      "Epoch: 5480, MSE: 0.2607744717523939, Learning Rate: 0.0726\n",
      "Epoch: 5481, MSE: 0.2607720923907491, Learning Rate: 0.072595\n",
      "Epoch: 5482, MSE: 0.26076971297809864, Learning Rate: 0.07259\n",
      "Epoch: 5483, MSE: 0.2607673335144443, Learning Rate: 0.072585\n",
      "Epoch: 5484, MSE: 0.2607649539997842, Learning Rate: 0.07258\n",
      "Epoch: 5485, MSE: 0.26076257443411976, Learning Rate: 0.072575\n",
      "Epoch: 5486, MSE: 0.2607601948174496, Learning Rate: 0.07257000000000001\n",
      "Epoch: 5487, MSE: 0.2607578151497741, Learning Rate: 0.072565\n",
      "Epoch: 5488, MSE: 0.26075543543109286, Learning Rate: 0.07256\n",
      "Epoch: 5489, MSE: 0.26075305566140455, Learning Rate: 0.072555\n",
      "Epoch: 5490, MSE: 0.2607506758407112, Learning Rate: 0.07255\n",
      "Epoch: 5491, MSE: 0.2607482959690108, Learning Rate: 0.072545\n",
      "Epoch: 5492, MSE: 0.2607459160463035, Learning Rate: 0.07254000000000001\n",
      "Epoch: 5493, MSE: 0.2607435360725898, Learning Rate: 0.072535\n",
      "Epoch: 5494, MSE: 0.26074115604786813, Learning Rate: 0.07253000000000001\n",
      "Epoch: 5495, MSE: 0.2607387759721391, Learning Rate: 0.07252499999999999\n",
      "Epoch: 5496, MSE: 0.26073639584540254, Learning Rate: 0.07252000000000002\n",
      "Epoch: 5497, MSE: 0.2607340156676584, Learning Rate: 0.072515\n",
      "Epoch: 5498, MSE: 0.2607316354389056, Learning Rate: 0.07251\n",
      "Epoch: 5499, MSE: 0.2607292551591447, Learning Rate: 0.072505\n",
      "Epoch: 5500, MSE: 0.2607268748283753, Learning Rate: 0.0725\n",
      "Epoch: 5501, MSE: 0.2607244944465966, Learning Rate: 0.072495\n",
      "Epoch: 5502, MSE: 0.2607221140138093, Learning Rate: 0.07249\n",
      "Epoch: 5503, MSE: 0.26071973353001265, Learning Rate: 0.07248500000000001\n",
      "Epoch: 5504, MSE: 0.2607173529952061, Learning Rate: 0.07248\n",
      "Epoch: 5505, MSE: 0.2607149724093904, Learning Rate: 0.072475\n",
      "Epoch: 5506, MSE: 0.2607125917725644, Learning Rate: 0.07247\n",
      "Epoch: 5507, MSE: 0.26071021108472797, Learning Rate: 0.072465\n",
      "Epoch: 5508, MSE: 0.260707830345881, Learning Rate: 0.07246000000000001\n",
      "Epoch: 5509, MSE: 0.26070544955602415, Learning Rate: 0.072455\n",
      "Epoch: 5510, MSE: 0.26070306871515614, Learning Rate: 0.07245\n",
      "Epoch: 5511, MSE: 0.2607006878232769, Learning Rate: 0.07244500000000001\n",
      "Epoch: 5512, MSE: 0.2606983068803862, Learning Rate: 0.07243999999999999\n",
      "Epoch: 5513, MSE: 0.2606959258864841, Learning Rate: 0.07243500000000001\n",
      "Epoch: 5514, MSE: 0.2606935448415702, Learning Rate: 0.07243\n",
      "Epoch: 5515, MSE: 0.2606911637456445, Learning Rate: 0.072425\n",
      "Epoch: 5516, MSE: 0.2606887825987059, Learning Rate: 0.07242\n",
      "Epoch: 5517, MSE: 0.26068640140075594, Learning Rate: 0.07241500000000001\n",
      "Epoch: 5518, MSE: 0.2606840201517926, Learning Rate: 0.07241\n",
      "Epoch: 5519, MSE: 0.2606816388518165, Learning Rate: 0.07240500000000001\n",
      "Epoch: 5520, MSE: 0.26067925750082716, Learning Rate: 0.0724\n",
      "Epoch: 5521, MSE: 0.26067687609882456, Learning Rate: 0.072395\n",
      "Epoch: 5522, MSE: 0.26067449464580783, Learning Rate: 0.07239\n",
      "Epoch: 5523, MSE: 0.26067211314177824, Learning Rate: 0.072385\n",
      "Epoch: 5524, MSE: 0.26066973158673473, Learning Rate: 0.07238\n",
      "Epoch: 5525, MSE: 0.2606673499806758, Learning Rate: 0.07237500000000001\n",
      "Epoch: 5526, MSE: 0.26066496832360414, Learning Rate: 0.07237\n",
      "Epoch: 5527, MSE: 0.2606625866155163, Learning Rate: 0.072365\n",
      "Epoch: 5528, MSE: 0.2606602048564143, Learning Rate: 0.07236000000000001\n",
      "Epoch: 5529, MSE: 0.260657823046297, Learning Rate: 0.072355\n",
      "Epoch: 5530, MSE: 0.26065544118516404, Learning Rate: 0.07235000000000001\n",
      "Epoch: 5531, MSE: 0.2606530592730163, Learning Rate: 0.07234499999999999\n",
      "Epoch: 5532, MSE: 0.2606506773098523, Learning Rate: 0.07234\n",
      "Epoch: 5533, MSE: 0.2606482952956719, Learning Rate: 0.072335\n",
      "Epoch: 5534, MSE: 0.26064591323047615, Learning Rate: 0.07233\n",
      "Epoch: 5535, MSE: 0.26064353111426336, Learning Rate: 0.072325\n",
      "Epoch: 5536, MSE: 0.26064114894703405, Learning Rate: 0.07232000000000001\n",
      "Epoch: 5537, MSE: 0.2606387667287884, Learning Rate: 0.072315\n",
      "Epoch: 5538, MSE: 0.2606363844595248, Learning Rate: 0.07231000000000001\n",
      "Epoch: 5539, MSE: 0.26063400213924465, Learning Rate: 0.072305\n",
      "Epoch: 5540, MSE: 0.26063161976794674, Learning Rate: 0.0723\n",
      "Epoch: 5541, MSE: 0.26062923734563126, Learning Rate: 0.072295\n",
      "Epoch: 5542, MSE: 0.2606268548722975, Learning Rate: 0.07229000000000001\n",
      "Epoch: 5543, MSE: 0.26062447234794545, Learning Rate: 0.072285\n",
      "Epoch: 5544, MSE: 0.2606220897725757, Learning Rate: 0.07228\n",
      "Epoch: 5545, MSE: 0.26061970714618676, Learning Rate: 0.072275\n",
      "Epoch: 5546, MSE: 0.26061732446877933, Learning Rate: 0.07227\n",
      "Epoch: 5547, MSE: 0.26061494174035266, Learning Rate: 0.07226500000000001\n",
      "Epoch: 5548, MSE: 0.2606125589609064, Learning Rate: 0.07226\n",
      "Epoch: 5549, MSE: 0.2606101761304415, Learning Rate: 0.072255\n",
      "Epoch: 5550, MSE: 0.2606077932489556, Learning Rate: 0.07225\n",
      "Epoch: 5551, MSE: 0.26060541031645085, Learning Rate: 0.072245\n",
      "Epoch: 5552, MSE: 0.2606030273329264, Learning Rate: 0.07224\n",
      "Epoch: 5553, MSE: 0.2606006442983812, Learning Rate: 0.07223500000000001\n",
      "Epoch: 5554, MSE: 0.2605982612128151, Learning Rate: 0.07223\n",
      "Epoch: 5555, MSE: 0.2605958780762283, Learning Rate: 0.07222500000000001\n",
      "Epoch: 5556, MSE: 0.2605934948886207, Learning Rate: 0.07221999999999999\n",
      "Epoch: 5557, MSE: 0.26059111164999227, Learning Rate: 0.07221500000000002\n",
      "Epoch: 5558, MSE: 0.2605887283603427, Learning Rate: 0.07221\n",
      "Epoch: 5559, MSE: 0.2605863450196704, Learning Rate: 0.072205\n",
      "Epoch: 5560, MSE: 0.2605839616279775, Learning Rate: 0.0722\n",
      "Epoch: 5561, MSE: 0.2605815781852617, Learning Rate: 0.072195\n",
      "Epoch: 5562, MSE: 0.2605791946915249, Learning Rate: 0.07219\n",
      "Epoch: 5563, MSE: 0.2605768111467648, Learning Rate: 0.072185\n",
      "Epoch: 5564, MSE: 0.2605744275509821, Learning Rate: 0.07218000000000001\n",
      "Epoch: 5565, MSE: 0.26057204390417615, Learning Rate: 0.072175\n",
      "Epoch: 5566, MSE: 0.2605696602063477, Learning Rate: 0.07217\n",
      "Epoch: 5567, MSE: 0.26056727645749617, Learning Rate: 0.072165\n",
      "Epoch: 5568, MSE: 0.2605648926576207, Learning Rate: 0.07216\n",
      "Epoch: 5569, MSE: 0.26056250880672116, Learning Rate: 0.07215500000000001\n",
      "Epoch: 5570, MSE: 0.26056012490479863, Learning Rate: 0.07215\n",
      "Epoch: 5571, MSE: 0.26055774095185175, Learning Rate: 0.072145\n",
      "Epoch: 5572, MSE: 0.2605553569478806, Learning Rate: 0.07214000000000001\n",
      "Epoch: 5573, MSE: 0.260552972892885, Learning Rate: 0.07213499999999999\n",
      "Epoch: 5574, MSE: 0.2605505887868643, Learning Rate: 0.07213000000000001\n",
      "Epoch: 5575, MSE: 0.2605482046298192, Learning Rate: 0.072125\n",
      "Epoch: 5576, MSE: 0.26054582042174834, Learning Rate: 0.07212\n",
      "Epoch: 5577, MSE: 0.26054343616265246, Learning Rate: 0.072115\n",
      "Epoch: 5578, MSE: 0.2605410518525314, Learning Rate: 0.07211000000000001\n",
      "Epoch: 5579, MSE: 0.2605386674913837, Learning Rate: 0.072105\n",
      "Epoch: 5580, MSE: 0.2605362830792108, Learning Rate: 0.0721\n",
      "Epoch: 5581, MSE: 0.2605338986160114, Learning Rate: 0.072095\n",
      "Epoch: 5582, MSE: 0.2605315141017861, Learning Rate: 0.07209\n",
      "Epoch: 5583, MSE: 0.2605291295365335, Learning Rate: 0.072085\n",
      "Epoch: 5584, MSE: 0.26052674492025496, Learning Rate: 0.07208\n",
      "Epoch: 5585, MSE: 0.26052436025294917, Learning Rate: 0.072075\n",
      "Epoch: 5586, MSE: 0.2605219755346156, Learning Rate: 0.07207000000000001\n",
      "Epoch: 5587, MSE: 0.2605195907652551, Learning Rate: 0.072065\n",
      "Epoch: 5588, MSE: 0.260517205944867, Learning Rate: 0.07206\n",
      "Epoch: 5589, MSE: 0.26051482107345114, Learning Rate: 0.07205500000000001\n",
      "Epoch: 5590, MSE: 0.26051243615100783, Learning Rate: 0.07204999999999999\n",
      "Epoch: 5591, MSE: 0.2605100511775351, Learning Rate: 0.07204500000000001\n",
      "Epoch: 5592, MSE: 0.2605076661530349, Learning Rate: 0.07203999999999999\n",
      "Epoch: 5593, MSE: 0.26050528107750587, Learning Rate: 0.072035\n",
      "Epoch: 5594, MSE: 0.2605028959509484, Learning Rate: 0.07203\n",
      "Epoch: 5595, MSE: 0.26050051077336156, Learning Rate: 0.072025\n",
      "Epoch: 5596, MSE: 0.26049812554474533, Learning Rate: 0.07202\n",
      "Epoch: 5597, MSE: 0.26049574026510025, Learning Rate: 0.07201500000000001\n",
      "Epoch: 5598, MSE: 0.26049335493442527, Learning Rate: 0.07201\n",
      "Epoch: 5599, MSE: 0.2604909695527203, Learning Rate: 0.07200500000000001\n",
      "Epoch: 5600, MSE: 0.26048858411998543, Learning Rate: 0.072\n",
      "Epoch: 5601, MSE: 0.2604861986362208, Learning Rate: 0.071995\n",
      "Epoch: 5602, MSE: 0.26048381310142527, Learning Rate: 0.07199\n",
      "Epoch: 5603, MSE: 0.2604814275155996, Learning Rate: 0.07198500000000001\n",
      "Epoch: 5604, MSE: 0.2604790418787427, Learning Rate: 0.07198\n",
      "Epoch: 5605, MSE: 0.26047665619085475, Learning Rate: 0.071975\n",
      "Epoch: 5606, MSE: 0.2604742704519358, Learning Rate: 0.07197\n",
      "Epoch: 5607, MSE: 0.26047188466198595, Learning Rate: 0.071965\n",
      "Epoch: 5608, MSE: 0.2604694988210036, Learning Rate: 0.07196000000000001\n",
      "Epoch: 5609, MSE: 0.2604671129289904, Learning Rate: 0.071955\n",
      "Epoch: 5610, MSE: 0.26046472698594525, Learning Rate: 0.07195\n",
      "Epoch: 5611, MSE: 0.26046234099186644, Learning Rate: 0.071945\n",
      "Epoch: 5612, MSE: 0.260459954946757, Learning Rate: 0.07194\n",
      "Epoch: 5613, MSE: 0.2604575688506142, Learning Rate: 0.071935\n",
      "Epoch: 5614, MSE: 0.26045518270343976, Learning Rate: 0.07193000000000001\n",
      "Epoch: 5615, MSE: 0.2604527965052305, Learning Rate: 0.071925\n",
      "Epoch: 5616, MSE: 0.2604504102559898, Learning Rate: 0.07192000000000001\n",
      "Epoch: 5617, MSE: 0.2604480239557145, Learning Rate: 0.07191499999999999\n",
      "Epoch: 5618, MSE: 0.2604456376044056, Learning Rate: 0.07191000000000002\n",
      "Epoch: 5619, MSE: 0.26044325120206396, Learning Rate: 0.071905\n",
      "Epoch: 5620, MSE: 0.26044086474868844, Learning Rate: 0.0719\n",
      "Epoch: 5621, MSE: 0.2604384782442779, Learning Rate: 0.071895\n",
      "Epoch: 5622, MSE: 0.2604360916888341, Learning Rate: 0.07189\n",
      "Epoch: 5623, MSE: 0.260433705082355, Learning Rate: 0.071885\n",
      "Epoch: 5624, MSE: 0.26043131842484163, Learning Rate: 0.07188\n",
      "Epoch: 5625, MSE: 0.2604289317162927, Learning Rate: 0.07187500000000001\n",
      "Epoch: 5626, MSE: 0.2604265449567098, Learning Rate: 0.07187\n",
      "Epoch: 5627, MSE: 0.2604241581460908, Learning Rate: 0.071865\n",
      "Epoch: 5628, MSE: 0.26042177128443667, Learning Rate: 0.07186000000000001\n",
      "Epoch: 5629, MSE: 0.2604193843717476, Learning Rate: 0.071855\n",
      "Epoch: 5630, MSE: 0.26041699740802204, Learning Rate: 0.07185000000000001\n",
      "Epoch: 5631, MSE: 0.2604146103932599, Learning Rate: 0.071845\n",
      "Epoch: 5632, MSE: 0.26041222332746283, Learning Rate: 0.07184\n",
      "Epoch: 5633, MSE: 0.2604098362106272, Learning Rate: 0.07183500000000001\n",
      "Epoch: 5634, MSE: 0.26040744904275714, Learning Rate: 0.07182999999999999\n",
      "Epoch: 5635, MSE: 0.26040506182384976, Learning Rate: 0.07182500000000001\n",
      "Epoch: 5636, MSE: 0.26040267455390503, Learning Rate: 0.07182\n",
      "Epoch: 5637, MSE: 0.26040028723292313, Learning Rate: 0.071815\n",
      "Epoch: 5638, MSE: 0.26039789986090434, Learning Rate: 0.07181\n",
      "Epoch: 5639, MSE: 0.26039551243784803, Learning Rate: 0.07180500000000001\n",
      "Epoch: 5640, MSE: 0.26039312496375405, Learning Rate: 0.0718\n",
      "Epoch: 5641, MSE: 0.2603907374386215, Learning Rate: 0.071795\n",
      "Epoch: 5642, MSE: 0.26038834986245124, Learning Rate: 0.07179\n",
      "Epoch: 5643, MSE: 0.2603859622352426, Learning Rate: 0.071785\n",
      "Epoch: 5644, MSE: 0.2603835745569956, Learning Rate: 0.07178\n",
      "Epoch: 5645, MSE: 0.26038118682771033, Learning Rate: 0.071775\n",
      "Epoch: 5646, MSE: 0.2603787990473857, Learning Rate: 0.07177\n",
      "Epoch: 5647, MSE: 0.2603764112160225, Learning Rate: 0.07176500000000001\n",
      "Epoch: 5648, MSE: 0.2603740233336198, Learning Rate: 0.07176\n",
      "Epoch: 5649, MSE: 0.2603716354001778, Learning Rate: 0.071755\n",
      "Epoch: 5650, MSE: 0.260369247415696, Learning Rate: 0.07175000000000001\n",
      "Epoch: 5651, MSE: 0.2603668593801746, Learning Rate: 0.07174499999999999\n",
      "Epoch: 5652, MSE: 0.2603644712936133, Learning Rate: 0.07174000000000001\n",
      "Epoch: 5653, MSE: 0.2603620831560124, Learning Rate: 0.071735\n",
      "Epoch: 5654, MSE: 0.26035969496737094, Learning Rate: 0.07173\n",
      "Epoch: 5655, MSE: 0.2603573067276882, Learning Rate: 0.071725\n",
      "Epoch: 5656, MSE: 0.26035491843696573, Learning Rate: 0.07172\n",
      "Epoch: 5657, MSE: 0.260352530095202, Learning Rate: 0.071715\n",
      "Epoch: 5658, MSE: 0.2603501417023971, Learning Rate: 0.07171000000000001\n",
      "Epoch: 5659, MSE: 0.2603477532585515, Learning Rate: 0.071705\n",
      "Epoch: 5660, MSE: 0.26034536476366416, Learning Rate: 0.07170000000000001\n",
      "Epoch: 5661, MSE: 0.26034297621773506, Learning Rate: 0.071695\n",
      "Epoch: 5662, MSE: 0.2603405876207648, Learning Rate: 0.07169\n",
      "Epoch: 5663, MSE: 0.2603381989727521, Learning Rate: 0.071685\n",
      "Epoch: 5664, MSE: 0.2603358102736979, Learning Rate: 0.07168000000000001\n",
      "Epoch: 5665, MSE: 0.2603334215236006, Learning Rate: 0.071675\n",
      "Epoch: 5666, MSE: 0.2603310327224615, Learning Rate: 0.07167\n",
      "Epoch: 5667, MSE: 0.2603286438702793, Learning Rate: 0.071665\n",
      "Epoch: 5668, MSE: 0.26032625496705475, Learning Rate: 0.07166\n",
      "Epoch: 5669, MSE: 0.2603238660127871, Learning Rate: 0.07165500000000001\n",
      "Epoch: 5670, MSE: 0.260321477007476, Learning Rate: 0.07165\n",
      "Epoch: 5671, MSE: 0.2603190879511212, Learning Rate: 0.071645\n",
      "Epoch: 5672, MSE: 0.26031669884372394, Learning Rate: 0.07164\n",
      "Epoch: 5673, MSE: 0.26031430968528213, Learning Rate: 0.071635\n",
      "Epoch: 5674, MSE: 0.2603119204757961, Learning Rate: 0.07163\n",
      "Epoch: 5675, MSE: 0.2603095312152666, Learning Rate: 0.07162500000000001\n",
      "Epoch: 5676, MSE: 0.2603071419036936, Learning Rate: 0.07162\n",
      "Epoch: 5677, MSE: 0.2603047525410745, Learning Rate: 0.07161500000000001\n",
      "Epoch: 5678, MSE: 0.26030236312741184, Learning Rate: 0.07161\n",
      "Epoch: 5679, MSE: 0.26029997366270474, Learning Rate: 0.07160500000000002\n",
      "Epoch: 5680, MSE: 0.2602975841469521, Learning Rate: 0.0716\n",
      "Epoch: 5681, MSE: 0.26029519458015415, Learning Rate: 0.071595\n",
      "Epoch: 5682, MSE: 0.2602928049623115, Learning Rate: 0.07159\n",
      "Epoch: 5683, MSE: 0.2602904152934232, Learning Rate: 0.071585\n",
      "Epoch: 5684, MSE: 0.26028802557348935, Learning Rate: 0.07158\n",
      "Epoch: 5685, MSE: 0.2602856358025092, Learning Rate: 0.071575\n",
      "Epoch: 5686, MSE: 0.2602832459804832, Learning Rate: 0.07157000000000001\n",
      "Epoch: 5687, MSE: 0.26028085610741175, Learning Rate: 0.071565\n",
      "Epoch: 5688, MSE: 0.2602784661832933, Learning Rate: 0.07156\n",
      "Epoch: 5689, MSE: 0.26027607620812765, Learning Rate: 0.07155500000000001\n",
      "Epoch: 5690, MSE: 0.26027368618191704, Learning Rate: 0.07155\n",
      "Epoch: 5691, MSE: 0.26027129610465866, Learning Rate: 0.071545\n",
      "Epoch: 5692, MSE: 0.2602689059763535, Learning Rate: 0.07154\n",
      "Epoch: 5693, MSE: 0.2602665157970004, Learning Rate: 0.071535\n",
      "Epoch: 5694, MSE: 0.2602641255666013, Learning Rate: 0.07153000000000001\n",
      "Epoch: 5695, MSE: 0.260261735285153, Learning Rate: 0.07152499999999999\n",
      "Epoch: 5696, MSE: 0.26025934495265807, Learning Rate: 0.07152000000000001\n",
      "Epoch: 5697, MSE: 0.26025695456911546, Learning Rate: 0.071515\n",
      "Epoch: 5698, MSE: 0.2602545641345242, Learning Rate: 0.07151\n",
      "Epoch: 5699, MSE: 0.2602521736488848, Learning Rate: 0.071505\n",
      "Epoch: 5700, MSE: 0.2602497831121973, Learning Rate: 0.07150000000000001\n",
      "Epoch: 5701, MSE: 0.26024739252446116, Learning Rate: 0.071495\n",
      "Epoch: 5702, MSE: 0.26024500188567656, Learning Rate: 0.07149\n",
      "Epoch: 5703, MSE: 0.260242611195842, Learning Rate: 0.071485\n",
      "Epoch: 5704, MSE: 0.26024022045495926, Learning Rate: 0.07148\n",
      "Epoch: 5705, MSE: 0.26023782966302805, Learning Rate: 0.071475\n",
      "Epoch: 5706, MSE: 0.2602354388200462, Learning Rate: 0.07147\n",
      "Epoch: 5707, MSE: 0.2602330479260156, Learning Rate: 0.071465\n",
      "Epoch: 5708, MSE: 0.2602306569809345, Learning Rate: 0.07146000000000001\n",
      "Epoch: 5709, MSE: 0.2602282659848036, Learning Rate: 0.071455\n",
      "Epoch: 5710, MSE: 0.26022587493762345, Learning Rate: 0.07145\n",
      "Epoch: 5711, MSE: 0.2602234838393925, Learning Rate: 0.07144500000000001\n",
      "Epoch: 5712, MSE: 0.26022109269011123, Learning Rate: 0.07143999999999999\n",
      "Epoch: 5713, MSE: 0.26021870148977944, Learning Rate: 0.07143500000000001\n",
      "Epoch: 5714, MSE: 0.26021631023839764, Learning Rate: 0.07143\n",
      "Epoch: 5715, MSE: 0.26021391893596385, Learning Rate: 0.071425\n",
      "Epoch: 5716, MSE: 0.2602115275824793, Learning Rate: 0.07142\n",
      "Epoch: 5717, MSE: 0.26020913617794394, Learning Rate: 0.071415\n",
      "Epoch: 5718, MSE: 0.26020674472235666, Learning Rate: 0.07141\n",
      "Epoch: 5719, MSE: 0.26020435321571905, Learning Rate: 0.07140500000000001\n",
      "Epoch: 5720, MSE: 0.26020196165802906, Learning Rate: 0.0714\n",
      "Epoch: 5721, MSE: 0.2601995700492865, Learning Rate: 0.071395\n",
      "Epoch: 5722, MSE: 0.2601971783894929, Learning Rate: 0.07139\n",
      "Epoch: 5723, MSE: 0.2601947866786466, Learning Rate: 0.071385\n",
      "Epoch: 5724, MSE: 0.26019239491674856, Learning Rate: 0.07138\n",
      "Epoch: 5725, MSE: 0.2601900031037976, Learning Rate: 0.07137500000000001\n",
      "Epoch: 5726, MSE: 0.2601876112397939, Learning Rate: 0.07137\n",
      "Epoch: 5727, MSE: 0.26018521932473765, Learning Rate: 0.071365\n",
      "Epoch: 5728, MSE: 0.26018282735862786, Learning Rate: 0.07136\n",
      "Epoch: 5729, MSE: 0.2601804353414654, Learning Rate: 0.071355\n",
      "Epoch: 5730, MSE: 0.2601780432732498, Learning Rate: 0.07135000000000001\n",
      "Epoch: 5731, MSE: 0.2601756511539803, Learning Rate: 0.07134499999999999\n",
      "Epoch: 5732, MSE: 0.26017325898365734, Learning Rate: 0.07134\n",
      "Epoch: 5733, MSE: 0.26017086676228096, Learning Rate: 0.071335\n",
      "Epoch: 5734, MSE: 0.2601684744898504, Learning Rate: 0.07133\n",
      "Epoch: 5735, MSE: 0.26016608216636483, Learning Rate: 0.071325\n",
      "Epoch: 5736, MSE: 0.26016368979182664, Learning Rate: 0.07132000000000001\n",
      "Epoch: 5737, MSE: 0.2601612973662333, Learning Rate: 0.071315\n",
      "Epoch: 5738, MSE: 0.26015890488958543, Learning Rate: 0.07131000000000001\n",
      "Epoch: 5739, MSE: 0.2601565123618825, Learning Rate: 0.071305\n",
      "Epoch: 5740, MSE: 0.26015411978312547, Learning Rate: 0.07130000000000002\n",
      "Epoch: 5741, MSE: 0.26015172715331325, Learning Rate: 0.071295\n",
      "Epoch: 5742, MSE: 0.260149334472446, Learning Rate: 0.07129\n",
      "Epoch: 5743, MSE: 0.2601469417405227, Learning Rate: 0.071285\n",
      "Epoch: 5744, MSE: 0.26014454895754396, Learning Rate: 0.07128\n",
      "Epoch: 5745, MSE: 0.2601421561235096, Learning Rate: 0.071275\n",
      "Epoch: 5746, MSE: 0.26013976323841975, Learning Rate: 0.07127\n",
      "Epoch: 5747, MSE: 0.26013737030227335, Learning Rate: 0.07126500000000001\n",
      "Epoch: 5748, MSE: 0.26013497731507157, Learning Rate: 0.07126\n",
      "Epoch: 5749, MSE: 0.2601325842768128, Learning Rate: 0.071255\n",
      "Epoch: 5750, MSE: 0.26013019118749836, Learning Rate: 0.07125000000000001\n",
      "Epoch: 5751, MSE: 0.2601277980471272, Learning Rate: 0.071245\n",
      "Epoch: 5752, MSE: 0.2601254048556991, Learning Rate: 0.07124\n",
      "Epoch: 5753, MSE: 0.260123011613214, Learning Rate: 0.071235\n",
      "Epoch: 5754, MSE: 0.26012061831967215, Learning Rate: 0.07123\n",
      "Epoch: 5755, MSE: 0.26011822497507314, Learning Rate: 0.07122500000000001\n",
      "Epoch: 5756, MSE: 0.2601158315794169, Learning Rate: 0.07121999999999999\n",
      "Epoch: 5757, MSE: 0.26011343813270305, Learning Rate: 0.07121500000000001\n",
      "Epoch: 5758, MSE: 0.26011104463493145, Learning Rate: 0.07121\n",
      "Epoch: 5759, MSE: 0.26010865108610204, Learning Rate: 0.071205\n",
      "Epoch: 5760, MSE: 0.2601062574862145, Learning Rate: 0.0712\n",
      "Epoch: 5761, MSE: 0.26010386383526884, Learning Rate: 0.07119500000000001\n",
      "Epoch: 5762, MSE: 0.2601014701332658, Learning Rate: 0.07119\n",
      "Epoch: 5763, MSE: 0.2600990763802035, Learning Rate: 0.071185\n",
      "Epoch: 5764, MSE: 0.26009668257608354, Learning Rate: 0.07118000000000001\n",
      "Epoch: 5765, MSE: 0.2600942887209043, Learning Rate: 0.071175\n",
      "Epoch: 5766, MSE: 0.2600918948146657, Learning Rate: 0.07117\n",
      "Epoch: 5767, MSE: 0.2600895008573693, Learning Rate: 0.071165\n",
      "Epoch: 5768, MSE: 0.2600871068490128, Learning Rate: 0.07116\n",
      "Epoch: 5769, MSE: 0.26008471278959766, Learning Rate: 0.07115500000000001\n",
      "Epoch: 5770, MSE: 0.26008231867912274, Learning Rate: 0.07115\n",
      "Epoch: 5771, MSE: 0.2600799245175888, Learning Rate: 0.071145\n",
      "Epoch: 5772, MSE: 0.2600775303049948, Learning Rate: 0.07114000000000001\n",
      "Epoch: 5773, MSE: 0.26007513604134086, Learning Rate: 0.07113499999999999\n",
      "Epoch: 5774, MSE: 0.26007274172662664, Learning Rate: 0.07113000000000001\n",
      "Epoch: 5775, MSE: 0.26007034736085216, Learning Rate: 0.071125\n",
      "Epoch: 5776, MSE: 0.2600679529440176, Learning Rate: 0.07112\n",
      "Epoch: 5777, MSE: 0.2600655584761233, Learning Rate: 0.071115\n",
      "Epoch: 5778, MSE: 0.2600631639571679, Learning Rate: 0.07111\n",
      "Epoch: 5779, MSE: 0.2600607693871515, Learning Rate: 0.071105\n",
      "Epoch: 5780, MSE: 0.26005837476607446, Learning Rate: 0.07110000000000001\n",
      "Epoch: 5781, MSE: 0.2600559800939362, Learning Rate: 0.071095\n",
      "Epoch: 5782, MSE: 0.2600535853707373, Learning Rate: 0.07109\n",
      "Epoch: 5783, MSE: 0.2600511905964774, Learning Rate: 0.071085\n",
      "Epoch: 5784, MSE: 0.26004879577115475, Learning Rate: 0.07108\n",
      "Epoch: 5785, MSE: 0.26004640089477166, Learning Rate: 0.071075\n",
      "Epoch: 5786, MSE: 0.26004400596732613, Learning Rate: 0.07107000000000001\n",
      "Epoch: 5787, MSE: 0.2600416109888198, Learning Rate: 0.071065\n",
      "Epoch: 5788, MSE: 0.2600392159592498, Learning Rate: 0.07106\n",
      "Epoch: 5789, MSE: 0.26003682087861896, Learning Rate: 0.07105500000000001\n",
      "Epoch: 5790, MSE: 0.26003442574692526, Learning Rate: 0.07105\n",
      "Epoch: 5791, MSE: 0.2600320305641693, Learning Rate: 0.07104500000000001\n",
      "Epoch: 5792, MSE: 0.26002963533035073, Learning Rate: 0.07103999999999999\n",
      "Epoch: 5793, MSE: 0.2600272400454691, Learning Rate: 0.071035\n",
      "Epoch: 5794, MSE: 0.2600248447095253, Learning Rate: 0.07103\n",
      "Epoch: 5795, MSE: 0.26002244932251856, Learning Rate: 0.071025\n",
      "Epoch: 5796, MSE: 0.26002005388444793, Learning Rate: 0.07102\n",
      "Epoch: 5797, MSE: 0.26001765839531443, Learning Rate: 0.07101500000000001\n",
      "Epoch: 5798, MSE: 0.26001526285511756, Learning Rate: 0.07101\n",
      "Epoch: 5799, MSE: 0.26001286726385686, Learning Rate: 0.07100500000000001\n",
      "Epoch: 5800, MSE: 0.2600104716215329, Learning Rate: 0.071\n",
      "Epoch: 5801, MSE: 0.260008075928145, Learning Rate: 0.07099500000000002\n",
      "Epoch: 5802, MSE: 0.2600056801836933, Learning Rate: 0.07099\n",
      "Epoch: 5803, MSE: 0.2600032843881767, Learning Rate: 0.070985\n",
      "Epoch: 5804, MSE: 0.2600008885415967, Learning Rate: 0.07098\n",
      "Epoch: 5805, MSE: 0.2599984926439516, Learning Rate: 0.070975\n",
      "Epoch: 5806, MSE: 0.25999609669524293, Learning Rate: 0.07097\n",
      "Epoch: 5807, MSE: 0.2599937006954687, Learning Rate: 0.070965\n",
      "Epoch: 5808, MSE: 0.25999130464463077, Learning Rate: 0.07096000000000001\n",
      "Epoch: 5809, MSE: 0.259988908542727, Learning Rate: 0.070955\n",
      "Epoch: 5810, MSE: 0.2599865123897586, Learning Rate: 0.07095\n",
      "Epoch: 5811, MSE: 0.259984116185725, Learning Rate: 0.07094500000000001\n",
      "Epoch: 5812, MSE: 0.259981719930626, Learning Rate: 0.07094\n",
      "Epoch: 5813, MSE: 0.2599793236244615, Learning Rate: 0.070935\n",
      "Epoch: 5814, MSE: 0.2599769272672317, Learning Rate: 0.07093\n",
      "Epoch: 5815, MSE: 0.25997453085893546, Learning Rate: 0.070925\n",
      "Epoch: 5816, MSE: 0.25997213439957456, Learning Rate: 0.07092000000000001\n",
      "Epoch: 5817, MSE: 0.25996973788914635, Learning Rate: 0.07091499999999999\n",
      "Epoch: 5818, MSE: 0.259967341327653, Learning Rate: 0.07091000000000001\n",
      "Epoch: 5819, MSE: 0.2599649447150934, Learning Rate: 0.070905\n",
      "Epoch: 5820, MSE: 0.259962548051467, Learning Rate: 0.0709\n",
      "Epoch: 5821, MSE: 0.259960151336774, Learning Rate: 0.070895\n",
      "Epoch: 5822, MSE: 0.2599577545710149, Learning Rate: 0.07089\n",
      "Epoch: 5823, MSE: 0.2599553577541881, Learning Rate: 0.070885\n",
      "Epoch: 5824, MSE: 0.25995296088629594, Learning Rate: 0.07088\n",
      "Epoch: 5825, MSE: 0.2599505639673348, Learning Rate: 0.07087500000000001\n",
      "Epoch: 5826, MSE: 0.2599481669973085, Learning Rate: 0.07087\n",
      "Epoch: 5827, MSE: 0.25994576997621416, Learning Rate: 0.070865\n",
      "Epoch: 5828, MSE: 0.25994337290405173, Learning Rate: 0.07086\n",
      "Epoch: 5829, MSE: 0.25994097578082237, Learning Rate: 0.070855\n",
      "Epoch: 5830, MSE: 0.2599385786065255, Learning Rate: 0.07085000000000001\n",
      "Epoch: 5831, MSE: 0.2599361813811604, Learning Rate: 0.070845\n",
      "Epoch: 5832, MSE: 0.259933784104728, Learning Rate: 0.07084\n",
      "Epoch: 5833, MSE: 0.259931386777227, Learning Rate: 0.07083500000000001\n",
      "Epoch: 5834, MSE: 0.2599289893986582, Learning Rate: 0.07082999999999999\n",
      "Epoch: 5835, MSE: 0.25992659196902057, Learning Rate: 0.07082500000000001\n",
      "Epoch: 5836, MSE: 0.2599241944883146, Learning Rate: 0.07082\n",
      "Epoch: 5837, MSE: 0.25992179695654066, Learning Rate: 0.070815\n",
      "Epoch: 5838, MSE: 0.2599193993736975, Learning Rate: 0.07081\n",
      "Epoch: 5839, MSE: 0.2599170017397859, Learning Rate: 0.070805\n",
      "Epoch: 5840, MSE: 0.25991460405480565, Learning Rate: 0.0708\n",
      "Epoch: 5841, MSE: 0.25991220631875556, Learning Rate: 0.07079500000000001\n",
      "Epoch: 5842, MSE: 0.25990980853163664, Learning Rate: 0.07079\n",
      "Epoch: 5843, MSE: 0.25990741069344775, Learning Rate: 0.070785\n",
      "Epoch: 5844, MSE: 0.25990501280419026, Learning Rate: 0.07078\n",
      "Epoch: 5845, MSE: 0.25990261486386346, Learning Rate: 0.070775\n",
      "Epoch: 5846, MSE: 0.259900216872466, Learning Rate: 0.07077\n",
      "Epoch: 5847, MSE: 0.25989781882999935, Learning Rate: 0.07076500000000001\n",
      "Epoch: 5848, MSE: 0.2598954207364626, Learning Rate: 0.07076\n",
      "Epoch: 5849, MSE: 0.2598930225918566, Learning Rate: 0.070755\n",
      "Epoch: 5850, MSE: 0.2598906243961794, Learning Rate: 0.07075000000000001\n",
      "Epoch: 5851, MSE: 0.259888226149433, Learning Rate: 0.070745\n",
      "Epoch: 5852, MSE: 0.2598858278516148, Learning Rate: 0.07074000000000001\n",
      "Epoch: 5853, MSE: 0.259883429502727, Learning Rate: 0.07073499999999999\n",
      "Epoch: 5854, MSE: 0.2598810311027686, Learning Rate: 0.07073\n",
      "Epoch: 5855, MSE: 0.25987863265173955, Learning Rate: 0.070725\n",
      "Epoch: 5856, MSE: 0.25987623414963884, Learning Rate: 0.07072\n",
      "Epoch: 5857, MSE: 0.2598738355964676, Learning Rate: 0.070715\n",
      "Epoch: 5858, MSE: 0.25987143699222476, Learning Rate: 0.07071000000000001\n",
      "Epoch: 5859, MSE: 0.25986903833691094, Learning Rate: 0.070705\n",
      "Epoch: 5860, MSE: 0.2598666396305261, Learning Rate: 0.07070000000000001\n",
      "Epoch: 5861, MSE: 0.25986424087307003, Learning Rate: 0.070695\n",
      "Epoch: 5862, MSE: 0.2598618420645415, Learning Rate: 0.07069\n",
      "Epoch: 5863, MSE: 0.2598594432049416, Learning Rate: 0.070685\n",
      "Epoch: 5864, MSE: 0.2598570442942697, Learning Rate: 0.07068\n",
      "Epoch: 5865, MSE: 0.25985464533252634, Learning Rate: 0.070675\n",
      "Epoch: 5866, MSE: 0.25985224631971104, Learning Rate: 0.07067\n",
      "Epoch: 5867, MSE: 0.259849847255823, Learning Rate: 0.070665\n",
      "Epoch: 5868, MSE: 0.2598474481408627, Learning Rate: 0.07066\n",
      "Epoch: 5869, MSE: 0.2598450489748301, Learning Rate: 0.07065500000000001\n",
      "Epoch: 5870, MSE: 0.2598426497577254, Learning Rate: 0.07065\n",
      "Epoch: 5871, MSE: 0.25984025048954734, Learning Rate: 0.070645\n",
      "Epoch: 5872, MSE: 0.2598378511702969, Learning Rate: 0.07064\n",
      "Epoch: 5873, MSE: 0.25983545179997347, Learning Rate: 0.070635\n",
      "Epoch: 5874, MSE: 0.25983305237857707, Learning Rate: 0.07063\n",
      "Epoch: 5875, MSE: 0.25983065290610763, Learning Rate: 0.07062500000000001\n",
      "Epoch: 5876, MSE: 0.25982825338256504, Learning Rate: 0.07062\n",
      "Epoch: 5877, MSE: 0.25982585380794904, Learning Rate: 0.07061500000000001\n",
      "Epoch: 5878, MSE: 0.25982345418225966, Learning Rate: 0.07060999999999999\n",
      "Epoch: 5879, MSE: 0.25982105450549714, Learning Rate: 0.07060500000000001\n",
      "Epoch: 5880, MSE: 0.2598186547776603, Learning Rate: 0.0706\n",
      "Epoch: 5881, MSE: 0.2598162549987495, Learning Rate: 0.070595\n",
      "Epoch: 5882, MSE: 0.25981385516876565, Learning Rate: 0.07059\n",
      "Epoch: 5883, MSE: 0.25981145528770705, Learning Rate: 0.070585\n",
      "Epoch: 5884, MSE: 0.2598090553555742, Learning Rate: 0.07058\n",
      "Epoch: 5885, MSE: 0.25980665537236824, Learning Rate: 0.070575\n",
      "Epoch: 5886, MSE: 0.2598042553380878, Learning Rate: 0.07057000000000001\n",
      "Epoch: 5887, MSE: 0.2598018552527317, Learning Rate: 0.070565\n",
      "Epoch: 5888, MSE: 0.2597994551163022, Learning Rate: 0.07056\n",
      "Epoch: 5889, MSE: 0.25979705492879773, Learning Rate: 0.070555\n",
      "Epoch: 5890, MSE: 0.2597946546902181, Learning Rate: 0.07055\n",
      "Epoch: 5891, MSE: 0.2597922544005639, Learning Rate: 0.07054500000000001\n",
      "Epoch: 5892, MSE: 0.2597898540598343, Learning Rate: 0.07054\n",
      "Epoch: 5893, MSE: 0.2597874536680295, Learning Rate: 0.070535\n",
      "Epoch: 5894, MSE: 0.2597850532251502, Learning Rate: 0.07053000000000001\n",
      "Epoch: 5895, MSE: 0.2597826527311957, Learning Rate: 0.07052499999999999\n",
      "Epoch: 5896, MSE: 0.25978025218616535, Learning Rate: 0.07052000000000001\n",
      "Epoch: 5897, MSE: 0.25977785159005956, Learning Rate: 0.070515\n",
      "Epoch: 5898, MSE: 0.2597754509428779, Learning Rate: 0.07051\n",
      "Epoch: 5899, MSE: 0.2597730502446214, Learning Rate: 0.070505\n",
      "Epoch: 5900, MSE: 0.25977064949528844, Learning Rate: 0.07050000000000001\n",
      "Epoch: 5901, MSE: 0.259768248694879, Learning Rate: 0.070495\n",
      "Epoch: 5902, MSE: 0.25976584784339435, Learning Rate: 0.07049000000000001\n",
      "Epoch: 5903, MSE: 0.2597634469408331, Learning Rate: 0.070485\n",
      "Epoch: 5904, MSE: 0.2597610459871954, Learning Rate: 0.07048\n",
      "Epoch: 5905, MSE: 0.25975864498248186, Learning Rate: 0.070475\n",
      "Epoch: 5906, MSE: 0.25975624392669155, Learning Rate: 0.07047\n",
      "Epoch: 5907, MSE: 0.25975384281982544, Learning Rate: 0.070465\n",
      "Epoch: 5908, MSE: 0.2597514416618819, Learning Rate: 0.07046000000000001\n",
      "Epoch: 5909, MSE: 0.2597490404528614, Learning Rate: 0.070455\n",
      "Epoch: 5910, MSE: 0.25974663919276414, Learning Rate: 0.07045\n",
      "Epoch: 5911, MSE: 0.25974423788158957, Learning Rate: 0.07044500000000001\n",
      "Epoch: 5912, MSE: 0.259741836519339, Learning Rate: 0.07044\n",
      "Epoch: 5913, MSE: 0.25973943510601055, Learning Rate: 0.07043500000000001\n",
      "Epoch: 5914, MSE: 0.25973703364160483, Learning Rate: 0.07042999999999999\n",
      "Epoch: 5915, MSE: 0.2597346321261215, Learning Rate: 0.070425\n",
      "Epoch: 5916, MSE: 0.259732230559561, Learning Rate: 0.07042\n",
      "Epoch: 5917, MSE: 0.2597298289419232, Learning Rate: 0.070415\n",
      "Epoch: 5918, MSE: 0.2597274272732074, Learning Rate: 0.07041\n",
      "Epoch: 5919, MSE: 0.2597250255534137, Learning Rate: 0.07040500000000001\n",
      "Epoch: 5920, MSE: 0.25972262378254235, Learning Rate: 0.0704\n",
      "Epoch: 5921, MSE: 0.25972022196059236, Learning Rate: 0.07039500000000001\n",
      "Epoch: 5922, MSE: 0.2597178200875657, Learning Rate: 0.07039\n",
      "Epoch: 5923, MSE: 0.2597154181634595, Learning Rate: 0.070385\n",
      "Epoch: 5924, MSE: 0.2597130161882757, Learning Rate: 0.07038\n",
      "Epoch: 5925, MSE: 0.2597106141620131, Learning Rate: 0.07037500000000001\n",
      "Epoch: 5926, MSE: 0.25970821208467243, Learning Rate: 0.07037\n",
      "Epoch: 5927, MSE: 0.2597058099562531, Learning Rate: 0.070365\n",
      "Epoch: 5928, MSE: 0.25970340777675405, Learning Rate: 0.07036\n",
      "Epoch: 5929, MSE: 0.2597010055461778, Learning Rate: 0.070355\n",
      "Epoch: 5930, MSE: 0.25969860326452243, Learning Rate: 0.07035000000000001\n",
      "Epoch: 5931, MSE: 0.25969620093178736, Learning Rate: 0.070345\n",
      "Epoch: 5932, MSE: 0.25969379854797386, Learning Rate: 0.07034\n",
      "Epoch: 5933, MSE: 0.25969139611308073, Learning Rate: 0.070335\n",
      "Epoch: 5934, MSE: 0.2596889936271093, Learning Rate: 0.07033\n",
      "Epoch: 5935, MSE: 0.25968659109005743, Learning Rate: 0.070325\n",
      "Epoch: 5936, MSE: 0.2596841885019266, Learning Rate: 0.07032000000000001\n",
      "Epoch: 5937, MSE: 0.2596817858627163, Learning Rate: 0.070315\n",
      "Epoch: 5938, MSE: 0.2596793831724257, Learning Rate: 0.07031000000000001\n",
      "Epoch: 5939, MSE: 0.25967698043105647, Learning Rate: 0.07030499999999999\n",
      "Epoch: 5940, MSE: 0.25967457763860696, Learning Rate: 0.07030000000000002\n",
      "Epoch: 5941, MSE: 0.2596721747950771, Learning Rate: 0.070295\n",
      "Epoch: 5942, MSE: 0.2596697719004683, Learning Rate: 0.07029\n",
      "Epoch: 5943, MSE: 0.25966736895477865, Learning Rate: 0.070285\n",
      "Epoch: 5944, MSE: 0.2596649659580089, Learning Rate: 0.07028\n",
      "Epoch: 5945, MSE: 0.25966256291015877, Learning Rate: 0.070275\n",
      "Epoch: 5946, MSE: 0.25966015981122864, Learning Rate: 0.07027\n",
      "Epoch: 5947, MSE: 0.2596577566612179, Learning Rate: 0.07026500000000001\n",
      "Epoch: 5948, MSE: 0.2596553534601268, Learning Rate: 0.07026\n",
      "Epoch: 5949, MSE: 0.2596529502079545, Learning Rate: 0.070255\n",
      "Epoch: 5950, MSE: 0.2596505469047023, Learning Rate: 0.07025\n",
      "Epoch: 5951, MSE: 0.2596481435503687, Learning Rate: 0.070245\n",
      "Epoch: 5952, MSE: 0.2596457401449546, Learning Rate: 0.07024000000000001\n",
      "Epoch: 5953, MSE: 0.2596433366884587, Learning Rate: 0.070235\n",
      "Epoch: 5954, MSE: 0.2596409331808832, Learning Rate: 0.07023\n",
      "Epoch: 5955, MSE: 0.25963852962222533, Learning Rate: 0.07022500000000001\n",
      "Epoch: 5956, MSE: 0.25963612601248637, Learning Rate: 0.07021999999999999\n",
      "Epoch: 5957, MSE: 0.25963372235166626, Learning Rate: 0.07021500000000001\n",
      "Epoch: 5958, MSE: 0.259631318639765, Learning Rate: 0.07021\n",
      "Epoch: 5959, MSE: 0.2596289148767825, Learning Rate: 0.070205\n",
      "Epoch: 5960, MSE: 0.2596265110627177, Learning Rate: 0.0702\n",
      "Epoch: 5961, MSE: 0.2596241071975715, Learning Rate: 0.07019500000000001\n",
      "Epoch: 5962, MSE: 0.2596217032813434, Learning Rate: 0.07019\n",
      "Epoch: 5963, MSE: 0.2596192993140337, Learning Rate: 0.070185\n",
      "Epoch: 5964, MSE: 0.2596168952956413, Learning Rate: 0.07018\n",
      "Epoch: 5965, MSE: 0.2596144912261681, Learning Rate: 0.070175\n",
      "Epoch: 5966, MSE: 0.25961208710561184, Learning Rate: 0.07017\n",
      "Epoch: 5967, MSE: 0.25960968293397424, Learning Rate: 0.070165\n",
      "Epoch: 5968, MSE: 0.25960727871125416, Learning Rate: 0.07016\n",
      "Epoch: 5969, MSE: 0.25960487443745145, Learning Rate: 0.07015500000000001\n",
      "Epoch: 5970, MSE: 0.2596024701125658, Learning Rate: 0.07015\n",
      "Epoch: 5971, MSE: 0.2596000657365986, Learning Rate: 0.070145\n",
      "Epoch: 5972, MSE: 0.2595976613095481, Learning Rate: 0.07014000000000001\n",
      "Epoch: 5973, MSE: 0.25959525683141493, Learning Rate: 0.07013499999999999\n",
      "Epoch: 5974, MSE: 0.25959285230219964, Learning Rate: 0.07013000000000001\n",
      "Epoch: 5975, MSE: 0.25959044772190126, Learning Rate: 0.07012499999999999\n",
      "Epoch: 5976, MSE: 0.25958804309051986, Learning Rate: 0.07012\n",
      "Epoch: 5977, MSE: 0.25958563840805515, Learning Rate: 0.070115\n",
      "Epoch: 5978, MSE: 0.2595832336745073, Learning Rate: 0.07011\n",
      "Epoch: 5979, MSE: 0.25958082888987727, Learning Rate: 0.070105\n",
      "Epoch: 5980, MSE: 0.2595784240541626, Learning Rate: 0.07010000000000001\n",
      "Epoch: 5981, MSE: 0.25957601916736556, Learning Rate: 0.070095\n",
      "Epoch: 5982, MSE: 0.2595736142294856, Learning Rate: 0.07009000000000001\n",
      "Epoch: 5983, MSE: 0.2595712092405211, Learning Rate: 0.070085\n",
      "Epoch: 5984, MSE: 0.25956880420047346, Learning Rate: 0.07008\n",
      "Epoch: 5985, MSE: 0.25956639910934215, Learning Rate: 0.070075\n",
      "Epoch: 5986, MSE: 0.2595639939671271, Learning Rate: 0.07007000000000001\n",
      "Epoch: 5987, MSE: 0.25956158877382807, Learning Rate: 0.070065\n",
      "Epoch: 5988, MSE: 0.25955918352944585, Learning Rate: 0.07006\n",
      "Epoch: 5989, MSE: 0.2595567782339791, Learning Rate: 0.070055\n",
      "Epoch: 5990, MSE: 0.2595543728874282, Learning Rate: 0.07005\n",
      "Epoch: 5991, MSE: 0.2595519674897941, Learning Rate: 0.07004500000000001\n",
      "Epoch: 5992, MSE: 0.25954956204107443, Learning Rate: 0.07004\n",
      "Epoch: 5993, MSE: 0.259547156541272, Learning Rate: 0.070035\n",
      "Epoch: 5994, MSE: 0.25954475099038427, Learning Rate: 0.07003\n",
      "Epoch: 5995, MSE: 0.2595423453884116, Learning Rate: 0.070025\n",
      "Epoch: 5996, MSE: 0.2595399397353551, Learning Rate: 0.07002\n",
      "Epoch: 5997, MSE: 0.25953753403121466, Learning Rate: 0.07001500000000001\n",
      "Epoch: 5998, MSE: 0.2595351282759893, Learning Rate: 0.07001\n",
      "Epoch: 5999, MSE: 0.2595327224696788, Learning Rate: 0.07000500000000001\n",
      "Epoch: 6000, MSE: 0.2595303166122839, Learning Rate: 0.06999999999999999\n",
      "Epoch: 6001, MSE: 0.2595279107038036, Learning Rate: 0.06999500000000002\n",
      "Epoch: 6002, MSE: 0.2595255047442396, Learning Rate: 0.06999\n",
      "Epoch: 6003, MSE: 0.25952309873358936, Learning Rate: 0.069985\n",
      "Epoch: 6004, MSE: 0.2595206926718548, Learning Rate: 0.06998\n",
      "Epoch: 6005, MSE: 0.25951828655903497, Learning Rate: 0.069975\n",
      "Epoch: 6006, MSE: 0.2595158803951297, Learning Rate: 0.06997\n",
      "Epoch: 6007, MSE: 0.25951347418013926, Learning Rate: 0.069965\n",
      "Epoch: 6008, MSE: 0.25951106791406386, Learning Rate: 0.06996000000000001\n",
      "Epoch: 6009, MSE: 0.25950866159690267, Learning Rate: 0.069955\n",
      "Epoch: 6010, MSE: 0.259506255228656, Learning Rate: 0.06995\n",
      "Epoch: 6011, MSE: 0.25950384880932353, Learning Rate: 0.06994500000000001\n",
      "Epoch: 6012, MSE: 0.2595014423389061, Learning Rate: 0.06994\n",
      "Epoch: 6013, MSE: 0.2594990358174021, Learning Rate: 0.06993500000000001\n",
      "Epoch: 6014, MSE: 0.2594966292448132, Learning Rate: 0.06993\n",
      "Epoch: 6015, MSE: 0.25949422262113836, Learning Rate: 0.069925\n",
      "Epoch: 6016, MSE: 0.25949181594637766, Learning Rate: 0.06992000000000001\n",
      "Epoch: 6017, MSE: 0.2594894092205302, Learning Rate: 0.06991499999999999\n",
      "Epoch: 6018, MSE: 0.2594870024435974, Learning Rate: 0.06991000000000001\n",
      "Epoch: 6019, MSE: 0.2594845956155785, Learning Rate: 0.069905\n",
      "Epoch: 6020, MSE: 0.25948218873647316, Learning Rate: 0.0699\n",
      "Epoch: 6021, MSE: 0.2594797818062817, Learning Rate: 0.069895\n",
      "Epoch: 6022, MSE: 0.25947737482500394, Learning Rate: 0.06989000000000001\n",
      "Epoch: 6023, MSE: 0.2594749677926402, Learning Rate: 0.069885\n",
      "Epoch: 6024, MSE: 0.2594725607091892, Learning Rate: 0.06988\n",
      "Epoch: 6025, MSE: 0.2594701535746526, Learning Rate: 0.069875\n",
      "Epoch: 6026, MSE: 0.2594677463890293, Learning Rate: 0.06987\n",
      "Epoch: 6027, MSE: 0.2594653391523195, Learning Rate: 0.069865\n",
      "Epoch: 6028, MSE: 0.2594629318645221, Learning Rate: 0.06986\n",
      "Epoch: 6029, MSE: 0.2594605245256386, Learning Rate: 0.069855\n",
      "Epoch: 6030, MSE: 0.2594581171356685, Learning Rate: 0.06985000000000001\n",
      "Epoch: 6031, MSE: 0.25945570969461174, Learning Rate: 0.069845\n",
      "Epoch: 6032, MSE: 0.2594533022024673, Learning Rate: 0.06984\n",
      "Epoch: 6033, MSE: 0.2594508946592363, Learning Rate: 0.06983500000000001\n",
      "Epoch: 6034, MSE: 0.2594484870649182, Learning Rate: 0.06982999999999999\n",
      "Epoch: 6035, MSE: 0.25944607941951264, Learning Rate: 0.06982500000000001\n",
      "Epoch: 6036, MSE: 0.2594436717230202, Learning Rate: 0.06982\n",
      "Epoch: 6037, MSE: 0.2594412639754404, Learning Rate: 0.069815\n",
      "Epoch: 6038, MSE: 0.2594388561767738, Learning Rate: 0.06981\n",
      "Epoch: 6039, MSE: 0.25943644832701934, Learning Rate: 0.069805\n",
      "Epoch: 6040, MSE: 0.25943404042617724, Learning Rate: 0.0698\n",
      "Epoch: 6041, MSE: 0.2594316324742484, Learning Rate: 0.06979500000000001\n",
      "Epoch: 6042, MSE: 0.2594292244712314, Learning Rate: 0.06979\n",
      "Epoch: 6043, MSE: 0.25942681641712717, Learning Rate: 0.06978500000000001\n",
      "Epoch: 6044, MSE: 0.2594244083119353, Learning Rate: 0.06978\n",
      "Epoch: 6045, MSE: 0.25942200015565536, Learning Rate: 0.069775\n",
      "Epoch: 6046, MSE: 0.2594195919482879, Learning Rate: 0.06977\n",
      "Epoch: 6047, MSE: 0.2594171836898324, Learning Rate: 0.06976500000000001\n",
      "Epoch: 6048, MSE: 0.2594147753802899, Learning Rate: 0.06976\n",
      "Epoch: 6049, MSE: 0.2594123670196581, Learning Rate: 0.069755\n",
      "Epoch: 6050, MSE: 0.259409958607939, Learning Rate: 0.06975\n",
      "Epoch: 6051, MSE: 0.25940755014513167, Learning Rate: 0.069745\n",
      "Epoch: 6052, MSE: 0.2594051416312364, Learning Rate: 0.06974000000000001\n",
      "Epoch: 6053, MSE: 0.2594027330662535, Learning Rate: 0.069735\n",
      "Epoch: 6054, MSE: 0.2594003244501814, Learning Rate: 0.06973\n",
      "Epoch: 6055, MSE: 0.25939791578302146, Learning Rate: 0.069725\n",
      "Epoch: 6056, MSE: 0.25939550706477293, Learning Rate: 0.06972\n",
      "Epoch: 6057, MSE: 0.2593930982954367, Learning Rate: 0.069715\n",
      "Epoch: 6058, MSE: 0.2593906894750114, Learning Rate: 0.06971000000000001\n",
      "Epoch: 6059, MSE: 0.2593882806034979, Learning Rate: 0.069705\n",
      "Epoch: 6060, MSE: 0.2593858716808957, Learning Rate: 0.06970000000000001\n",
      "Epoch: 6061, MSE: 0.2593834627072052, Learning Rate: 0.069695\n",
      "Epoch: 6062, MSE: 0.25938105368242614, Learning Rate: 0.06969000000000002\n",
      "Epoch: 6063, MSE: 0.25937864460655785, Learning Rate: 0.069685\n",
      "Epoch: 6064, MSE: 0.2593762354796014, Learning Rate: 0.06968\n",
      "Epoch: 6065, MSE: 0.2593738263015553, Learning Rate: 0.069675\n",
      "Epoch: 6066, MSE: 0.2593714170724211, Learning Rate: 0.06967\n",
      "Epoch: 6067, MSE: 0.25936900779219735, Learning Rate: 0.069665\n",
      "Epoch: 6068, MSE: 0.2593665984608853, Learning Rate: 0.06966\n",
      "Epoch: 6069, MSE: 0.2593641890784842, Learning Rate: 0.06965500000000001\n",
      "Epoch: 6070, MSE: 0.2593617796449936, Learning Rate: 0.06965\n",
      "Epoch: 6071, MSE: 0.25935937016041444, Learning Rate: 0.069645\n",
      "Epoch: 6072, MSE: 0.2593569606247456, Learning Rate: 0.06964000000000001\n",
      "Epoch: 6073, MSE: 0.2593545510379884, Learning Rate: 0.069635\n",
      "Epoch: 6074, MSE: 0.2593521414001407, Learning Rate: 0.06963\n",
      "Epoch: 6075, MSE: 0.25934973171120457, Learning Rate: 0.069625\n",
      "Epoch: 6076, MSE: 0.25934732197117877, Learning Rate: 0.06962\n",
      "Epoch: 6077, MSE: 0.25934491218006395, Learning Rate: 0.06961500000000001\n",
      "Epoch: 6078, MSE: 0.25934250233785916, Learning Rate: 0.06960999999999999\n",
      "Epoch: 6079, MSE: 0.2593400924445652, Learning Rate: 0.06960500000000001\n",
      "Epoch: 6080, MSE: 0.2593376825001818, Learning Rate: 0.0696\n",
      "Epoch: 6081, MSE: 0.25933527250470867, Learning Rate: 0.069595\n",
      "Epoch: 6082, MSE: 0.2593328624581462, Learning Rate: 0.06959\n",
      "Epoch: 6083, MSE: 0.2593304523604936, Learning Rate: 0.06958500000000001\n",
      "Epoch: 6084, MSE: 0.25932804221175165, Learning Rate: 0.06958\n",
      "Epoch: 6085, MSE: 0.25932563201191927, Learning Rate: 0.069575\n",
      "Epoch: 6086, MSE: 0.25932322176099815, Learning Rate: 0.06957\n",
      "Epoch: 6087, MSE: 0.25932081145898656, Learning Rate: 0.069565\n",
      "Epoch: 6088, MSE: 0.25931840110588444, Learning Rate: 0.06956\n",
      "Epoch: 6089, MSE: 0.25931599070169403, Learning Rate: 0.069555\n",
      "Epoch: 6090, MSE: 0.25931358024641277, Learning Rate: 0.06955\n",
      "Epoch: 6091, MSE: 0.2593111697400409, Learning Rate: 0.06954500000000001\n",
      "Epoch: 6092, MSE: 0.25930875918257984, Learning Rate: 0.06954\n",
      "Epoch: 6093, MSE: 0.2593063485740279, Learning Rate: 0.069535\n",
      "Epoch: 6094, MSE: 0.2593039379143867, Learning Rate: 0.06953000000000001\n",
      "Epoch: 6095, MSE: 0.25930152720365457, Learning Rate: 0.06952499999999999\n",
      "Epoch: 6096, MSE: 0.25929911644183284, Learning Rate: 0.06952000000000001\n",
      "Epoch: 6097, MSE: 0.25929670562892065, Learning Rate: 0.069515\n",
      "Epoch: 6098, MSE: 0.2592942947649173, Learning Rate: 0.06951\n",
      "Epoch: 6099, MSE: 0.25929188384982477, Learning Rate: 0.069505\n",
      "Epoch: 6100, MSE: 0.2592894728836415, Learning Rate: 0.0695\n",
      "Epoch: 6101, MSE: 0.2592870618663681, Learning Rate: 0.069495\n",
      "Epoch: 6102, MSE: 0.25928465079800306, Learning Rate: 0.06949000000000001\n",
      "Epoch: 6103, MSE: 0.2592822396785487, Learning Rate: 0.069485\n",
      "Epoch: 6104, MSE: 0.25927982850800324, Learning Rate: 0.06948\n",
      "Epoch: 6105, MSE: 0.2592774172863677, Learning Rate: 0.069475\n",
      "Epoch: 6106, MSE: 0.25927500601364073, Learning Rate: 0.06947\n",
      "Epoch: 6107, MSE: 0.25927259468982367, Learning Rate: 0.069465\n",
      "Epoch: 6108, MSE: 0.259270183314916, Learning Rate: 0.06946000000000001\n",
      "Epoch: 6109, MSE: 0.2592677718889173, Learning Rate: 0.069455\n",
      "Epoch: 6110, MSE: 0.2592653604118284, Learning Rate: 0.06945\n",
      "Epoch: 6111, MSE: 0.25926294888364826, Learning Rate: 0.069445\n",
      "Epoch: 6112, MSE: 0.2592605373043772, Learning Rate: 0.06944\n",
      "Epoch: 6113, MSE: 0.25925812567401546, Learning Rate: 0.06943500000000001\n",
      "Epoch: 6114, MSE: 0.2592557139925623, Learning Rate: 0.06942999999999999\n",
      "Epoch: 6115, MSE: 0.259253302260019, Learning Rate: 0.069425\n",
      "Epoch: 6116, MSE: 0.2592508904763841, Learning Rate: 0.06942\n",
      "Epoch: 6117, MSE: 0.2592484786416589, Learning Rate: 0.069415\n",
      "Epoch: 6118, MSE: 0.2592460667558422, Learning Rate: 0.06941\n",
      "Epoch: 6119, MSE: 0.2592436548189347, Learning Rate: 0.06940500000000001\n",
      "Epoch: 6120, MSE: 0.25924124283093586, Learning Rate: 0.0694\n",
      "Epoch: 6121, MSE: 0.25923883079184534, Learning Rate: 0.06939500000000001\n",
      "Epoch: 6122, MSE: 0.2592364187016644, Learning Rate: 0.06939\n",
      "Epoch: 6123, MSE: 0.25923400656039236, Learning Rate: 0.06938500000000002\n",
      "Epoch: 6124, MSE: 0.2592315943680286, Learning Rate: 0.06938\n",
      "Epoch: 6125, MSE: 0.2592291821245742, Learning Rate: 0.069375\n",
      "Epoch: 6126, MSE: 0.25922676983002757, Learning Rate: 0.06937\n",
      "Epoch: 6127, MSE: 0.25922435748439054, Learning Rate: 0.069365\n",
      "Epoch: 6128, MSE: 0.2592219450876611, Learning Rate: 0.06936\n",
      "Epoch: 6129, MSE: 0.25921953263984115, Learning Rate: 0.069355\n",
      "Epoch: 6130, MSE: 0.2592171201409291, Learning Rate: 0.06935000000000001\n",
      "Epoch: 6131, MSE: 0.2592147075909262, Learning Rate: 0.069345\n",
      "Epoch: 6132, MSE: 0.2592122949898312, Learning Rate: 0.06934\n",
      "Epoch: 6133, MSE: 0.2592098823376462, Learning Rate: 0.06933500000000001\n",
      "Epoch: 6134, MSE: 0.2592074696343684, Learning Rate: 0.06933\n",
      "Epoch: 6135, MSE: 0.25920505687999934, Learning Rate: 0.069325\n",
      "Epoch: 6136, MSE: 0.259202644074539, Learning Rate: 0.06932\n",
      "Epoch: 6137, MSE: 0.2592002312179864, Learning Rate: 0.069315\n",
      "Epoch: 6138, MSE: 0.2591978183103419, Learning Rate: 0.06931000000000001\n",
      "Epoch: 6139, MSE: 0.2591954053516062, Learning Rate: 0.06930499999999999\n",
      "Epoch: 6140, MSE: 0.25919299234177945, Learning Rate: 0.06930000000000001\n",
      "Epoch: 6141, MSE: 0.25919057928086053, Learning Rate: 0.069295\n",
      "Epoch: 6142, MSE: 0.2591881661688491, Learning Rate: 0.06929\n",
      "Epoch: 6143, MSE: 0.25918575300574814, Learning Rate: 0.069285\n",
      "Epoch: 6144, MSE: 0.2591833397915528, Learning Rate: 0.06928000000000001\n",
      "Epoch: 6145, MSE: 0.2591809265262666, Learning Rate: 0.069275\n",
      "Epoch: 6146, MSE: 0.25917851320988816, Learning Rate: 0.06927\n",
      "Epoch: 6147, MSE: 0.2591760998424185, Learning Rate: 0.06926500000000001\n",
      "Epoch: 6148, MSE: 0.2591736864238565, Learning Rate: 0.06926\n",
      "Epoch: 6149, MSE: 0.2591712729542037, Learning Rate: 0.069255\n",
      "Epoch: 6150, MSE: 0.2591688594334579, Learning Rate: 0.06925\n",
      "Epoch: 6151, MSE: 0.25916644586162035, Learning Rate: 0.069245\n",
      "Epoch: 6152, MSE: 0.25916403223869106, Learning Rate: 0.06924000000000001\n",
      "Epoch: 6153, MSE: 0.2591616185646694, Learning Rate: 0.069235\n",
      "Epoch: 6154, MSE: 0.2591592048395564, Learning Rate: 0.06923\n",
      "Epoch: 6155, MSE: 0.2591567910633505, Learning Rate: 0.06922500000000001\n",
      "Epoch: 6156, MSE: 0.2591543772360531, Learning Rate: 0.06921999999999999\n",
      "Epoch: 6157, MSE: 0.25915196335766355, Learning Rate: 0.06921500000000001\n",
      "Epoch: 6158, MSE: 0.2591495494281816, Learning Rate: 0.06921\n",
      "Epoch: 6159, MSE: 0.25914713544760737, Learning Rate: 0.069205\n",
      "Epoch: 6160, MSE: 0.2591447214159416, Learning Rate: 0.0692\n",
      "Epoch: 6161, MSE: 0.2591423073331838, Learning Rate: 0.069195\n",
      "Epoch: 6162, MSE: 0.2591398931993333, Learning Rate: 0.06919\n",
      "Epoch: 6163, MSE: 0.2591374790143907, Learning Rate: 0.06918500000000001\n",
      "Epoch: 6164, MSE: 0.25913506477835624, Learning Rate: 0.06918\n",
      "Epoch: 6165, MSE: 0.2591326504912295, Learning Rate: 0.069175\n",
      "Epoch: 6166, MSE: 0.25913023615300995, Learning Rate: 0.06917\n",
      "Epoch: 6167, MSE: 0.25912782176369825, Learning Rate: 0.069165\n",
      "Epoch: 6168, MSE: 0.2591254073232946, Learning Rate: 0.06916\n",
      "Epoch: 6169, MSE: 0.25912299283179946, Learning Rate: 0.06915500000000001\n",
      "Epoch: 6170, MSE: 0.25912057828921026, Learning Rate: 0.06915\n",
      "Epoch: 6171, MSE: 0.25911816369552976, Learning Rate: 0.069145\n",
      "Epoch: 6172, MSE: 0.2591157490507572, Learning Rate: 0.06914000000000001\n",
      "Epoch: 6173, MSE: 0.2591133343548913, Learning Rate: 0.069135\n",
      "Epoch: 6174, MSE: 0.2591109196079338, Learning Rate: 0.06913000000000001\n",
      "Epoch: 6175, MSE: 0.25910850480988357, Learning Rate: 0.06912499999999999\n",
      "Epoch: 6176, MSE: 0.259106089960741, Learning Rate: 0.06912\n",
      "Epoch: 6177, MSE: 0.2591036750605064, Learning Rate: 0.069115\n",
      "Epoch: 6178, MSE: 0.259101260109179, Learning Rate: 0.06911\n",
      "Epoch: 6179, MSE: 0.25909884510675973, Learning Rate: 0.069105\n",
      "Epoch: 6180, MSE: 0.259096430053247, Learning Rate: 0.06910000000000001\n",
      "Epoch: 6181, MSE: 0.2590940149486427, Learning Rate: 0.069095\n",
      "Epoch: 6182, MSE: 0.25909159979294577, Learning Rate: 0.06909000000000001\n",
      "Epoch: 6183, MSE: 0.25908918458615593, Learning Rate: 0.069085\n",
      "Epoch: 6184, MSE: 0.25908676932827374, Learning Rate: 0.06908000000000002\n",
      "Epoch: 6185, MSE: 0.25908435401929897, Learning Rate: 0.069075\n",
      "Epoch: 6186, MSE: 0.2590819386592324, Learning Rate: 0.06907\n",
      "Epoch: 6187, MSE: 0.2590795232480729, Learning Rate: 0.069065\n",
      "Epoch: 6188, MSE: 0.2590771077858203, Learning Rate: 0.06906\n",
      "Epoch: 6189, MSE: 0.259074692272476, Learning Rate: 0.069055\n",
      "Epoch: 6190, MSE: 0.25907227670803895, Learning Rate: 0.06905\n",
      "Epoch: 6191, MSE: 0.25906986109250857, Learning Rate: 0.06904500000000001\n",
      "Epoch: 6192, MSE: 0.25906744542588683, Learning Rate: 0.06904\n",
      "Epoch: 6193, MSE: 0.2590650297081714, Learning Rate: 0.069035\n",
      "Epoch: 6194, MSE: 0.259062613939364, Learning Rate: 0.06903000000000001\n",
      "Epoch: 6195, MSE: 0.25906019811946385, Learning Rate: 0.069025\n",
      "Epoch: 6196, MSE: 0.2590577822484713, Learning Rate: 0.06902\n",
      "Epoch: 6197, MSE: 0.25905536632638637, Learning Rate: 0.069015\n",
      "Epoch: 6198, MSE: 0.2590529503532081, Learning Rate: 0.06901\n",
      "Epoch: 6199, MSE: 0.2590505343289374, Learning Rate: 0.06900500000000001\n",
      "Epoch: 6200, MSE: 0.25904811825357477, Learning Rate: 0.06899999999999999\n",
      "Epoch: 6201, MSE: 0.25904570212711897, Learning Rate: 0.06899500000000001\n",
      "Epoch: 6202, MSE: 0.25904328594957093, Learning Rate: 0.06899\n",
      "Epoch: 6203, MSE: 0.25904086972093004, Learning Rate: 0.068985\n",
      "Epoch: 6204, MSE: 0.25903845344119575, Learning Rate: 0.06898\n",
      "Epoch: 6205, MSE: 0.25903603711037076, Learning Rate: 0.068975\n",
      "Epoch: 6206, MSE: 0.25903362072845076, Learning Rate: 0.06897\n",
      "Epoch: 6207, MSE: 0.2590312042954393, Learning Rate: 0.068965\n",
      "Epoch: 6208, MSE: 0.25902878781133565, Learning Rate: 0.06896000000000001\n",
      "Epoch: 6209, MSE: 0.25902637127613926, Learning Rate: 0.068955\n",
      "Epoch: 6210, MSE: 0.2590239546898487, Learning Rate: 0.06895\n",
      "Epoch: 6211, MSE: 0.25902153805246664, Learning Rate: 0.068945\n",
      "Epoch: 6212, MSE: 0.25901912136399247, Learning Rate: 0.06894\n",
      "Epoch: 6213, MSE: 0.2590167046244251, Learning Rate: 0.06893500000000001\n",
      "Epoch: 6214, MSE: 0.2590142878337648, Learning Rate: 0.06893\n",
      "Epoch: 6215, MSE: 0.2590118709920124, Learning Rate: 0.068925\n",
      "Epoch: 6216, MSE: 0.2590094540991669, Learning Rate: 0.06892000000000001\n",
      "Epoch: 6217, MSE: 0.25900703715522866, Learning Rate: 0.06891499999999999\n",
      "Epoch: 6218, MSE: 0.2590046201601981, Learning Rate: 0.06891000000000001\n",
      "Epoch: 6219, MSE: 0.25900220311407485, Learning Rate: 0.068905\n",
      "Epoch: 6220, MSE: 0.258999786016859, Learning Rate: 0.0689\n",
      "Epoch: 6221, MSE: 0.2589973688685503, Learning Rate: 0.068895\n",
      "Epoch: 6222, MSE: 0.25899495166914904, Learning Rate: 0.06889\n",
      "Epoch: 6223, MSE: 0.25899253441865516, Learning Rate: 0.068885\n",
      "Epoch: 6224, MSE: 0.25899011711706876, Learning Rate: 0.06888000000000001\n",
      "Epoch: 6225, MSE: 0.25898769976438957, Learning Rate: 0.068875\n",
      "Epoch: 6226, MSE: 0.2589852823606181, Learning Rate: 0.06887\n",
      "Epoch: 6227, MSE: 0.2589828649057535, Learning Rate: 0.068865\n",
      "Epoch: 6228, MSE: 0.2589804473997965, Learning Rate: 0.06886\n",
      "Epoch: 6229, MSE: 0.2589780298427468, Learning Rate: 0.068855\n",
      "Epoch: 6230, MSE: 0.25897561223460425, Learning Rate: 0.06885000000000001\n",
      "Epoch: 6231, MSE: 0.2589731945753696, Learning Rate: 0.068845\n",
      "Epoch: 6232, MSE: 0.2589707768650419, Learning Rate: 0.06884\n",
      "Epoch: 6233, MSE: 0.25896835910362226, Learning Rate: 0.06883500000000001\n",
      "Epoch: 6234, MSE: 0.2589659412911093, Learning Rate: 0.06883\n",
      "Epoch: 6235, MSE: 0.2589635234275042, Learning Rate: 0.06882500000000001\n",
      "Epoch: 6236, MSE: 0.25896110551280666, Learning Rate: 0.06881999999999999\n",
      "Epoch: 6237, MSE: 0.25895868754701684, Learning Rate: 0.068815\n",
      "Epoch: 6238, MSE: 0.2589562695301334, Learning Rate: 0.06881\n",
      "Epoch: 6239, MSE: 0.2589538514621579, Learning Rate: 0.068805\n",
      "Epoch: 6240, MSE: 0.25895143334308957, Learning Rate: 0.0688\n",
      "Epoch: 6241, MSE: 0.25894901517292995, Learning Rate: 0.06879500000000001\n",
      "Epoch: 6242, MSE: 0.258946596951676, Learning Rate: 0.06879\n",
      "Epoch: 6243, MSE: 0.25894417867933106, Learning Rate: 0.06878500000000001\n",
      "Epoch: 6244, MSE: 0.2589417603558925, Learning Rate: 0.06878\n",
      "Epoch: 6245, MSE: 0.2589393419813622, Learning Rate: 0.068775\n",
      "Epoch: 6246, MSE: 0.25893692355573916, Learning Rate: 0.06877\n",
      "Epoch: 6247, MSE: 0.25893450507902394, Learning Rate: 0.068765\n",
      "Epoch: 6248, MSE: 0.2589320865512155, Learning Rate: 0.06876\n",
      "Epoch: 6249, MSE: 0.25892966797231526, Learning Rate: 0.068755\n",
      "Epoch: 6250, MSE: 0.25892724934232286, Learning Rate: 0.06875\n",
      "Epoch: 6251, MSE: 0.2589248306612366, Learning Rate: 0.068745\n",
      "Epoch: 6252, MSE: 0.2589224119290592, Learning Rate: 0.06874000000000001\n",
      "Epoch: 6253, MSE: 0.25891999314578995, Learning Rate: 0.068735\n",
      "Epoch: 6254, MSE: 0.2589175743114273, Learning Rate: 0.06873\n",
      "Epoch: 6255, MSE: 0.25891515542597193, Learning Rate: 0.06872500000000001\n",
      "Epoch: 6256, MSE: 0.25891273648942487, Learning Rate: 0.06872\n",
      "Epoch: 6257, MSE: 0.25891031750178584, Learning Rate: 0.068715\n",
      "Epoch: 6258, MSE: 0.25890789846305395, Learning Rate: 0.06871000000000001\n",
      "Epoch: 6259, MSE: 0.2589054793732297, Learning Rate: 0.068705\n",
      "Epoch: 6260, MSE: 0.25890306023231335, Learning Rate: 0.06870000000000001\n",
      "Epoch: 6261, MSE: 0.25890064104030464, Learning Rate: 0.06869499999999999\n",
      "Epoch: 6262, MSE: 0.25889822179720334, Learning Rate: 0.06869000000000001\n",
      "Epoch: 6263, MSE: 0.2588958025030106, Learning Rate: 0.068685\n",
      "Epoch: 6264, MSE: 0.25889338315772464, Learning Rate: 0.06868\n",
      "Epoch: 6265, MSE: 0.2588909637613475, Learning Rate: 0.068675\n",
      "Epoch: 6266, MSE: 0.2588885443138776, Learning Rate: 0.06867\n",
      "Epoch: 6267, MSE: 0.2588861248153157, Learning Rate: 0.068665\n",
      "Epoch: 6268, MSE: 0.25888370526566185, Learning Rate: 0.06866\n",
      "Epoch: 6269, MSE: 0.25888128566491553, Learning Rate: 0.06865500000000001\n",
      "Epoch: 6270, MSE: 0.2588788660130765, Learning Rate: 0.06865\n",
      "Epoch: 6271, MSE: 0.25887644631014606, Learning Rate: 0.068645\n",
      "Epoch: 6272, MSE: 0.25887402655612396, Learning Rate: 0.06864\n",
      "Epoch: 6273, MSE: 0.2588716067510092, Learning Rate: 0.068635\n",
      "Epoch: 6274, MSE: 0.25886918689480304, Learning Rate: 0.06863000000000001\n",
      "Epoch: 6275, MSE: 0.25886676698750427, Learning Rate: 0.068625\n",
      "Epoch: 6276, MSE: 0.2588643470291132, Learning Rate: 0.06862\n",
      "Epoch: 6277, MSE: 0.25886192701963034, Learning Rate: 0.06861500000000001\n",
      "Epoch: 6278, MSE: 0.25885950695905574, Learning Rate: 0.06860999999999999\n",
      "Epoch: 6279, MSE: 0.2588570868473897, Learning Rate: 0.06860500000000001\n",
      "Epoch: 6280, MSE: 0.25885466668463103, Learning Rate: 0.0686\n",
      "Epoch: 6281, MSE: 0.25885224647078076, Learning Rate: 0.068595\n",
      "Epoch: 6282, MSE: 0.258849826205839, Learning Rate: 0.06859\n",
      "Epoch: 6283, MSE: 0.2588474058898052, Learning Rate: 0.06858500000000001\n",
      "Epoch: 6284, MSE: 0.25884498552267904, Learning Rate: 0.06858\n",
      "Epoch: 6285, MSE: 0.2588425651044621, Learning Rate: 0.06857500000000001\n",
      "Epoch: 6286, MSE: 0.25884014463515237, Learning Rate: 0.06857\n",
      "Epoch: 6287, MSE: 0.25883772411475137, Learning Rate: 0.068565\n",
      "Epoch: 6288, MSE: 0.25883530354325845, Learning Rate: 0.06856\n",
      "Epoch: 6289, MSE: 0.2588328829206739, Learning Rate: 0.068555\n",
      "Epoch: 6290, MSE: 0.2588304622469983, Learning Rate: 0.06855\n",
      "Epoch: 6291, MSE: 0.25882804152223, Learning Rate: 0.06854500000000001\n",
      "Epoch: 6292, MSE: 0.25882562074637055, Learning Rate: 0.06854\n",
      "Epoch: 6293, MSE: 0.25882319991941927, Learning Rate: 0.068535\n",
      "Epoch: 6294, MSE: 0.25882077904137735, Learning Rate: 0.06853000000000001\n",
      "Epoch: 6295, MSE: 0.2588183581122433, Learning Rate: 0.068525\n",
      "Epoch: 6296, MSE: 0.2588159371320179, Learning Rate: 0.06852000000000001\n",
      "Epoch: 6297, MSE: 0.25881351610070086, Learning Rate: 0.06851499999999999\n",
      "Epoch: 6298, MSE: 0.25881109501829297, Learning Rate: 0.06851\n",
      "Epoch: 6299, MSE: 0.25880867388479334, Learning Rate: 0.068505\n",
      "Epoch: 6300, MSE: 0.25880625270020213, Learning Rate: 0.0685\n",
      "Epoch: 6301, MSE: 0.25880383146451946, Learning Rate: 0.068495\n",
      "Epoch: 6302, MSE: 0.25880141017774605, Learning Rate: 0.06849000000000001\n",
      "Epoch: 6303, MSE: 0.2587989888398802, Learning Rate: 0.068485\n",
      "Epoch: 6304, MSE: 0.25879656745092444, Learning Rate: 0.06848000000000001\n",
      "Epoch: 6305, MSE: 0.25879414601087697, Learning Rate: 0.068475\n",
      "Epoch: 6306, MSE: 0.2587917245197382, Learning Rate: 0.06847\n",
      "Epoch: 6307, MSE: 0.25878930297750874, Learning Rate: 0.068465\n",
      "Epoch: 6308, MSE: 0.2587868813841871, Learning Rate: 0.06846000000000001\n",
      "Epoch: 6309, MSE: 0.25878445973977554, Learning Rate: 0.068455\n",
      "Epoch: 6310, MSE: 0.2587820380442726, Learning Rate: 0.06845\n",
      "Epoch: 6311, MSE: 0.258779616297678, Learning Rate: 0.068445\n",
      "Epoch: 6312, MSE: 0.2587771944999931, Learning Rate: 0.06844\n",
      "Epoch: 6313, MSE: 0.2587747726512171, Learning Rate: 0.06843500000000001\n",
      "Epoch: 6314, MSE: 0.25877235075134997, Learning Rate: 0.06843\n",
      "Epoch: 6315, MSE: 0.25876992880039223, Learning Rate: 0.068425\n",
      "Epoch: 6316, MSE: 0.25876750679834326, Learning Rate: 0.06842\n",
      "Epoch: 6317, MSE: 0.2587650847452037, Learning Rate: 0.068415\n",
      "Epoch: 6318, MSE: 0.2587626626409738, Learning Rate: 0.06841\n",
      "Epoch: 6319, MSE: 0.258760240485652, Learning Rate: 0.06840500000000001\n",
      "Epoch: 6320, MSE: 0.25875781827924055, Learning Rate: 0.0684\n",
      "Epoch: 6321, MSE: 0.25875539602173797, Learning Rate: 0.06839500000000001\n",
      "Epoch: 6322, MSE: 0.25875297371314554, Learning Rate: 0.06838999999999999\n",
      "Epoch: 6323, MSE: 0.2587505513534619, Learning Rate: 0.06838500000000002\n",
      "Epoch: 6324, MSE: 0.2587481289426874, Learning Rate: 0.06838\n",
      "Epoch: 6325, MSE: 0.2587457064808226, Learning Rate: 0.068375\n",
      "Epoch: 6326, MSE: 0.25874328396786805, Learning Rate: 0.06837\n",
      "Epoch: 6327, MSE: 0.25874086140382146, Learning Rate: 0.068365\n",
      "Epoch: 6328, MSE: 0.2587384387886857, Learning Rate: 0.06836\n",
      "Epoch: 6329, MSE: 0.2587360161224597, Learning Rate: 0.068355\n",
      "Epoch: 6330, MSE: 0.25873359340514324, Learning Rate: 0.06835000000000001\n",
      "Epoch: 6331, MSE: 0.2587311706367363, Learning Rate: 0.068345\n",
      "Epoch: 6332, MSE: 0.25872874781723937, Learning Rate: 0.06834\n",
      "Epoch: 6333, MSE: 0.25872632494665115, Learning Rate: 0.068335\n",
      "Epoch: 6334, MSE: 0.2587239020249742, Learning Rate: 0.06833\n",
      "Epoch: 6335, MSE: 0.2587214790522065, Learning Rate: 0.06832500000000001\n",
      "Epoch: 6336, MSE: 0.2587190560283491, Learning Rate: 0.06832\n",
      "Epoch: 6337, MSE: 0.2587166329534016, Learning Rate: 0.068315\n",
      "Epoch: 6338, MSE: 0.25871420982736376, Learning Rate: 0.06831000000000001\n",
      "Epoch: 6339, MSE: 0.25871178665023603, Learning Rate: 0.06830499999999999\n",
      "Epoch: 6340, MSE: 0.25870936342201895, Learning Rate: 0.06830000000000001\n",
      "Epoch: 6341, MSE: 0.25870694014271145, Learning Rate: 0.068295\n",
      "Epoch: 6342, MSE: 0.25870451681231454, Learning Rate: 0.06829\n",
      "Epoch: 6343, MSE: 0.258702093430828, Learning Rate: 0.068285\n",
      "Epoch: 6344, MSE: 0.2586996699982515, Learning Rate: 0.06828000000000001\n",
      "Epoch: 6345, MSE: 0.25869724651458476, Learning Rate: 0.068275\n",
      "Epoch: 6346, MSE: 0.2586948229798292, Learning Rate: 0.06827\n",
      "Epoch: 6347, MSE: 0.2586923993939842, Learning Rate: 0.068265\n",
      "Epoch: 6348, MSE: 0.25868997575704905, Learning Rate: 0.06826\n",
      "Epoch: 6349, MSE: 0.2586875520690249, Learning Rate: 0.068255\n",
      "Epoch: 6350, MSE: 0.2586851283299109, Learning Rate: 0.06825\n",
      "Epoch: 6351, MSE: 0.258682704539708, Learning Rate: 0.068245\n",
      "Epoch: 6352, MSE: 0.2586802806984157, Learning Rate: 0.06824000000000001\n",
      "Epoch: 6353, MSE: 0.2586778568060336, Learning Rate: 0.068235\n",
      "Epoch: 6354, MSE: 0.2586754328625629, Learning Rate: 0.06823\n",
      "Epoch: 6355, MSE: 0.2586730088680022, Learning Rate: 0.06822500000000001\n",
      "Epoch: 6356, MSE: 0.25867058482235306, Learning Rate: 0.06821999999999999\n",
      "Epoch: 6357, MSE: 0.2586681607256154, Learning Rate: 0.06821500000000001\n",
      "Epoch: 6358, MSE: 0.2586657365777878, Learning Rate: 0.06820999999999999\n",
      "Epoch: 6359, MSE: 0.2586633123788716, Learning Rate: 0.068205\n",
      "Epoch: 6360, MSE: 0.25866088812886606, Learning Rate: 0.0682\n",
      "Epoch: 6361, MSE: 0.2586584638277717, Learning Rate: 0.068195\n",
      "Epoch: 6362, MSE: 0.2586560394755889, Learning Rate: 0.06819\n",
      "Epoch: 6363, MSE: 0.25865361507231716, Learning Rate: 0.06818500000000001\n",
      "Epoch: 6364, MSE: 0.2586511906179564, Learning Rate: 0.06818\n",
      "Epoch: 6365, MSE: 0.25864876611250776, Learning Rate: 0.06817500000000001\n",
      "Epoch: 6366, MSE: 0.25864634155597027, Learning Rate: 0.06817\n",
      "Epoch: 6367, MSE: 0.25864391694834354, Learning Rate: 0.068165\n",
      "Epoch: 6368, MSE: 0.25864149228962885, Learning Rate: 0.06816\n",
      "Epoch: 6369, MSE: 0.2586390675798255, Learning Rate: 0.06815500000000001\n",
      "Epoch: 6370, MSE: 0.25863664281893367, Learning Rate: 0.06815\n",
      "Epoch: 6371, MSE: 0.2586342180069539, Learning Rate: 0.068145\n",
      "Epoch: 6372, MSE: 0.2586317931438854, Learning Rate: 0.06814\n",
      "Epoch: 6373, MSE: 0.258629368229729, Learning Rate: 0.068135\n",
      "Epoch: 6374, MSE: 0.25862694326448443, Learning Rate: 0.06813000000000001\n",
      "Epoch: 6375, MSE: 0.25862451824815147, Learning Rate: 0.068125\n",
      "Epoch: 6376, MSE: 0.25862209318073126, Learning Rate: 0.06812\n",
      "Epoch: 6377, MSE: 0.2586196680622223, Learning Rate: 0.068115\n",
      "Epoch: 6378, MSE: 0.2586172428926254, Learning Rate: 0.06811\n",
      "Epoch: 6379, MSE: 0.25861481767194083, Learning Rate: 0.068105\n",
      "Epoch: 6380, MSE: 0.25861239240016837, Learning Rate: 0.06810000000000001\n",
      "Epoch: 6381, MSE: 0.2586099670773079, Learning Rate: 0.068095\n",
      "Epoch: 6382, MSE: 0.25860754170336003, Learning Rate: 0.06809000000000001\n",
      "Epoch: 6383, MSE: 0.25860511627832433, Learning Rate: 0.06808499999999999\n",
      "Epoch: 6384, MSE: 0.2586026908022013, Learning Rate: 0.06808000000000002\n",
      "Epoch: 6385, MSE: 0.2586002652749911, Learning Rate: 0.068075\n",
      "Epoch: 6386, MSE: 0.2585978396966929, Learning Rate: 0.06807\n",
      "Epoch: 6387, MSE: 0.25859541406730713, Learning Rate: 0.068065\n",
      "Epoch: 6388, MSE: 0.25859298838683437, Learning Rate: 0.06806\n",
      "Epoch: 6389, MSE: 0.2585905626552742, Learning Rate: 0.068055\n",
      "Epoch: 6390, MSE: 0.25858813687262683, Learning Rate: 0.06805\n",
      "Epoch: 6391, MSE: 0.2585857110388927, Learning Rate: 0.06804500000000001\n",
      "Epoch: 6392, MSE: 0.2585832851540705, Learning Rate: 0.06804\n",
      "Epoch: 6393, MSE: 0.25858085921816176, Learning Rate: 0.068035\n",
      "Epoch: 6394, MSE: 0.2585784332311658, Learning Rate: 0.06803000000000001\n",
      "Epoch: 6395, MSE: 0.2585760071930838, Learning Rate: 0.068025\n",
      "Epoch: 6396, MSE: 0.2585735811039148, Learning Rate: 0.06802000000000001\n",
      "Epoch: 6397, MSE: 0.2585711549636588, Learning Rate: 0.068015\n",
      "Epoch: 6398, MSE: 0.25856872877231557, Learning Rate: 0.06801\n",
      "Epoch: 6399, MSE: 0.25856630252988644, Learning Rate: 0.06800500000000001\n",
      "Epoch: 6400, MSE: 0.2585638762363703, Learning Rate: 0.06799999999999999\n",
      "Epoch: 6401, MSE: 0.2585614498917677, Learning Rate: 0.06799500000000001\n",
      "Epoch: 6402, MSE: 0.25855902349607895, Learning Rate: 0.06799\n",
      "Epoch: 6403, MSE: 0.2585565970493035, Learning Rate: 0.067985\n",
      "Epoch: 6404, MSE: 0.2585541705514422, Learning Rate: 0.06798\n",
      "Epoch: 6405, MSE: 0.2585517440024938, Learning Rate: 0.06797500000000001\n",
      "Epoch: 6406, MSE: 0.25854931740246, Learning Rate: 0.06797\n",
      "Epoch: 6407, MSE: 0.2585468907513397, Learning Rate: 0.067965\n",
      "Epoch: 6408, MSE: 0.2585444640491332, Learning Rate: 0.06796\n",
      "Epoch: 6409, MSE: 0.2585420372958412, Learning Rate: 0.067955\n",
      "Epoch: 6410, MSE: 0.2585396104914635, Learning Rate: 0.06795\n",
      "Epoch: 6411, MSE: 0.2585371836359989, Learning Rate: 0.067945\n",
      "Epoch: 6412, MSE: 0.25853475672944953, Learning Rate: 0.06794\n",
      "Epoch: 6413, MSE: 0.25853232977181445, Learning Rate: 0.06793500000000001\n",
      "Epoch: 6414, MSE: 0.2585299027630932, Learning Rate: 0.06793\n",
      "Epoch: 6415, MSE: 0.2585274757032868, Learning Rate: 0.067925\n",
      "Epoch: 6416, MSE: 0.2585250485923946, Learning Rate: 0.06792000000000001\n",
      "Epoch: 6417, MSE: 0.25852262143041754, Learning Rate: 0.06791499999999999\n",
      "Epoch: 6418, MSE: 0.25852019421735495, Learning Rate: 0.06791000000000001\n",
      "Epoch: 6419, MSE: 0.25851776695320633, Learning Rate: 0.067905\n",
      "Epoch: 6420, MSE: 0.25851533963797335, Learning Rate: 0.0679\n",
      "Epoch: 6421, MSE: 0.2585129122716556, Learning Rate: 0.067895\n",
      "Epoch: 6422, MSE: 0.2585104848542517, Learning Rate: 0.06789\n",
      "Epoch: 6423, MSE: 0.258508057385764, Learning Rate: 0.067885\n",
      "Epoch: 6424, MSE: 0.25850562986619047, Learning Rate: 0.06788000000000001\n",
      "Epoch: 6425, MSE: 0.25850320229553336, Learning Rate: 0.067875\n",
      "Epoch: 6426, MSE: 0.25850077467379023, Learning Rate: 0.06787000000000001\n",
      "Epoch: 6427, MSE: 0.2584983470009635, Learning Rate: 0.067865\n",
      "Epoch: 6428, MSE: 0.25849591927705123, Learning Rate: 0.06786\n",
      "Epoch: 6429, MSE: 0.2584934915020547, Learning Rate: 0.067855\n",
      "Epoch: 6430, MSE: 0.2584910636759736, Learning Rate: 0.06785000000000001\n",
      "Epoch: 6431, MSE: 0.25848863579880876, Learning Rate: 0.067845\n",
      "Epoch: 6432, MSE: 0.2584862078705592, Learning Rate: 0.06784\n",
      "Epoch: 6433, MSE: 0.2584837798912251, Learning Rate: 0.067835\n",
      "Epoch: 6434, MSE: 0.25848135186080795, Learning Rate: 0.06783\n",
      "Epoch: 6435, MSE: 0.2584789237793062, Learning Rate: 0.06782500000000001\n",
      "Epoch: 6436, MSE: 0.25847649564672, Learning Rate: 0.06782\n",
      "Epoch: 6437, MSE: 0.25847406746305085, Learning Rate: 0.067815\n",
      "Epoch: 6438, MSE: 0.25847163922829736, Learning Rate: 0.06781\n",
      "Epoch: 6439, MSE: 0.2584692109424599, Learning Rate: 0.067805\n",
      "Epoch: 6440, MSE: 0.2584667826055395, Learning Rate: 0.0678\n",
      "Epoch: 6441, MSE: 0.2584643542175345, Learning Rate: 0.06779500000000001\n",
      "Epoch: 6442, MSE: 0.2584619257784472, Learning Rate: 0.06779\n",
      "Epoch: 6443, MSE: 0.25845949728827616, Learning Rate: 0.06778500000000001\n",
      "Epoch: 6444, MSE: 0.25845706874702135, Learning Rate: 0.06777999999999999\n",
      "Epoch: 6445, MSE: 0.2584546401546832, Learning Rate: 0.06777500000000002\n",
      "Epoch: 6446, MSE: 0.2584522115112628, Learning Rate: 0.06777\n",
      "Epoch: 6447, MSE: 0.25844978281675896, Learning Rate: 0.067765\n",
      "Epoch: 6448, MSE: 0.25844735407117164, Learning Rate: 0.06776\n",
      "Epoch: 6449, MSE: 0.2584449252745025, Learning Rate: 0.067755\n",
      "Epoch: 6450, MSE: 0.25844249642674894, Learning Rate: 0.06775\n",
      "Epoch: 6451, MSE: 0.25844006752791354, Learning Rate: 0.067745\n",
      "Epoch: 6452, MSE: 0.25843763857799545, Learning Rate: 0.06774000000000001\n",
      "Epoch: 6453, MSE: 0.25843520957699523, Learning Rate: 0.067735\n",
      "Epoch: 6454, MSE: 0.258432780524912, Learning Rate: 0.06773\n",
      "Epoch: 6455, MSE: 0.2584303514217466, Learning Rate: 0.06772500000000001\n",
      "Epoch: 6456, MSE: 0.2584279222674982, Learning Rate: 0.06772\n",
      "Epoch: 6457, MSE: 0.25842549306216883, Learning Rate: 0.067715\n",
      "Epoch: 6458, MSE: 0.2584230638057568, Learning Rate: 0.06771\n",
      "Epoch: 6459, MSE: 0.2584206344982621, Learning Rate: 0.067705\n",
      "Epoch: 6460, MSE: 0.2584182051396869, Learning Rate: 0.06770000000000001\n",
      "Epoch: 6461, MSE: 0.25841577573002805, Learning Rate: 0.06769499999999999\n",
      "Epoch: 6462, MSE: 0.2584133462692886, Learning Rate: 0.06769000000000001\n",
      "Epoch: 6463, MSE: 0.2584109167574668, Learning Rate: 0.067685\n",
      "Epoch: 6464, MSE: 0.2584084871945644, Learning Rate: 0.06768\n",
      "Epoch: 6465, MSE: 0.25840605758057955, Learning Rate: 0.067675\n",
      "Epoch: 6466, MSE: 0.2584036279155134, Learning Rate: 0.06767000000000001\n",
      "Epoch: 6467, MSE: 0.2584011981993665, Learning Rate: 0.067665\n",
      "Epoch: 6468, MSE: 0.25839876843213766, Learning Rate: 0.06766\n",
      "Epoch: 6469, MSE: 0.25839633861382805, Learning Rate: 0.067655\n",
      "Epoch: 6470, MSE: 0.2583939087444372, Learning Rate: 0.06765\n",
      "Epoch: 6471, MSE: 0.2583914788239654, Learning Rate: 0.067645\n",
      "Epoch: 6472, MSE: 0.2583890488524131, Learning Rate: 0.06764\n",
      "Epoch: 6473, MSE: 0.2583866188297796, Learning Rate: 0.067635\n",
      "Epoch: 6474, MSE: 0.2583841887560655, Learning Rate: 0.06763000000000001\n",
      "Epoch: 6475, MSE: 0.2583817586312705, Learning Rate: 0.067625\n",
      "Epoch: 6476, MSE: 0.25837932845539546, Learning Rate: 0.06762\n",
      "Epoch: 6477, MSE: 0.25837689822843984, Learning Rate: 0.06761500000000001\n",
      "Epoch: 6478, MSE: 0.25837446795040475, Learning Rate: 0.06760999999999999\n",
      "Epoch: 6479, MSE: 0.2583720376212886, Learning Rate: 0.06760500000000001\n",
      "Epoch: 6480, MSE: 0.25836960724109187, Learning Rate: 0.0676\n",
      "Epoch: 6481, MSE: 0.25836717680981564, Learning Rate: 0.067595\n",
      "Epoch: 6482, MSE: 0.2583647463274599, Learning Rate: 0.06759\n",
      "Epoch: 6483, MSE: 0.2583623157940243, Learning Rate: 0.067585\n",
      "Epoch: 6484, MSE: 0.2583598852095086, Learning Rate: 0.06758\n",
      "Epoch: 6485, MSE: 0.2583574545739129, Learning Rate: 0.06757500000000001\n",
      "Epoch: 6486, MSE: 0.25835502388723824, Learning Rate: 0.06757\n",
      "Epoch: 6487, MSE: 0.2583525931494842, Learning Rate: 0.067565\n",
      "Epoch: 6488, MSE: 0.25835016236065006, Learning Rate: 0.06756\n",
      "Epoch: 6489, MSE: 0.2583477315207369, Learning Rate: 0.067555\n",
      "Epoch: 6490, MSE: 0.2583453006297452, Learning Rate: 0.06755\n",
      "Epoch: 6491, MSE: 0.25834286968767384, Learning Rate: 0.06754500000000001\n",
      "Epoch: 6492, MSE: 0.25834043869452433, Learning Rate: 0.06754\n",
      "Epoch: 6493, MSE: 0.25833800765029546, Learning Rate: 0.067535\n",
      "Epoch: 6494, MSE: 0.25833557655498823, Learning Rate: 0.06753\n",
      "Epoch: 6495, MSE: 0.2583331454086013, Learning Rate: 0.067525\n",
      "Epoch: 6496, MSE: 0.2583307142111369, Learning Rate: 0.06752000000000001\n",
      "Epoch: 6497, MSE: 0.25832828296259347, Learning Rate: 0.06751499999999999\n",
      "Epoch: 6498, MSE: 0.2583258516629714, Learning Rate: 0.06751\n",
      "Epoch: 6499, MSE: 0.2583234203122719, Learning Rate: 0.067505\n",
      "Epoch: 6500, MSE: 0.2583209889104936, Learning Rate: 0.0675\n",
      "Epoch: 6501, MSE: 0.25831855745763754, Learning Rate: 0.067495\n",
      "Epoch: 6502, MSE: 0.25831612595370373, Learning Rate: 0.06749000000000001\n",
      "Epoch: 6503, MSE: 0.2583136943986925, Learning Rate: 0.067485\n",
      "Epoch: 6504, MSE: 0.258311262792603, Learning Rate: 0.06748000000000001\n",
      "Epoch: 6505, MSE: 0.2583088311354353, Learning Rate: 0.067475\n",
      "Epoch: 6506, MSE: 0.25830639942719114, Learning Rate: 0.06747000000000002\n",
      "Epoch: 6507, MSE: 0.25830396766786934, Learning Rate: 0.067465\n",
      "Epoch: 6508, MSE: 0.25830153585746984, Learning Rate: 0.06746\n",
      "Epoch: 6509, MSE: 0.2582991039959938, Learning Rate: 0.067455\n",
      "Epoch: 6510, MSE: 0.2582966720834394, Learning Rate: 0.06745\n",
      "Epoch: 6511, MSE: 0.25829424011980906, Learning Rate: 0.067445\n",
      "Epoch: 6512, MSE: 0.2582918081051019, Learning Rate: 0.06744\n",
      "Epoch: 6513, MSE: 0.2582893760393178, Learning Rate: 0.06743500000000001\n",
      "Epoch: 6514, MSE: 0.25828694392245694, Learning Rate: 0.06743\n",
      "Epoch: 6515, MSE: 0.25828451175451916, Learning Rate: 0.067425\n",
      "Epoch: 6516, MSE: 0.2582820795355054, Learning Rate: 0.06742000000000001\n",
      "Epoch: 6517, MSE: 0.25827964726541497, Learning Rate: 0.067415\n",
      "Epoch: 6518, MSE: 0.25827721494424943, Learning Rate: 0.06741\n",
      "Epoch: 6519, MSE: 0.2582747825720064, Learning Rate: 0.067405\n",
      "Epoch: 6520, MSE: 0.25827235014868805, Learning Rate: 0.0674\n",
      "Epoch: 6521, MSE: 0.25826991767429325, Learning Rate: 0.06739500000000001\n",
      "Epoch: 6522, MSE: 0.25826748514882303, Learning Rate: 0.06738999999999999\n",
      "Epoch: 6523, MSE: 0.25826505257227755, Learning Rate: 0.06738500000000001\n",
      "Epoch: 6524, MSE: 0.25826261994465605, Learning Rate: 0.06738\n",
      "Epoch: 6525, MSE: 0.2582601872659595, Learning Rate: 0.067375\n",
      "Epoch: 6526, MSE: 0.2582577545361869, Learning Rate: 0.06737\n",
      "Epoch: 6527, MSE: 0.25825532175533944, Learning Rate: 0.06736500000000001\n",
      "Epoch: 6528, MSE: 0.25825288892341697, Learning Rate: 0.06736\n",
      "Epoch: 6529, MSE: 0.25825045604041985, Learning Rate: 0.067355\n",
      "Epoch: 6530, MSE: 0.25824802310634715, Learning Rate: 0.06735000000000001\n",
      "Epoch: 6531, MSE: 0.2582455901212003, Learning Rate: 0.067345\n",
      "Epoch: 6532, MSE: 0.25824315708497764, Learning Rate: 0.06734\n",
      "Epoch: 6533, MSE: 0.25824072399768194, Learning Rate: 0.067335\n",
      "Epoch: 6534, MSE: 0.25823829085931094, Learning Rate: 0.06733\n",
      "Epoch: 6535, MSE: 0.25823585766986645, Learning Rate: 0.06732500000000001\n",
      "Epoch: 6536, MSE: 0.2582334244293467, Learning Rate: 0.06732\n",
      "Epoch: 6537, MSE: 0.2582309911377534, Learning Rate: 0.067315\n",
      "Epoch: 6538, MSE: 0.2582285577950861, Learning Rate: 0.06731000000000001\n",
      "Epoch: 6539, MSE: 0.2582261244013444, Learning Rate: 0.06730499999999999\n",
      "Epoch: 6540, MSE: 0.25822369095653036, Learning Rate: 0.06730000000000001\n",
      "Epoch: 6541, MSE: 0.2582212574606415, Learning Rate: 0.067295\n",
      "Epoch: 6542, MSE: 0.25821882391367995, Learning Rate: 0.06729\n",
      "Epoch: 6543, MSE: 0.25821639031564436, Learning Rate: 0.067285\n",
      "Epoch: 6544, MSE: 0.25821395666653574, Learning Rate: 0.06728\n",
      "Epoch: 6545, MSE: 0.2582115229663541, Learning Rate: 0.067275\n",
      "Epoch: 6546, MSE: 0.2582090892150991, Learning Rate: 0.06727000000000001\n",
      "Epoch: 6547, MSE: 0.2582066554127719, Learning Rate: 0.067265\n",
      "Epoch: 6548, MSE: 0.2582042215593718, Learning Rate: 0.06726\n",
      "Epoch: 6549, MSE: 0.2582017876548988, Learning Rate: 0.067255\n",
      "Epoch: 6550, MSE: 0.2581993536993531, Learning Rate: 0.06725\n",
      "Epoch: 6551, MSE: 0.2581969196927354, Learning Rate: 0.067245\n",
      "Epoch: 6552, MSE: 0.25819448563504516, Learning Rate: 0.06724000000000001\n",
      "Epoch: 6553, MSE: 0.25819205152628205, Learning Rate: 0.067235\n",
      "Epoch: 6554, MSE: 0.25818961736644835, Learning Rate: 0.06723\n",
      "Epoch: 6555, MSE: 0.2581871831555415, Learning Rate: 0.06722500000000001\n",
      "Epoch: 6556, MSE: 0.2581847488935636, Learning Rate: 0.06722\n",
      "Epoch: 6557, MSE: 0.2581823145805138, Learning Rate: 0.06721500000000001\n",
      "Epoch: 6558, MSE: 0.2581798802163927, Learning Rate: 0.06720999999999999\n",
      "Epoch: 6559, MSE: 0.25817744580120033, Learning Rate: 0.067205\n",
      "Epoch: 6560, MSE: 0.25817501133493603, Learning Rate: 0.0672\n",
      "Epoch: 6561, MSE: 0.25817257681760075, Learning Rate: 0.067195\n",
      "Epoch: 6562, MSE: 0.258170142249195, Learning Rate: 0.06719\n",
      "Epoch: 6563, MSE: 0.2581677076297177, Learning Rate: 0.06718500000000001\n",
      "Epoch: 6564, MSE: 0.25816527295917, Learning Rate: 0.06718\n",
      "Epoch: 6565, MSE: 0.2581628382375515, Learning Rate: 0.06717500000000001\n",
      "Epoch: 6566, MSE: 0.25816040346486263, Learning Rate: 0.06717\n",
      "Epoch: 6567, MSE: 0.25815796864110285, Learning Rate: 0.06716500000000002\n",
      "Epoch: 6568, MSE: 0.2581555337662733, Learning Rate: 0.06716\n",
      "Epoch: 6569, MSE: 0.25815309884037285, Learning Rate: 0.067155\n",
      "Epoch: 6570, MSE: 0.2581506638634032, Learning Rate: 0.06715\n",
      "Epoch: 6571, MSE: 0.25814822883536354, Learning Rate: 0.067145\n",
      "Epoch: 6572, MSE: 0.2581457937562539, Learning Rate: 0.06714\n",
      "Epoch: 6573, MSE: 0.258143358626075, Learning Rate: 0.067135\n",
      "Epoch: 6574, MSE: 0.25814092344482664, Learning Rate: 0.06713000000000001\n",
      "Epoch: 6575, MSE: 0.2581384882125081, Learning Rate: 0.067125\n",
      "Epoch: 6576, MSE: 0.25813605292912095, Learning Rate: 0.06712\n",
      "Epoch: 6577, MSE: 0.2581336175946643, Learning Rate: 0.06711500000000001\n",
      "Epoch: 6578, MSE: 0.2581311822091385, Learning Rate: 0.06711\n",
      "Epoch: 6579, MSE: 0.25812874677254505, Learning Rate: 0.067105\n",
      "Epoch: 6580, MSE: 0.2581263112848817, Learning Rate: 0.0671\n",
      "Epoch: 6581, MSE: 0.2581238757461505, Learning Rate: 0.067095\n",
      "Epoch: 6582, MSE: 0.25812144015635047, Learning Rate: 0.06709000000000001\n",
      "Epoch: 6583, MSE: 0.25811900451548253, Learning Rate: 0.06708499999999999\n",
      "Epoch: 6584, MSE: 0.2581165688235458, Learning Rate: 0.06708000000000001\n",
      "Epoch: 6585, MSE: 0.2581141330805413, Learning Rate: 0.067075\n",
      "Epoch: 6586, MSE: 0.25811169728646927, Learning Rate: 0.06707\n",
      "Epoch: 6587, MSE: 0.25810926144132973, Learning Rate: 0.067065\n",
      "Epoch: 6588, MSE: 0.2581068255451216, Learning Rate: 0.06706\n",
      "Epoch: 6589, MSE: 0.2581043895978467, Learning Rate: 0.067055\n",
      "Epoch: 6590, MSE: 0.25810195359950383, Learning Rate: 0.06705\n",
      "Epoch: 6591, MSE: 0.25809951755009414, Learning Rate: 0.06704500000000001\n",
      "Epoch: 6592, MSE: 0.2580970814496173, Learning Rate: 0.06704\n",
      "Epoch: 6593, MSE: 0.25809464529807385, Learning Rate: 0.067035\n",
      "Epoch: 6594, MSE: 0.2580922090954629, Learning Rate: 0.06703\n",
      "Epoch: 6595, MSE: 0.25808977284178586, Learning Rate: 0.067025\n",
      "Epoch: 6596, MSE: 0.258087336537042, Learning Rate: 0.06702000000000001\n",
      "Epoch: 6597, MSE: 0.2580849001812325, Learning Rate: 0.067015\n",
      "Epoch: 6598, MSE: 0.25808246377435556, Learning Rate: 0.06701\n",
      "Epoch: 6599, MSE: 0.258080027316413, Learning Rate: 0.06700500000000001\n",
      "Epoch: 6600, MSE: 0.2580775908074051, Learning Rate: 0.06699999999999999\n",
      "Epoch: 6601, MSE: 0.2580751542473295, Learning Rate: 0.06699500000000001\n",
      "Epoch: 6602, MSE: 0.2580727176361895, Learning Rate: 0.06699\n",
      "Epoch: 6603, MSE: 0.2580702809739841, Learning Rate: 0.066985\n",
      "Epoch: 6604, MSE: 0.2580678442607136, Learning Rate: 0.06698\n",
      "Epoch: 6605, MSE: 0.25806540749637685, Learning Rate: 0.066975\n",
      "Epoch: 6606, MSE: 0.2580629706809757, Learning Rate: 0.06697\n",
      "Epoch: 6607, MSE: 0.25806053381450944, Learning Rate: 0.06696500000000001\n",
      "Epoch: 6608, MSE: 0.2580580968969786, Learning Rate: 0.06696\n",
      "Epoch: 6609, MSE: 0.2580556599283828, Learning Rate: 0.066955\n",
      "Epoch: 6610, MSE: 0.25805322290872257, Learning Rate: 0.06695\n",
      "Epoch: 6611, MSE: 0.2580507858379974, Learning Rate: 0.066945\n",
      "Epoch: 6612, MSE: 0.2580483487162082, Learning Rate: 0.06694\n",
      "Epoch: 6613, MSE: 0.25804591154335504, Learning Rate: 0.06693500000000001\n",
      "Epoch: 6614, MSE: 0.2580434743194381, Learning Rate: 0.06693\n",
      "Epoch: 6615, MSE: 0.2580410370444573, Learning Rate: 0.066925\n",
      "Epoch: 6616, MSE: 0.2580385997184125, Learning Rate: 0.06692000000000001\n",
      "Epoch: 6617, MSE: 0.2580361623413041, Learning Rate: 0.066915\n",
      "Epoch: 6618, MSE: 0.2580337249131333, Learning Rate: 0.06691000000000001\n",
      "Epoch: 6619, MSE: 0.25803128743389847, Learning Rate: 0.06690499999999999\n",
      "Epoch: 6620, MSE: 0.25802884990360014, Learning Rate: 0.0669\n",
      "Epoch: 6621, MSE: 0.2580264123222397, Learning Rate: 0.066895\n",
      "Epoch: 6622, MSE: 0.258023974689816, Learning Rate: 0.06689\n",
      "Epoch: 6623, MSE: 0.2580215370063303, Learning Rate: 0.066885\n",
      "Epoch: 6624, MSE: 0.25801909927178157, Learning Rate: 0.06688000000000001\n",
      "Epoch: 6625, MSE: 0.25801666148617014, Learning Rate: 0.066875\n",
      "Epoch: 6626, MSE: 0.25801422364949694, Learning Rate: 0.06687000000000001\n",
      "Epoch: 6627, MSE: 0.25801178576176215, Learning Rate: 0.066865\n",
      "Epoch: 6628, MSE: 0.2580093478229645, Learning Rate: 0.06686000000000002\n",
      "Epoch: 6629, MSE: 0.25800690983310637, Learning Rate: 0.066855\n",
      "Epoch: 6630, MSE: 0.2580044717921856, Learning Rate: 0.06685\n",
      "Epoch: 6631, MSE: 0.25800203370020364, Learning Rate: 0.066845\n",
      "Epoch: 6632, MSE: 0.2579995955571602, Learning Rate: 0.06684\n",
      "Epoch: 6633, MSE: 0.25799715736305623, Learning Rate: 0.066835\n",
      "Epoch: 6634, MSE: 0.2579947191178907, Learning Rate: 0.06683\n",
      "Epoch: 6635, MSE: 0.25799228082166503, Learning Rate: 0.06682500000000001\n",
      "Epoch: 6636, MSE: 0.2579898424743781, Learning Rate: 0.06682\n",
      "Epoch: 6637, MSE: 0.25798740407603116, Learning Rate: 0.066815\n",
      "Epoch: 6638, MSE: 0.2579849656266242, Learning Rate: 0.06681000000000001\n",
      "Epoch: 6639, MSE: 0.2579825271261561, Learning Rate: 0.066805\n",
      "Epoch: 6640, MSE: 0.2579800885746284, Learning Rate: 0.0668\n",
      "Epoch: 6641, MSE: 0.2579776499720406, Learning Rate: 0.06679500000000001\n",
      "Epoch: 6642, MSE: 0.2579752113183938, Learning Rate: 0.06679\n",
      "Epoch: 6643, MSE: 0.25797277261368556, Learning Rate: 0.06678500000000001\n",
      "Epoch: 6644, MSE: 0.25797033385791984, Learning Rate: 0.06677999999999999\n",
      "Epoch: 6645, MSE: 0.2579678950510942, Learning Rate: 0.06677500000000001\n",
      "Epoch: 6646, MSE: 0.2579654561932096, Learning Rate: 0.06677\n",
      "Epoch: 6647, MSE: 0.2579630172842654, Learning Rate: 0.066765\n",
      "Epoch: 6648, MSE: 0.2579605783242628, Learning Rate: 0.06676\n",
      "Epoch: 6649, MSE: 0.2579581393132022, Learning Rate: 0.066755\n",
      "Epoch: 6650, MSE: 0.25795570025108255, Learning Rate: 0.06675\n",
      "Epoch: 6651, MSE: 0.2579532611379049, Learning Rate: 0.066745\n",
      "Epoch: 6652, MSE: 0.2579508219736684, Learning Rate: 0.06674000000000001\n",
      "Epoch: 6653, MSE: 0.2579483827583755, Learning Rate: 0.066735\n",
      "Epoch: 6654, MSE: 0.25794594349202327, Learning Rate: 0.06673\n",
      "Epoch: 6655, MSE: 0.25794350417461337, Learning Rate: 0.066725\n",
      "Epoch: 6656, MSE: 0.2579410648061467, Learning Rate: 0.06672\n",
      "Epoch: 6657, MSE: 0.25793862538662216, Learning Rate: 0.06671500000000001\n",
      "Epoch: 6658, MSE: 0.2579361859160407, Learning Rate: 0.06671\n",
      "Epoch: 6659, MSE: 0.2579337463944027, Learning Rate: 0.066705\n",
      "Epoch: 6660, MSE: 0.2579313068217073, Learning Rate: 0.06670000000000001\n",
      "Epoch: 6661, MSE: 0.2579288671979556, Learning Rate: 0.06669499999999999\n",
      "Epoch: 6662, MSE: 0.2579264275231465, Learning Rate: 0.06669000000000001\n",
      "Epoch: 6663, MSE: 0.2579239877972817, Learning Rate: 0.066685\n",
      "Epoch: 6664, MSE: 0.257921548020361, Learning Rate: 0.06668\n",
      "Epoch: 6665, MSE: 0.25791910819238373, Learning Rate: 0.066675\n",
      "Epoch: 6666, MSE: 0.2579166683133506, Learning Rate: 0.06667000000000001\n",
      "Epoch: 6667, MSE: 0.2579142283832623, Learning Rate: 0.066665\n",
      "Epoch: 6668, MSE: 0.25791178840211787, Learning Rate: 0.06666000000000001\n",
      "Epoch: 6669, MSE: 0.25790934836991875, Learning Rate: 0.066655\n",
      "Epoch: 6670, MSE: 0.2579069082866642, Learning Rate: 0.06665\n",
      "Epoch: 6671, MSE: 0.2579044681523542, Learning Rate: 0.066645\n",
      "Epoch: 6672, MSE: 0.2579020279669901, Learning Rate: 0.06664\n",
      "Epoch: 6673, MSE: 0.2578995877305705, Learning Rate: 0.066635\n",
      "Epoch: 6674, MSE: 0.25789714744309666, Learning Rate: 0.06663000000000001\n",
      "Epoch: 6675, MSE: 0.257894707104569, Learning Rate: 0.066625\n",
      "Epoch: 6676, MSE: 0.25789226671498616, Learning Rate: 0.06662\n",
      "Epoch: 6677, MSE: 0.2578898262743499, Learning Rate: 0.06661500000000001\n",
      "Epoch: 6678, MSE: 0.2578873857826603, Learning Rate: 0.06661\n",
      "Epoch: 6679, MSE: 0.2578849452399164, Learning Rate: 0.06660500000000001\n",
      "Epoch: 6680, MSE: 0.25788250464611917, Learning Rate: 0.06659999999999999\n",
      "Epoch: 6681, MSE: 0.2578800640012681, Learning Rate: 0.066595\n",
      "Epoch: 6682, MSE: 0.25787762330536423, Learning Rate: 0.06659\n",
      "Epoch: 6683, MSE: 0.25787518255840736, Learning Rate: 0.066585\n",
      "Epoch: 6684, MSE: 0.2578727417603982, Learning Rate: 0.06658\n",
      "Epoch: 6685, MSE: 0.257870300911336, Learning Rate: 0.06657500000000001\n",
      "Epoch: 6686, MSE: 0.2578678600112215, Learning Rate: 0.06657\n",
      "Epoch: 6687, MSE: 0.25786541906005467, Learning Rate: 0.06656500000000001\n",
      "Epoch: 6688, MSE: 0.2578629780578352, Learning Rate: 0.06656\n",
      "Epoch: 6689, MSE: 0.2578605370045647, Learning Rate: 0.066555\n",
      "Epoch: 6690, MSE: 0.25785809590024106, Learning Rate: 0.06655\n",
      "Epoch: 6691, MSE: 0.25785565474486727, Learning Rate: 0.066545\n",
      "Epoch: 6692, MSE: 0.2578532135384417, Learning Rate: 0.06654\n",
      "Epoch: 6693, MSE: 0.25785077228096465, Learning Rate: 0.066535\n",
      "Epoch: 6694, MSE: 0.25784833097243637, Learning Rate: 0.06653\n",
      "Epoch: 6695, MSE: 0.2578458896128578, Learning Rate: 0.066525\n",
      "Epoch: 6696, MSE: 0.2578434482022279, Learning Rate: 0.06652000000000001\n",
      "Epoch: 6697, MSE: 0.25784100674054733, Learning Rate: 0.066515\n",
      "Epoch: 6698, MSE: 0.25783856522781734, Learning Rate: 0.06651\n",
      "Epoch: 6699, MSE: 0.2578361236640366, Learning Rate: 0.066505\n",
      "Epoch: 6700, MSE: 0.2578336820492055, Learning Rate: 0.0665\n",
      "Epoch: 6701, MSE: 0.2578312403833253, Learning Rate: 0.066495\n",
      "Epoch: 6702, MSE: 0.25782879866639485, Learning Rate: 0.06649000000000001\n",
      "Epoch: 6703, MSE: 0.2578263568984152, Learning Rate: 0.066485\n",
      "Epoch: 6704, MSE: 0.25782391507938646, Learning Rate: 0.06648000000000001\n",
      "Epoch: 6705, MSE: 0.25782147320930865, Learning Rate: 0.06647499999999999\n",
      "Epoch: 6706, MSE: 0.25781903128818223, Learning Rate: 0.06647000000000002\n",
      "Epoch: 6707, MSE: 0.25781658931600593, Learning Rate: 0.066465\n",
      "Epoch: 6708, MSE: 0.2578141472927823, Learning Rate: 0.06646\n",
      "Epoch: 6709, MSE: 0.2578117052185097, Learning Rate: 0.066455\n",
      "Epoch: 6710, MSE: 0.2578092630931892, Learning Rate: 0.06645\n",
      "Epoch: 6711, MSE: 0.2578068209168205, Learning Rate: 0.066445\n",
      "Epoch: 6712, MSE: 0.2578043786894046, Learning Rate: 0.06644\n",
      "Epoch: 6713, MSE: 0.25780193641093996, Learning Rate: 0.06643500000000001\n",
      "Epoch: 6714, MSE: 0.25779949408142844, Learning Rate: 0.06643\n",
      "Epoch: 6715, MSE: 0.2577970517008694, Learning Rate: 0.066425\n",
      "Epoch: 6716, MSE: 0.25779460926926334, Learning Rate: 0.06642\n",
      "Epoch: 6717, MSE: 0.257792166786611, Learning Rate: 0.066415\n",
      "Epoch: 6718, MSE: 0.25778972425291163, Learning Rate: 0.06641000000000001\n",
      "Epoch: 6719, MSE: 0.2577872816681658, Learning Rate: 0.066405\n",
      "Epoch: 6720, MSE: 0.2577848390323724, Learning Rate: 0.0664\n",
      "Epoch: 6721, MSE: 0.2577823963455345, Learning Rate: 0.06639500000000001\n",
      "Epoch: 6722, MSE: 0.25777995360765044, Learning Rate: 0.06638999999999999\n",
      "Epoch: 6723, MSE: 0.2577775108187202, Learning Rate: 0.06638500000000001\n",
      "Epoch: 6724, MSE: 0.2577750679787447, Learning Rate: 0.06638\n",
      "Epoch: 6725, MSE: 0.2577726250877232, Learning Rate: 0.066375\n",
      "Epoch: 6726, MSE: 0.25777018214565733, Learning Rate: 0.06637\n",
      "Epoch: 6727, MSE: 0.25776773915254536, Learning Rate: 0.06636500000000001\n",
      "Epoch: 6728, MSE: 0.2577652961083895, Learning Rate: 0.06636\n",
      "Epoch: 6729, MSE: 0.25776285301318896, Learning Rate: 0.066355\n",
      "Epoch: 6730, MSE: 0.2577604098669432, Learning Rate: 0.06635\n",
      "Epoch: 6731, MSE: 0.2577579666696531, Learning Rate: 0.066345\n",
      "Epoch: 6732, MSE: 0.2577555234213197, Learning Rate: 0.06634\n",
      "Epoch: 6733, MSE: 0.257753080121943, Learning Rate: 0.066335\n",
      "Epoch: 6734, MSE: 0.2577506367715213, Learning Rate: 0.06633\n",
      "Epoch: 6735, MSE: 0.25774819337005705, Learning Rate: 0.06632500000000001\n",
      "Epoch: 6736, MSE: 0.2577457499175493, Learning Rate: 0.06632\n",
      "Epoch: 6737, MSE: 0.2577433064139981, Learning Rate: 0.066315\n",
      "Epoch: 6738, MSE: 0.25774086285940384, Learning Rate: 0.06631000000000001\n",
      "Epoch: 6739, MSE: 0.2577384192537675, Learning Rate: 0.06630499999999999\n",
      "Epoch: 6740, MSE: 0.25773597559708866, Learning Rate: 0.06630000000000001\n",
      "Epoch: 6741, MSE: 0.25773353188936726, Learning Rate: 0.06629499999999999\n",
      "Epoch: 6742, MSE: 0.25773108813060347, Learning Rate: 0.06629\n",
      "Epoch: 6743, MSE: 0.25772864432079773, Learning Rate: 0.066285\n",
      "Epoch: 6744, MSE: 0.25772620045995054, Learning Rate: 0.06628\n",
      "Epoch: 6745, MSE: 0.25772375654806223, Learning Rate: 0.066275\n",
      "Epoch: 6746, MSE: 0.25772131258513215, Learning Rate: 0.06627000000000001\n",
      "Epoch: 6747, MSE: 0.257718868571161, Learning Rate: 0.066265\n",
      "Epoch: 6748, MSE: 0.2577164245061486, Learning Rate: 0.06626000000000001\n",
      "Epoch: 6749, MSE: 0.25771398039009574, Learning Rate: 0.066255\n",
      "Epoch: 6750, MSE: 0.2577115362230026, Learning Rate: 0.06625\n",
      "Epoch: 6751, MSE: 0.25770909200486836, Learning Rate: 0.066245\n",
      "Epoch: 6752, MSE: 0.25770664773569446, Learning Rate: 0.06624000000000001\n",
      "Epoch: 6753, MSE: 0.2577042034154808, Learning Rate: 0.066235\n",
      "Epoch: 6754, MSE: 0.25770175904422715, Learning Rate: 0.06623\n",
      "Epoch: 6755, MSE: 0.25769931462193424, Learning Rate: 0.066225\n",
      "Epoch: 6756, MSE: 0.25769687014860126, Learning Rate: 0.06622\n",
      "Epoch: 6757, MSE: 0.2576944256242296, Learning Rate: 0.06621500000000001\n",
      "Epoch: 6758, MSE: 0.2576919810488196, Learning Rate: 0.06621\n",
      "Epoch: 6759, MSE: 0.2576895364223695, Learning Rate: 0.066205\n",
      "Epoch: 6760, MSE: 0.25768709174488175, Learning Rate: 0.0662\n",
      "Epoch: 6761, MSE: 0.2576846470163558, Learning Rate: 0.066195\n",
      "Epoch: 6762, MSE: 0.2576822022367916, Learning Rate: 0.06619\n",
      "Epoch: 6763, MSE: 0.2576797574061891, Learning Rate: 0.06618500000000001\n",
      "Epoch: 6764, MSE: 0.25767731252454906, Learning Rate: 0.06618\n",
      "Epoch: 6765, MSE: 0.25767486759187175, Learning Rate: 0.06617500000000001\n",
      "Epoch: 6766, MSE: 0.2576724226081564, Learning Rate: 0.06616999999999999\n",
      "Epoch: 6767, MSE: 0.2576699775734044, Learning Rate: 0.06616500000000002\n",
      "Epoch: 6768, MSE: 0.25766753248761604, Learning Rate: 0.06616\n",
      "Epoch: 6769, MSE: 0.25766508735079013, Learning Rate: 0.066155\n",
      "Epoch: 6770, MSE: 0.25766264216292795, Learning Rate: 0.06615\n",
      "Epoch: 6771, MSE: 0.25766019692402936, Learning Rate: 0.066145\n",
      "Epoch: 6772, MSE: 0.2576577516340955, Learning Rate: 0.06614\n",
      "Epoch: 6773, MSE: 0.2576553062931248, Learning Rate: 0.066135\n",
      "Epoch: 6774, MSE: 0.2576528609011194, Learning Rate: 0.06613000000000001\n",
      "Epoch: 6775, MSE: 0.2576504154580776, Learning Rate: 0.066125\n",
      "Epoch: 6776, MSE: 0.2576479699640012, Learning Rate: 0.06612\n",
      "Epoch: 6777, MSE: 0.2576455244188894, Learning Rate: 0.06611500000000001\n",
      "Epoch: 6778, MSE: 0.257643078822743, Learning Rate: 0.06611\n",
      "Epoch: 6779, MSE: 0.25764063317556163, Learning Rate: 0.06610500000000001\n",
      "Epoch: 6780, MSE: 0.2576381874773465, Learning Rate: 0.0661\n",
      "Epoch: 6781, MSE: 0.257635741728097, Learning Rate: 0.066095\n",
      "Epoch: 6782, MSE: 0.25763329592781314, Learning Rate: 0.06609000000000001\n",
      "Epoch: 6783, MSE: 0.2576308500764959, Learning Rate: 0.06608499999999999\n",
      "Epoch: 6784, MSE: 0.2576284041741445, Learning Rate: 0.06608000000000001\n",
      "Epoch: 6785, MSE: 0.2576259582207596, Learning Rate: 0.066075\n",
      "Epoch: 6786, MSE: 0.25762351221634233, Learning Rate: 0.06607\n",
      "Epoch: 6787, MSE: 0.25762106616089214, Learning Rate: 0.066065\n",
      "Epoch: 6788, MSE: 0.25761862005440944, Learning Rate: 0.06606000000000001\n",
      "Epoch: 6789, MSE: 0.25761617389689345, Learning Rate: 0.066055\n",
      "Epoch: 6790, MSE: 0.2576137276883454, Learning Rate: 0.06605\n",
      "Epoch: 6791, MSE: 0.25761128142876605, Learning Rate: 0.066045\n",
      "Epoch: 6792, MSE: 0.2576088351181537, Learning Rate: 0.06604\n",
      "Epoch: 6793, MSE: 0.25760638875651043, Learning Rate: 0.066035\n",
      "Epoch: 6794, MSE: 0.25760394234383494, Learning Rate: 0.06603\n",
      "Epoch: 6795, MSE: 0.257601495880129, Learning Rate: 0.066025\n",
      "Epoch: 6796, MSE: 0.25759904936539235, Learning Rate: 0.06602000000000001\n",
      "Epoch: 6797, MSE: 0.25759660279962426, Learning Rate: 0.066015\n",
      "Epoch: 6798, MSE: 0.25759415618282516, Learning Rate: 0.06601\n",
      "Epoch: 6799, MSE: 0.2575917095149972, Learning Rate: 0.06600500000000001\n",
      "Epoch: 6800, MSE: 0.25758926279613775, Learning Rate: 0.06599999999999999\n",
      "Epoch: 6801, MSE: 0.25758681602624944, Learning Rate: 0.06599500000000001\n",
      "Epoch: 6802, MSE: 0.25758436920533123, Learning Rate: 0.06599\n",
      "Epoch: 6803, MSE: 0.25758192233338323, Learning Rate: 0.065985\n",
      "Epoch: 6804, MSE: 0.2575794754104067, Learning Rate: 0.06598\n",
      "Epoch: 6805, MSE: 0.25757702843640023, Learning Rate: 0.065975\n",
      "Epoch: 6806, MSE: 0.2575745814113656, Learning Rate: 0.06597\n",
      "Epoch: 6807, MSE: 0.25757213433530185, Learning Rate: 0.06596500000000001\n",
      "Epoch: 6808, MSE: 0.25756968720821005, Learning Rate: 0.06596\n",
      "Epoch: 6809, MSE: 0.25756724003009046, Learning Rate: 0.06595500000000001\n",
      "Epoch: 6810, MSE: 0.25756479280094224, Learning Rate: 0.06595\n",
      "Epoch: 6811, MSE: 0.25756234552076634, Learning Rate: 0.065945\n",
      "Epoch: 6812, MSE: 0.2575598981895633, Learning Rate: 0.06594\n",
      "Epoch: 6813, MSE: 0.2575574508073333, Learning Rate: 0.06593500000000001\n",
      "Epoch: 6814, MSE: 0.2575550033740763, Learning Rate: 0.06593\n",
      "Epoch: 6815, MSE: 0.25755255588979187, Learning Rate: 0.065925\n",
      "Epoch: 6816, MSE: 0.2575501083544812, Learning Rate: 0.06592\n",
      "Epoch: 6817, MSE: 0.2575476607681447, Learning Rate: 0.065915\n",
      "Epoch: 6818, MSE: 0.2575452131307811, Learning Rate: 0.06591000000000001\n",
      "Epoch: 6819, MSE: 0.25754276544239246, Learning Rate: 0.065905\n",
      "Epoch: 6820, MSE: 0.257540317702978, Learning Rate: 0.0659\n",
      "Epoch: 6821, MSE: 0.25753786991253796, Learning Rate: 0.065895\n",
      "Epoch: 6822, MSE: 0.2575354220710721, Learning Rate: 0.06589\n",
      "Epoch: 6823, MSE: 0.25753297417858223, Learning Rate: 0.065885\n",
      "Epoch: 6824, MSE: 0.2575305262350674, Learning Rate: 0.06588000000000001\n",
      "Epoch: 6825, MSE: 0.2575280782405275, Learning Rate: 0.065875\n",
      "Epoch: 6826, MSE: 0.25752563019496405, Learning Rate: 0.06587000000000001\n",
      "Epoch: 6827, MSE: 0.2575231820983762, Learning Rate: 0.06586499999999999\n",
      "Epoch: 6828, MSE: 0.25752073395076425, Learning Rate: 0.06586000000000002\n",
      "Epoch: 6829, MSE: 0.2575182857521289, Learning Rate: 0.065855\n",
      "Epoch: 6830, MSE: 0.25751583750247037, Learning Rate: 0.06585\n",
      "Epoch: 6831, MSE: 0.25751338920178823, Learning Rate: 0.065845\n",
      "Epoch: 6832, MSE: 0.25751094085008314, Learning Rate: 0.06584\n",
      "Epoch: 6833, MSE: 0.25750849244735624, Learning Rate: 0.065835\n",
      "Epoch: 6834, MSE: 0.2575060439936058, Learning Rate: 0.06583\n",
      "Epoch: 6835, MSE: 0.25750359548883395, Learning Rate: 0.06582500000000001\n",
      "Epoch: 6836, MSE: 0.2575011469330391, Learning Rate: 0.06582\n",
      "Epoch: 6837, MSE: 0.25749869832622396, Learning Rate: 0.065815\n",
      "Epoch: 6838, MSE: 0.25749624966838613, Learning Rate: 0.06581000000000001\n",
      "Epoch: 6839, MSE: 0.25749380095952795, Learning Rate: 0.065805\n",
      "Epoch: 6840, MSE: 0.25749135219964786, Learning Rate: 0.0658\n",
      "Epoch: 6841, MSE: 0.25748890338874786, Learning Rate: 0.065795\n",
      "Epoch: 6842, MSE: 0.2574864545268264, Learning Rate: 0.06579\n",
      "Epoch: 6843, MSE: 0.2574840056138851, Learning Rate: 0.06578500000000001\n",
      "Epoch: 6844, MSE: 0.25748155664992345, Learning Rate: 0.06577999999999999\n",
      "Epoch: 6845, MSE: 0.2574791076349421, Learning Rate: 0.06577500000000001\n",
      "Epoch: 6846, MSE: 0.25747665856894064, Learning Rate: 0.06577\n",
      "Epoch: 6847, MSE: 0.2574742094519202, Learning Rate: 0.065765\n",
      "Epoch: 6848, MSE: 0.25747176028388036, Learning Rate: 0.06576\n",
      "Epoch: 6849, MSE: 0.2574693110648223, Learning Rate: 0.06575500000000001\n",
      "Epoch: 6850, MSE: 0.25746686179474476, Learning Rate: 0.06575\n",
      "Epoch: 6851, MSE: 0.2574644124736489, Learning Rate: 0.065745\n",
      "Epoch: 6852, MSE: 0.2574619631015347, Learning Rate: 0.06574\n",
      "Epoch: 6853, MSE: 0.2574595136784032, Learning Rate: 0.065735\n",
      "Epoch: 6854, MSE: 0.25745706420425346, Learning Rate: 0.06573\n",
      "Epoch: 6855, MSE: 0.2574546146790866, Learning Rate: 0.065725\n",
      "Epoch: 6856, MSE: 0.25745216510290236, Learning Rate: 0.06572\n",
      "Epoch: 6857, MSE: 0.25744971547570106, Learning Rate: 0.06571500000000001\n",
      "Epoch: 6858, MSE: 0.25744726579748256, Learning Rate: 0.06571\n",
      "Epoch: 6859, MSE: 0.25744481606824715, Learning Rate: 0.065705\n",
      "Epoch: 6860, MSE: 0.2574423662879974, Learning Rate: 0.06570000000000001\n",
      "Epoch: 6861, MSE: 0.25743991645673053, Learning Rate: 0.06569499999999999\n",
      "Epoch: 6862, MSE: 0.25743746657444755, Learning Rate: 0.06569000000000001\n",
      "Epoch: 6863, MSE: 0.25743501664114904, Learning Rate: 0.065685\n",
      "Epoch: 6864, MSE: 0.2574325666568357, Learning Rate: 0.06568\n",
      "Epoch: 6865, MSE: 0.25743011662150683, Learning Rate: 0.065675\n",
      "Epoch: 6866, MSE: 0.2574276665351636, Learning Rate: 0.06567\n",
      "Epoch: 6867, MSE: 0.25742521639780586, Learning Rate: 0.065665\n",
      "Epoch: 6868, MSE: 0.25742276620943283, Learning Rate: 0.06566000000000001\n",
      "Epoch: 6869, MSE: 0.25742031597004644, Learning Rate: 0.065655\n",
      "Epoch: 6870, MSE: 0.25741786567964575, Learning Rate: 0.06565\n",
      "Epoch: 6871, MSE: 0.25741541533823237, Learning Rate: 0.065645\n",
      "Epoch: 6872, MSE: 0.2574129649458048, Learning Rate: 0.06564\n",
      "Epoch: 6873, MSE: 0.25741051450236485, Learning Rate: 0.065635\n",
      "Epoch: 6874, MSE: 0.25740806400791183, Learning Rate: 0.06563000000000001\n",
      "Epoch: 6875, MSE: 0.25740561346244606, Learning Rate: 0.065625\n",
      "Epoch: 6876, MSE: 0.2574031628659671, Learning Rate: 0.06562\n",
      "Epoch: 6877, MSE: 0.25740071221847777, Learning Rate: 0.065615\n",
      "Epoch: 6878, MSE: 0.25739826151997547, Learning Rate: 0.06561\n",
      "Epoch: 6879, MSE: 0.257395810770462, Learning Rate: 0.06560500000000001\n",
      "Epoch: 6880, MSE: 0.2573933599699366, Learning Rate: 0.0656\n",
      "Epoch: 6881, MSE: 0.2573909091184006, Learning Rate: 0.065595\n",
      "Epoch: 6882, MSE: 0.25738845821585377, Learning Rate: 0.06559\n",
      "Epoch: 6883, MSE: 0.2573860072622962, Learning Rate: 0.065585\n",
      "Epoch: 6884, MSE: 0.2573835562577281, Learning Rate: 0.06558\n",
      "Epoch: 6885, MSE: 0.25738110520215035, Learning Rate: 0.06557500000000001\n",
      "Epoch: 6886, MSE: 0.2573786540955626, Learning Rate: 0.06557\n",
      "Epoch: 6887, MSE: 0.25737620293796576, Learning Rate: 0.06556500000000001\n",
      "Epoch: 6888, MSE: 0.2573737517293585, Learning Rate: 0.06556\n",
      "Epoch: 6889, MSE: 0.25737130046974316, Learning Rate: 0.06555500000000002\n",
      "Epoch: 6890, MSE: 0.2573688491591175, Learning Rate: 0.06555\n",
      "Epoch: 6891, MSE: 0.25736639779748527, Learning Rate: 0.065545\n",
      "Epoch: 6892, MSE: 0.25736394638484367, Learning Rate: 0.06554\n",
      "Epoch: 6893, MSE: 0.2573614949211939, Learning Rate: 0.065535\n",
      "Epoch: 6894, MSE: 0.25735904340653704, Learning Rate: 0.06553\n",
      "Epoch: 6895, MSE: 0.2573565918408723, Learning Rate: 0.065525\n",
      "Epoch: 6896, MSE: 0.25735414022419983, Learning Rate: 0.06552000000000001\n",
      "Epoch: 6897, MSE: 0.25735168855652135, Learning Rate: 0.065515\n",
      "Epoch: 6898, MSE: 0.2573492368378349, Learning Rate: 0.06551\n",
      "Epoch: 6899, MSE: 0.25734678506814246, Learning Rate: 0.06550500000000001\n",
      "Epoch: 6900, MSE: 0.25734433324744443, Learning Rate: 0.0655\n",
      "Epoch: 6901, MSE: 0.25734188137573893, Learning Rate: 0.065495\n",
      "Epoch: 6902, MSE: 0.2573394294530287, Learning Rate: 0.06549\n",
      "Epoch: 6903, MSE: 0.25733697747931333, Learning Rate: 0.065485\n",
      "Epoch: 6904, MSE: 0.2573345254545922, Learning Rate: 0.06548000000000001\n",
      "Epoch: 6905, MSE: 0.2573320733788662, Learning Rate: 0.06547499999999999\n",
      "Epoch: 6906, MSE: 0.2573296212521351, Learning Rate: 0.06547000000000001\n",
      "Epoch: 6907, MSE: 0.25732716907440045, Learning Rate: 0.065465\n",
      "Epoch: 6908, MSE: 0.2573247168456605, Learning Rate: 0.06546\n",
      "Epoch: 6909, MSE: 0.25732226456591756, Learning Rate: 0.065455\n",
      "Epoch: 6910, MSE: 0.2573198122351703, Learning Rate: 0.06545000000000001\n",
      "Epoch: 6911, MSE: 0.257317359853421, Learning Rate: 0.065445\n",
      "Epoch: 6912, MSE: 0.25731490742066726, Learning Rate: 0.06544\n",
      "Epoch: 6913, MSE: 0.25731245493691074, Learning Rate: 0.06543500000000001\n",
      "Epoch: 6914, MSE: 0.257310002402152, Learning Rate: 0.06543\n",
      "Epoch: 6915, MSE: 0.2573075498163911, Learning Rate: 0.065425\n",
      "Epoch: 6916, MSE: 0.25730509717962846, Learning Rate: 0.06542\n",
      "Epoch: 6917, MSE: 0.25730264449186285, Learning Rate: 0.065415\n",
      "Epoch: 6918, MSE: 0.257300191753097, Learning Rate: 0.06541000000000001\n",
      "Epoch: 6919, MSE: 0.257297738963329, Learning Rate: 0.065405\n",
      "Epoch: 6920, MSE: 0.25729528612256053, Learning Rate: 0.0654\n",
      "Epoch: 6921, MSE: 0.257292833230791, Learning Rate: 0.06539500000000001\n",
      "Epoch: 6922, MSE: 0.2572903802880203, Learning Rate: 0.06538999999999999\n",
      "Epoch: 6923, MSE: 0.2572879272942505, Learning Rate: 0.06538500000000001\n",
      "Epoch: 6924, MSE: 0.2572854742494806, Learning Rate: 0.06538\n",
      "Epoch: 6925, MSE: 0.2572830211537113, Learning Rate: 0.065375\n",
      "Epoch: 6926, MSE: 0.2572805680069418, Learning Rate: 0.06537\n",
      "Epoch: 6927, MSE: 0.25727811480917345, Learning Rate: 0.065365\n",
      "Epoch: 6928, MSE: 0.25727566156040627, Learning Rate: 0.06536\n",
      "Epoch: 6929, MSE: 0.25727320826064126, Learning Rate: 0.06535500000000001\n",
      "Epoch: 6930, MSE: 0.25727075490987716, Learning Rate: 0.06535\n",
      "Epoch: 6931, MSE: 0.2572683015081152, Learning Rate: 0.065345\n",
      "Epoch: 6932, MSE: 0.2572658480553561, Learning Rate: 0.06534\n",
      "Epoch: 6933, MSE: 0.25726339455159875, Learning Rate: 0.065335\n",
      "Epoch: 6934, MSE: 0.25726094099684454, Learning Rate: 0.06533\n",
      "Epoch: 6935, MSE: 0.257258487391093, Learning Rate: 0.06532500000000001\n",
      "Epoch: 6936, MSE: 0.2572560337343451, Learning Rate: 0.06532\n",
      "Epoch: 6937, MSE: 0.2572535800266005, Learning Rate: 0.065315\n",
      "Epoch: 6938, MSE: 0.25725112626786023, Learning Rate: 0.06531\n",
      "Epoch: 6939, MSE: 0.2572486724581243, Learning Rate: 0.065305\n",
      "Epoch: 6940, MSE: 0.2572462185973918, Learning Rate: 0.06530000000000001\n",
      "Epoch: 6941, MSE: 0.2572437646856644, Learning Rate: 0.06529499999999999\n",
      "Epoch: 6942, MSE: 0.25724131072294243, Learning Rate: 0.06529\n",
      "Epoch: 6943, MSE: 0.2572388567092258, Learning Rate: 0.065285\n",
      "Epoch: 6944, MSE: 0.2572364026445141, Learning Rate: 0.06528\n",
      "Epoch: 6945, MSE: 0.25723394852880826, Learning Rate: 0.065275\n",
      "Epoch: 6946, MSE: 0.2572314943621088, Learning Rate: 0.06527000000000001\n",
      "Epoch: 6947, MSE: 0.25722904014441594, Learning Rate: 0.065265\n",
      "Epoch: 6948, MSE: 0.257226585875729, Learning Rate: 0.06526000000000001\n",
      "Epoch: 6949, MSE: 0.2572241315560497, Learning Rate: 0.065255\n",
      "Epoch: 6950, MSE: 0.2572216771853775, Learning Rate: 0.06525000000000002\n",
      "Epoch: 6951, MSE: 0.2572192227637125, Learning Rate: 0.065245\n",
      "Epoch: 6952, MSE: 0.25721676829105566, Learning Rate: 0.06524\n",
      "Epoch: 6953, MSE: 0.25721431376740633, Learning Rate: 0.065235\n",
      "Epoch: 6954, MSE: 0.25721185919276596, Learning Rate: 0.06523\n",
      "Epoch: 6955, MSE: 0.257209404567133, Learning Rate: 0.065225\n",
      "Epoch: 6956, MSE: 0.25720694989050974, Learning Rate: 0.06522\n",
      "Epoch: 6957, MSE: 0.25720449516289573, Learning Rate: 0.06521500000000001\n",
      "Epoch: 6958, MSE: 0.2572020403842912, Learning Rate: 0.06521\n",
      "Epoch: 6959, MSE: 0.2571995855546964, Learning Rate: 0.065205\n",
      "Epoch: 6960, MSE: 0.25719713067411165, Learning Rate: 0.06520000000000001\n",
      "Epoch: 6961, MSE: 0.25719467574253724, Learning Rate: 0.065195\n",
      "Epoch: 6962, MSE: 0.25719222075997294, Learning Rate: 0.06519\n",
      "Epoch: 6963, MSE: 0.2571897657264199, Learning Rate: 0.065185\n",
      "Epoch: 6964, MSE: 0.25718731064187805, Learning Rate: 0.06518\n",
      "Epoch: 6965, MSE: 0.2571848555063476, Learning Rate: 0.06517500000000001\n",
      "Epoch: 6966, MSE: 0.25718240031982875, Learning Rate: 0.06516999999999999\n",
      "Epoch: 6967, MSE: 0.2571799450823217, Learning Rate: 0.06516500000000001\n",
      "Epoch: 6968, MSE: 0.2571774897938275, Learning Rate: 0.06516\n",
      "Epoch: 6969, MSE: 0.25717503445434525, Learning Rate: 0.065155\n",
      "Epoch: 6970, MSE: 0.25717257906387636, Learning Rate: 0.06515\n",
      "Epoch: 6971, MSE: 0.2571701236224203, Learning Rate: 0.065145\n",
      "Epoch: 6972, MSE: 0.25716766812997743, Learning Rate: 0.06514\n",
      "Epoch: 6973, MSE: 0.257165212586549, Learning Rate: 0.065135\n",
      "Epoch: 6974, MSE: 0.2571627569921342, Learning Rate: 0.06513000000000001\n",
      "Epoch: 6975, MSE: 0.25716030134673384, Learning Rate: 0.065125\n",
      "Epoch: 6976, MSE: 0.25715784565034877, Learning Rate: 0.06512\n",
      "Epoch: 6977, MSE: 0.2571553899029775, Learning Rate: 0.065115\n",
      "Epoch: 6978, MSE: 0.25715293410462153, Learning Rate: 0.06511\n",
      "Epoch: 6979, MSE: 0.25715047825528153, Learning Rate: 0.06510500000000001\n",
      "Epoch: 6980, MSE: 0.25714802235495743, Learning Rate: 0.0651\n",
      "Epoch: 6981, MSE: 0.25714556640364844, Learning Rate: 0.065095\n",
      "Epoch: 6982, MSE: 0.2571431104013567, Learning Rate: 0.06509000000000001\n",
      "Epoch: 6983, MSE: 0.2571406543480813, Learning Rate: 0.06508499999999999\n",
      "Epoch: 6984, MSE: 0.25713819824382317, Learning Rate: 0.06508000000000001\n",
      "Epoch: 6985, MSE: 0.25713574208858125, Learning Rate: 0.065075\n",
      "Epoch: 6986, MSE: 0.25713328588235757, Learning Rate: 0.06507\n",
      "Epoch: 6987, MSE: 0.25713082962515205, Learning Rate: 0.065065\n",
      "Epoch: 6988, MSE: 0.2571283733169644, Learning Rate: 0.06506\n",
      "Epoch: 6989, MSE: 0.2571259169577947, Learning Rate: 0.065055\n",
      "Epoch: 6990, MSE: 0.2571234605476443, Learning Rate: 0.06505000000000001\n",
      "Epoch: 6991, MSE: 0.25712100408651234, Learning Rate: 0.065045\n",
      "Epoch: 6992, MSE: 0.2571185475744002, Learning Rate: 0.06504\n",
      "Epoch: 6993, MSE: 0.2571160910113076, Learning Rate: 0.065035\n",
      "Epoch: 6994, MSE: 0.2571136343972348, Learning Rate: 0.06503\n",
      "Epoch: 6995, MSE: 0.2571111777321826, Learning Rate: 0.065025\n",
      "Epoch: 6996, MSE: 0.25710872101614995, Learning Rate: 0.06502000000000001\n",
      "Epoch: 6997, MSE: 0.2571062642491385, Learning Rate: 0.065015\n",
      "Epoch: 6998, MSE: 0.25710380743114797, Learning Rate: 0.06501\n",
      "Epoch: 6999, MSE: 0.25710135056217986, Learning Rate: 0.06500500000000001\n",
      "Epoch: 7000, MSE: 0.2570988936422325, Learning Rate: 0.065\n",
      "Epoch: 7001, MSE: 0.2570964366713072, Learning Rate: 0.06499500000000001\n",
      "Epoch: 7002, MSE: 0.25709397964940417, Learning Rate: 0.06498999999999999\n",
      "Epoch: 7003, MSE: 0.2570915225765239, Learning Rate: 0.064985\n",
      "Epoch: 7004, MSE: 0.25708906545266613, Learning Rate: 0.06498\n",
      "Epoch: 7005, MSE: 0.2570866082778323, Learning Rate: 0.064975\n",
      "Epoch: 7006, MSE: 0.25708415105202154, Learning Rate: 0.06497\n",
      "Epoch: 7007, MSE: 0.2570816937752343, Learning Rate: 0.06496500000000001\n",
      "Epoch: 7008, MSE: 0.257079236447471, Learning Rate: 0.06496\n",
      "Epoch: 7009, MSE: 0.25707677906873294, Learning Rate: 0.06495500000000001\n",
      "Epoch: 7010, MSE: 0.2570743216390195, Learning Rate: 0.06495\n",
      "Epoch: 7011, MSE: 0.2570718641583301, Learning Rate: 0.06494500000000002\n",
      "Epoch: 7012, MSE: 0.2570694066266667, Learning Rate: 0.06494\n",
      "Epoch: 7013, MSE: 0.25706694904402827, Learning Rate: 0.064935\n",
      "Epoch: 7014, MSE: 0.257064491410417, Learning Rate: 0.06493\n",
      "Epoch: 7015, MSE: 0.2570620337258313, Learning Rate: 0.064925\n",
      "Epoch: 7016, MSE: 0.2570595759902724, Learning Rate: 0.06492\n",
      "Epoch: 7017, MSE: 0.2570571182037401, Learning Rate: 0.064915\n",
      "Epoch: 7018, MSE: 0.2570546603662349, Learning Rate: 0.06491000000000001\n",
      "Epoch: 7019, MSE: 0.2570522024777569, Learning Rate: 0.064905\n",
      "Epoch: 7020, MSE: 0.2570497445383068, Learning Rate: 0.0649\n",
      "Epoch: 7021, MSE: 0.25704728654788506, Learning Rate: 0.06489500000000001\n",
      "Epoch: 7022, MSE: 0.25704482850649185, Learning Rate: 0.06489\n",
      "Epoch: 7023, MSE: 0.25704237041412703, Learning Rate: 0.064885\n",
      "Epoch: 7024, MSE: 0.25703991227079115, Learning Rate: 0.06488000000000001\n",
      "Epoch: 7025, MSE: 0.2570374540764854, Learning Rate: 0.064875\n",
      "Epoch: 7026, MSE: 0.25703499583120826, Learning Rate: 0.06487000000000001\n",
      "Epoch: 7027, MSE: 0.2570325375349613, Learning Rate: 0.06486499999999999\n",
      "Epoch: 7028, MSE: 0.2570300791877449, Learning Rate: 0.06486000000000001\n",
      "Epoch: 7029, MSE: 0.2570276207895582, Learning Rate: 0.064855\n",
      "Epoch: 7030, MSE: 0.2570251623404039, Learning Rate: 0.06485\n",
      "Epoch: 7031, MSE: 0.2570227038402794, Learning Rate: 0.064845\n",
      "Epoch: 7032, MSE: 0.25702024528918704, Learning Rate: 0.06484\n",
      "Epoch: 7033, MSE: 0.2570177866871261, Learning Rate: 0.064835\n",
      "Epoch: 7034, MSE: 0.25701532803409816, Learning Rate: 0.06483\n",
      "Epoch: 7035, MSE: 0.25701286933010187, Learning Rate: 0.06482500000000001\n",
      "Epoch: 7036, MSE: 0.2570104105751387, Learning Rate: 0.06482\n",
      "Epoch: 7037, MSE: 0.2570079517692081, Learning Rate: 0.064815\n",
      "Epoch: 7038, MSE: 0.2570054929123115, Learning Rate: 0.06481\n",
      "Epoch: 7039, MSE: 0.2570030340044476, Learning Rate: 0.064805\n",
      "Epoch: 7040, MSE: 0.25700057504561874, Learning Rate: 0.06480000000000001\n",
      "Epoch: 7041, MSE: 0.25699811603582395, Learning Rate: 0.064795\n",
      "Epoch: 7042, MSE: 0.2569956569750638, Learning Rate: 0.06479\n",
      "Epoch: 7043, MSE: 0.2569931978633381, Learning Rate: 0.06478500000000001\n",
      "Epoch: 7044, MSE: 0.2569907387006489, Learning Rate: 0.06477999999999999\n",
      "Epoch: 7045, MSE: 0.2569882794869945, Learning Rate: 0.06477500000000001\n",
      "Epoch: 7046, MSE: 0.2569858202223761, Learning Rate: 0.06477\n",
      "Epoch: 7047, MSE: 0.25698336090679397, Learning Rate: 0.064765\n",
      "Epoch: 7048, MSE: 0.25698090154024794, Learning Rate: 0.06476\n",
      "Epoch: 7049, MSE: 0.25697844212274035, Learning Rate: 0.06475500000000001\n",
      "Epoch: 7050, MSE: 0.2569759826542682, Learning Rate: 0.06475\n",
      "Epoch: 7051, MSE: 0.25697352313483407, Learning Rate: 0.06474500000000001\n",
      "Epoch: 7052, MSE: 0.2569710635644384, Learning Rate: 0.06474\n",
      "Epoch: 7053, MSE: 0.25696860394307963, Learning Rate: 0.064735\n",
      "Epoch: 7054, MSE: 0.2569661442707607, Learning Rate: 0.06473\n",
      "Epoch: 7055, MSE: 0.2569636845474802, Learning Rate: 0.064725\n",
      "Epoch: 7056, MSE: 0.2569612247732385, Learning Rate: 0.06472\n",
      "Epoch: 7057, MSE: 0.25695876494803616, Learning Rate: 0.06471500000000001\n",
      "Epoch: 7058, MSE: 0.2569563050718744, Learning Rate: 0.06471\n",
      "Epoch: 7059, MSE: 0.2569538451447525, Learning Rate: 0.064705\n",
      "Epoch: 7060, MSE: 0.2569513851666706, Learning Rate: 0.06470000000000001\n",
      "Epoch: 7061, MSE: 0.25694892513763007, Learning Rate: 0.064695\n",
      "Epoch: 7062, MSE: 0.25694646505763014, Learning Rate: 0.06469000000000001\n",
      "Epoch: 7063, MSE: 0.25694400492667113, Learning Rate: 0.06468499999999999\n",
      "Epoch: 7064, MSE: 0.25694154474475467, Learning Rate: 0.06468\n",
      "Epoch: 7065, MSE: 0.25693908451188013, Learning Rate: 0.064675\n",
      "Epoch: 7066, MSE: 0.25693662422804764, Learning Rate: 0.06467\n",
      "Epoch: 7067, MSE: 0.2569341638932583, Learning Rate: 0.064665\n",
      "Epoch: 7068, MSE: 0.2569317035075121, Learning Rate: 0.06466000000000001\n",
      "Epoch: 7069, MSE: 0.25692924307080917, Learning Rate: 0.064655\n",
      "Epoch: 7070, MSE: 0.25692678258314955, Learning Rate: 0.06465000000000001\n",
      "Epoch: 7071, MSE: 0.2569243220445342, Learning Rate: 0.064645\n",
      "Epoch: 7072, MSE: 0.2569218614549634, Learning Rate: 0.06464\n",
      "Epoch: 7073, MSE: 0.2569194008144368, Learning Rate: 0.064635\n",
      "Epoch: 7074, MSE: 0.25691694012295624, Learning Rate: 0.06463\n",
      "Epoch: 7075, MSE: 0.25691447938052003, Learning Rate: 0.064625\n",
      "Epoch: 7076, MSE: 0.25691201858713064, Learning Rate: 0.06462\n",
      "Epoch: 7077, MSE: 0.25690955774278557, Learning Rate: 0.064615\n",
      "Epoch: 7078, MSE: 0.25690709684748775, Learning Rate: 0.06461\n",
      "Epoch: 7079, MSE: 0.25690463590123713, Learning Rate: 0.06460500000000001\n",
      "Epoch: 7080, MSE: 0.2569021749040329, Learning Rate: 0.0646\n",
      "Epoch: 7081, MSE: 0.2568997138558764, Learning Rate: 0.064595\n",
      "Epoch: 7082, MSE: 0.2568972527567672, Learning Rate: 0.06459\n",
      "Epoch: 7083, MSE: 0.25689479160670625, Learning Rate: 0.064585\n",
      "Epoch: 7084, MSE: 0.25689233040569376, Learning Rate: 0.06458\n",
      "Epoch: 7085, MSE: 0.2568898691537303, Learning Rate: 0.06457500000000001\n",
      "Epoch: 7086, MSE: 0.25688740785081504, Learning Rate: 0.06457\n",
      "Epoch: 7087, MSE: 0.256884946496949, Learning Rate: 0.06456500000000001\n",
      "Epoch: 7088, MSE: 0.2568824850921338, Learning Rate: 0.06455999999999999\n",
      "Epoch: 7089, MSE: 0.2568800236363675, Learning Rate: 0.06455500000000002\n",
      "Epoch: 7090, MSE: 0.2568775621296525, Learning Rate: 0.06455\n",
      "Epoch: 7091, MSE: 0.25687510057198804, Learning Rate: 0.064545\n",
      "Epoch: 7092, MSE: 0.25687263896337476, Learning Rate: 0.06454\n",
      "Epoch: 7093, MSE: 0.25687017730381173, Learning Rate: 0.064535\n",
      "Epoch: 7094, MSE: 0.2568677155933019, Learning Rate: 0.06453\n",
      "Epoch: 7095, MSE: 0.25686525383184344, Learning Rate: 0.064525\n",
      "Epoch: 7096, MSE: 0.2568627920194371, Learning Rate: 0.06452000000000001\n",
      "Epoch: 7097, MSE: 0.2568603301560837, Learning Rate: 0.064515\n",
      "Epoch: 7098, MSE: 0.2568578682417843, Learning Rate: 0.06451\n",
      "Epoch: 7099, MSE: 0.25685540627653736, Learning Rate: 0.064505\n",
      "Epoch: 7100, MSE: 0.2568529442603441, Learning Rate: 0.0645\n",
      "Epoch: 7101, MSE: 0.25685048219320583, Learning Rate: 0.06449500000000001\n",
      "Epoch: 7102, MSE: 0.2568480200751208, Learning Rate: 0.06449\n",
      "Epoch: 7103, MSE: 0.2568455579060915, Learning Rate: 0.064485\n",
      "Epoch: 7104, MSE: 0.25684309568611746, Learning Rate: 0.06448000000000001\n",
      "Epoch: 7105, MSE: 0.2568406334151981, Learning Rate: 0.06447499999999999\n",
      "Epoch: 7106, MSE: 0.25683817109333495, Learning Rate: 0.06447000000000001\n",
      "Epoch: 7107, MSE: 0.2568357087205283, Learning Rate: 0.064465\n",
      "Epoch: 7108, MSE: 0.25683324629677795, Learning Rate: 0.06446\n",
      "Epoch: 7109, MSE: 0.25683078382208474, Learning Rate: 0.064455\n",
      "Epoch: 7110, MSE: 0.2568283212964486, Learning Rate: 0.06445000000000001\n",
      "Epoch: 7111, MSE: 0.25682585871986957, Learning Rate: 0.064445\n",
      "Epoch: 7112, MSE: 0.2568233960923491, Learning Rate: 0.06444\n",
      "Epoch: 7113, MSE: 0.25682093341388634, Learning Rate: 0.064435\n",
      "Epoch: 7114, MSE: 0.2568184706844827, Learning Rate: 0.06443\n",
      "Epoch: 7115, MSE: 0.25681600790413756, Learning Rate: 0.064425\n",
      "Epoch: 7116, MSE: 0.2568135450728517, Learning Rate: 0.06442\n",
      "Epoch: 7117, MSE: 0.25681108219062615, Learning Rate: 0.064415\n",
      "Epoch: 7118, MSE: 0.2568086192574602, Learning Rate: 0.06441000000000001\n",
      "Epoch: 7119, MSE: 0.2568061562733553, Learning Rate: 0.064405\n",
      "Epoch: 7120, MSE: 0.25680369323830987, Learning Rate: 0.0644\n",
      "Epoch: 7121, MSE: 0.2568012301523261, Learning Rate: 0.06439500000000001\n",
      "Epoch: 7122, MSE: 0.256798767015404, Learning Rate: 0.06438999999999999\n",
      "Epoch: 7123, MSE: 0.2567963038275428, Learning Rate: 0.06438500000000001\n",
      "Epoch: 7124, MSE: 0.2567938405887444, Learning Rate: 0.06437999999999999\n",
      "Epoch: 7125, MSE: 0.2567913772990079, Learning Rate: 0.064375\n",
      "Epoch: 7126, MSE: 0.256788913958335, Learning Rate: 0.06437\n",
      "Epoch: 7127, MSE: 0.25678645056672494, Learning Rate: 0.064365\n",
      "Epoch: 7128, MSE: 0.2567839871241786, Learning Rate: 0.06436\n",
      "Epoch: 7129, MSE: 0.2567815236306954, Learning Rate: 0.06435500000000001\n",
      "Epoch: 7130, MSE: 0.2567790600862773, Learning Rate: 0.06435\n",
      "Epoch: 7131, MSE: 0.256776596490923, Learning Rate: 0.06434500000000001\n",
      "Epoch: 7132, MSE: 0.25677413284463435, Learning Rate: 0.06434\n",
      "Epoch: 7133, MSE: 0.2567716691474103, Learning Rate: 0.064335\n",
      "Epoch: 7134, MSE: 0.25676920539925274, Learning Rate: 0.06433\n",
      "Epoch: 7135, MSE: 0.2567667416001608, Learning Rate: 0.06432500000000001\n",
      "Epoch: 7136, MSE: 0.2567642777501351, Learning Rate: 0.06432\n",
      "Epoch: 7137, MSE: 0.2567618138491762, Learning Rate: 0.064315\n",
      "Epoch: 7138, MSE: 0.2567593498972838, Learning Rate: 0.06431\n",
      "Epoch: 7139, MSE: 0.25675688589446, Learning Rate: 0.064305\n",
      "Epoch: 7140, MSE: 0.2567544218407036, Learning Rate: 0.06430000000000001\n",
      "Epoch: 7141, MSE: 0.25675195773601533, Learning Rate: 0.064295\n",
      "Epoch: 7142, MSE: 0.25674949358039517, Learning Rate: 0.06429\n",
      "Epoch: 7143, MSE: 0.2567470293738438, Learning Rate: 0.064285\n",
      "Epoch: 7144, MSE: 0.2567445651163623, Learning Rate: 0.06428\n",
      "Epoch: 7145, MSE: 0.2567421008079508, Learning Rate: 0.064275\n",
      "Epoch: 7146, MSE: 0.25673963644860825, Learning Rate: 0.06427000000000001\n",
      "Epoch: 7147, MSE: 0.2567371720383362, Learning Rate: 0.064265\n",
      "Epoch: 7148, MSE: 0.2567347075771349, Learning Rate: 0.06426000000000001\n",
      "Epoch: 7149, MSE: 0.25673224306500464, Learning Rate: 0.06425499999999999\n",
      "Epoch: 7150, MSE: 0.2567297785019457, Learning Rate: 0.06425000000000002\n",
      "Epoch: 7151, MSE: 0.2567273138879591, Learning Rate: 0.064245\n",
      "Epoch: 7152, MSE: 0.25672484922304434, Learning Rate: 0.06424\n",
      "Epoch: 7153, MSE: 0.2567223845072019, Learning Rate: 0.064235\n",
      "Epoch: 7154, MSE: 0.2567199197404325, Learning Rate: 0.06423\n",
      "Epoch: 7155, MSE: 0.256717454922736, Learning Rate: 0.064225\n",
      "Epoch: 7156, MSE: 0.25671499005411325, Learning Rate: 0.06422\n",
      "Epoch: 7157, MSE: 0.25671252513456544, Learning Rate: 0.06421500000000001\n",
      "Epoch: 7158, MSE: 0.2567100601640906, Learning Rate: 0.06421\n",
      "Epoch: 7159, MSE: 0.2567075951426908, Learning Rate: 0.064205\n",
      "Epoch: 7160, MSE: 0.25670513007036644, Learning Rate: 0.06420000000000001\n",
      "Epoch: 7161, MSE: 0.2567026649471172, Learning Rate: 0.064195\n",
      "Epoch: 7162, MSE: 0.2567001997729443, Learning Rate: 0.06419000000000001\n",
      "Epoch: 7163, MSE: 0.256697734547847, Learning Rate: 0.064185\n",
      "Epoch: 7164, MSE: 0.2566952692718263, Learning Rate: 0.06418\n",
      "Epoch: 7165, MSE: 0.25669280394488253, Learning Rate: 0.06417500000000001\n",
      "Epoch: 7166, MSE: 0.25669033856701645, Learning Rate: 0.06416999999999999\n",
      "Epoch: 7167, MSE: 0.2566878731382278, Learning Rate: 0.06416500000000001\n",
      "Epoch: 7168, MSE: 0.25668540765851755, Learning Rate: 0.06416\n",
      "Epoch: 7169, MSE: 0.25668294212788434, Learning Rate: 0.064155\n",
      "Epoch: 7170, MSE: 0.2566804765463316, Learning Rate: 0.06415\n",
      "Epoch: 7171, MSE: 0.25667801091385684, Learning Rate: 0.06414500000000001\n",
      "Epoch: 7172, MSE: 0.25667554523046193, Learning Rate: 0.06414\n",
      "Epoch: 7173, MSE: 0.25667307949614687, Learning Rate: 0.064135\n",
      "Epoch: 7174, MSE: 0.25667061371091193, Learning Rate: 0.06413\n",
      "Epoch: 7175, MSE: 0.2566681478747579, Learning Rate: 0.064125\n",
      "Epoch: 7176, MSE: 0.2566656819876848, Learning Rate: 0.06412\n",
      "Epoch: 7177, MSE: 0.2566632160496926, Learning Rate: 0.064115\n",
      "Epoch: 7178, MSE: 0.25666075006078276, Learning Rate: 0.06411\n",
      "Epoch: 7179, MSE: 0.2566582840209546, Learning Rate: 0.06410500000000001\n",
      "Epoch: 7180, MSE: 0.25665581793020975, Learning Rate: 0.0641\n",
      "Epoch: 7181, MSE: 0.25665335178854726, Learning Rate: 0.064095\n",
      "Epoch: 7182, MSE: 0.25665088559596805, Learning Rate: 0.06409000000000001\n",
      "Epoch: 7183, MSE: 0.2566484193524727, Learning Rate: 0.06408499999999999\n",
      "Epoch: 7184, MSE: 0.256645953058061, Learning Rate: 0.06408000000000001\n",
      "Epoch: 7185, MSE: 0.2566434867127338, Learning Rate: 0.064075\n",
      "Epoch: 7186, MSE: 0.2566410203164912, Learning Rate: 0.06407\n",
      "Epoch: 7187, MSE: 0.2566385538693339, Learning Rate: 0.064065\n",
      "Epoch: 7188, MSE: 0.2566360873712625, Learning Rate: 0.06406\n",
      "Epoch: 7189, MSE: 0.25663362082227614, Learning Rate: 0.064055\n",
      "Epoch: 7190, MSE: 0.2566311542223768, Learning Rate: 0.06405000000000001\n",
      "Epoch: 7191, MSE: 0.25662868757156393, Learning Rate: 0.064045\n",
      "Epoch: 7192, MSE: 0.25662622086983855, Learning Rate: 0.06404000000000001\n",
      "Epoch: 7193, MSE: 0.2566237541171998, Learning Rate: 0.064035\n",
      "Epoch: 7194, MSE: 0.25662128731364914, Learning Rate: 0.06403\n",
      "Epoch: 7195, MSE: 0.256618820459187, Learning Rate: 0.064025\n",
      "Epoch: 7196, MSE: 0.2566163535538134, Learning Rate: 0.06402000000000001\n",
      "Epoch: 7197, MSE: 0.25661388659752876, Learning Rate: 0.064015\n",
      "Epoch: 7198, MSE: 0.25661141959033296, Learning Rate: 0.06401\n",
      "Epoch: 7199, MSE: 0.2566089525322274, Learning Rate: 0.064005\n",
      "Epoch: 7200, MSE: 0.25660648542321146, Learning Rate: 0.064\n",
      "Epoch: 7201, MSE: 0.2566040182632866, Learning Rate: 0.06399500000000001\n",
      "Epoch: 7202, MSE: 0.2566015510524519, Learning Rate: 0.06399\n",
      "Epoch: 7203, MSE: 0.2565990837907092, Learning Rate: 0.063985\n",
      "Epoch: 7204, MSE: 0.25659661647805837, Learning Rate: 0.06398\n",
      "Epoch: 7205, MSE: 0.2565941491144988, Learning Rate: 0.063975\n",
      "Epoch: 7206, MSE: 0.2565916817000315, Learning Rate: 0.06397\n",
      "Epoch: 7207, MSE: 0.2565892142346586, Learning Rate: 0.06396500000000001\n",
      "Epoch: 7208, MSE: 0.25658674671837717, Learning Rate: 0.06396\n",
      "Epoch: 7209, MSE: 0.25658427915119075, Learning Rate: 0.06395500000000001\n",
      "Epoch: 7210, MSE: 0.25658181153309717, Learning Rate: 0.06394999999999999\n",
      "Epoch: 7211, MSE: 0.2565793438640983, Learning Rate: 0.06394500000000002\n",
      "Epoch: 7212, MSE: 0.2565768761441943, Learning Rate: 0.06394\n",
      "Epoch: 7213, MSE: 0.25657440837338513, Learning Rate: 0.063935\n",
      "Epoch: 7214, MSE: 0.2565719405516718, Learning Rate: 0.06393\n",
      "Epoch: 7215, MSE: 0.2565694726790543, Learning Rate: 0.063925\n",
      "Epoch: 7216, MSE: 0.2565670047555332, Learning Rate: 0.06392\n",
      "Epoch: 7217, MSE: 0.25656453678110913, Learning Rate: 0.063915\n",
      "Epoch: 7218, MSE: 0.25656206875578175, Learning Rate: 0.06391000000000001\n",
      "Epoch: 7219, MSE: 0.2565596006795519, Learning Rate: 0.063905\n",
      "Epoch: 7220, MSE: 0.25655713255242, Learning Rate: 0.0639\n",
      "Epoch: 7221, MSE: 0.2565546643743863, Learning Rate: 0.06389500000000001\n",
      "Epoch: 7222, MSE: 0.2565521961454517, Learning Rate: 0.06389\n",
      "Epoch: 7223, MSE: 0.2565497278656156, Learning Rate: 0.063885\n",
      "Epoch: 7224, MSE: 0.2565472595348797, Learning Rate: 0.06388\n",
      "Epoch: 7225, MSE: 0.2565447911532433, Learning Rate: 0.063875\n",
      "Epoch: 7226, MSE: 0.2565423227207073, Learning Rate: 0.06387000000000001\n",
      "Epoch: 7227, MSE: 0.2565398542372716, Learning Rate: 0.06386499999999999\n",
      "Epoch: 7228, MSE: 0.256537385702937, Learning Rate: 0.06386000000000001\n",
      "Epoch: 7229, MSE: 0.2565349171177045, Learning Rate: 0.063855\n",
      "Epoch: 7230, MSE: 0.25653244848157347, Learning Rate: 0.06385\n",
      "Epoch: 7231, MSE: 0.25652997979454417, Learning Rate: 0.063845\n",
      "Epoch: 7232, MSE: 0.25652751105661853, Learning Rate: 0.06384000000000001\n",
      "Epoch: 7233, MSE: 0.25652504226779543, Learning Rate: 0.063835\n",
      "Epoch: 7234, MSE: 0.2565225734280756, Learning Rate: 0.06383\n",
      "Epoch: 7235, MSE: 0.2565201045374596, Learning Rate: 0.063825\n",
      "Epoch: 7236, MSE: 0.2565176355959476, Learning Rate: 0.06382\n",
      "Epoch: 7237, MSE: 0.2565151666035412, Learning Rate: 0.063815\n",
      "Epoch: 7238, MSE: 0.25651269756023837, Learning Rate: 0.06381\n",
      "Epoch: 7239, MSE: 0.25651022846604354, Learning Rate: 0.063805\n",
      "Epoch: 7240, MSE: 0.25650775932095216, Learning Rate: 0.06380000000000001\n",
      "Epoch: 7241, MSE: 0.2565052901249681, Learning Rate: 0.063795\n",
      "Epoch: 7242, MSE: 0.25650282087809056, Learning Rate: 0.06379\n",
      "Epoch: 7243, MSE: 0.25650035158032014, Learning Rate: 0.06378500000000001\n",
      "Epoch: 7244, MSE: 0.25649788223165676, Learning Rate: 0.06377999999999999\n",
      "Epoch: 7245, MSE: 0.25649541283210175, Learning Rate: 0.06377500000000001\n",
      "Epoch: 7246, MSE: 0.2564929433816547, Learning Rate: 0.06377\n",
      "Epoch: 7247, MSE: 0.25649047388031654, Learning Rate: 0.063765\n",
      "Epoch: 7248, MSE: 0.2564880043280877, Learning Rate: 0.06376\n",
      "Epoch: 7249, MSE: 0.2564855347249677, Learning Rate: 0.063755\n",
      "Epoch: 7250, MSE: 0.2564830650709579, Learning Rate: 0.06375\n",
      "Epoch: 7251, MSE: 0.2564805953660589, Learning Rate: 0.06374500000000001\n",
      "Epoch: 7252, MSE: 0.25647812561026984, Learning Rate: 0.06374\n",
      "Epoch: 7253, MSE: 0.2564756558035919, Learning Rate: 0.06373500000000001\n",
      "Epoch: 7254, MSE: 0.25647318594602647, Learning Rate: 0.06373\n",
      "Epoch: 7255, MSE: 0.2564707160375712, Learning Rate: 0.063725\n",
      "Epoch: 7256, MSE: 0.2564682460782304, Learning Rate: 0.06372\n",
      "Epoch: 7257, MSE: 0.25646577606800175, Learning Rate: 0.06371500000000001\n",
      "Epoch: 7258, MSE: 0.2564633060068863, Learning Rate: 0.06371\n",
      "Epoch: 7259, MSE: 0.25646083589488333, Learning Rate: 0.063705\n",
      "Epoch: 7260, MSE: 0.2564583657319948, Learning Rate: 0.0637\n",
      "Epoch: 7261, MSE: 0.2564558955182216, Learning Rate: 0.063695\n",
      "Epoch: 7262, MSE: 0.25645342525356224, Learning Rate: 0.06369000000000001\n",
      "Epoch: 7263, MSE: 0.25645095493801817, Learning Rate: 0.063685\n",
      "Epoch: 7264, MSE: 0.2564484845715902, Learning Rate: 0.06368\n",
      "Epoch: 7265, MSE: 0.25644601415427787, Learning Rate: 0.063675\n",
      "Epoch: 7266, MSE: 0.2564435436860825, Learning Rate: 0.06367\n",
      "Epoch: 7267, MSE: 0.2564410731670037, Learning Rate: 0.063665\n",
      "Epoch: 7268, MSE: 0.25643860259704193, Learning Rate: 0.06366000000000001\n",
      "Epoch: 7269, MSE: 0.25643613197619874, Learning Rate: 0.063655\n",
      "Epoch: 7270, MSE: 0.2564336613044727, Learning Rate: 0.06365000000000001\n",
      "Epoch: 7271, MSE: 0.2564311905818662, Learning Rate: 0.063645\n",
      "Epoch: 7272, MSE: 0.25642871980837734, Learning Rate: 0.06364000000000002\n",
      "Epoch: 7273, MSE: 0.25642624898400856, Learning Rate: 0.063635\n",
      "Epoch: 7274, MSE: 0.2564237781087595, Learning Rate: 0.06363\n",
      "Epoch: 7275, MSE: 0.25642130718263095, Learning Rate: 0.063625\n",
      "Epoch: 7276, MSE: 0.25641883620562284, Learning Rate: 0.06362\n",
      "Epoch: 7277, MSE: 0.25641636517773536, Learning Rate: 0.063615\n",
      "Epoch: 7278, MSE: 0.25641389409897014, Learning Rate: 0.06361\n",
      "Epoch: 7279, MSE: 0.2564114229693263, Learning Rate: 0.06360500000000001\n",
      "Epoch: 7280, MSE: 0.25640895178880435, Learning Rate: 0.0636\n",
      "Epoch: 7281, MSE: 0.2564064805574054, Learning Rate: 0.063595\n",
      "Epoch: 7282, MSE: 0.25640400927512985, Learning Rate: 0.06359000000000001\n",
      "Epoch: 7283, MSE: 0.25640153794197823, Learning Rate: 0.063585\n",
      "Epoch: 7284, MSE: 0.25639906655795003, Learning Rate: 0.06358\n",
      "Epoch: 7285, MSE: 0.2563965951230468, Learning Rate: 0.063575\n",
      "Epoch: 7286, MSE: 0.2563941236372678, Learning Rate: 0.06357\n",
      "Epoch: 7287, MSE: 0.2563916521006139, Learning Rate: 0.06356500000000001\n",
      "Epoch: 7288, MSE: 0.256389180513086, Learning Rate: 0.06355999999999999\n",
      "Epoch: 7289, MSE: 0.2563867088746843, Learning Rate: 0.06355500000000001\n",
      "Epoch: 7290, MSE: 0.2563842371854092, Learning Rate: 0.06355\n",
      "Epoch: 7291, MSE: 0.25638176544526037, Learning Rate: 0.063545\n",
      "Epoch: 7292, MSE: 0.25637929365423984, Learning Rate: 0.06354\n",
      "Epoch: 7293, MSE: 0.2563768218123458, Learning Rate: 0.06353500000000001\n",
      "Epoch: 7294, MSE: 0.2563743499195812, Learning Rate: 0.06353\n",
      "Epoch: 7295, MSE: 0.25637187797594524, Learning Rate: 0.063525\n",
      "Epoch: 7296, MSE: 0.2563694059814376, Learning Rate: 0.06352000000000001\n",
      "Epoch: 7297, MSE: 0.2563669339360597, Learning Rate: 0.063515\n",
      "Epoch: 7298, MSE: 0.25636446183981215, Learning Rate: 0.06351\n",
      "Epoch: 7299, MSE: 0.2563619896926945, Learning Rate: 0.063505\n",
      "Epoch: 7300, MSE: 0.25635951749470826, Learning Rate: 0.0635\n",
      "Epoch: 7301, MSE: 0.2563570452458524, Learning Rate: 0.06349500000000001\n",
      "Epoch: 7302, MSE: 0.2563545729461284, Learning Rate: 0.06349\n",
      "Epoch: 7303, MSE: 0.2563521005955364, Learning Rate: 0.063485\n",
      "Epoch: 7304, MSE: 0.2563496281940768, Learning Rate: 0.06348000000000001\n",
      "Epoch: 7305, MSE: 0.2563471557417505, Learning Rate: 0.06347499999999999\n",
      "Epoch: 7306, MSE: 0.2563446832385575, Learning Rate: 0.06347000000000001\n",
      "Epoch: 7307, MSE: 0.2563422106844984, Learning Rate: 0.063465\n",
      "Epoch: 7308, MSE: 0.25633973807957344, Learning Rate: 0.06346\n",
      "Epoch: 7309, MSE: 0.25633726542378293, Learning Rate: 0.063455\n",
      "Epoch: 7310, MSE: 0.25633479271712767, Learning Rate: 0.06345\n",
      "Epoch: 7311, MSE: 0.25633231995960865, Learning Rate: 0.063445\n",
      "Epoch: 7312, MSE: 0.25632984715122437, Learning Rate: 0.06344000000000001\n",
      "Epoch: 7313, MSE: 0.25632737429197716, Learning Rate: 0.063435\n",
      "Epoch: 7314, MSE: 0.25632490138186614, Learning Rate: 0.06343\n",
      "Epoch: 7315, MSE: 0.2563224284208931, Learning Rate: 0.063425\n",
      "Epoch: 7316, MSE: 0.25631995540905755, Learning Rate: 0.06342\n",
      "Epoch: 7317, MSE: 0.25631748234636026, Learning Rate: 0.063415\n",
      "Epoch: 7318, MSE: 0.2563150092328011, Learning Rate: 0.06341000000000001\n",
      "Epoch: 7319, MSE: 0.2563125360683815, Learning Rate: 0.063405\n",
      "Epoch: 7320, MSE: 0.2563100628531011, Learning Rate: 0.0634\n",
      "Epoch: 7321, MSE: 0.2563075895869604, Learning Rate: 0.063395\n",
      "Epoch: 7322, MSE: 0.25630511626995967, Learning Rate: 0.06339\n",
      "Epoch: 7323, MSE: 0.25630264290210025, Learning Rate: 0.06338500000000001\n",
      "Epoch: 7324, MSE: 0.2563001694833822, Learning Rate: 0.06337999999999999\n",
      "Epoch: 7325, MSE: 0.2562976960138058, Learning Rate: 0.063375\n",
      "Epoch: 7326, MSE: 0.2562952224933708, Learning Rate: 0.06337\n",
      "Epoch: 7327, MSE: 0.25629274892207893, Learning Rate: 0.063365\n",
      "Epoch: 7328, MSE: 0.25629027529992954, Learning Rate: 0.06336\n",
      "Epoch: 7329, MSE: 0.2562878016269239, Learning Rate: 0.06335500000000001\n",
      "Epoch: 7330, MSE: 0.2562853279030623, Learning Rate: 0.06335\n",
      "Epoch: 7331, MSE: 0.25628285412834473, Learning Rate: 0.06334500000000001\n",
      "Epoch: 7332, MSE: 0.2562803803027718, Learning Rate: 0.06334\n",
      "Epoch: 7333, MSE: 0.25627790642634385, Learning Rate: 0.06333500000000002\n",
      "Epoch: 7334, MSE: 0.2562754324990619, Learning Rate: 0.06333\n",
      "Epoch: 7335, MSE: 0.25627295852092613, Learning Rate: 0.063325\n",
      "Epoch: 7336, MSE: 0.2562704844919359, Learning Rate: 0.06332\n",
      "Epoch: 7337, MSE: 0.25626801041209313, Learning Rate: 0.063315\n",
      "Epoch: 7338, MSE: 0.25626553628139814, Learning Rate: 0.06331\n",
      "Epoch: 7339, MSE: 0.2562630620998512, Learning Rate: 0.063305\n",
      "Epoch: 7340, MSE: 0.2562605878674518, Learning Rate: 0.06330000000000001\n",
      "Epoch: 7341, MSE: 0.25625811358420075, Learning Rate: 0.063295\n",
      "Epoch: 7342, MSE: 0.25625563925010003, Learning Rate: 0.06329\n",
      "Epoch: 7343, MSE: 0.2562531648651482, Learning Rate: 0.06328500000000001\n",
      "Epoch: 7344, MSE: 0.2562506904293471, Learning Rate: 0.06328\n",
      "Epoch: 7345, MSE: 0.25624821594269565, Learning Rate: 0.063275\n",
      "Epoch: 7346, MSE: 0.2562457414051956, Learning Rate: 0.06327\n",
      "Epoch: 7347, MSE: 0.2562432668168472, Learning Rate: 0.063265\n",
      "Epoch: 7348, MSE: 0.25624079217765017, Learning Rate: 0.06326000000000001\n",
      "Epoch: 7349, MSE: 0.2562383174876058, Learning Rate: 0.06325499999999999\n",
      "Epoch: 7350, MSE: 0.2562358427467139, Learning Rate: 0.06325000000000001\n",
      "Epoch: 7351, MSE: 0.25623336795497575, Learning Rate: 0.063245\n",
      "Epoch: 7352, MSE: 0.2562308931123906, Learning Rate: 0.06324\n",
      "Epoch: 7353, MSE: 0.2562284182189597, Learning Rate: 0.063235\n",
      "Epoch: 7354, MSE: 0.25622594327468423, Learning Rate: 0.06323\n",
      "Epoch: 7355, MSE: 0.2562234682795631, Learning Rate: 0.063225\n",
      "Epoch: 7356, MSE: 0.2562209932335969, Learning Rate: 0.06322\n",
      "Epoch: 7357, MSE: 0.25621851813678714, Learning Rate: 0.06321500000000001\n",
      "Epoch: 7358, MSE: 0.25621604298913414, Learning Rate: 0.06321\n",
      "Epoch: 7359, MSE: 0.2562135677906376, Learning Rate: 0.063205\n",
      "Epoch: 7360, MSE: 0.2562110925412979, Learning Rate: 0.0632\n",
      "Epoch: 7361, MSE: 0.25620861724111693, Learning Rate: 0.063195\n",
      "Epoch: 7362, MSE: 0.2562061418900935, Learning Rate: 0.06319000000000001\n",
      "Epoch: 7363, MSE: 0.25620366648822884, Learning Rate: 0.063185\n",
      "Epoch: 7364, MSE: 0.25620119103552363, Learning Rate: 0.06318\n",
      "Epoch: 7365, MSE: 0.25619871553197754, Learning Rate: 0.06317500000000001\n",
      "Epoch: 7366, MSE: 0.25619623997759206, Learning Rate: 0.06316999999999999\n",
      "Epoch: 7367, MSE: 0.256193764372366, Learning Rate: 0.06316500000000001\n",
      "Epoch: 7368, MSE: 0.25619128871630215, Learning Rate: 0.06316\n",
      "Epoch: 7369, MSE: 0.2561888130093994, Learning Rate: 0.063155\n",
      "Epoch: 7370, MSE: 0.25618633725165785, Learning Rate: 0.06315\n",
      "Epoch: 7371, MSE: 0.25618386144307903, Learning Rate: 0.063145\n",
      "Epoch: 7372, MSE: 0.2561813855836625, Learning Rate: 0.06314\n",
      "Epoch: 7373, MSE: 0.25617890967341, Learning Rate: 0.06313500000000001\n",
      "Epoch: 7374, MSE: 0.25617643371232096, Learning Rate: 0.06313\n",
      "Epoch: 7375, MSE: 0.25617395770039614, Learning Rate: 0.063125\n",
      "Epoch: 7376, MSE: 0.2561714816376358, Learning Rate: 0.06312\n",
      "Epoch: 7377, MSE: 0.2561690055240404, Learning Rate: 0.063115\n",
      "Epoch: 7378, MSE: 0.2561665293596108, Learning Rate: 0.06311\n",
      "Epoch: 7379, MSE: 0.2561640531443471, Learning Rate: 0.06310500000000001\n",
      "Epoch: 7380, MSE: 0.25616157687825036, Learning Rate: 0.0631\n",
      "Epoch: 7381, MSE: 0.25615910056132013, Learning Rate: 0.063095\n",
      "Epoch: 7382, MSE: 0.2561566241935574, Learning Rate: 0.06309000000000001\n",
      "Epoch: 7383, MSE: 0.2561541477749623, Learning Rate: 0.063085\n",
      "Epoch: 7384, MSE: 0.256151671305536, Learning Rate: 0.06308000000000001\n",
      "Epoch: 7385, MSE: 0.25614919478527853, Learning Rate: 0.06307499999999999\n",
      "Epoch: 7386, MSE: 0.2561467182141902, Learning Rate: 0.06307\n",
      "Epoch: 7387, MSE: 0.25614424159227134, Learning Rate: 0.063065\n",
      "Epoch: 7388, MSE: 0.2561417649195227, Learning Rate: 0.06306\n",
      "Epoch: 7389, MSE: 0.25613928819594445, Learning Rate: 0.063055\n",
      "Epoch: 7390, MSE: 0.25613681142153844, Learning Rate: 0.06305000000000001\n",
      "Epoch: 7391, MSE: 0.25613433459630275, Learning Rate: 0.063045\n",
      "Epoch: 7392, MSE: 0.25613185772023994, Learning Rate: 0.06304000000000001\n",
      "Epoch: 7393, MSE: 0.25612938079334957, Learning Rate: 0.063035\n",
      "Epoch: 7394, MSE: 0.2561269038156323, Learning Rate: 0.06303000000000002\n",
      "Epoch: 7395, MSE: 0.2561244267870887, Learning Rate: 0.063025\n",
      "Epoch: 7396, MSE: 0.256121949707719, Learning Rate: 0.06302\n",
      "Epoch: 7397, MSE: 0.25611947257752277, Learning Rate: 0.063015\n",
      "Epoch: 7398, MSE: 0.2561169953965022, Learning Rate: 0.06301\n",
      "Epoch: 7399, MSE: 0.2561145181646573, Learning Rate: 0.063005\n",
      "Epoch: 7400, MSE: 0.25611204088198797, Learning Rate: 0.063\n",
      "Epoch: 7401, MSE: 0.2561095635484954, Learning Rate: 0.06299500000000001\n",
      "Epoch: 7402, MSE: 0.256107086164179, Learning Rate: 0.06299\n",
      "Epoch: 7403, MSE: 0.2561046087290402, Learning Rate: 0.062985\n",
      "Epoch: 7404, MSE: 0.25610213124307923, Learning Rate: 0.06298000000000001\n",
      "Epoch: 7405, MSE: 0.25609965370629606, Learning Rate: 0.062975\n",
      "Epoch: 7406, MSE: 0.256097176118692, Learning Rate: 0.06297\n",
      "Epoch: 7407, MSE: 0.25609469848026695, Learning Rate: 0.06296500000000001\n",
      "Epoch: 7408, MSE: 0.25609222079102106, Learning Rate: 0.06296\n",
      "Epoch: 7409, MSE: 0.2560897430509561, Learning Rate: 0.06295500000000001\n",
      "Epoch: 7410, MSE: 0.25608726526007125, Learning Rate: 0.06294999999999999\n",
      "Epoch: 7411, MSE: 0.2560847874183679, Learning Rate: 0.06294500000000001\n",
      "Epoch: 7412, MSE: 0.2560823095258459, Learning Rate: 0.06294\n",
      "Epoch: 7413, MSE: 0.2560798315825056, Learning Rate: 0.062935\n",
      "Epoch: 7414, MSE: 0.25607735358834866, Learning Rate: 0.06293\n",
      "Epoch: 7415, MSE: 0.25607487554337405, Learning Rate: 0.062925\n",
      "Epoch: 7416, MSE: 0.2560723974475834, Learning Rate: 0.06292\n",
      "Epoch: 7417, MSE: 0.25606991930097606, Learning Rate: 0.062915\n",
      "Epoch: 7418, MSE: 0.25606744110355373, Learning Rate: 0.06291000000000001\n",
      "Epoch: 7419, MSE: 0.2560649628553166, Learning Rate: 0.062905\n",
      "Epoch: 7420, MSE: 0.25606248455626335, Learning Rate: 0.0629\n",
      "Epoch: 7421, MSE: 0.2560600062063978, Learning Rate: 0.062895\n",
      "Epoch: 7422, MSE: 0.2560575278057176, Learning Rate: 0.06289\n",
      "Epoch: 7423, MSE: 0.2560550493542243, Learning Rate: 0.06288500000000001\n",
      "Epoch: 7424, MSE: 0.25605257085191885, Learning Rate: 0.06288\n",
      "Epoch: 7425, MSE: 0.25605009229880094, Learning Rate: 0.062875\n",
      "Epoch: 7426, MSE: 0.2560476136948718, Learning Rate: 0.06287000000000001\n",
      "Epoch: 7427, MSE: 0.2560451350401307, Learning Rate: 0.06286499999999999\n",
      "Epoch: 7428, MSE: 0.2560426563345794, Learning Rate: 0.06286000000000001\n",
      "Epoch: 7429, MSE: 0.25604017757821734, Learning Rate: 0.062855\n",
      "Epoch: 7430, MSE: 0.2560376987710459, Learning Rate: 0.06285\n",
      "Epoch: 7431, MSE: 0.2560352199130653, Learning Rate: 0.062845\n",
      "Epoch: 7432, MSE: 0.2560327410042757, Learning Rate: 0.06284000000000001\n",
      "Epoch: 7433, MSE: 0.256030262044678, Learning Rate: 0.062835\n",
      "Epoch: 7434, MSE: 0.2560277830342725, Learning Rate: 0.06283000000000001\n",
      "Epoch: 7435, MSE: 0.2560253039730596, Learning Rate: 0.062825\n",
      "Epoch: 7436, MSE: 0.2560228248610399, Learning Rate: 0.06282\n",
      "Epoch: 7437, MSE: 0.25602034569821386, Learning Rate: 0.062815\n",
      "Epoch: 7438, MSE: 0.2560178664845815, Learning Rate: 0.06281\n",
      "Epoch: 7439, MSE: 0.2560153872201447, Learning Rate: 0.062805\n",
      "Epoch: 7440, MSE: 0.2560129079049024, Learning Rate: 0.06280000000000001\n",
      "Epoch: 7441, MSE: 0.25601042853885614, Learning Rate: 0.062795\n",
      "Epoch: 7442, MSE: 0.25600794912200575, Learning Rate: 0.06279\n",
      "Epoch: 7443, MSE: 0.256005469654352, Learning Rate: 0.06278500000000001\n",
      "Epoch: 7444, MSE: 0.256002990135895, Learning Rate: 0.06278\n",
      "Epoch: 7445, MSE: 0.25600051056663614, Learning Rate: 0.06277500000000001\n",
      "Epoch: 7446, MSE: 0.2559980309465751, Learning Rate: 0.06276999999999999\n",
      "Epoch: 7447, MSE: 0.25599555127571316, Learning Rate: 0.062765\n",
      "Epoch: 7448, MSE: 0.2559930715540492, Learning Rate: 0.06276\n",
      "Epoch: 7449, MSE: 0.25599059178158606, Learning Rate: 0.062755\n",
      "Epoch: 7450, MSE: 0.25598811195832244, Learning Rate: 0.06275\n",
      "Epoch: 7451, MSE: 0.25598563208425945, Learning Rate: 0.06274500000000001\n",
      "Epoch: 7452, MSE: 0.25598315215939815, Learning Rate: 0.06274\n",
      "Epoch: 7453, MSE: 0.2559806721837367, Learning Rate: 0.06273500000000001\n",
      "Epoch: 7454, MSE: 0.2559781921572788, Learning Rate: 0.06273\n",
      "Epoch: 7455, MSE: 0.255975712080023, Learning Rate: 0.062725\n",
      "Epoch: 7456, MSE: 0.25597323195197047, Learning Rate: 0.06272\n",
      "Epoch: 7457, MSE: 0.2559707517731208, Learning Rate: 0.062715\n",
      "Epoch: 7458, MSE: 0.2559682715434757, Learning Rate: 0.06271\n",
      "Epoch: 7459, MSE: 0.2559657912630354, Learning Rate: 0.062705\n",
      "Epoch: 7460, MSE: 0.2559633109317992, Learning Rate: 0.0627\n",
      "Epoch: 7461, MSE: 0.2559608305497693, Learning Rate: 0.062695\n",
      "Epoch: 7462, MSE: 0.2559583501169464, Learning Rate: 0.06269000000000001\n",
      "Epoch: 7463, MSE: 0.25595586963332856, Learning Rate: 0.062685\n",
      "Epoch: 7464, MSE: 0.2559533890989182, Learning Rate: 0.06268\n",
      "Epoch: 7465, MSE: 0.2559509085137152, Learning Rate: 0.062675\n",
      "Epoch: 7466, MSE: 0.2559484278777206, Learning Rate: 0.06267\n",
      "Epoch: 7467, MSE: 0.25594594719093444, Learning Rate: 0.062665\n",
      "Epoch: 7468, MSE: 0.25594346645335764, Learning Rate: 0.06266000000000001\n",
      "Epoch: 7469, MSE: 0.25594098566499, Learning Rate: 0.062655\n",
      "Epoch: 7470, MSE: 0.25593850482583247, Learning Rate: 0.06265000000000001\n",
      "Epoch: 7471, MSE: 0.255936023935886, Learning Rate: 0.06264499999999999\n",
      "Epoch: 7472, MSE: 0.25593354299514987, Learning Rate: 0.06264000000000002\n",
      "Epoch: 7473, MSE: 0.2559310620036258, Learning Rate: 0.062635\n",
      "Epoch: 7474, MSE: 0.2559285809613138, Learning Rate: 0.06263\n",
      "Epoch: 7475, MSE: 0.2559260998682145, Learning Rate: 0.062625\n",
      "Epoch: 7476, MSE: 0.25592361872432823, Learning Rate: 0.06262\n",
      "Epoch: 7477, MSE: 0.2559211375296557, Learning Rate: 0.062615\n",
      "Epoch: 7478, MSE: 0.25591865628419697, Learning Rate: 0.06261\n",
      "Epoch: 7479, MSE: 0.25591617498795305, Learning Rate: 0.06260500000000001\n",
      "Epoch: 7480, MSE: 0.25591369364092387, Learning Rate: 0.0626\n",
      "Epoch: 7481, MSE: 0.255911212243111, Learning Rate: 0.062595\n",
      "Epoch: 7482, MSE: 0.2559087307945141, Learning Rate: 0.06259\n",
      "Epoch: 7483, MSE: 0.2559062492951338, Learning Rate: 0.062585\n",
      "Epoch: 7484, MSE: 0.2559037677449706, Learning Rate: 0.06258000000000001\n",
      "Epoch: 7485, MSE: 0.2559012861440256, Learning Rate: 0.062575\n",
      "Epoch: 7486, MSE: 0.25589880449229824, Learning Rate: 0.06257\n",
      "Epoch: 7487, MSE: 0.25589632278978997, Learning Rate: 0.06256500000000001\n",
      "Epoch: 7488, MSE: 0.25589384103650087, Learning Rate: 0.06255999999999999\n",
      "Epoch: 7489, MSE: 0.2558913592324315, Learning Rate: 0.06255500000000001\n",
      "Epoch: 7490, MSE: 0.2558888773775824, Learning Rate: 0.06255\n",
      "Epoch: 7491, MSE: 0.2558863954719534, Learning Rate: 0.062545\n",
      "Epoch: 7492, MSE: 0.2558839135155464, Learning Rate: 0.06254\n",
      "Epoch: 7493, MSE: 0.25588143150836123, Learning Rate: 0.06253500000000001\n",
      "Epoch: 7494, MSE: 0.25587894945039824, Learning Rate: 0.06253\n",
      "Epoch: 7495, MSE: 0.25587646734165825, Learning Rate: 0.062525\n",
      "Epoch: 7496, MSE: 0.25587398518214166, Learning Rate: 0.06252\n",
      "Epoch: 7497, MSE: 0.25587150297184885, Learning Rate: 0.062515\n",
      "Epoch: 7498, MSE: 0.25586902071077994, Learning Rate: 0.06251\n",
      "Epoch: 7499, MSE: 0.25586653839893586, Learning Rate: 0.062505\n",
      "Epoch: 7500, MSE: 0.25586405603631773, Learning Rate: 0.0625\n",
      "Epoch: 7501, MSE: 0.25586157362292594, Learning Rate: 0.062495\n",
      "Epoch: 7502, MSE: 0.2558590911587598, Learning Rate: 0.062490000000000004\n",
      "Epoch: 7503, MSE: 0.255856608643821, Learning Rate: 0.062485000000000006\n",
      "Epoch: 7504, MSE: 0.25585412607810976, Learning Rate: 0.06248000000000001\n",
      "Epoch: 7505, MSE: 0.25585164346162625, Learning Rate: 0.062475\n",
      "Epoch: 7506, MSE: 0.25584916079437187, Learning Rate: 0.062470000000000005\n",
      "Epoch: 7507, MSE: 0.2558466780763454, Learning Rate: 0.06246499999999999\n",
      "Epoch: 7508, MSE: 0.2558441953075496, Learning Rate: 0.06246000000000001\n",
      "Epoch: 7509, MSE: 0.25584171248798354, Learning Rate: 0.062455\n",
      "Epoch: 7510, MSE: 0.25583922961764827, Learning Rate: 0.062450000000000006\n",
      "Epoch: 7511, MSE: 0.2558367466965441, Learning Rate: 0.062445\n",
      "Epoch: 7512, MSE: 0.2558342637246718, Learning Rate: 0.06244000000000001\n",
      "Epoch: 7513, MSE: 0.255831780702031, Learning Rate: 0.062435\n",
      "Epoch: 7514, MSE: 0.2558292976286238, Learning Rate: 0.06243000000000001\n",
      "Epoch: 7515, MSE: 0.2558268145044495, Learning Rate: 0.062425\n",
      "Epoch: 7516, MSE: 0.25582433132950866, Learning Rate: 0.06242\n",
      "Epoch: 7517, MSE: 0.25582184810380215, Learning Rate: 0.062415\n",
      "Epoch: 7518, MSE: 0.25581936482733086, Learning Rate: 0.06241\n",
      "Epoch: 7519, MSE: 0.25581688150009463, Learning Rate: 0.062405\n",
      "Epoch: 7520, MSE: 0.25581439812209456, Learning Rate: 0.062400000000000004\n",
      "Epoch: 7521, MSE: 0.25581191469333087, Learning Rate: 0.062395000000000006\n",
      "Epoch: 7522, MSE: 0.2558094312138037, Learning Rate: 0.06239\n",
      "Epoch: 7523, MSE: 0.2558069476835148, Learning Rate: 0.062385\n",
      "Epoch: 7524, MSE: 0.2558044641024631, Learning Rate: 0.062380000000000005\n",
      "Epoch: 7525, MSE: 0.25580198047065106, Learning Rate: 0.06237500000000001\n",
      "Epoch: 7526, MSE: 0.2557994967880761, Learning Rate: 0.062369999999999995\n",
      "Epoch: 7527, MSE: 0.2557970130547423, Learning Rate: 0.062365000000000004\n",
      "Epoch: 7528, MSE: 0.2557945292706481, Learning Rate: 0.06236\n",
      "Epoch: 7529, MSE: 0.2557920454357948, Learning Rate: 0.06235500000000001\n",
      "Epoch: 7530, MSE: 0.2557895615501828, Learning Rate: 0.062349999999999996\n",
      "Epoch: 7531, MSE: 0.2557870776138119, Learning Rate: 0.06234500000000001\n",
      "Epoch: 7532, MSE: 0.2557845936266831, Learning Rate: 0.06234\n",
      "Epoch: 7533, MSE: 0.25578210958879805, Learning Rate: 0.06233500000000001\n",
      "Epoch: 7534, MSE: 0.25577962550015587, Learning Rate: 0.062329999999999997\n",
      "Epoch: 7535, MSE: 0.2557771413607577, Learning Rate: 0.06232500000000001\n",
      "Epoch: 7536, MSE: 0.2557746571706028, Learning Rate: 0.06232\n",
      "Epoch: 7537, MSE: 0.25577217292969495, Learning Rate: 0.062315\n",
      "Epoch: 7538, MSE: 0.25576968863803073, Learning Rate: 0.062310000000000004\n",
      "Epoch: 7539, MSE: 0.25576720429561284, Learning Rate: 0.062305\n",
      "Epoch: 7540, MSE: 0.2557647199024416, Learning Rate: 0.0623\n",
      "Epoch: 7541, MSE: 0.2557622354585176, Learning Rate: 0.062295\n",
      "Epoch: 7542, MSE: 0.25575975096384174, Learning Rate: 0.062290000000000005\n",
      "Epoch: 7543, MSE: 0.2557572664184129, Learning Rate: 0.06228500000000001\n",
      "Epoch: 7544, MSE: 0.2557547818222336, Learning Rate: 0.06228\n",
      "Epoch: 7545, MSE: 0.2557522971753034, Learning Rate: 0.062275000000000004\n",
      "Epoch: 7546, MSE: 0.25574981247762213, Learning Rate: 0.062270000000000006\n",
      "Epoch: 7547, MSE: 0.25574732772919206, Learning Rate: 0.062264999999999994\n",
      "Epoch: 7548, MSE: 0.2557448429300126, Learning Rate: 0.06226000000000001\n",
      "Epoch: 7549, MSE: 0.25574235808008444, Learning Rate: 0.062255\n",
      "Epoch: 7550, MSE: 0.255739873179408, Learning Rate: 0.06225000000000001\n",
      "Epoch: 7551, MSE: 0.2557373882279845, Learning Rate: 0.062244999999999995\n",
      "Epoch: 7552, MSE: 0.25573490322581405, Learning Rate: 0.06224000000000001\n",
      "Epoch: 7553, MSE: 0.25573241817289644, Learning Rate: 0.062235\n",
      "Epoch: 7554, MSE: 0.2557299330692335, Learning Rate: 0.06223000000000001\n",
      "Epoch: 7555, MSE: 0.2557274479148244, Learning Rate: 0.062225\n",
      "Epoch: 7556, MSE: 0.2557249627096715, Learning Rate: 0.06222\n",
      "Epoch: 7557, MSE: 0.25572247745377363, Learning Rate: 0.062215\n",
      "Epoch: 7558, MSE: 0.2557199921471325, Learning Rate: 0.06221\n",
      "Epoch: 7559, MSE: 0.25571750678974786, Learning Rate: 0.062205\n",
      "Epoch: 7560, MSE: 0.25571502138162033, Learning Rate: 0.062200000000000005\n",
      "Epoch: 7561, MSE: 0.25571253592275117, Learning Rate: 0.062195\n",
      "Epoch: 7562, MSE: 0.2557100504131401, Learning Rate: 0.06219\n",
      "Epoch: 7563, MSE: 0.2557075648527882, Learning Rate: 0.062185000000000004\n",
      "Epoch: 7564, MSE: 0.2557050792416964, Learning Rate: 0.062180000000000006\n",
      "Epoch: 7565, MSE: 0.2557025935798641, Learning Rate: 0.06217500000000001\n",
      "Epoch: 7566, MSE: 0.2557001078672926, Learning Rate: 0.062169999999999996\n",
      "Epoch: 7567, MSE: 0.2556976221039818, Learning Rate: 0.062165000000000005\n",
      "Epoch: 7568, MSE: 0.255695136289933, Learning Rate: 0.06215999999999999\n",
      "Epoch: 7569, MSE: 0.2556926504251469, Learning Rate: 0.06215500000000001\n",
      "Epoch: 7570, MSE: 0.25569016450962334, Learning Rate: 0.06215\n",
      "Epoch: 7571, MSE: 0.2556876785433633, Learning Rate: 0.062145000000000006\n",
      "Epoch: 7572, MSE: 0.2556851925263672, Learning Rate: 0.06214\n",
      "Epoch: 7573, MSE: 0.2556827064586351, Learning Rate: 0.06213500000000001\n",
      "Epoch: 7574, MSE: 0.2556802203401681, Learning Rate: 0.06213\n",
      "Epoch: 7575, MSE: 0.2556777341709671, Learning Rate: 0.062125000000000014\n",
      "Epoch: 7576, MSE: 0.2556752479510329, Learning Rate: 0.06212\n",
      "Epoch: 7577, MSE: 0.25567276168036424, Learning Rate: 0.062115000000000004\n",
      "Epoch: 7578, MSE: 0.25567027535896336, Learning Rate: 0.06211\n",
      "Epoch: 7579, MSE: 0.25566778898682996, Learning Rate: 0.062105\n",
      "Epoch: 7580, MSE: 0.25566530256396497, Learning Rate: 0.0621\n",
      "Epoch: 7581, MSE: 0.2556628160903693, Learning Rate: 0.062095000000000004\n",
      "Epoch: 7582, MSE: 0.25566032956604307, Learning Rate: 0.062090000000000006\n",
      "Epoch: 7583, MSE: 0.25565784299098643, Learning Rate: 0.062085\n",
      "Epoch: 7584, MSE: 0.25565535636520026, Learning Rate: 0.06208\n",
      "Epoch: 7585, MSE: 0.255652869688686, Learning Rate: 0.062075000000000005\n",
      "Epoch: 7586, MSE: 0.2556503829614429, Learning Rate: 0.06207000000000001\n",
      "Epoch: 7587, MSE: 0.2556478961834721, Learning Rate: 0.062064999999999995\n",
      "Epoch: 7588, MSE: 0.2556454093547742, Learning Rate: 0.062060000000000004\n",
      "Epoch: 7589, MSE: 0.25564292247534925, Learning Rate: 0.062055\n",
      "Epoch: 7590, MSE: 0.2556404355451994, Learning Rate: 0.06205000000000001\n",
      "Epoch: 7591, MSE: 0.25563794856432326, Learning Rate: 0.062044999999999996\n",
      "Epoch: 7592, MSE: 0.25563546153272226, Learning Rate: 0.06204000000000001\n",
      "Epoch: 7593, MSE: 0.2556329744503969, Learning Rate: 0.062035\n",
      "Epoch: 7594, MSE: 0.2556304873173478, Learning Rate: 0.06203000000000001\n",
      "Epoch: 7595, MSE: 0.25562800013357534, Learning Rate: 0.062025\n",
      "Epoch: 7596, MSE: 0.25562551289907964, Learning Rate: 0.06202\n",
      "Epoch: 7597, MSE: 0.25562302561386235, Learning Rate: 0.062015\n",
      "Epoch: 7598, MSE: 0.2556205382779237, Learning Rate: 0.06201\n",
      "Epoch: 7599, MSE: 0.2556180508912645, Learning Rate: 0.062005000000000005\n",
      "Epoch: 7600, MSE: 0.25561556345388375, Learning Rate: 0.062\n",
      "Epoch: 7601, MSE: 0.2556130759657835, Learning Rate: 0.061995\n",
      "Epoch: 7602, MSE: 0.255610588426964, Learning Rate: 0.06199\n",
      "Epoch: 7603, MSE: 0.2556081008374261, Learning Rate: 0.061985000000000005\n",
      "Epoch: 7604, MSE: 0.25560561319716985, Learning Rate: 0.06198000000000001\n",
      "Epoch: 7605, MSE: 0.2556031255061952, Learning Rate: 0.061975\n",
      "Epoch: 7606, MSE: 0.2556006377645046, Learning Rate: 0.06197\n",
      "Epoch: 7607, MSE: 0.255598149972097, Learning Rate: 0.061965000000000006\n",
      "Epoch: 7608, MSE: 0.2555956621289736, Learning Rate: 0.061959999999999994\n",
      "Epoch: 7609, MSE: 0.2555931742351347, Learning Rate: 0.06195500000000001\n",
      "Epoch: 7610, MSE: 0.2555906862905811, Learning Rate: 0.06195\n",
      "Epoch: 7611, MSE: 0.25558819829531354, Learning Rate: 0.06194500000000001\n",
      "Epoch: 7612, MSE: 0.2555857102493326, Learning Rate: 0.061939999999999995\n",
      "Epoch: 7613, MSE: 0.25558322215263746, Learning Rate: 0.06193500000000001\n",
      "Epoch: 7614, MSE: 0.2555807340052309, Learning Rate: 0.06193\n",
      "Epoch: 7615, MSE: 0.2555782458071119, Learning Rate: 0.06192500000000001\n",
      "Epoch: 7616, MSE: 0.2555757575582825, Learning Rate: 0.06192\n",
      "Epoch: 7617, MSE: 0.2555732692587409, Learning Rate: 0.061915\n",
      "Epoch: 7618, MSE: 0.25557078090848945, Learning Rate: 0.06191\n",
      "Epoch: 7619, MSE: 0.25556829250752894, Learning Rate: 0.061905\n",
      "Epoch: 7620, MSE: 0.25556580405585866, Learning Rate: 0.061900000000000004\n",
      "Epoch: 7621, MSE: 0.2555633155534811, Learning Rate: 0.061895000000000006\n",
      "Epoch: 7622, MSE: 0.25556082700039434, Learning Rate: 0.06189\n",
      "Epoch: 7623, MSE: 0.2555583383966014, Learning Rate: 0.061885\n",
      "Epoch: 7624, MSE: 0.2555558497421009, Learning Rate: 0.061880000000000004\n",
      "Epoch: 7625, MSE: 0.25555336103689447, Learning Rate: 0.061875000000000006\n",
      "Epoch: 7626, MSE: 0.2555508722809823, Learning Rate: 0.06187000000000001\n",
      "Epoch: 7627, MSE: 0.2555483834743656, Learning Rate: 0.061864999999999996\n",
      "Epoch: 7628, MSE: 0.25554589461704336, Learning Rate: 0.061860000000000005\n",
      "Epoch: 7629, MSE: 0.2555434057090176, Learning Rate: 0.06185499999999999\n",
      "Epoch: 7630, MSE: 0.2555409167502886, Learning Rate: 0.06185000000000001\n",
      "Epoch: 7631, MSE: 0.2555384277408578, Learning Rate: 0.061845\n",
      "Epoch: 7632, MSE: 0.25553593868072466, Learning Rate: 0.061840000000000006\n",
      "Epoch: 7633, MSE: 0.2555334495698889, Learning Rate: 0.061835\n",
      "Epoch: 7634, MSE: 0.2555309604083529, Learning Rate: 0.06183000000000001\n",
      "Epoch: 7635, MSE: 0.2555284711961161, Learning Rate: 0.061825\n",
      "Epoch: 7636, MSE: 0.25552598193317994, Learning Rate: 0.061820000000000014\n",
      "Epoch: 7637, MSE: 0.2555234926195444, Learning Rate: 0.061815\n",
      "Epoch: 7638, MSE: 0.2555210032552102, Learning Rate: 0.061810000000000004\n",
      "Epoch: 7639, MSE: 0.25551851384017804, Learning Rate: 0.061805\n",
      "Epoch: 7640, MSE: 0.25551602437444754, Learning Rate: 0.0618\n",
      "Epoch: 7641, MSE: 0.2555135348580213, Learning Rate: 0.061795\n",
      "Epoch: 7642, MSE: 0.2555110452908987, Learning Rate: 0.061790000000000005\n",
      "Epoch: 7643, MSE: 0.25550855567307973, Learning Rate: 0.06178500000000001\n",
      "Epoch: 7644, MSE: 0.2555060660045654, Learning Rate: 0.06178\n",
      "Epoch: 7645, MSE: 0.2555035762853569, Learning Rate: 0.061775000000000004\n",
      "Epoch: 7646, MSE: 0.25550108651545506, Learning Rate: 0.061770000000000005\n",
      "Epoch: 7647, MSE: 0.255498596694859, Learning Rate: 0.06176500000000001\n",
      "Epoch: 7648, MSE: 0.25549610682357, Learning Rate: 0.061759999999999995\n",
      "Epoch: 7649, MSE: 0.25549361690158934, Learning Rate: 0.061755000000000004\n",
      "Epoch: 7650, MSE: 0.25549112692891746, Learning Rate: 0.06175\n",
      "Epoch: 7651, MSE: 0.25548863690555346, Learning Rate: 0.06174500000000001\n",
      "Epoch: 7652, MSE: 0.2554861468314996, Learning Rate: 0.061739999999999996\n",
      "Epoch: 7653, MSE: 0.2554836567067552, Learning Rate: 0.06173500000000001\n",
      "Epoch: 7654, MSE: 0.2554811665313221, Learning Rate: 0.06173\n",
      "Epoch: 7655, MSE: 0.25547867630520066, Learning Rate: 0.06172500000000001\n",
      "Epoch: 7656, MSE: 0.2554761860283908, Learning Rate: 0.06172\n",
      "Epoch: 7657, MSE: 0.25547369570089323, Learning Rate: 0.061715\n",
      "Epoch: 7658, MSE: 0.2554712053227092, Learning Rate: 0.06171\n",
      "Epoch: 7659, MSE: 0.2554687148938381, Learning Rate: 0.061705\n",
      "Epoch: 7660, MSE: 0.2554662244142815, Learning Rate: 0.061700000000000005\n",
      "Epoch: 7661, MSE: 0.2554637338840401, Learning Rate: 0.061695\n",
      "Epoch: 7662, MSE: 0.25546124330311437, Learning Rate: 0.06169\n",
      "Epoch: 7663, MSE: 0.25545875267150436, Learning Rate: 0.061685000000000004\n",
      "Epoch: 7664, MSE: 0.2554562619892106, Learning Rate: 0.061680000000000006\n",
      "Epoch: 7665, MSE: 0.2554537712562344, Learning Rate: 0.06167500000000001\n",
      "Epoch: 7666, MSE: 0.2554512804725764, Learning Rate: 0.06167\n",
      "Epoch: 7667, MSE: 0.25544878963823686, Learning Rate: 0.061665\n",
      "Epoch: 7668, MSE: 0.2554462987532158, Learning Rate: 0.061660000000000006\n",
      "Epoch: 7669, MSE: 0.2554438078175145, Learning Rate: 0.061654999999999995\n",
      "Epoch: 7670, MSE: 0.2554413168311339, Learning Rate: 0.06165000000000001\n",
      "Epoch: 7671, MSE: 0.2554388257940732, Learning Rate: 0.061645\n",
      "Epoch: 7672, MSE: 0.2554363347063351, Learning Rate: 0.06164000000000001\n",
      "Epoch: 7673, MSE: 0.2554338435679176, Learning Rate: 0.061634999999999995\n",
      "Epoch: 7674, MSE: 0.25543135237882364, Learning Rate: 0.06163000000000001\n",
      "Epoch: 7675, MSE: 0.2554288611390526, Learning Rate: 0.061625\n",
      "Epoch: 7676, MSE: 0.25542636984860534, Learning Rate: 0.06162000000000001\n",
      "Epoch: 7677, MSE: 0.25542387850748266, Learning Rate: 0.061615\n",
      "Epoch: 7678, MSE: 0.25542138711568557, Learning Rate: 0.06161\n",
      "Epoch: 7679, MSE: 0.2554188956732131, Learning Rate: 0.061605\n",
      "Epoch: 7680, MSE: 0.25541640418006745, Learning Rate: 0.0616\n",
      "Epoch: 7681, MSE: 0.2554139126362482, Learning Rate: 0.061595000000000004\n",
      "Epoch: 7682, MSE: 0.2554114210417565, Learning Rate: 0.061590000000000006\n",
      "Epoch: 7683, MSE: 0.25540892939659293, Learning Rate: 0.061585\n",
      "Epoch: 7684, MSE: 0.255406437700758, Learning Rate: 0.06158\n",
      "Epoch: 7685, MSE: 0.2554039459542522, Learning Rate: 0.061575000000000005\n",
      "Epoch: 7686, MSE: 0.25540145415707627, Learning Rate: 0.06157000000000001\n",
      "Epoch: 7687, MSE: 0.2553989623092305, Learning Rate: 0.06156500000000001\n",
      "Epoch: 7688, MSE: 0.25539647041071645, Learning Rate: 0.06156\n",
      "Epoch: 7689, MSE: 0.25539397846153344, Learning Rate: 0.061555000000000006\n",
      "Epoch: 7690, MSE: 0.25539148646168247, Learning Rate: 0.061549999999999994\n",
      "Epoch: 7691, MSE: 0.25538899441116464, Learning Rate: 0.06154500000000001\n",
      "Epoch: 7692, MSE: 0.2553865023099813, Learning Rate: 0.06154\n",
      "Epoch: 7693, MSE: 0.2553840101581307, Learning Rate: 0.061535000000000006\n",
      "Epoch: 7694, MSE: 0.25538151795561614, Learning Rate: 0.06153\n",
      "Epoch: 7695, MSE: 0.25537902570243537, Learning Rate: 0.06152500000000001\n",
      "Epoch: 7696, MSE: 0.2553765333985916, Learning Rate: 0.06152\n",
      "Epoch: 7697, MSE: 0.2553740410440834, Learning Rate: 0.061515\n",
      "Epoch: 7698, MSE: 0.255371548638913, Learning Rate: 0.06151\n",
      "Epoch: 7699, MSE: 0.2553690561830802, Learning Rate: 0.061505000000000004\n",
      "Epoch: 7700, MSE: 0.2553665636765856, Learning Rate: 0.0615\n",
      "Epoch: 7701, MSE: 0.25536407111943, Learning Rate: 0.061495\n",
      "Epoch: 7702, MSE: 0.25536157851161334, Learning Rate: 0.06149\n",
      "Epoch: 7703, MSE: 0.25535908585313843, Learning Rate: 0.061485000000000005\n",
      "Epoch: 7704, MSE: 0.2553565931440027, Learning Rate: 0.06148000000000001\n",
      "Epoch: 7705, MSE: 0.25535410038420897, Learning Rate: 0.061475\n",
      "Epoch: 7706, MSE: 0.2553516075737578, Learning Rate: 0.061470000000000004\n",
      "Epoch: 7707, MSE: 0.25534911471264926, Learning Rate: 0.06146499999999999\n",
      "Epoch: 7708, MSE: 0.255346621800883, Learning Rate: 0.06146000000000001\n",
      "Epoch: 7709, MSE: 0.25534412883846147, Learning Rate: 0.061454999999999996\n",
      "Epoch: 7710, MSE: 0.25534163582538405, Learning Rate: 0.061450000000000005\n",
      "Epoch: 7711, MSE: 0.2553391427616514, Learning Rate: 0.061445\n",
      "Epoch: 7712, MSE: 0.2553366496472652, Learning Rate: 0.06144000000000001\n",
      "Epoch: 7713, MSE: 0.2553341564822248, Learning Rate: 0.061435\n",
      "Epoch: 7714, MSE: 0.25533166326653167, Learning Rate: 0.06143000000000001\n",
      "Epoch: 7715, MSE: 0.25532917000018585, Learning Rate: 0.061425\n",
      "Epoch: 7716, MSE: 0.25532667668318915, Learning Rate: 0.06142000000000001\n",
      "Epoch: 7717, MSE: 0.25532418331554013, Learning Rate: 0.061415\n",
      "Epoch: 7718, MSE: 0.25532168989724124, Learning Rate: 0.06141\n",
      "Epoch: 7719, MSE: 0.25531919642829176, Learning Rate: 0.061405\n",
      "Epoch: 7720, MSE: 0.25531670290869324, Learning Rate: 0.0614\n",
      "Epoch: 7721, MSE: 0.25531420933844645, Learning Rate: 0.061395000000000005\n",
      "Epoch: 7722, MSE: 0.2553117157175507, Learning Rate: 0.06139\n",
      "Epoch: 7723, MSE: 0.25530922204600814, Learning Rate: 0.061385\n",
      "Epoch: 7724, MSE: 0.25530672832381823, Learning Rate: 0.061380000000000004\n",
      "Epoch: 7725, MSE: 0.25530423455098267, Learning Rate: 0.061375000000000006\n",
      "Epoch: 7726, MSE: 0.2553017407275008, Learning Rate: 0.06137000000000001\n",
      "Epoch: 7727, MSE: 0.25529924685337463, Learning Rate: 0.061365\n",
      "Epoch: 7728, MSE: 0.25529675292860377, Learning Rate: 0.06136\n",
      "Epoch: 7729, MSE: 0.25529425895318925, Learning Rate: 0.06135500000000001\n",
      "Epoch: 7730, MSE: 0.2552917649271317, Learning Rate: 0.061349999999999995\n",
      "Epoch: 7731, MSE: 0.2552892708504314, Learning Rate: 0.06134500000000001\n",
      "Epoch: 7732, MSE: 0.25528677672309036, Learning Rate: 0.06134\n",
      "Epoch: 7733, MSE: 0.25528428254510627, Learning Rate: 0.06133500000000001\n",
      "Epoch: 7734, MSE: 0.255281788316483, Learning Rate: 0.061329999999999996\n",
      "Epoch: 7735, MSE: 0.2552792940372189, Learning Rate: 0.06132500000000001\n",
      "Epoch: 7736, MSE: 0.25527679970731637, Learning Rate: 0.06132\n",
      "Epoch: 7737, MSE: 0.25527430532677425, Learning Rate: 0.061315\n",
      "Epoch: 7738, MSE: 0.2552718108955942, Learning Rate: 0.06131\n",
      "Epoch: 7739, MSE: 0.25526931641377726, Learning Rate: 0.061305\n",
      "Epoch: 7740, MSE: 0.25526682188132294, Learning Rate: 0.0613\n",
      "Epoch: 7741, MSE: 0.2552643272982325, Learning Rate: 0.061295\n",
      "Epoch: 7742, MSE: 0.25526183266450736, Learning Rate: 0.061290000000000004\n",
      "Epoch: 7743, MSE: 0.25525933798014583, Learning Rate: 0.061285000000000006\n",
      "Epoch: 7744, MSE: 0.2552568432451509, Learning Rate: 0.06128\n",
      "Epoch: 7745, MSE: 0.2552543484595226, Learning Rate: 0.061275\n",
      "Epoch: 7746, MSE: 0.2552518536232605, Learning Rate: 0.061270000000000005\n",
      "Epoch: 7747, MSE: 0.2552493587363668, Learning Rate: 0.06126499999999999\n",
      "Epoch: 7748, MSE: 0.2552468637988406, Learning Rate: 0.06126000000000001\n",
      "Epoch: 7749, MSE: 0.25524436881068363, Learning Rate: 0.061255\n",
      "Epoch: 7750, MSE: 0.25524187377189606, Learning Rate: 0.061250000000000006\n",
      "Epoch: 7751, MSE: 0.25523937868247865, Learning Rate: 0.061244999999999994\n",
      "Epoch: 7752, MSE: 0.2552368835424321, Learning Rate: 0.06124000000000001\n",
      "Epoch: 7753, MSE: 0.2552343883517565, Learning Rate: 0.061235\n",
      "Epoch: 7754, MSE: 0.2552318931104537, Learning Rate: 0.06123000000000001\n",
      "Epoch: 7755, MSE: 0.25522939781852294, Learning Rate: 0.061225\n",
      "Epoch: 7756, MSE: 0.2552269024759652, Learning Rate: 0.06122000000000001\n",
      "Epoch: 7757, MSE: 0.25522440708278293, Learning Rate: 0.061215\n",
      "Epoch: 7758, MSE: 0.255221911638974, Learning Rate: 0.06121\n",
      "Epoch: 7759, MSE: 0.25521941614454063, Learning Rate: 0.061205\n",
      "Epoch: 7760, MSE: 0.2552169205994832, Learning Rate: 0.061200000000000004\n",
      "Epoch: 7761, MSE: 0.2552144250038018, Learning Rate: 0.061195\n",
      "Epoch: 7762, MSE: 0.2552119293574981, Learning Rate: 0.06119\n",
      "Epoch: 7763, MSE: 0.25520943366057214, Learning Rate: 0.061185\n",
      "Epoch: 7764, MSE: 0.2552069379130254, Learning Rate: 0.061180000000000005\n",
      "Epoch: 7765, MSE: 0.25520444211485677, Learning Rate: 0.06117500000000001\n",
      "Epoch: 7766, MSE: 0.2552019462660676, Learning Rate: 0.06117\n",
      "Epoch: 7767, MSE: 0.25519945036665975, Learning Rate: 0.061165000000000004\n",
      "Epoch: 7768, MSE: 0.2551969544166319, Learning Rate: 0.06115999999999999\n",
      "Epoch: 7769, MSE: 0.25519445841598654, Learning Rate: 0.06115500000000001\n",
      "Epoch: 7770, MSE: 0.25519196236472297, Learning Rate: 0.061149999999999996\n",
      "Epoch: 7771, MSE: 0.2551894662628424, Learning Rate: 0.061145000000000005\n",
      "Epoch: 7772, MSE: 0.25518697011034575, Learning Rate: 0.06114\n",
      "Epoch: 7773, MSE: 0.25518447390723326, Learning Rate: 0.06113500000000001\n",
      "Epoch: 7774, MSE: 0.2551819776535052, Learning Rate: 0.06113\n",
      "Epoch: 7775, MSE: 0.2551794813491628, Learning Rate: 0.06112500000000001\n",
      "Epoch: 7776, MSE: 0.25517698499420693, Learning Rate: 0.06112\n",
      "Epoch: 7777, MSE: 0.25517448858863834, Learning Rate: 0.06111500000000001\n",
      "Epoch: 7778, MSE: 0.25517199213245584, Learning Rate: 0.06111\n",
      "Epoch: 7779, MSE: 0.25516949562566243, Learning Rate: 0.061105\n",
      "Epoch: 7780, MSE: 0.2551669990682579, Learning Rate: 0.0611\n",
      "Epoch: 7781, MSE: 0.2551645024602421, Learning Rate: 0.061095000000000003\n",
      "Epoch: 7782, MSE: 0.2551620058016175, Learning Rate: 0.061090000000000005\n",
      "Epoch: 7783, MSE: 0.2551595090923826, Learning Rate: 0.061085\n",
      "Epoch: 7784, MSE: 0.2551570123325392, Learning Rate: 0.06108\n",
      "Epoch: 7785, MSE: 0.255154515522088, Learning Rate: 0.061075000000000004\n",
      "Epoch: 7786, MSE: 0.2551520186610293, Learning Rate: 0.061070000000000006\n",
      "Epoch: 7787, MSE: 0.2551495217493642, Learning Rate: 0.06106500000000001\n",
      "Epoch: 7788, MSE: 0.2551470247870929, Learning Rate: 0.06106\n",
      "Epoch: 7789, MSE: 0.2551445277742166, Learning Rate: 0.061055\n",
      "Epoch: 7790, MSE: 0.25514203071073466, Learning Rate: 0.06105000000000001\n",
      "Epoch: 7791, MSE: 0.25513953359664976, Learning Rate: 0.061044999999999995\n",
      "Epoch: 7792, MSE: 0.2551370364319609, Learning Rate: 0.06104000000000001\n",
      "Epoch: 7793, MSE: 0.2551345392166693, Learning Rate: 0.061035\n",
      "Epoch: 7794, MSE: 0.25513204195077566, Learning Rate: 0.06103000000000001\n",
      "Epoch: 7795, MSE: 0.25512954463428084, Learning Rate: 0.061024999999999996\n",
      "Epoch: 7796, MSE: 0.255127047267185, Learning Rate: 0.06102000000000001\n",
      "Epoch: 7797, MSE: 0.25512454984948935, Learning Rate: 0.061015\n",
      "Epoch: 7798, MSE: 0.2551220523811939, Learning Rate: 0.06101\n",
      "Epoch: 7799, MSE: 0.2551195548622994, Learning Rate: 0.061005000000000004\n",
      "Epoch: 7800, MSE: 0.25511705729280726, Learning Rate: 0.061\n",
      "Epoch: 7801, MSE: 0.2551145596727174, Learning Rate: 0.060995\n",
      "Epoch: 7802, MSE: 0.2551120620020309, Learning Rate: 0.06099\n",
      "Epoch: 7803, MSE: 0.25510956428074794, Learning Rate: 0.060985000000000004\n",
      "Epoch: 7804, MSE: 0.2551070665088701, Learning Rate: 0.060980000000000006\n",
      "Epoch: 7805, MSE: 0.2551045686863965, Learning Rate: 0.060975\n",
      "Epoch: 7806, MSE: 0.25510207081332914, Learning Rate: 0.06097\n",
      "Epoch: 7807, MSE: 0.25509957288966817, Learning Rate: 0.060965000000000005\n",
      "Epoch: 7808, MSE: 0.25509707491541433, Learning Rate: 0.06095999999999999\n",
      "Epoch: 7809, MSE: 0.25509457689056836, Learning Rate: 0.06095500000000001\n",
      "Epoch: 7810, MSE: 0.2550920788151312, Learning Rate: 0.06095\n",
      "Epoch: 7811, MSE: 0.2550895806891027, Learning Rate: 0.060945000000000006\n",
      "Epoch: 7812, MSE: 0.25508708251248424, Learning Rate: 0.060939999999999994\n",
      "Epoch: 7813, MSE: 0.25508458428527625, Learning Rate: 0.06093500000000001\n",
      "Epoch: 7814, MSE: 0.25508208600747995, Learning Rate: 0.06093\n",
      "Epoch: 7815, MSE: 0.2550795876790941, Learning Rate: 0.06092500000000001\n",
      "Epoch: 7816, MSE: 0.2550770893001215, Learning Rate: 0.06092\n",
      "Epoch: 7817, MSE: 0.2550745908705622, Learning Rate: 0.06091500000000001\n",
      "Epoch: 7818, MSE: 0.2550720923904161, Learning Rate: 0.06091\n",
      "Epoch: 7819, MSE: 0.2550695938596849, Learning Rate: 0.060905\n",
      "Epoch: 7820, MSE: 0.2550670952783685, Learning Rate: 0.0609\n",
      "Epoch: 7821, MSE: 0.2550645966464684, Learning Rate: 0.060895000000000005\n",
      "Epoch: 7822, MSE: 0.2550620979639845, Learning Rate: 0.06089\n",
      "Epoch: 7823, MSE: 0.2550595992309178, Learning Rate: 0.060885\n",
      "Epoch: 7824, MSE: 0.25505710044726854, Learning Rate: 0.060880000000000004\n",
      "Epoch: 7825, MSE: 0.25505460161303867, Learning Rate: 0.060875000000000005\n",
      "Epoch: 7826, MSE: 0.25505210272822676, Learning Rate: 0.06087000000000001\n",
      "Epoch: 7827, MSE: 0.25504960379283514, Learning Rate: 0.060865\n",
      "Epoch: 7828, MSE: 0.2550471048068641, Learning Rate: 0.060860000000000004\n",
      "Epoch: 7829, MSE: 0.2550446057703147, Learning Rate: 0.06085499999999999\n",
      "Epoch: 7830, MSE: 0.2550421066831864, Learning Rate: 0.06085000000000001\n",
      "Epoch: 7831, MSE: 0.2550396075454813, Learning Rate: 0.060844999999999996\n",
      "Epoch: 7832, MSE: 0.2550371083571982, Learning Rate: 0.060840000000000005\n",
      "Epoch: 7833, MSE: 0.25503460911834025, Learning Rate: 0.060835\n",
      "Epoch: 7834, MSE: 0.2550321098289059, Learning Rate: 0.06083000000000001\n",
      "Epoch: 7835, MSE: 0.2550296104888973, Learning Rate: 0.060825\n",
      "Epoch: 7836, MSE: 0.255027111098315, Learning Rate: 0.06082000000000001\n",
      "Epoch: 7837, MSE: 0.2550246116571584, Learning Rate: 0.060815\n",
      "Epoch: 7838, MSE: 0.25502211216542997, Learning Rate: 0.06081\n",
      "Epoch: 7839, MSE: 0.25501961262312817, Learning Rate: 0.060805\n",
      "Epoch: 7840, MSE: 0.2550171130302565, Learning Rate: 0.0608\n",
      "Epoch: 7841, MSE: 0.2550146133868129, Learning Rate: 0.060795\n",
      "Epoch: 7842, MSE: 0.25501211369279986, Learning Rate: 0.060790000000000004\n",
      "Epoch: 7843, MSE: 0.25500961394821653, Learning Rate: 0.060785000000000006\n",
      "Epoch: 7844, MSE: 0.25500711415306554, Learning Rate: 0.06078\n",
      "Epoch: 7845, MSE: 0.2550046143073466, Learning Rate: 0.060775\n",
      "Epoch: 7846, MSE: 0.2550021144110594, Learning Rate: 0.060770000000000005\n",
      "Epoch: 7847, MSE: 0.25499961446420666, Learning Rate: 0.060765000000000007\n",
      "Epoch: 7848, MSE: 0.25499711446678724, Learning Rate: 0.060759999999999995\n",
      "Epoch: 7849, MSE: 0.2549946144188025, Learning Rate: 0.060755\n",
      "Epoch: 7850, MSE: 0.2549921143202537, Learning Rate: 0.06075\n",
      "Epoch: 7851, MSE: 0.2549896141711403, Learning Rate: 0.06074500000000001\n",
      "Epoch: 7852, MSE: 0.254987113971464, Learning Rate: 0.060739999999999995\n",
      "Epoch: 7853, MSE: 0.2549846137212253, Learning Rate: 0.06073500000000001\n",
      "Epoch: 7854, MSE: 0.25498211342042465, Learning Rate: 0.06073\n",
      "Epoch: 7855, MSE: 0.2549796130690626, Learning Rate: 0.06072500000000001\n",
      "Epoch: 7856, MSE: 0.25497711266714024, Learning Rate: 0.060719999999999996\n",
      "Epoch: 7857, MSE: 0.25497461221465795, Learning Rate: 0.06071500000000001\n",
      "Epoch: 7858, MSE: 0.2549721117116172, Learning Rate: 0.06071\n",
      "Epoch: 7859, MSE: 0.2549696111580169, Learning Rate: 0.060705\n",
      "Epoch: 7860, MSE: 0.2549671105538594, Learning Rate: 0.060700000000000004\n",
      "Epoch: 7861, MSE: 0.25496460989914504, Learning Rate: 0.060695\n",
      "Epoch: 7862, MSE: 0.25496210919387435, Learning Rate: 0.06069\n",
      "Epoch: 7863, MSE: 0.2549596084380477, Learning Rate: 0.060685\n",
      "Epoch: 7864, MSE: 0.25495710763166635, Learning Rate: 0.060680000000000005\n",
      "Epoch: 7865, MSE: 0.2549546067747301, Learning Rate: 0.06067500000000001\n",
      "Epoch: 7866, MSE: 0.25495210586724104, Learning Rate: 0.06067\n",
      "Epoch: 7867, MSE: 0.2549496049091982, Learning Rate: 0.060665000000000004\n",
      "Epoch: 7868, MSE: 0.254947103900604, Learning Rate: 0.060660000000000006\n",
      "Epoch: 7869, MSE: 0.25494460284145765, Learning Rate: 0.060654999999999994\n",
      "Epoch: 7870, MSE: 0.25494210173176124, Learning Rate: 0.06065000000000001\n",
      "Epoch: 7871, MSE: 0.2549396005715139, Learning Rate: 0.060645\n",
      "Epoch: 7872, MSE: 0.25493709936071723, Learning Rate: 0.060640000000000006\n",
      "Epoch: 7873, MSE: 0.25493459809937197, Learning Rate: 0.060634999999999994\n",
      "Epoch: 7874, MSE: 0.25493209678747797, Learning Rate: 0.06063000000000001\n",
      "Epoch: 7875, MSE: 0.2549295954250378, Learning Rate: 0.060625\n",
      "Epoch: 7876, MSE: 0.2549270940120503, Learning Rate: 0.06062000000000001\n",
      "Epoch: 7877, MSE: 0.254924592548517, Learning Rate: 0.060615\n",
      "Epoch: 7878, MSE: 0.25492209103443764, Learning Rate: 0.06061000000000001\n",
      "Epoch: 7879, MSE: 0.25491958946981486, Learning Rate: 0.060605\n",
      "Epoch: 7880, MSE: 0.25491708785464773, Learning Rate: 0.0606\n",
      "Epoch: 7881, MSE: 0.25491458618893664, Learning Rate: 0.060595\n",
      "Epoch: 7882, MSE: 0.2549120844726844, Learning Rate: 0.060590000000000005\n",
      "Epoch: 7883, MSE: 0.25490958270588954, Learning Rate: 0.060585\n",
      "Epoch: 7884, MSE: 0.25490708088855435, Learning Rate: 0.06058\n",
      "Epoch: 7885, MSE: 0.2549045790206779, Learning Rate: 0.060575000000000004\n",
      "Epoch: 7886, MSE: 0.2549020771022622, Learning Rate: 0.060570000000000006\n",
      "Epoch: 7887, MSE: 0.25489957513330647, Learning Rate: 0.06056500000000001\n",
      "Epoch: 7888, MSE: 0.25489707311381365, Learning Rate: 0.06056\n",
      "Epoch: 7889, MSE: 0.2548945710437828, Learning Rate: 0.060555000000000005\n",
      "Epoch: 7890, MSE: 0.2548920689232155, Learning Rate: 0.06054999999999999\n",
      "Epoch: 7891, MSE: 0.2548895667521121, Learning Rate: 0.06054500000000001\n",
      "Epoch: 7892, MSE: 0.25488706453047266, Learning Rate: 0.06054\n",
      "Epoch: 7893, MSE: 0.2548845622582985, Learning Rate: 0.060535000000000005\n",
      "Epoch: 7894, MSE: 0.2548820599355904, Learning Rate: 0.06053\n",
      "Epoch: 7895, MSE: 0.25487955756234815, Learning Rate: 0.06052500000000001\n",
      "Epoch: 7896, MSE: 0.2548770551385747, Learning Rate: 0.06052\n",
      "Epoch: 7897, MSE: 0.25487455266426823, Learning Rate: 0.06051500000000001\n",
      "Epoch: 7898, MSE: 0.25487205013943093, Learning Rate: 0.06051\n",
      "Epoch: 7899, MSE: 0.25486954756406277, Learning Rate: 0.060505\n",
      "Epoch: 7900, MSE: 0.25486704493816514, Learning Rate: 0.0605\n",
      "Epoch: 7901, MSE: 0.25486454226173794, Learning Rate: 0.060495\n",
      "Epoch: 7902, MSE: 0.2548620395347829, Learning Rate: 0.06049\n",
      "Epoch: 7903, MSE: 0.2548595367572994, Learning Rate: 0.060485000000000004\n",
      "Epoch: 7904, MSE: 0.2548570339292898, Learning Rate: 0.060480000000000006\n",
      "Epoch: 7905, MSE: 0.25485453105075323, Learning Rate: 0.060475\n",
      "Epoch: 7906, MSE: 0.25485202812169105, Learning Rate: 0.06047\n",
      "Epoch: 7907, MSE: 0.2548495251421036, Learning Rate: 0.060465000000000005\n",
      "Epoch: 7908, MSE: 0.25484702211199384, Learning Rate: 0.06046000000000001\n",
      "Epoch: 7909, MSE: 0.25484451903135846, Learning Rate: 0.060454999999999995\n",
      "Epoch: 7910, MSE: 0.2548420159002012, Learning Rate: 0.060450000000000004\n",
      "Epoch: 7911, MSE: 0.25483951271852207, Learning Rate: 0.060445\n",
      "Epoch: 7912, MSE: 0.25483700948632165, Learning Rate: 0.06044000000000001\n",
      "Epoch: 7913, MSE: 0.2548345062036003, Learning Rate: 0.060434999999999996\n",
      "Epoch: 7914, MSE: 0.25483200287035906, Learning Rate: 0.06043000000000001\n",
      "Epoch: 7915, MSE: 0.25482949948659867, Learning Rate: 0.060425\n",
      "Epoch: 7916, MSE: 0.25482699605232034, Learning Rate: 0.06042000000000001\n",
      "Epoch: 7917, MSE: 0.25482449256752354, Learning Rate: 0.060414999999999996\n",
      "Epoch: 7918, MSE: 0.2548219890322099, Learning Rate: 0.06041000000000001\n",
      "Epoch: 7919, MSE: 0.25481948544638017, Learning Rate: 0.060405\n",
      "Epoch: 7920, MSE: 0.25481698181003515, Learning Rate: 0.0604\n",
      "Epoch: 7921, MSE: 0.2548144781231745, Learning Rate: 0.060395000000000004\n",
      "Epoch: 7922, MSE: 0.2548119743858003, Learning Rate: 0.06039\n",
      "Epoch: 7923, MSE: 0.2548094705979119, Learning Rate: 0.060385\n",
      "Epoch: 7924, MSE: 0.2548069667595114, Learning Rate: 0.06038\n",
      "Epoch: 7925, MSE: 0.25480446287059866, Learning Rate: 0.060375000000000005\n",
      "Epoch: 7926, MSE: 0.25480195893117513, Learning Rate: 0.06037000000000001\n",
      "Epoch: 7927, MSE: 0.25479945494123996, Learning Rate: 0.060365\n",
      "Epoch: 7928, MSE: 0.25479695090079557, Learning Rate: 0.060360000000000004\n",
      "Epoch: 7929, MSE: 0.2547944468098426, Learning Rate: 0.060355000000000006\n",
      "Epoch: 7930, MSE: 0.25479194266838007, Learning Rate: 0.060349999999999994\n",
      "Epoch: 7931, MSE: 0.254789438476411, Learning Rate: 0.06034500000000001\n",
      "Epoch: 7932, MSE: 0.2547869342339348, Learning Rate: 0.06034\n",
      "Epoch: 7933, MSE: 0.2547844299409511, Learning Rate: 0.06033500000000001\n",
      "Epoch: 7934, MSE: 0.25478192559746315, Learning Rate: 0.060329999999999995\n",
      "Epoch: 7935, MSE: 0.2547794212034696, Learning Rate: 0.06032500000000001\n",
      "Epoch: 7936, MSE: 0.25477691675897285, Learning Rate: 0.06032\n",
      "Epoch: 7937, MSE: 0.25477441226397235, Learning Rate: 0.06031500000000001\n",
      "Epoch: 7938, MSE: 0.2547719077184691, Learning Rate: 0.06031\n",
      "Epoch: 7939, MSE: 0.25476940312246427, Learning Rate: 0.060305\n",
      "Epoch: 7940, MSE: 0.25476689847595807, Learning Rate: 0.0603\n",
      "Epoch: 7941, MSE: 0.25476439377895127, Learning Rate: 0.060295\n",
      "Epoch: 7942, MSE: 0.25476188903144553, Learning Rate: 0.06029\n",
      "Epoch: 7943, MSE: 0.25475938423343997, Learning Rate: 0.060285000000000005\n",
      "Epoch: 7944, MSE: 0.2547568793849359, Learning Rate: 0.06028\n",
      "Epoch: 7945, MSE: 0.25475437448593546, Learning Rate: 0.060275\n",
      "Epoch: 7946, MSE: 0.25475186953643714, Learning Rate: 0.060270000000000004\n",
      "Epoch: 7947, MSE: 0.25474936453644326, Learning Rate: 0.060265000000000006\n",
      "Epoch: 7948, MSE: 0.25474685948595416, Learning Rate: 0.06026000000000001\n",
      "Epoch: 7949, MSE: 0.2547443543849701, Learning Rate: 0.060254999999999996\n",
      "Epoch: 7950, MSE: 0.2547418492334922, Learning Rate: 0.060250000000000005\n",
      "Epoch: 7951, MSE: 0.25473934403152154, Learning Rate: 0.06024499999999999\n",
      "Epoch: 7952, MSE: 0.25473683877905867, Learning Rate: 0.06024000000000001\n",
      "Epoch: 7953, MSE: 0.254734333476103, Learning Rate: 0.060235\n",
      "Epoch: 7954, MSE: 0.25473182812265777, Learning Rate: 0.060230000000000006\n",
      "Epoch: 7955, MSE: 0.2547293227187214, Learning Rate: 0.060225\n",
      "Epoch: 7956, MSE: 0.25472681726429536, Learning Rate: 0.06022000000000001\n",
      "Epoch: 7957, MSE: 0.25472431175938154, Learning Rate: 0.060215\n",
      "Epoch: 7958, MSE: 0.25472180620397894, Learning Rate: 0.060210000000000014\n",
      "Epoch: 7959, MSE: 0.25471930059808934, Learning Rate: 0.060205\n",
      "Epoch: 7960, MSE: 0.2547167949417129, Learning Rate: 0.060200000000000004\n",
      "Epoch: 7961, MSE: 0.25471428923485145, Learning Rate: 0.060195\n",
      "Epoch: 7962, MSE: 0.2547117834775041, Learning Rate: 0.06019\n",
      "Epoch: 7963, MSE: 0.25470927766967305, Learning Rate: 0.060185\n",
      "Epoch: 7964, MSE: 0.2547067718113582, Learning Rate: 0.060180000000000004\n",
      "Epoch: 7965, MSE: 0.2547042659025605, Learning Rate: 0.060175000000000006\n",
      "Epoch: 7966, MSE: 0.2547017599432802, Learning Rate: 0.06017\n",
      "Epoch: 7967, MSE: 0.2546992539335199, Learning Rate: 0.060165\n",
      "Epoch: 7968, MSE: 0.2546967478732779, Learning Rate: 0.060160000000000005\n",
      "Epoch: 7969, MSE: 0.2546942417625561, Learning Rate: 0.06015500000000001\n",
      "Epoch: 7970, MSE: 0.2546917356013551, Learning Rate: 0.060149999999999995\n",
      "Epoch: 7971, MSE: 0.2546892293896757, Learning Rate: 0.060145000000000004\n",
      "Epoch: 7972, MSE: 0.25468672312751894, Learning Rate: 0.06014\n",
      "Epoch: 7973, MSE: 0.2546842168148845, Learning Rate: 0.06013500000000001\n",
      "Epoch: 7974, MSE: 0.2546817104517758, Learning Rate: 0.060129999999999996\n",
      "Epoch: 7975, MSE: 0.2546792040381902, Learning Rate: 0.06012500000000001\n",
      "Epoch: 7976, MSE: 0.2546766975741296, Learning Rate: 0.06012\n",
      "Epoch: 7977, MSE: 0.2546741910595957, Learning Rate: 0.06011500000000001\n",
      "Epoch: 7978, MSE: 0.2546716844945886, Learning Rate: 0.06011\n",
      "Epoch: 7979, MSE: 0.2546691778791086, Learning Rate: 0.060105\n",
      "Epoch: 7980, MSE: 0.2546666712131571, Learning Rate: 0.0601\n",
      "Epoch: 7981, MSE: 0.2546641644967349, Learning Rate: 0.060095\n",
      "Epoch: 7982, MSE: 0.25466165772984245, Learning Rate: 0.060090000000000005\n",
      "Epoch: 7983, MSE: 0.25465915091248054, Learning Rate: 0.060085\n",
      "Epoch: 7984, MSE: 0.25465664404464994, Learning Rate: 0.06008\n",
      "Epoch: 7985, MSE: 0.25465413712635115, Learning Rate: 0.060075\n",
      "Epoch: 7986, MSE: 0.2546516301575848, Learning Rate: 0.060070000000000005\n",
      "Epoch: 7987, MSE: 0.25464912313835336, Learning Rate: 0.06006500000000001\n",
      "Epoch: 7988, MSE: 0.2546466160686544, Learning Rate: 0.06006\n",
      "Epoch: 7989, MSE: 0.25464410894849165, Learning Rate: 0.060055\n",
      "Epoch: 7990, MSE: 0.2546416017778645, Learning Rate: 0.060050000000000006\n",
      "Epoch: 7991, MSE: 0.254639094556774, Learning Rate: 0.060044999999999994\n",
      "Epoch: 7992, MSE: 0.2546365872852202, Learning Rate: 0.06004000000000001\n",
      "Epoch: 7993, MSE: 0.25463407996320486, Learning Rate: 0.060035\n",
      "Epoch: 7994, MSE: 0.2546315725907282, Learning Rate: 0.06003000000000001\n",
      "Epoch: 7995, MSE: 0.2546290651677914, Learning Rate: 0.060024999999999995\n",
      "Epoch: 7996, MSE: 0.2546265576943949, Learning Rate: 0.06002000000000001\n",
      "Epoch: 7997, MSE: 0.254624050170539, Learning Rate: 0.060015\n",
      "Epoch: 7998, MSE: 0.25462154259622544, Learning Rate: 0.06001000000000001\n",
      "Epoch: 7999, MSE: 0.2546190349714537, Learning Rate: 0.060005\n",
      "Epoch: 8000, MSE: 0.2546165272962258, Learning Rate: 0.06\n",
      "Epoch: 8001, MSE: 0.25461401957054164, Learning Rate: 0.059995\n",
      "Epoch: 8002, MSE: 0.2546115117944035, Learning Rate: 0.05999\n",
      "Epoch: 8003, MSE: 0.25460900396780956, Learning Rate: 0.059985000000000004\n",
      "Epoch: 8004, MSE: 0.25460649609076297, Learning Rate: 0.059980000000000006\n",
      "Epoch: 8005, MSE: 0.2546039881632622, Learning Rate: 0.059975\n",
      "Epoch: 8006, MSE: 0.25460148018530987, Learning Rate: 0.05997\n",
      "Epoch: 8007, MSE: 0.25459897215690724, Learning Rate: 0.059965000000000004\n",
      "Epoch: 8008, MSE: 0.2545964640780524, Learning Rate: 0.059960000000000006\n",
      "Epoch: 8009, MSE: 0.2545939559487489, Learning Rate: 0.05995500000000001\n",
      "Epoch: 8010, MSE: 0.2545914477689956, Learning Rate: 0.059949999999999996\n",
      "Epoch: 8011, MSE: 0.2545889395387943, Learning Rate: 0.059945000000000005\n",
      "Epoch: 8012, MSE: 0.25458643125814523, Learning Rate: 0.05993999999999999\n",
      "Epoch: 8013, MSE: 0.2545839229270499, Learning Rate: 0.05993500000000001\n",
      "Epoch: 8014, MSE: 0.25458141454550803, Learning Rate: 0.05993\n",
      "Epoch: 8015, MSE: 0.2545789061135209, Learning Rate: 0.059925000000000006\n",
      "Epoch: 8016, MSE: 0.2545763976310892, Learning Rate: 0.05992\n",
      "Epoch: 8017, MSE: 0.2545738890982139, Learning Rate: 0.05991500000000001\n",
      "Epoch: 8018, MSE: 0.25457138051489636, Learning Rate: 0.05991\n",
      "Epoch: 8019, MSE: 0.2545688718811348, Learning Rate: 0.059905000000000014\n",
      "Epoch: 8020, MSE: 0.2545663631969331, Learning Rate: 0.0599\n",
      "Epoch: 8021, MSE: 0.25456385446229096, Learning Rate: 0.059895000000000004\n",
      "Epoch: 8022, MSE: 0.25456134567720784, Learning Rate: 0.05989\n",
      "Epoch: 8023, MSE: 0.2545588368416862, Learning Rate: 0.059885\n",
      "Epoch: 8024, MSE: 0.2545563279557261, Learning Rate: 0.05988\n",
      "Epoch: 8025, MSE: 0.2545538190193281, Learning Rate: 0.059875000000000005\n",
      "Epoch: 8026, MSE: 0.2545513100324939, Learning Rate: 0.05987000000000001\n",
      "Epoch: 8027, MSE: 0.2545488009952234, Learning Rate: 0.059865\n",
      "Epoch: 8028, MSE: 0.2545462919075174, Learning Rate: 0.059860000000000003\n",
      "Epoch: 8029, MSE: 0.2545437827693767, Learning Rate: 0.059855000000000005\n",
      "Epoch: 8030, MSE: 0.2545412735808026, Learning Rate: 0.05985000000000001\n",
      "Epoch: 8031, MSE: 0.25453876434179484, Learning Rate: 0.059844999999999995\n",
      "Epoch: 8032, MSE: 0.2545362550523555, Learning Rate: 0.059840000000000004\n",
      "Epoch: 8033, MSE: 0.2545337457124847, Learning Rate: 0.059835\n",
      "Epoch: 8034, MSE: 0.2545312363221831, Learning Rate: 0.05983000000000001\n",
      "Epoch: 8035, MSE: 0.25452872688145106, Learning Rate: 0.059824999999999996\n",
      "Epoch: 8036, MSE: 0.25452621739029124, Learning Rate: 0.05982000000000001\n",
      "Epoch: 8037, MSE: 0.25452370784870176, Learning Rate: 0.059815\n",
      "Epoch: 8038, MSE: 0.25452119825668507, Learning Rate: 0.05981000000000001\n",
      "Epoch: 8039, MSE: 0.25451868861424215, Learning Rate: 0.059805\n",
      "Epoch: 8040, MSE: 0.25451617892137207, Learning Rate: 0.0598\n",
      "Epoch: 8041, MSE: 0.25451366917807744, Learning Rate: 0.059795\n",
      "Epoch: 8042, MSE: 0.25451115938435864, Learning Rate: 0.05979\n",
      "Epoch: 8043, MSE: 0.25450864954021574, Learning Rate: 0.059785000000000005\n",
      "Epoch: 8044, MSE: 0.25450613964564955, Learning Rate: 0.05978\n",
      "Epoch: 8045, MSE: 0.2545036297006618, Learning Rate: 0.059775\n",
      "Epoch: 8046, MSE: 0.25450111970525224, Learning Rate: 0.059770000000000004\n",
      "Epoch: 8047, MSE: 0.2544986096594225, Learning Rate: 0.059765000000000006\n",
      "Epoch: 8048, MSE: 0.2544960995631723, Learning Rate: 0.05976000000000001\n",
      "Epoch: 8049, MSE: 0.25449358941650396, Learning Rate: 0.059755\n",
      "Epoch: 8050, MSE: 0.2544910792194173, Learning Rate: 0.05975\n",
      "Epoch: 8051, MSE: 0.25448856897191297, Learning Rate: 0.059745000000000006\n",
      "Epoch: 8052, MSE: 0.2544860586739918, Learning Rate: 0.059739999999999994\n",
      "Epoch: 8053, MSE: 0.25448354832565445, Learning Rate: 0.05973500000000001\n",
      "Epoch: 8054, MSE: 0.2544810379269025, Learning Rate: 0.05973\n",
      "Epoch: 8055, MSE: 0.25447852747773575, Learning Rate: 0.05972500000000001\n",
      "Epoch: 8056, MSE: 0.2544760169781562, Learning Rate: 0.059719999999999995\n",
      "Epoch: 8057, MSE: 0.2544735064281626, Learning Rate: 0.05971500000000001\n",
      "Epoch: 8058, MSE: 0.2544709958277576, Learning Rate: 0.05971\n",
      "Epoch: 8059, MSE: 0.2544684851769418, Learning Rate: 0.05970500000000001\n",
      "Epoch: 8060, MSE: 0.2544659744757155, Learning Rate: 0.0597\n",
      "Epoch: 8061, MSE: 0.2544634637240791, Learning Rate: 0.059695\n",
      "Epoch: 8062, MSE: 0.2544609529220344, Learning Rate: 0.05969\n",
      "Epoch: 8063, MSE: 0.254458442069581, Learning Rate: 0.059685\n",
      "Epoch: 8064, MSE: 0.25445593116672144, Learning Rate: 0.059680000000000004\n",
      "Epoch: 8065, MSE: 0.2544534202134548, Learning Rate: 0.059675000000000006\n",
      "Epoch: 8066, MSE: 0.2544509092097822, Learning Rate: 0.05967\n",
      "Epoch: 8067, MSE: 0.2544483981557051, Learning Rate: 0.059665\n",
      "Epoch: 8068, MSE: 0.25444588705122345, Learning Rate: 0.059660000000000005\n",
      "Epoch: 8069, MSE: 0.25444337589633886, Learning Rate: 0.05965500000000001\n",
      "Epoch: 8070, MSE: 0.2544408646910517, Learning Rate: 0.05965000000000001\n",
      "Epoch: 8071, MSE: 0.2544383534353625, Learning Rate: 0.059645\n",
      "Epoch: 8072, MSE: 0.25443584212927295, Learning Rate: 0.059640000000000006\n",
      "Epoch: 8073, MSE: 0.2544333307727825, Learning Rate: 0.059634999999999994\n",
      "Epoch: 8074, MSE: 0.2544308193658934, Learning Rate: 0.05963000000000001\n",
      "Epoch: 8075, MSE: 0.25442830790860516, Learning Rate: 0.059625\n",
      "Epoch: 8076, MSE: 0.25442579640091945, Learning Rate: 0.059620000000000006\n",
      "Epoch: 8077, MSE: 0.2544232848428369, Learning Rate: 0.059615\n",
      "Epoch: 8078, MSE: 0.25442077323435686, Learning Rate: 0.05961000000000001\n",
      "Epoch: 8079, MSE: 0.2544182615754827, Learning Rate: 0.059605\n",
      "Epoch: 8080, MSE: 0.25441574986621446, Learning Rate: 0.0596\n",
      "Epoch: 8081, MSE: 0.25441323810655114, Learning Rate: 0.059595\n",
      "Epoch: 8082, MSE: 0.2544107262964958, Learning Rate: 0.059590000000000004\n",
      "Epoch: 8083, MSE: 0.254408214436048, Learning Rate: 0.059585\n",
      "Epoch: 8084, MSE: 0.25440570252520806, Learning Rate: 0.05958\n",
      "Epoch: 8085, MSE: 0.25440319056397825, Learning Rate: 0.059575\n",
      "Epoch: 8086, MSE: 0.2544006785523585, Learning Rate: 0.059570000000000005\n",
      "Epoch: 8087, MSE: 0.2543981664903492, Learning Rate: 0.05956500000000001\n",
      "Epoch: 8088, MSE: 0.25439565437795253, Learning Rate: 0.05956\n",
      "Epoch: 8089, MSE: 0.2543931422151679, Learning Rate: 0.059555000000000004\n",
      "Epoch: 8090, MSE: 0.2543906300019969, Learning Rate: 0.05954999999999999\n",
      "Epoch: 8091, MSE: 0.25438811773843995, Learning Rate: 0.05954500000000001\n",
      "Epoch: 8092, MSE: 0.2543856054244985, Learning Rate: 0.059539999999999996\n",
      "Epoch: 8093, MSE: 0.25438309306017215, Learning Rate: 0.059535000000000005\n",
      "Epoch: 8094, MSE: 0.25438058064546243, Learning Rate: 0.05953\n",
      "Epoch: 8095, MSE: 0.25437806818037056, Learning Rate: 0.05952500000000001\n",
      "Epoch: 8096, MSE: 0.2543755556648962, Learning Rate: 0.059519999999999997\n",
      "Epoch: 8097, MSE: 0.25437304309904146, Learning Rate: 0.05951500000000001\n",
      "Epoch: 8098, MSE: 0.2543705304828067, Learning Rate: 0.05951\n",
      "Epoch: 8099, MSE: 0.2543680178161924, Learning Rate: 0.05950500000000001\n",
      "Epoch: 8100, MSE: 0.2543655050991997, Learning Rate: 0.0595\n",
      "Epoch: 8101, MSE: 0.2543629923318285, Learning Rate: 0.059495\n",
      "Epoch: 8102, MSE: 0.2543604795140804, Learning Rate: 0.05949\n",
      "Epoch: 8103, MSE: 0.25435796664595656, Learning Rate: 0.059485\n",
      "Epoch: 8104, MSE: 0.2543554537274573, Learning Rate: 0.059480000000000005\n",
      "Epoch: 8105, MSE: 0.2543529407585836, Learning Rate: 0.059475\n",
      "Epoch: 8106, MSE: 0.25435042773933547, Learning Rate: 0.05947\n",
      "Epoch: 8107, MSE: 0.2543479146697154, Learning Rate: 0.059465000000000004\n",
      "Epoch: 8108, MSE: 0.2543454015497229, Learning Rate: 0.059460000000000006\n",
      "Epoch: 8109, MSE: 0.2543428883793589, Learning Rate: 0.05945500000000001\n",
      "Epoch: 8110, MSE: 0.2543403751586245, Learning Rate: 0.05945\n",
      "Epoch: 8111, MSE: 0.2543378618875203, Learning Rate: 0.059445\n",
      "Epoch: 8112, MSE: 0.2543353485660473, Learning Rate: 0.05944000000000001\n",
      "Epoch: 8113, MSE: 0.25433283519420624, Learning Rate: 0.059434999999999995\n",
      "Epoch: 8114, MSE: 0.2543303217719977, Learning Rate: 0.05943000000000001\n",
      "Epoch: 8115, MSE: 0.2543278082994227, Learning Rate: 0.059425\n",
      "Epoch: 8116, MSE: 0.25432529477648286, Learning Rate: 0.05942000000000001\n",
      "Epoch: 8117, MSE: 0.2543227812031773, Learning Rate: 0.059414999999999996\n",
      "Epoch: 8118, MSE: 0.2543202675795083, Learning Rate: 0.05941000000000001\n",
      "Epoch: 8119, MSE: 0.2543177539054757, Learning Rate: 0.059405\n",
      "Epoch: 8120, MSE: 0.25431524018108154, Learning Rate: 0.0594\n",
      "Epoch: 8121, MSE: 0.25431272640632535, Learning Rate: 0.059395\n",
      "Epoch: 8122, MSE: 0.25431021258120806, Learning Rate: 0.05939\n",
      "Epoch: 8123, MSE: 0.254307698705731, Learning Rate: 0.059385\n",
      "Epoch: 8124, MSE: 0.25430518477989505, Learning Rate: 0.05938\n",
      "Epoch: 8125, MSE: 0.2543026708037009, Learning Rate: 0.059375000000000004\n",
      "Epoch: 8126, MSE: 0.25430015677714946, Learning Rate: 0.059370000000000006\n",
      "Epoch: 8127, MSE: 0.2542976427002408, Learning Rate: 0.059365\n",
      "Epoch: 8128, MSE: 0.2542951285729765, Learning Rate: 0.05936\n",
      "Epoch: 8129, MSE: 0.2542926143953576, Learning Rate: 0.059355000000000005\n",
      "Epoch: 8130, MSE: 0.254290100167384, Learning Rate: 0.05935000000000001\n",
      "Epoch: 8131, MSE: 0.2542875858890573, Learning Rate: 0.05934500000000001\n",
      "Epoch: 8132, MSE: 0.2542850715603778, Learning Rate: 0.05934\n",
      "Epoch: 8133, MSE: 0.2542825571813474, Learning Rate: 0.059335000000000006\n",
      "Epoch: 8134, MSE: 0.25428004275196553, Learning Rate: 0.059329999999999994\n",
      "Epoch: 8135, MSE: 0.2542775282722336, Learning Rate: 0.05932500000000001\n",
      "Epoch: 8136, MSE: 0.25427501374215206, Learning Rate: 0.05932\n",
      "Epoch: 8137, MSE: 0.2542724991617227, Learning Rate: 0.05931500000000001\n",
      "Epoch: 8138, MSE: 0.25426998453094546, Learning Rate: 0.05931\n",
      "Epoch: 8139, MSE: 0.2542674698498214, Learning Rate: 0.05930500000000001\n",
      "Epoch: 8140, MSE: 0.25426495511835107, Learning Rate: 0.0593\n",
      "Epoch: 8141, MSE: 0.254262440336536, Learning Rate: 0.059295\n",
      "Epoch: 8142, MSE: 0.25425992550437676, Learning Rate: 0.05929\n",
      "Epoch: 8143, MSE: 0.25425741062187374, Learning Rate: 0.059285000000000004\n",
      "Epoch: 8144, MSE: 0.2542548956890283, Learning Rate: 0.05928\n",
      "Epoch: 8145, MSE: 0.25425238070584183, Learning Rate: 0.059275\n",
      "Epoch: 8146, MSE: 0.2542498656723138, Learning Rate: 0.05927\n",
      "Epoch: 8147, MSE: 0.25424735058844417, Learning Rate: 0.059265000000000005\n",
      "Epoch: 8148, MSE: 0.2542448354542371, Learning Rate: 0.05926000000000001\n",
      "Epoch: 8149, MSE: 0.2542423202696913, Learning Rate: 0.059255\n",
      "Epoch: 8150, MSE: 0.2542398050348062, Learning Rate: 0.059250000000000004\n",
      "Epoch: 8151, MSE: 0.25423728974958615, Learning Rate: 0.05924499999999999\n",
      "Epoch: 8152, MSE: 0.2542347744140294, Learning Rate: 0.05924000000000001\n",
      "Epoch: 8153, MSE: 0.2542322590281375, Learning Rate: 0.059234999999999996\n",
      "Epoch: 8154, MSE: 0.2542297435919111, Learning Rate: 0.059230000000000005\n",
      "Epoch: 8155, MSE: 0.2542272281053514, Learning Rate: 0.059225\n",
      "Epoch: 8156, MSE: 0.25422471256845985, Learning Rate: 0.05922000000000001\n",
      "Epoch: 8157, MSE: 0.2542221969812348, Learning Rate: 0.059215\n",
      "Epoch: 8158, MSE: 0.25421968134367956, Learning Rate: 0.05921000000000001\n",
      "Epoch: 8159, MSE: 0.2542171656557947, Learning Rate: 0.059205\n",
      "Epoch: 8160, MSE: 0.2542146499175797, Learning Rate: 0.05920000000000001\n",
      "Epoch: 8161, MSE: 0.254212134129036, Learning Rate: 0.059195\n",
      "Epoch: 8162, MSE: 0.2542096182901656, Learning Rate: 0.05919\n",
      "Epoch: 8163, MSE: 0.2542071024009678, Learning Rate: 0.059185\n",
      "Epoch: 8164, MSE: 0.2542045864614434, Learning Rate: 0.05918\n",
      "Epoch: 8165, MSE: 0.2542020704715957, Learning Rate: 0.059175000000000005\n",
      "Epoch: 8166, MSE: 0.254199554431422, Learning Rate: 0.05917\n",
      "Epoch: 8167, MSE: 0.2541970383409254, Learning Rate: 0.059165\n",
      "Epoch: 8168, MSE: 0.2541945222001064, Learning Rate: 0.059160000000000004\n",
      "Epoch: 8169, MSE: 0.2541920060089651, Learning Rate: 0.059155000000000006\n",
      "Epoch: 8170, MSE: 0.25418948976750355, Learning Rate: 0.05915000000000001\n",
      "Epoch: 8171, MSE: 0.2541869734757217, Learning Rate: 0.059145\n",
      "Epoch: 8172, MSE: 0.2541844571336201, Learning Rate: 0.05914\n",
      "Epoch: 8173, MSE: 0.25418194074120043, Learning Rate: 0.05913500000000001\n",
      "Epoch: 8174, MSE: 0.2541794242984629, Learning Rate: 0.059129999999999995\n",
      "Epoch: 8175, MSE: 0.25417690780540925, Learning Rate: 0.05912500000000001\n",
      "Epoch: 8176, MSE: 0.25417439126203945, Learning Rate: 0.05912\n",
      "Epoch: 8177, MSE: 0.2541718746683535, Learning Rate: 0.05911500000000001\n",
      "Epoch: 8178, MSE: 0.25416935802435486, Learning Rate: 0.059109999999999996\n",
      "Epoch: 8179, MSE: 0.254166841330042, Learning Rate: 0.05910500000000001\n",
      "Epoch: 8180, MSE: 0.25416432458541727, Learning Rate: 0.0591\n",
      "Epoch: 8181, MSE: 0.2541618077904798, Learning Rate: 0.059095\n",
      "Epoch: 8182, MSE: 0.254159290945233, Learning Rate: 0.059090000000000004\n",
      "Epoch: 8183, MSE: 0.2541567740496753, Learning Rate: 0.059085\n",
      "Epoch: 8184, MSE: 0.25415425710380857, Learning Rate: 0.05908\n",
      "Epoch: 8185, MSE: 0.2541517401076344, Learning Rate: 0.059075\n",
      "Epoch: 8186, MSE: 0.25414922306115156, Learning Rate: 0.059070000000000004\n",
      "Epoch: 8187, MSE: 0.2541467059643628, Learning Rate: 0.059065000000000006\n",
      "Epoch: 8188, MSE: 0.25414418881726725, Learning Rate: 0.05906\n",
      "Epoch: 8189, MSE: 0.25414167161986834, Learning Rate: 0.059055\n",
      "Epoch: 8190, MSE: 0.25413915437216494, Learning Rate: 0.059050000000000005\n",
      "Epoch: 8191, MSE: 0.2541366370741581, Learning Rate: 0.05904499999999999\n",
      "Epoch: 8192, MSE: 0.25413411972584954, Learning Rate: 0.05904000000000001\n",
      "Epoch: 8193, MSE: 0.25413160232723864, Learning Rate: 0.059035\n",
      "Epoch: 8194, MSE: 0.25412908487832725, Learning Rate: 0.059030000000000006\n",
      "Epoch: 8195, MSE: 0.2541265673791169, Learning Rate: 0.059024999999999994\n",
      "Epoch: 8196, MSE: 0.25412404982960624, Learning Rate: 0.05902000000000001\n",
      "Epoch: 8197, MSE: 0.2541215322297985, Learning Rate: 0.059015\n",
      "Epoch: 8198, MSE: 0.25411901457969394, Learning Rate: 0.05901000000000001\n",
      "Epoch: 8199, MSE: 0.25411649687929266, Learning Rate: 0.059005\n",
      "Epoch: 8200, MSE: 0.2541139791285953, Learning Rate: 0.05900000000000001\n",
      "Epoch: 8201, MSE: 0.25411146132760415, Learning Rate: 0.058995\n",
      "Epoch: 8202, MSE: 0.2541089434763184, Learning Rate: 0.05899\n",
      "Epoch: 8203, MSE: 0.2541064255747401, Learning Rate: 0.058985\n",
      "Epoch: 8204, MSE: 0.25410390762286983, Learning Rate: 0.058980000000000005\n",
      "Epoch: 8205, MSE: 0.2541013896207084, Learning Rate: 0.058975\n",
      "Epoch: 8206, MSE: 0.25409887156825656, Learning Rate: 0.05897\n",
      "Epoch: 8207, MSE: 0.25409635346551546, Learning Rate: 0.058965000000000004\n",
      "Epoch: 8208, MSE: 0.25409383531248503, Learning Rate: 0.058960000000000005\n",
      "Epoch: 8209, MSE: 0.25409131710916727, Learning Rate: 0.05895500000000001\n",
      "Epoch: 8210, MSE: 0.2540887988555627, Learning Rate: 0.05895\n",
      "Epoch: 8211, MSE: 0.2540862805516718, Learning Rate: 0.058945000000000004\n",
      "Epoch: 8212, MSE: 0.2540837621974964, Learning Rate: 0.05893999999999999\n",
      "Epoch: 8213, MSE: 0.2540812437930364, Learning Rate: 0.05893500000000001\n",
      "Epoch: 8214, MSE: 0.2540787253382927, Learning Rate: 0.058929999999999996\n",
      "Epoch: 8215, MSE: 0.25407620683326637, Learning Rate: 0.058925000000000005\n",
      "Epoch: 8216, MSE: 0.254073688277958, Learning Rate: 0.05892\n",
      "Epoch: 8217, MSE: 0.254071169672369, Learning Rate: 0.05891500000000001\n",
      "Epoch: 8218, MSE: 0.2540686510165007, Learning Rate: 0.05891\n",
      "Epoch: 8219, MSE: 0.2540661323103524, Learning Rate: 0.05890500000000001\n",
      "Epoch: 8220, MSE: 0.25406361355392576, Learning Rate: 0.0589\n",
      "Epoch: 8221, MSE: 0.25406109474722244, Learning Rate: 0.058895\n",
      "Epoch: 8222, MSE: 0.2540585758902423, Learning Rate: 0.05889\n",
      "Epoch: 8223, MSE: 0.25405605698298667, Learning Rate: 0.058885\n",
      "Epoch: 8224, MSE: 0.25405353802545577, Learning Rate: 0.05888\n",
      "Epoch: 8225, MSE: 0.2540510190176514, Learning Rate: 0.058875000000000004\n",
      "Epoch: 8226, MSE: 0.25404849995957385, Learning Rate: 0.058870000000000006\n",
      "Epoch: 8227, MSE: 0.25404598085122393, Learning Rate: 0.058865\n",
      "Epoch: 8228, MSE: 0.2540434616926026, Learning Rate: 0.05886\n",
      "Epoch: 8229, MSE: 0.2540409424837114, Learning Rate: 0.058855000000000005\n",
      "Epoch: 8230, MSE: 0.25403842322455017, Learning Rate: 0.058850000000000006\n",
      "Epoch: 8231, MSE: 0.25403590391512015, Learning Rate: 0.058844999999999995\n",
      "Epoch: 8232, MSE: 0.25403338455542324, Learning Rate: 0.05884\n",
      "Epoch: 8233, MSE: 0.2540308651454572, Learning Rate: 0.058835\n",
      "Epoch: 8234, MSE: 0.2540283456852262, Learning Rate: 0.05883000000000001\n",
      "Epoch: 8235, MSE: 0.2540258261747311, Learning Rate: 0.058824999999999995\n",
      "Epoch: 8236, MSE: 0.2540233066139706, Learning Rate: 0.05882000000000001\n",
      "Epoch: 8237, MSE: 0.25402078700294667, Learning Rate: 0.058815\n",
      "Epoch: 8238, MSE: 0.2540182673416603, Learning Rate: 0.05881000000000001\n",
      "Epoch: 8239, MSE: 0.2540157476301121, Learning Rate: 0.058804999999999996\n",
      "Epoch: 8240, MSE: 0.2540132278683027, Learning Rate: 0.05880000000000001\n",
      "Epoch: 8241, MSE: 0.254010708056234, Learning Rate: 0.058795\n",
      "Epoch: 8242, MSE: 0.25400818819390575, Learning Rate: 0.05879\n",
      "Epoch: 8243, MSE: 0.25400566828131965, Learning Rate: 0.058785000000000004\n",
      "Epoch: 8244, MSE: 0.25400314831847626, Learning Rate: 0.05878\n",
      "Epoch: 8245, MSE: 0.25400062830537606, Learning Rate: 0.058775\n",
      "Epoch: 8246, MSE: 0.25399810824202074, Learning Rate: 0.05877\n",
      "Epoch: 8247, MSE: 0.25399558812841005, Learning Rate: 0.058765000000000005\n",
      "Epoch: 8248, MSE: 0.2539930679645456, Learning Rate: 0.05876000000000001\n",
      "Epoch: 8249, MSE: 0.2539905477504284, Learning Rate: 0.058755\n",
      "Epoch: 8250, MSE: 0.25398802748605975, Learning Rate: 0.058750000000000004\n",
      "Epoch: 8251, MSE: 0.2539855071714393, Learning Rate: 0.058745000000000006\n",
      "Epoch: 8252, MSE: 0.2539829868065686, Learning Rate: 0.058739999999999994\n",
      "Epoch: 8253, MSE: 0.25398046639144767, Learning Rate: 0.05873500000000001\n",
      "Epoch: 8254, MSE: 0.25397794592607964, Learning Rate: 0.05873\n",
      "Epoch: 8255, MSE: 0.253975425410464, Learning Rate: 0.058725000000000006\n",
      "Epoch: 8256, MSE: 0.25397290484460117, Learning Rate: 0.058719999999999994\n",
      "Epoch: 8257, MSE: 0.253970384228492, Learning Rate: 0.05871500000000001\n",
      "Epoch: 8258, MSE: 0.25396786356213824, Learning Rate: 0.05871\n",
      "Epoch: 8259, MSE: 0.25396534284554, Learning Rate: 0.05870500000000001\n",
      "Epoch: 8260, MSE: 0.2539628220786992, Learning Rate: 0.0587\n",
      "Epoch: 8261, MSE: 0.2539603012616156, Learning Rate: 0.05869500000000001\n",
      "Epoch: 8262, MSE: 0.2539577803942908, Learning Rate: 0.05869\n",
      "Epoch: 8263, MSE: 0.2539552594767252, Learning Rate: 0.058685\n",
      "Epoch: 8264, MSE: 0.25395273850891975, Learning Rate: 0.05868\n",
      "Epoch: 8265, MSE: 0.2539502174908757, Learning Rate: 0.058675000000000005\n",
      "Epoch: 8266, MSE: 0.25394769642259396, Learning Rate: 0.05867\n",
      "Epoch: 8267, MSE: 0.2539451753040759, Learning Rate: 0.058665\n",
      "Epoch: 8268, MSE: 0.2539426541353208, Learning Rate: 0.058660000000000004\n",
      "Epoch: 8269, MSE: 0.25394013291632994, Learning Rate: 0.058655000000000006\n",
      "Epoch: 8270, MSE: 0.25393761164710615, Learning Rate: 0.05865000000000001\n",
      "Epoch: 8271, MSE: 0.2539350903276484, Learning Rate: 0.058645\n",
      "Epoch: 8272, MSE: 0.25393256895795785, Learning Rate: 0.058640000000000005\n",
      "Epoch: 8273, MSE: 0.2539300475380356, Learning Rate: 0.05863499999999999\n",
      "Epoch: 8274, MSE: 0.2539275260678827, Learning Rate: 0.05863000000000001\n",
      "Epoch: 8275, MSE: 0.2539250045474998, Learning Rate: 0.058625\n",
      "Epoch: 8276, MSE: 0.2539224829768881, Learning Rate: 0.058620000000000005\n",
      "Epoch: 8277, MSE: 0.25391996135604883, Learning Rate: 0.058615\n",
      "Epoch: 8278, MSE: 0.2539174396849818, Learning Rate: 0.05861000000000001\n",
      "Epoch: 8279, MSE: 0.2539149179636882, Learning Rate: 0.058605\n",
      "Epoch: 8280, MSE: 0.2539123961921701, Learning Rate: 0.05860000000000001\n",
      "Epoch: 8281, MSE: 0.2539098743704269, Learning Rate: 0.058595\n",
      "Epoch: 8282, MSE: 0.2539073524984602, Learning Rate: 0.05859\n",
      "Epoch: 8283, MSE: 0.25390483057627067, Learning Rate: 0.058585\n",
      "Epoch: 8284, MSE: 0.25390230860385943, Learning Rate: 0.05858\n",
      "Epoch: 8285, MSE: 0.253899786581227, Learning Rate: 0.058575\n",
      "Epoch: 8286, MSE: 0.25389726450837546, Learning Rate: 0.058570000000000004\n",
      "Epoch: 8287, MSE: 0.2538947423853038, Learning Rate: 0.058565000000000006\n",
      "Epoch: 8288, MSE: 0.25389222021201496, Learning Rate: 0.05856\n",
      "Epoch: 8289, MSE: 0.25388969798850786, Learning Rate: 0.058555\n",
      "Epoch: 8290, MSE: 0.2538871757147848, Learning Rate: 0.058550000000000005\n",
      "Epoch: 8291, MSE: 0.2538846533908464, Learning Rate: 0.05854500000000001\n",
      "Epoch: 8292, MSE: 0.2538821310166934, Learning Rate: 0.058539999999999995\n",
      "Epoch: 8293, MSE: 0.25387960859232694, Learning Rate: 0.058535000000000004\n",
      "Epoch: 8294, MSE: 0.2538770861177475, Learning Rate: 0.05853\n",
      "Epoch: 8295, MSE: 0.25387456359295607, Learning Rate: 0.05852500000000001\n",
      "Epoch: 8296, MSE: 0.2538720410179529, Learning Rate: 0.058519999999999996\n",
      "Epoch: 8297, MSE: 0.25386951839274047, Learning Rate: 0.05851500000000001\n",
      "Epoch: 8298, MSE: 0.25386699571731913, Learning Rate: 0.05851\n",
      "Epoch: 8299, MSE: 0.25386447299168896, Learning Rate: 0.05850500000000001\n",
      "Epoch: 8300, MSE: 0.2538619502158519, Learning Rate: 0.058499999999999996\n",
      "Epoch: 8301, MSE: 0.2538594273898079, Learning Rate: 0.05849500000000001\n",
      "Epoch: 8302, MSE: 0.2538569045135586, Learning Rate: 0.05849\n",
      "Epoch: 8303, MSE: 0.2538543815871045, Learning Rate: 0.058485\n",
      "Epoch: 8304, MSE: 0.25385185861044723, Learning Rate: 0.058480000000000004\n",
      "Epoch: 8305, MSE: 0.2538493355835867, Learning Rate: 0.058475\n",
      "Epoch: 8306, MSE: 0.25384681250652436, Learning Rate: 0.05847\n",
      "Epoch: 8307, MSE: 0.2538442893792609, Learning Rate: 0.058465\n",
      "Epoch: 8308, MSE: 0.2538417662017971, Learning Rate: 0.058460000000000005\n",
      "Epoch: 8309, MSE: 0.25383924297413507, Learning Rate: 0.05845500000000001\n",
      "Epoch: 8310, MSE: 0.2538367196962742, Learning Rate: 0.05845\n",
      "Epoch: 8311, MSE: 0.2538341963682161, Learning Rate: 0.058445000000000004\n",
      "Epoch: 8312, MSE: 0.2538316729899611, Learning Rate: 0.058440000000000006\n",
      "Epoch: 8313, MSE: 0.2538291495615114, Learning Rate: 0.058434999999999994\n",
      "Epoch: 8314, MSE: 0.25382662608286677, Learning Rate: 0.05843000000000001\n",
      "Epoch: 8315, MSE: 0.2538241025540279, Learning Rate: 0.058425\n",
      "Epoch: 8316, MSE: 0.25382157897499696, Learning Rate: 0.05842000000000001\n",
      "Epoch: 8317, MSE: 0.25381905534577404, Learning Rate: 0.058414999999999995\n",
      "Epoch: 8318, MSE: 0.2538165316663595, Learning Rate: 0.05841000000000001\n",
      "Epoch: 8319, MSE: 0.2538140079367553, Learning Rate: 0.058405\n",
      "Epoch: 8320, MSE: 0.2538114841569624, Learning Rate: 0.05840000000000001\n",
      "Epoch: 8321, MSE: 0.25380896032698114, Learning Rate: 0.058395\n",
      "Epoch: 8322, MSE: 0.25380643644681267, Learning Rate: 0.05839\n",
      "Epoch: 8323, MSE: 0.25380391251645745, Learning Rate: 0.058385\n",
      "Epoch: 8324, MSE: 0.25380138853591727, Learning Rate: 0.05838\n",
      "Epoch: 8325, MSE: 0.2537988645051923, Learning Rate: 0.058375\n",
      "Epoch: 8326, MSE: 0.25379634042428356, Learning Rate: 0.058370000000000005\n",
      "Epoch: 8327, MSE: 0.25379381629319264, Learning Rate: 0.058365\n",
      "Epoch: 8328, MSE: 0.2537912921119192, Learning Rate: 0.05836\n",
      "Epoch: 8329, MSE: 0.2537887678804659, Learning Rate: 0.058355000000000004\n",
      "Epoch: 8330, MSE: 0.253786243598832, Learning Rate: 0.058350000000000006\n",
      "Epoch: 8331, MSE: 0.2537837192670189, Learning Rate: 0.05834500000000001\n",
      "Epoch: 8332, MSE: 0.25378119488502826, Learning Rate: 0.058339999999999996\n",
      "Epoch: 8333, MSE: 0.2537786704528601, Learning Rate: 0.058335000000000005\n",
      "Epoch: 8334, MSE: 0.25377614597051606, Learning Rate: 0.05832999999999999\n",
      "Epoch: 8335, MSE: 0.2537736214379963, Learning Rate: 0.05832500000000001\n",
      "Epoch: 8336, MSE: 0.25377109685530247, Learning Rate: 0.05832\n",
      "Epoch: 8337, MSE: 0.25376857222243554, Learning Rate: 0.058315000000000006\n",
      "Epoch: 8338, MSE: 0.2537660475393957, Learning Rate: 0.05831\n",
      "Epoch: 8339, MSE: 0.253763522806184, Learning Rate: 0.05830500000000001\n",
      "Epoch: 8340, MSE: 0.25376099802280216, Learning Rate: 0.0583\n",
      "Epoch: 8341, MSE: 0.2537584731892505, Learning Rate: 0.058295000000000013\n",
      "Epoch: 8342, MSE: 0.2537559483055292, Learning Rate: 0.05829\n",
      "Epoch: 8343, MSE: 0.25375342337164114, Learning Rate: 0.058285000000000003\n",
      "Epoch: 8344, MSE: 0.25375089838758597, Learning Rate: 0.05828\n",
      "Epoch: 8345, MSE: 0.25374837335336414, Learning Rate: 0.058275\n",
      "Epoch: 8346, MSE: 0.25374584826897734, Learning Rate: 0.05827\n",
      "Epoch: 8347, MSE: 0.25374332313442666, Learning Rate: 0.058265000000000004\n",
      "Epoch: 8348, MSE: 0.25374079794971255, Learning Rate: 0.058260000000000006\n",
      "Epoch: 8349, MSE: 0.2537382727148364, Learning Rate: 0.058255\n",
      "Epoch: 8350, MSE: 0.2537357474297986, Learning Rate: 0.05825\n",
      "Epoch: 8351, MSE: 0.2537332220946001, Learning Rate: 0.058245000000000005\n",
      "Epoch: 8352, MSE: 0.2537306967092432, Learning Rate: 0.05824000000000001\n",
      "Epoch: 8353, MSE: 0.253728171273727, Learning Rate: 0.058234999999999995\n",
      "Epoch: 8354, MSE: 0.2537256457880533, Learning Rate: 0.058230000000000004\n",
      "Epoch: 8355, MSE: 0.25372312025222254, Learning Rate: 0.058225\n",
      "Epoch: 8356, MSE: 0.25372059466623675, Learning Rate: 0.05822000000000001\n",
      "Epoch: 8357, MSE: 0.25371806903009514, Learning Rate: 0.058214999999999996\n",
      "Epoch: 8358, MSE: 0.2537155433438006, Learning Rate: 0.05821000000000001\n",
      "Epoch: 8359, MSE: 0.253713017607352, Learning Rate: 0.058205\n",
      "Epoch: 8360, MSE: 0.2537104918207522, Learning Rate: 0.05820000000000001\n",
      "Epoch: 8361, MSE: 0.2537079659840012, Learning Rate: 0.058195\n",
      "Epoch: 8362, MSE: 0.2537054400970995, Learning Rate: 0.05819\n",
      "Epoch: 8363, MSE: 0.25370291416004953, Learning Rate: 0.058185\n",
      "Epoch: 8364, MSE: 0.2537003881728513, Learning Rate: 0.05818\n",
      "Epoch: 8365, MSE: 0.25369786213550516, Learning Rate: 0.058175000000000004\n",
      "Epoch: 8366, MSE: 0.253695336048013, Learning Rate: 0.05817\n",
      "Epoch: 8367, MSE: 0.25369280991037446, Learning Rate: 0.058165\n",
      "Epoch: 8368, MSE: 0.25369028372259217, Learning Rate: 0.05816\n",
      "Epoch: 8369, MSE: 0.2536877574846666, Learning Rate: 0.058155000000000005\n",
      "Epoch: 8370, MSE: 0.2536852311965979, Learning Rate: 0.05815000000000001\n",
      "Epoch: 8371, MSE: 0.2536827048583877, Learning Rate: 0.058145\n",
      "Epoch: 8372, MSE: 0.25368017847003665, Learning Rate: 0.05814\n",
      "Epoch: 8373, MSE: 0.2536776520315455, Learning Rate: 0.058135000000000006\n",
      "Epoch: 8374, MSE: 0.2536751255429169, Learning Rate: 0.058129999999999994\n",
      "Epoch: 8375, MSE: 0.2536725990041488, Learning Rate: 0.05812500000000001\n",
      "Epoch: 8376, MSE: 0.2536700724152444, Learning Rate: 0.05812\n",
      "Epoch: 8377, MSE: 0.2536675457762038, Learning Rate: 0.05811500000000001\n",
      "Epoch: 8378, MSE: 0.2536650190870289, Learning Rate: 0.058109999999999995\n",
      "Epoch: 8379, MSE: 0.2536624923477196, Learning Rate: 0.05810500000000001\n",
      "Epoch: 8380, MSE: 0.25365996555827647, Learning Rate: 0.0581\n",
      "Epoch: 8381, MSE: 0.25365743871870133, Learning Rate: 0.05809500000000001\n",
      "Epoch: 8382, MSE: 0.2536549118289948, Learning Rate: 0.05809\n",
      "Epoch: 8383, MSE: 0.2536523848891591, Learning Rate: 0.058085\n",
      "Epoch: 8384, MSE: 0.25364985789919275, Learning Rate: 0.05808\n",
      "Epoch: 8385, MSE: 0.2536473308590981, Learning Rate: 0.058075\n",
      "Epoch: 8386, MSE: 0.25364480376887644, Learning Rate: 0.058070000000000004\n",
      "Epoch: 8387, MSE: 0.25364227662852823, Learning Rate: 0.058065000000000005\n",
      "Epoch: 8388, MSE: 0.253639749438054, Learning Rate: 0.05806\n",
      "Epoch: 8389, MSE: 0.25363722219745594, Learning Rate: 0.058055\n",
      "Epoch: 8390, MSE: 0.25363469490673335, Learning Rate: 0.058050000000000004\n",
      "Epoch: 8391, MSE: 0.2536321675658886, Learning Rate: 0.058045000000000006\n",
      "Epoch: 8392, MSE: 0.25362964017492245, Learning Rate: 0.05804000000000001\n",
      "Epoch: 8393, MSE: 0.2536271127338351, Learning Rate: 0.058034999999999996\n",
      "Epoch: 8394, MSE: 0.25362458524262727, Learning Rate: 0.058030000000000005\n",
      "Epoch: 8395, MSE: 0.25362205770130153, Learning Rate: 0.05802499999999999\n",
      "Epoch: 8396, MSE: 0.2536195301098574, Learning Rate: 0.05802000000000001\n",
      "Epoch: 8397, MSE: 0.253617002468296, Learning Rate: 0.058015\n",
      "Epoch: 8398, MSE: 0.2536144747766193, Learning Rate: 0.058010000000000006\n",
      "Epoch: 8399, MSE: 0.2536119470348272, Learning Rate: 0.058005\n",
      "Epoch: 8400, MSE: 0.25360941924292035, Learning Rate: 0.05800000000000001\n",
      "Epoch: 8401, MSE: 0.2536068914009012, Learning Rate: 0.057995\n",
      "Epoch: 8402, MSE: 0.25360436350876925, Learning Rate: 0.057990000000000014\n",
      "Epoch: 8403, MSE: 0.25360183556652666, Learning Rate: 0.057985\n",
      "Epoch: 8404, MSE: 0.2535993075741734, Learning Rate: 0.057980000000000004\n",
      "Epoch: 8405, MSE: 0.25359677953171117, Learning Rate: 0.057975\n",
      "Epoch: 8406, MSE: 0.25359425143914016, Learning Rate: 0.05797\n",
      "Epoch: 8407, MSE: 0.2535917232964625, Learning Rate: 0.057965\n",
      "Epoch: 8408, MSE: 0.2535891951036779, Learning Rate: 0.057960000000000005\n",
      "Epoch: 8409, MSE: 0.2535866668607878, Learning Rate: 0.057955000000000007\n",
      "Epoch: 8410, MSE: 0.2535841385677937, Learning Rate: 0.05795\n",
      "Epoch: 8411, MSE: 0.2535816102246954, Learning Rate: 0.057945\n",
      "Epoch: 8412, MSE: 0.25357908183149475, Learning Rate: 0.057940000000000005\n",
      "Epoch: 8413, MSE: 0.2535765533881924, Learning Rate: 0.05793500000000001\n",
      "Epoch: 8414, MSE: 0.25357402489478903, Learning Rate: 0.057929999999999995\n",
      "Epoch: 8415, MSE: 0.2535714963512866, Learning Rate: 0.057925000000000004\n",
      "Epoch: 8416, MSE: 0.25356896775768584, Learning Rate: 0.05792\n",
      "Epoch: 8417, MSE: 0.2535664391139866, Learning Rate: 0.05791500000000001\n",
      "Epoch: 8418, MSE: 0.2535639104201908, Learning Rate: 0.057909999999999996\n",
      "Epoch: 8419, MSE: 0.2535613816762994, Learning Rate: 0.05790500000000001\n",
      "Epoch: 8420, MSE: 0.2535588528823133, Learning Rate: 0.0579\n",
      "Epoch: 8421, MSE: 0.2535563240382325, Learning Rate: 0.05789500000000001\n",
      "Epoch: 8422, MSE: 0.25355379514405935, Learning Rate: 0.05789\n",
      "Epoch: 8423, MSE: 0.2535512661997945, Learning Rate: 0.057885\n",
      "Epoch: 8424, MSE: 0.2535487372054383, Learning Rate: 0.05788\n",
      "Epoch: 8425, MSE: 0.25354620816099205, Learning Rate: 0.057875\n",
      "Epoch: 8426, MSE: 0.25354367906645736, Learning Rate: 0.057870000000000005\n",
      "Epoch: 8427, MSE: 0.25354114992183435, Learning Rate: 0.057865\n",
      "Epoch: 8428, MSE: 0.2535386207271239, Learning Rate: 0.05786\n",
      "Epoch: 8429, MSE: 0.25353609148232786, Learning Rate: 0.057855000000000004\n",
      "Epoch: 8430, MSE: 0.25353356218744616, Learning Rate: 0.057850000000000006\n",
      "Epoch: 8431, MSE: 0.2535310328424805, Learning Rate: 0.05784500000000001\n",
      "Epoch: 8432, MSE: 0.2535285034474319, Learning Rate: 0.05784\n",
      "Epoch: 8433, MSE: 0.2535259740023005, Learning Rate: 0.057835\n",
      "Epoch: 8434, MSE: 0.2535234445070883, Learning Rate: 0.057830000000000006\n",
      "Epoch: 8435, MSE: 0.25352091496179546, Learning Rate: 0.057824999999999994\n",
      "Epoch: 8436, MSE: 0.2535183853664242, Learning Rate: 0.05782000000000001\n",
      "Epoch: 8437, MSE: 0.25351585572097496, Learning Rate: 0.057815\n",
      "Epoch: 8438, MSE: 0.25351332602544707, Learning Rate: 0.05781000000000001\n",
      "Epoch: 8439, MSE: 0.2535107962798439, Learning Rate: 0.057804999999999995\n",
      "Epoch: 8440, MSE: 0.2535082664841643, Learning Rate: 0.05780000000000001\n",
      "Epoch: 8441, MSE: 0.25350573663841103, Learning Rate: 0.057795\n",
      "Epoch: 8442, MSE: 0.25350320674258403, Learning Rate: 0.05779000000000001\n",
      "Epoch: 8443, MSE: 0.2535006767966846, Learning Rate: 0.057785\n",
      "Epoch: 8444, MSE: 0.2534981468007146, Learning Rate: 0.05778\n",
      "Epoch: 8445, MSE: 0.25349561675467286, Learning Rate: 0.057775\n",
      "Epoch: 8446, MSE: 0.2534930866585619, Learning Rate: 0.05777\n",
      "Epoch: 8447, MSE: 0.2534905565123834, Learning Rate: 0.057765000000000004\n",
      "Epoch: 8448, MSE: 0.25348802631613654, Learning Rate: 0.057760000000000006\n",
      "Epoch: 8449, MSE: 0.25348549606982335, Learning Rate: 0.057755\n",
      "Epoch: 8450, MSE: 0.2534829657734443, Learning Rate: 0.05775\n",
      "Epoch: 8451, MSE: 0.25348043542700116, Learning Rate: 0.057745000000000005\n",
      "Epoch: 8452, MSE: 0.25347790503049455, Learning Rate: 0.05774000000000001\n",
      "Epoch: 8453, MSE: 0.25347537458392455, Learning Rate: 0.05773500000000001\n",
      "Epoch: 8454, MSE: 0.2534728440872935, Learning Rate: 0.05773\n",
      "Epoch: 8455, MSE: 0.2534703135406016, Learning Rate: 0.057725000000000005\n",
      "Epoch: 8456, MSE: 0.25346778294385003, Learning Rate: 0.057719999999999994\n",
      "Epoch: 8457, MSE: 0.2534652522970401, Learning Rate: 0.05771500000000001\n",
      "Epoch: 8458, MSE: 0.2534627216001724, Learning Rate: 0.05771\n",
      "Epoch: 8459, MSE: 0.2534601908532484, Learning Rate: 0.057705000000000006\n",
      "Epoch: 8460, MSE: 0.25345766005626824, Learning Rate: 0.0577\n",
      "Epoch: 8461, MSE: 0.25345512920923396, Learning Rate: 0.05769500000000001\n",
      "Epoch: 8462, MSE: 0.2534525983121453, Learning Rate: 0.05769\n",
      "Epoch: 8463, MSE: 0.2534500673650037, Learning Rate: 0.057685\n",
      "Epoch: 8464, MSE: 0.2534475363678107, Learning Rate: 0.05768\n",
      "Epoch: 8465, MSE: 0.2534450053205681, Learning Rate: 0.057675000000000004\n",
      "Epoch: 8466, MSE: 0.2534424742232739, Learning Rate: 0.05767\n",
      "Epoch: 8467, MSE: 0.25343994307593215, Learning Rate: 0.057665\n",
      "Epoch: 8468, MSE: 0.25343741187854196, Learning Rate: 0.05766\n",
      "Epoch: 8469, MSE: 0.2534348806311052, Learning Rate: 0.057655000000000005\n",
      "Epoch: 8470, MSE: 0.25343234933362296, Learning Rate: 0.05765000000000001\n",
      "Epoch: 8471, MSE: 0.25342981798609604, Learning Rate: 0.057645\n",
      "Epoch: 8472, MSE: 0.2534272865885249, Learning Rate: 0.057640000000000004\n",
      "Epoch: 8473, MSE: 0.25342475514091095, Learning Rate: 0.05763499999999999\n",
      "Epoch: 8474, MSE: 0.25342222364325534, Learning Rate: 0.05763000000000001\n",
      "Epoch: 8475, MSE: 0.25341969209555937, Learning Rate: 0.057624999999999996\n",
      "Epoch: 8476, MSE: 0.2534171604978231, Learning Rate: 0.057620000000000005\n",
      "Epoch: 8477, MSE: 0.2534146288500486, Learning Rate: 0.057615\n",
      "Epoch: 8478, MSE: 0.25341209715223534, Learning Rate: 0.05761000000000001\n",
      "Epoch: 8479, MSE: 0.25340956540438636, Learning Rate: 0.057604999999999996\n",
      "Epoch: 8480, MSE: 0.2534070336065009, Learning Rate: 0.05760000000000001\n",
      "Epoch: 8481, MSE: 0.25340450175858076, Learning Rate: 0.057595\n",
      "Epoch: 8482, MSE: 0.25340196986062674, Learning Rate: 0.05759000000000001\n",
      "Epoch: 8483, MSE: 0.2533994379126407, Learning Rate: 0.057585\n",
      "Epoch: 8484, MSE: 0.2533969059146218, Learning Rate: 0.05758\n",
      "Epoch: 8485, MSE: 0.25339437386657243, Learning Rate: 0.057575\n",
      "Epoch: 8486, MSE: 0.25339184176849316, Learning Rate: 0.05757\n",
      "Epoch: 8487, MSE: 0.25338930962038597, Learning Rate: 0.057565000000000005\n",
      "Epoch: 8488, MSE: 0.2533867774222502, Learning Rate: 0.05756\n",
      "Epoch: 8489, MSE: 0.2533842451740878, Learning Rate: 0.057555\n",
      "Epoch: 8490, MSE: 0.25338171287589956, Learning Rate: 0.057550000000000004\n",
      "Epoch: 8491, MSE: 0.2533791805276862, Learning Rate: 0.057545000000000006\n",
      "Epoch: 8492, MSE: 0.25337664812945004, Learning Rate: 0.05754000000000001\n",
      "Epoch: 8493, MSE: 0.2533741156811904, Learning Rate: 0.057535\n",
      "Epoch: 8494, MSE: 0.2533715831829091, Learning Rate: 0.05753\n",
      "Epoch: 8495, MSE: 0.25336905063460735, Learning Rate: 0.05752500000000001\n",
      "Epoch: 8496, MSE: 0.25336651803628557, Learning Rate: 0.057519999999999995\n",
      "Epoch: 8497, MSE: 0.25336398538794525, Learning Rate: 0.05751500000000001\n",
      "Epoch: 8498, MSE: 0.2533614526895868, Learning Rate: 0.05751\n",
      "Epoch: 8499, MSE: 0.25335891994121207, Learning Rate: 0.05750500000000001\n",
      "Epoch: 8500, MSE: 0.2533563871428212, Learning Rate: 0.057499999999999996\n",
      "Epoch: 8501, MSE: 0.2533538542944169, Learning Rate: 0.05749500000000001\n",
      "Epoch: 8502, MSE: 0.25335132139599725, Learning Rate: 0.05749\n",
      "Epoch: 8503, MSE: 0.2533487884475656, Learning Rate: 0.05748500000000001\n",
      "Epoch: 8504, MSE: 0.25334625544912215, Learning Rate: 0.05748\n",
      "Epoch: 8505, MSE: 0.25334372240066877, Learning Rate: 0.057475\n",
      "Epoch: 8506, MSE: 0.2533411893022056, Learning Rate: 0.05747\n",
      "Epoch: 8507, MSE: 0.25333865615373274, Learning Rate: 0.057465\n",
      "Epoch: 8508, MSE: 0.2533361229552534, Learning Rate: 0.057460000000000004\n",
      "Epoch: 8509, MSE: 0.25333358970676695, Learning Rate: 0.057455000000000006\n",
      "Epoch: 8510, MSE: 0.25333105640827464, Learning Rate: 0.05745\n",
      "Epoch: 8511, MSE: 0.25332852305977904, Learning Rate: 0.057445\n",
      "Epoch: 8512, MSE: 0.2533259896612785, Learning Rate: 0.057440000000000005\n",
      "Epoch: 8513, MSE: 0.25332345621277563, Learning Rate: 0.05743500000000001\n",
      "Epoch: 8514, MSE: 0.253320922714272, Learning Rate: 0.05743000000000001\n",
      "Epoch: 8515, MSE: 0.2533183891657666, Learning Rate: 0.057425\n",
      "Epoch: 8516, MSE: 0.25331585556726355, Learning Rate: 0.057420000000000006\n",
      "Epoch: 8517, MSE: 0.25331332191876127, Learning Rate: 0.057414999999999994\n",
      "Epoch: 8518, MSE: 0.2533107882202614, Learning Rate: 0.05741000000000001\n",
      "Epoch: 8519, MSE: 0.25330825447176447, Learning Rate: 0.057405\n",
      "Epoch: 8520, MSE: 0.25330572067327267, Learning Rate: 0.05740000000000001\n",
      "Epoch: 8521, MSE: 0.2533031868247867, Learning Rate: 0.057395\n",
      "Epoch: 8522, MSE: 0.2533006529263069, Learning Rate: 0.05739000000000001\n",
      "Epoch: 8523, MSE: 0.253298118977836, Learning Rate: 0.057385\n",
      "Epoch: 8524, MSE: 0.253295584979373, Learning Rate: 0.05738\n",
      "Epoch: 8525, MSE: 0.25329305093091914, Learning Rate: 0.057375\n",
      "Epoch: 8526, MSE: 0.2532905168324765, Learning Rate: 0.057370000000000004\n",
      "Epoch: 8527, MSE: 0.2532879826840458, Learning Rate: 0.057365\n",
      "Epoch: 8528, MSE: 0.25328544848562706, Learning Rate: 0.05736\n",
      "Epoch: 8529, MSE: 0.2532829142372232, Learning Rate: 0.057355\n",
      "Epoch: 8530, MSE: 0.25328037993883423, Learning Rate: 0.057350000000000005\n",
      "Epoch: 8531, MSE: 0.25327784559045985, Learning Rate: 0.05734500000000001\n",
      "Epoch: 8532, MSE: 0.2532753111921033, Learning Rate: 0.05734\n",
      "Epoch: 8533, MSE: 0.2532727767437644, Learning Rate: 0.057335000000000004\n",
      "Epoch: 8534, MSE: 0.2532702422454446, Learning Rate: 0.05732999999999999\n",
      "Epoch: 8535, MSE: 0.2532677076971444, Learning Rate: 0.05732500000000001\n",
      "Epoch: 8536, MSE: 0.253265173098866, Learning Rate: 0.057319999999999996\n",
      "Epoch: 8537, MSE: 0.2532626384506093, Learning Rate: 0.057315000000000005\n",
      "Epoch: 8538, MSE: 0.25326010375237484, Learning Rate: 0.05731\n",
      "Epoch: 8539, MSE: 0.25325756900416535, Learning Rate: 0.05730500000000001\n",
      "Epoch: 8540, MSE: 0.2532550342059811, Learning Rate: 0.0573\n",
      "Epoch: 8541, MSE: 0.25325249935782224, Learning Rate: 0.05729500000000001\n",
      "Epoch: 8542, MSE: 0.25324996445969106, Learning Rate: 0.05729\n",
      "Epoch: 8543, MSE: 0.2532474295115878, Learning Rate: 0.05728500000000001\n",
      "Epoch: 8544, MSE: 0.2532448945135137, Learning Rate: 0.05728\n",
      "Epoch: 8545, MSE: 0.25324235946546997, Learning Rate: 0.057275\n",
      "Epoch: 8546, MSE: 0.25323982436745845, Learning Rate: 0.05727\n",
      "Epoch: 8547, MSE: 0.25323728921947825, Learning Rate: 0.057265\n",
      "Epoch: 8548, MSE: 0.2532347540215321, Learning Rate: 0.057260000000000005\n",
      "Epoch: 8549, MSE: 0.2532322187736196, Learning Rate: 0.057255\n",
      "Epoch: 8550, MSE: 0.2532296834757433, Learning Rate: 0.05725\n",
      "Epoch: 8551, MSE: 0.25322714812790265, Learning Rate: 0.057245000000000004\n",
      "Epoch: 8552, MSE: 0.25322461273010016, Learning Rate: 0.057240000000000006\n",
      "Epoch: 8553, MSE: 0.253222077282336, Learning Rate: 0.05723500000000001\n",
      "Epoch: 8554, MSE: 0.2532195417846117, Learning Rate: 0.05723\n",
      "Epoch: 8555, MSE: 0.25321700623692783, Learning Rate: 0.057225\n",
      "Epoch: 8556, MSE: 0.2532144706392856, Learning Rate: 0.05722000000000001\n",
      "Epoch: 8557, MSE: 0.2532119349916858, Learning Rate: 0.057214999999999995\n",
      "Epoch: 8558, MSE: 0.25320939929413, Learning Rate: 0.05721000000000001\n",
      "Epoch: 8559, MSE: 0.25320686354661903, Learning Rate: 0.057205\n",
      "Epoch: 8560, MSE: 0.25320432774915413, Learning Rate: 0.05720000000000001\n",
      "Epoch: 8561, MSE: 0.2532017919017356, Learning Rate: 0.057194999999999996\n",
      "Epoch: 8562, MSE: 0.25319925600436555, Learning Rate: 0.05719000000000001\n",
      "Epoch: 8563, MSE: 0.2531967200570441, Learning Rate: 0.057185\n",
      "Epoch: 8564, MSE: 0.2531941840597735, Learning Rate: 0.05718\n",
      "Epoch: 8565, MSE: 0.2531916480125524, Learning Rate: 0.057175000000000004\n",
      "Epoch: 8566, MSE: 0.2531891119153848, Learning Rate: 0.05717\n",
      "Epoch: 8567, MSE: 0.25318657576826925, Learning Rate: 0.057165\n",
      "Epoch: 8568, MSE: 0.2531840395712081, Learning Rate: 0.05716\n",
      "Epoch: 8569, MSE: 0.253181503324203, Learning Rate: 0.057155000000000004\n",
      "Epoch: 8570, MSE: 0.25317896702725357, Learning Rate: 0.057150000000000006\n",
      "Epoch: 8571, MSE: 0.2531764306803617, Learning Rate: 0.057145\n",
      "Epoch: 8572, MSE: 0.2531738942835279, Learning Rate: 0.05714\n",
      "Epoch: 8573, MSE: 0.25317135783675376, Learning Rate: 0.057135000000000005\n",
      "Epoch: 8574, MSE: 0.25316882134003993, Learning Rate: 0.05712999999999999\n",
      "Epoch: 8575, MSE: 0.25316628479338776, Learning Rate: 0.05712500000000001\n",
      "Epoch: 8576, MSE: 0.25316374819679804, Learning Rate: 0.05712\n",
      "Epoch: 8577, MSE: 0.25316121155027194, Learning Rate: 0.057115000000000006\n",
      "Epoch: 8578, MSE: 0.25315867485381044, Learning Rate: 0.057109999999999994\n",
      "Epoch: 8579, MSE: 0.2531561381074149, Learning Rate: 0.05710500000000001\n",
      "Epoch: 8580, MSE: 0.2531536013110861, Learning Rate: 0.0571\n",
      "Epoch: 8581, MSE: 0.25315106446482516, Learning Rate: 0.05709500000000001\n",
      "Epoch: 8582, MSE: 0.25314852756863215, Learning Rate: 0.05709\n",
      "Epoch: 8583, MSE: 0.25314599062251, Learning Rate: 0.05708500000000001\n",
      "Epoch: 8584, MSE: 0.2531434536264587, Learning Rate: 0.05708\n",
      "Epoch: 8585, MSE: 0.25314091658047916, Learning Rate: 0.057075\n",
      "Epoch: 8586, MSE: 0.25313837948457313, Learning Rate: 0.05707\n",
      "Epoch: 8587, MSE: 0.2531358423387412, Learning Rate: 0.057065000000000005\n",
      "Epoch: 8588, MSE: 0.25313330514298427, Learning Rate: 0.05706\n",
      "Epoch: 8589, MSE: 0.25313076789730354, Learning Rate: 0.057055\n",
      "Epoch: 8590, MSE: 0.25312823060170014, Learning Rate: 0.057050000000000003\n",
      "Epoch: 8591, MSE: 0.2531256932561752, Learning Rate: 0.057045000000000005\n",
      "Epoch: 8592, MSE: 0.2531231558607295, Learning Rate: 0.05704000000000001\n",
      "Epoch: 8593, MSE: 0.25312061841536454, Learning Rate: 0.057035\n",
      "Epoch: 8594, MSE: 0.25311808092008115, Learning Rate: 0.057030000000000004\n",
      "Epoch: 8595, MSE: 0.25311554337488035, Learning Rate: 0.05702499999999999\n",
      "Epoch: 8596, MSE: 0.2531130057797634, Learning Rate: 0.05702000000000001\n",
      "Epoch: 8597, MSE: 0.2531104681347305, Learning Rate: 0.057014999999999996\n",
      "Epoch: 8598, MSE: 0.2531079304397842, Learning Rate: 0.057010000000000005\n",
      "Epoch: 8599, MSE: 0.25310539269492455, Learning Rate: 0.057005\n",
      "Epoch: 8600, MSE: 0.2531028549001524, Learning Rate: 0.05700000000000001\n",
      "Epoch: 8601, MSE: 0.25310031705546915, Learning Rate: 0.056995\n",
      "Epoch: 8602, MSE: 0.25309777916087645, Learning Rate: 0.05699000000000001\n",
      "Epoch: 8603, MSE: 0.2530952412163742, Learning Rate: 0.056985\n",
      "Epoch: 8604, MSE: 0.2530927032219646, Learning Rate: 0.05698\n",
      "Epoch: 8605, MSE: 0.2530901651776481, Learning Rate: 0.056975\n",
      "Epoch: 8606, MSE: 0.253087627083426, Learning Rate: 0.05697\n",
      "Epoch: 8607, MSE: 0.2530850889392988, Learning Rate: 0.056965\n",
      "Epoch: 8608, MSE: 0.25308255074526886, Learning Rate: 0.056960000000000004\n",
      "Epoch: 8609, MSE: 0.25308001250133577, Learning Rate: 0.056955000000000006\n",
      "Epoch: 8610, MSE: 0.2530774742075017, Learning Rate: 0.05695\n",
      "Epoch: 8611, MSE: 0.25307493586376656, Learning Rate: 0.056945\n",
      "Epoch: 8612, MSE: 0.2530723974701325, Learning Rate: 0.056940000000000004\n",
      "Epoch: 8613, MSE: 0.25306985902660056, Learning Rate: 0.056935000000000006\n",
      "Epoch: 8614, MSE: 0.25306732053317127, Learning Rate: 0.056929999999999994\n",
      "Epoch: 8615, MSE: 0.25306478198984567, Learning Rate: 0.056925\n",
      "Epoch: 8616, MSE: 0.25306224339662425, Learning Rate: 0.05692\n",
      "Epoch: 8617, MSE: 0.25305970475351014, Learning Rate: 0.05691500000000001\n",
      "Epoch: 8618, MSE: 0.25305716606050277, Learning Rate: 0.056909999999999995\n",
      "Epoch: 8619, MSE: 0.2530546273176033, Learning Rate: 0.05690500000000001\n",
      "Epoch: 8620, MSE: 0.25305208852481376, Learning Rate: 0.0569\n",
      "Epoch: 8621, MSE: 0.25304954968213417, Learning Rate: 0.05689500000000001\n",
      "Epoch: 8622, MSE: 0.2530470107895657, Learning Rate: 0.056889999999999996\n",
      "Epoch: 8623, MSE: 0.25304447184711043, Learning Rate: 0.05688500000000001\n",
      "Epoch: 8624, MSE: 0.25304193285476717, Learning Rate: 0.05688\n",
      "Epoch: 8625, MSE: 0.25303939381254004, Learning Rate: 0.056875\n",
      "Epoch: 8626, MSE: 0.2530368547204283, Learning Rate: 0.056870000000000004\n",
      "Epoch: 8627, MSE: 0.2530343155784329, Learning Rate: 0.056865\n",
      "Epoch: 8628, MSE: 0.25303177638655594, Learning Rate: 0.05686\n",
      "Epoch: 8629, MSE: 0.2530292371447976, Learning Rate: 0.056855\n",
      "Epoch: 8630, MSE: 0.25302669785315957, Learning Rate: 0.056850000000000005\n",
      "Epoch: 8631, MSE: 0.25302415851164206, Learning Rate: 0.05684500000000001\n",
      "Epoch: 8632, MSE: 0.2530216191202472, Learning Rate: 0.05684\n",
      "Epoch: 8633, MSE: 0.2530190796789752, Learning Rate: 0.056835000000000004\n",
      "Epoch: 8634, MSE: 0.2530165401878275, Learning Rate: 0.056830000000000006\n",
      "Epoch: 8635, MSE: 0.25301400064680585, Learning Rate: 0.056824999999999994\n",
      "Epoch: 8636, MSE: 0.2530114610559097, Learning Rate: 0.05682000000000001\n",
      "Epoch: 8637, MSE: 0.253008921415142, Learning Rate: 0.056815\n",
      "Epoch: 8638, MSE: 0.2530063817245025, Learning Rate: 0.056810000000000006\n",
      "Epoch: 8639, MSE: 0.25300384198399317, Learning Rate: 0.056804999999999994\n",
      "Epoch: 8640, MSE: 0.25300130219361455, Learning Rate: 0.05680000000000001\n",
      "Epoch: 8641, MSE: 0.25299876235336793, Learning Rate: 0.056795\n",
      "Epoch: 8642, MSE: 0.2529962224632534, Learning Rate: 0.05679000000000001\n",
      "Epoch: 8643, MSE: 0.2529936825232742, Learning Rate: 0.056785\n",
      "Epoch: 8644, MSE: 0.2529911425334293, Learning Rate: 0.05678000000000001\n",
      "Epoch: 8645, MSE: 0.2529886024937208, Learning Rate: 0.056775\n",
      "Epoch: 8646, MSE: 0.2529860624041495, Learning Rate: 0.05677\n",
      "Epoch: 8647, MSE: 0.25298352226471693, Learning Rate: 0.056765\n",
      "Epoch: 8648, MSE: 0.2529809820754234, Learning Rate: 0.056760000000000005\n",
      "Epoch: 8649, MSE: 0.2529784418362711, Learning Rate: 0.056755\n",
      "Epoch: 8650, MSE: 0.2529759015472599, Learning Rate: 0.05675\n",
      "Epoch: 8651, MSE: 0.25297336120839203, Learning Rate: 0.056745000000000004\n",
      "Epoch: 8652, MSE: 0.2529708208196671, Learning Rate: 0.056740000000000006\n",
      "Epoch: 8653, MSE: 0.2529682803810883, Learning Rate: 0.05673500000000001\n",
      "Epoch: 8654, MSE: 0.2529657398926552, Learning Rate: 0.05673\n",
      "Epoch: 8655, MSE: 0.2529631993543689, Learning Rate: 0.056725000000000005\n",
      "Epoch: 8656, MSE: 0.25296065876623064, Learning Rate: 0.05671999999999999\n",
      "Epoch: 8657, MSE: 0.2529581181282418, Learning Rate: 0.05671500000000001\n",
      "Epoch: 8658, MSE: 0.2529555774404042, Learning Rate: 0.056709999999999997\n",
      "Epoch: 8659, MSE: 0.25295303670271646, Learning Rate: 0.056705000000000005\n",
      "Epoch: 8660, MSE: 0.2529504959151825, Learning Rate: 0.0567\n",
      "Epoch: 8661, MSE: 0.25294795507780266, Learning Rate: 0.05669500000000001\n",
      "Epoch: 8662, MSE: 0.2529454141905765, Learning Rate: 0.05669\n",
      "Epoch: 8663, MSE: 0.2529428732535069, Learning Rate: 0.05668500000000001\n",
      "Epoch: 8664, MSE: 0.2529403322665943, Learning Rate: 0.05668\n",
      "Epoch: 8665, MSE: 0.25293779122983917, Learning Rate: 0.056675\n",
      "Epoch: 8666, MSE: 0.2529352501432434, Learning Rate: 0.05667\n",
      "Epoch: 8667, MSE: 0.2529327090068087, Learning Rate: 0.056665\n",
      "Epoch: 8668, MSE: 0.25293016782053424, Learning Rate: 0.05666\n",
      "Epoch: 8669, MSE: 0.25292762658442197, Learning Rate: 0.056655000000000004\n",
      "Epoch: 8670, MSE: 0.2529250852984742, Learning Rate: 0.056650000000000006\n",
      "Epoch: 8671, MSE: 0.25292254396269137, Learning Rate: 0.056645\n",
      "Epoch: 8672, MSE: 0.25292000257707403, Learning Rate: 0.05664\n",
      "Epoch: 8673, MSE: 0.25291746114162256, Learning Rate: 0.056635000000000005\n",
      "Epoch: 8674, MSE: 0.2529149196563398, Learning Rate: 0.05663000000000001\n",
      "Epoch: 8675, MSE: 0.25291237812122597, Learning Rate: 0.056624999999999995\n",
      "Epoch: 8676, MSE: 0.2529098365362824, Learning Rate: 0.056620000000000004\n",
      "Epoch: 8677, MSE: 0.2529072949015103, Learning Rate: 0.056615\n",
      "Epoch: 8678, MSE: 0.25290475321691036, Learning Rate: 0.05661000000000001\n",
      "Epoch: 8679, MSE: 0.25290221148248365, Learning Rate: 0.056604999999999996\n",
      "Epoch: 8680, MSE: 0.25289966969823136, Learning Rate: 0.05660000000000001\n",
      "Epoch: 8681, MSE: 0.25289712786415564, Learning Rate: 0.056595\n",
      "Epoch: 8682, MSE: 0.252894585980256, Learning Rate: 0.05659000000000001\n",
      "Epoch: 8683, MSE: 0.2528920440465345, Learning Rate: 0.056584999999999996\n",
      "Epoch: 8684, MSE: 0.25288950206299154, Learning Rate: 0.05658000000000001\n",
      "Epoch: 8685, MSE: 0.2528869600296291, Learning Rate: 0.056575\n",
      "Epoch: 8686, MSE: 0.2528844179464481, Learning Rate: 0.05657\n",
      "Epoch: 8687, MSE: 0.25288187581344934, Learning Rate: 0.056565000000000004\n",
      "Epoch: 8688, MSE: 0.2528793336306334, Learning Rate: 0.05656\n",
      "Epoch: 8689, MSE: 0.25287679139800207, Learning Rate: 0.056555\n",
      "Epoch: 8690, MSE: 0.25287424911555667, Learning Rate: 0.05655\n",
      "Epoch: 8691, MSE: 0.2528717067832979, Learning Rate: 0.056545000000000005\n",
      "Epoch: 8692, MSE: 0.2528691644012278, Learning Rate: 0.05654000000000001\n",
      "Epoch: 8693, MSE: 0.25286662196934573, Learning Rate: 0.056535\n",
      "Epoch: 8694, MSE: 0.2528640794876537, Learning Rate: 0.056530000000000004\n",
      "Epoch: 8695, MSE: 0.25286153695615327, Learning Rate: 0.056525000000000006\n",
      "Epoch: 8696, MSE: 0.25285899437484494, Learning Rate: 0.056519999999999994\n",
      "Epoch: 8697, MSE: 0.25285645174373067, Learning Rate: 0.05651500000000001\n",
      "Epoch: 8698, MSE: 0.2528539090628101, Learning Rate: 0.05651\n",
      "Epoch: 8699, MSE: 0.25285136633208544, Learning Rate: 0.05650500000000001\n",
      "Epoch: 8700, MSE: 0.2528488235515579, Learning Rate: 0.056499999999999995\n",
      "Epoch: 8701, MSE: 0.25284628072122767, Learning Rate: 0.05649500000000001\n",
      "Epoch: 8702, MSE: 0.25284373784109637, Learning Rate: 0.05649\n",
      "Epoch: 8703, MSE: 0.2528411949111659, Learning Rate: 0.05648500000000001\n",
      "Epoch: 8704, MSE: 0.25283865193143645, Learning Rate: 0.05648\n",
      "Epoch: 8705, MSE: 0.2528361089019088, Learning Rate: 0.056475\n",
      "Epoch: 8706, MSE: 0.2528335658225849, Learning Rate: 0.05647\n",
      "Epoch: 8707, MSE: 0.2528310226934657, Learning Rate: 0.056465\n",
      "Epoch: 8708, MSE: 0.25282847951455245, Learning Rate: 0.05646\n",
      "Epoch: 8709, MSE: 0.2528259362858454, Learning Rate: 0.056455000000000005\n",
      "Epoch: 8710, MSE: 0.252823393007347, Learning Rate: 0.05645\n",
      "Epoch: 8711, MSE: 0.2528208496790571, Learning Rate: 0.056445\n",
      "Epoch: 8712, MSE: 0.25281830630097735, Learning Rate: 0.056440000000000004\n",
      "Epoch: 8713, MSE: 0.25281576287310886, Learning Rate: 0.056435000000000006\n",
      "Epoch: 8714, MSE: 0.2528132193954536, Learning Rate: 0.05643000000000001\n",
      "Epoch: 8715, MSE: 0.25281067586801065, Learning Rate: 0.056424999999999996\n",
      "Epoch: 8716, MSE: 0.2528081322907832, Learning Rate: 0.056420000000000005\n",
      "Epoch: 8717, MSE: 0.252805588663772, Learning Rate: 0.05641499999999999\n",
      "Epoch: 8718, MSE: 0.25280304498697664, Learning Rate: 0.05641000000000001\n",
      "Epoch: 8719, MSE: 0.2528005012604004, Learning Rate: 0.056405\n",
      "Epoch: 8720, MSE: 0.2527979574840422, Learning Rate: 0.056400000000000006\n",
      "Epoch: 8721, MSE: 0.25279541365790476, Learning Rate: 0.056395\n",
      "Epoch: 8722, MSE: 0.25279286978198906, Learning Rate: 0.05639000000000001\n",
      "Epoch: 8723, MSE: 0.2527903258562954, Learning Rate: 0.056385\n",
      "Epoch: 8724, MSE: 0.2527877818808257, Learning Rate: 0.05638000000000001\n",
      "Epoch: 8725, MSE: 0.2527852378555811, Learning Rate: 0.056375\n",
      "Epoch: 8726, MSE: 0.25278269378056123, Learning Rate: 0.05637\n",
      "Epoch: 8727, MSE: 0.25278014965576967, Learning Rate: 0.056365\n",
      "Epoch: 8728, MSE: 0.2527776054812056, Learning Rate: 0.05636\n",
      "Epoch: 8729, MSE: 0.25277506125687105, Learning Rate: 0.056355\n",
      "Epoch: 8730, MSE: 0.2527725169827675, Learning Rate: 0.056350000000000004\n",
      "Epoch: 8731, MSE: 0.25276997265889506, Learning Rate: 0.056345000000000006\n",
      "Epoch: 8732, MSE: 0.25276742828525584, Learning Rate: 0.05634\n",
      "Epoch: 8733, MSE: 0.25276488386185003, Learning Rate: 0.056335\n",
      "Epoch: 8734, MSE: 0.25276233938867887, Learning Rate: 0.056330000000000005\n",
      "Epoch: 8735, MSE: 0.25275979486574385, Learning Rate: 0.05632500000000001\n",
      "Epoch: 8736, MSE: 0.2527572502930468, Learning Rate: 0.056319999999999995\n",
      "Epoch: 8737, MSE: 0.2527547056705877, Learning Rate: 0.056315000000000004\n",
      "Epoch: 8738, MSE: 0.2527521609983675, Learning Rate: 0.05631\n",
      "Epoch: 8739, MSE: 0.25274961627638853, Learning Rate: 0.05630500000000001\n",
      "Epoch: 8740, MSE: 0.2527470715046514, Learning Rate: 0.056299999999999996\n",
      "Epoch: 8741, MSE: 0.25274452668315733, Learning Rate: 0.05629500000000001\n",
      "Epoch: 8742, MSE: 0.252741981811907, Learning Rate: 0.05629\n",
      "Epoch: 8743, MSE: 0.2527394368909021, Learning Rate: 0.05628500000000001\n",
      "Epoch: 8744, MSE: 0.252736891920143, Learning Rate: 0.05628\n",
      "Epoch: 8745, MSE: 0.2527343468996321, Learning Rate: 0.056275\n",
      "Epoch: 8746, MSE: 0.2527318018293699, Learning Rate: 0.05627\n",
      "Epoch: 8747, MSE: 0.25272925670935653, Learning Rate: 0.056265\n",
      "Epoch: 8748, MSE: 0.25272671153959486, Learning Rate: 0.056260000000000004\n",
      "Epoch: 8749, MSE: 0.25272416632008426, Learning Rate: 0.056255\n",
      "Epoch: 8750, MSE: 0.2527216210508282, Learning Rate: 0.05625\n",
      "Epoch: 8751, MSE: 0.2527190757318258, Learning Rate: 0.056245\n",
      "Epoch: 8752, MSE: 0.2527165303630783, Learning Rate: 0.056240000000000005\n",
      "Epoch: 8753, MSE: 0.25271398494458813, Learning Rate: 0.05623500000000001\n",
      "Epoch: 8754, MSE: 0.2527114394763548, Learning Rate: 0.05623\n",
      "Epoch: 8755, MSE: 0.25270889395838136, Learning Rate: 0.056225000000000004\n",
      "Epoch: 8756, MSE: 0.25270634839066797, Learning Rate: 0.056220000000000006\n",
      "Epoch: 8757, MSE: 0.2527038027732159, Learning Rate: 0.056214999999999994\n",
      "Epoch: 8758, MSE: 0.25270125710602515, Learning Rate: 0.05621000000000001\n",
      "Epoch: 8759, MSE: 0.2526987113890986, Learning Rate: 0.056205\n",
      "Epoch: 8760, MSE: 0.252696165622436, Learning Rate: 0.05620000000000001\n",
      "Epoch: 8761, MSE: 0.25269361980604016, Learning Rate: 0.056194999999999995\n",
      "Epoch: 8762, MSE: 0.2526910739399105, Learning Rate: 0.05619000000000001\n",
      "Epoch: 8763, MSE: 0.2526885280240489, Learning Rate: 0.056185\n",
      "Epoch: 8764, MSE: 0.2526859820584565, Learning Rate: 0.05618000000000001\n",
      "Epoch: 8765, MSE: 0.25268343604313515, Learning Rate: 0.056175\n",
      "Epoch: 8766, MSE: 0.25268088997808474, Learning Rate: 0.05617\n",
      "Epoch: 8767, MSE: 0.25267834386330595, Learning Rate: 0.056165\n",
      "Epoch: 8768, MSE: 0.2526757976988031, Learning Rate: 0.05616\n",
      "Epoch: 8769, MSE: 0.2526732514845734, Learning Rate: 0.056155000000000004\n",
      "Epoch: 8770, MSE: 0.25267070522062085, Learning Rate: 0.056150000000000005\n",
      "Epoch: 8771, MSE: 0.25266815890694505, Learning Rate: 0.056145\n",
      "Epoch: 8772, MSE: 0.252665612543548, Learning Rate: 0.05614\n",
      "Epoch: 8773, MSE: 0.2526630661304298, Learning Rate: 0.056135000000000004\n",
      "Epoch: 8774, MSE: 0.25266051966759356, Learning Rate: 0.056130000000000006\n",
      "Epoch: 8775, MSE: 0.2526579731550384, Learning Rate: 0.05612500000000001\n",
      "Epoch: 8776, MSE: 0.25265542659276596, Learning Rate: 0.056119999999999996\n",
      "Epoch: 8777, MSE: 0.2526528799807782, Learning Rate: 0.056115000000000005\n",
      "Epoch: 8778, MSE: 0.2526503333190758, Learning Rate: 0.05610999999999999\n",
      "Epoch: 8779, MSE: 0.2526477866076601, Learning Rate: 0.05610500000000001\n",
      "Epoch: 8780, MSE: 0.25264523984653164, Learning Rate: 0.0561\n",
      "Epoch: 8781, MSE: 0.2526426930356915, Learning Rate: 0.056095000000000006\n",
      "Epoch: 8782, MSE: 0.25264014617514235, Learning Rate: 0.05609\n",
      "Epoch: 8783, MSE: 0.25263759926488366, Learning Rate: 0.05608500000000001\n",
      "Epoch: 8784, MSE: 0.25263505230491756, Learning Rate: 0.05608\n",
      "Epoch: 8785, MSE: 0.25263250529524506, Learning Rate: 0.056075000000000014\n",
      "Epoch: 8786, MSE: 0.2526299582358671, Learning Rate: 0.05607\n",
      "Epoch: 8787, MSE: 0.2526274111267849, Learning Rate: 0.056065000000000004\n",
      "Epoch: 8788, MSE: 0.2526248639679995, Learning Rate: 0.05606\n",
      "Epoch: 8789, MSE: 0.25262231675951236, Learning Rate: 0.056055\n",
      "Epoch: 8790, MSE: 0.2526197695013243, Learning Rate: 0.05605\n",
      "Epoch: 8791, MSE: 0.2526172221934361, Learning Rate: 0.056045000000000005\n",
      "Epoch: 8792, MSE: 0.2526146748358502, Learning Rate: 0.056040000000000006\n",
      "Epoch: 8793, MSE: 0.25261212742856665, Learning Rate: 0.056035\n",
      "Epoch: 8794, MSE: 0.25260957997158723, Learning Rate: 0.05603\n",
      "Epoch: 8795, MSE: 0.25260703246491284, Learning Rate: 0.056025000000000005\n",
      "Epoch: 8796, MSE: 0.2526044849085448, Learning Rate: 0.05602000000000001\n",
      "Epoch: 8797, MSE: 0.2526019373024845, Learning Rate: 0.056014999999999995\n",
      "Epoch: 8798, MSE: 0.25259938964673273, Learning Rate: 0.056010000000000004\n",
      "Epoch: 8799, MSE: 0.2525968419412897, Learning Rate: 0.056005\n",
      "Epoch: 8800, MSE: 0.25259429418615775, Learning Rate: 0.05600000000000001\n",
      "Epoch: 8801, MSE: 0.25259174638133863, Learning Rate: 0.055994999999999996\n",
      "Epoch: 8802, MSE: 0.2525891985268324, Learning Rate: 0.05599000000000001\n",
      "Epoch: 8803, MSE: 0.25258665062264074, Learning Rate: 0.055985\n",
      "Epoch: 8804, MSE: 0.25258410266876485, Learning Rate: 0.05598000000000001\n",
      "Epoch: 8805, MSE: 0.25258155466520565, Learning Rate: 0.055975\n",
      "Epoch: 8806, MSE: 0.2525790066119638, Learning Rate: 0.05597\n",
      "Epoch: 8807, MSE: 0.25257645850904137, Learning Rate: 0.055965\n",
      "Epoch: 8808, MSE: 0.25257391035643983, Learning Rate: 0.05596\n",
      "Epoch: 8809, MSE: 0.2525713621541586, Learning Rate: 0.055955000000000005\n",
      "Epoch: 8810, MSE: 0.2525688139022001, Learning Rate: 0.05595\n",
      "Epoch: 8811, MSE: 0.25256626560056633, Learning Rate: 0.055945\n",
      "Epoch: 8812, MSE: 0.25256371724925636, Learning Rate: 0.055940000000000004\n",
      "Epoch: 8813, MSE: 0.2525611688482733, Learning Rate: 0.055935000000000006\n",
      "Epoch: 8814, MSE: 0.2525586203976179, Learning Rate: 0.05593000000000001\n",
      "Epoch: 8815, MSE: 0.25255607189729085, Learning Rate: 0.055925\n",
      "Epoch: 8816, MSE: 0.2525535233472922, Learning Rate: 0.05592\n",
      "Epoch: 8817, MSE: 0.2525509747476258, Learning Rate: 0.055915000000000006\n",
      "Epoch: 8818, MSE: 0.25254842609829115, Learning Rate: 0.055909999999999994\n",
      "Epoch: 8819, MSE: 0.25254587739928913, Learning Rate: 0.05590500000000001\n",
      "Epoch: 8820, MSE: 0.2525433286506218, Learning Rate: 0.0559\n",
      "Epoch: 8821, MSE: 0.2525407798522898, Learning Rate: 0.05589500000000001\n",
      "Epoch: 8822, MSE: 0.2525382310042949, Learning Rate: 0.055889999999999995\n",
      "Epoch: 8823, MSE: 0.2525356821066381, Learning Rate: 0.05588500000000001\n",
      "Epoch: 8824, MSE: 0.25253313315931997, Learning Rate: 0.05588\n",
      "Epoch: 8825, MSE: 0.25253058416234264, Learning Rate: 0.05587500000000001\n",
      "Epoch: 8826, MSE: 0.2525280351157055, Learning Rate: 0.05587\n",
      "Epoch: 8827, MSE: 0.25252548601941227, Learning Rate: 0.055865\n",
      "Epoch: 8828, MSE: 0.25252293687346256, Learning Rate: 0.05586\n",
      "Epoch: 8829, MSE: 0.252520387677857, Learning Rate: 0.055855\n",
      "Epoch: 8830, MSE: 0.2525178384325983, Learning Rate: 0.055850000000000004\n",
      "Epoch: 8831, MSE: 0.25251528913768706, Learning Rate: 0.055845000000000006\n",
      "Epoch: 8832, MSE: 0.25251273979312405, Learning Rate: 0.05584\n",
      "Epoch: 8833, MSE: 0.2525101903989114, Learning Rate: 0.055835\n",
      "Epoch: 8834, MSE: 0.2525076409550496, Learning Rate: 0.055830000000000005\n",
      "Epoch: 8835, MSE: 0.2525050914615391, Learning Rate: 0.05582500000000001\n",
      "Epoch: 8836, MSE: 0.25250254191838223, Learning Rate: 0.05582000000000001\n",
      "Epoch: 8837, MSE: 0.25249999232558035, Learning Rate: 0.055815\n",
      "Epoch: 8838, MSE: 0.252497442683134, Learning Rate: 0.055810000000000005\n",
      "Epoch: 8839, MSE: 0.2524948929910443, Learning Rate: 0.055804999999999993\n",
      "Epoch: 8840, MSE: 0.2524923432493125, Learning Rate: 0.05580000000000001\n",
      "Epoch: 8841, MSE: 0.25248979345794015, Learning Rate: 0.055795\n",
      "Epoch: 8842, MSE: 0.2524872436169282, Learning Rate: 0.055790000000000006\n",
      "Epoch: 8843, MSE: 0.2524846937262778, Learning Rate: 0.055785\n",
      "Epoch: 8844, MSE: 0.2524821437859907, Learning Rate: 0.05578000000000001\n",
      "Epoch: 8845, MSE: 0.25247959379606666, Learning Rate: 0.055775\n",
      "Epoch: 8846, MSE: 0.25247704375650853, Learning Rate: 0.05577\n",
      "Epoch: 8847, MSE: 0.2524744936673169, Learning Rate: 0.055765\n",
      "Epoch: 8848, MSE: 0.2524719435284926, Learning Rate: 0.055760000000000004\n",
      "Epoch: 8849, MSE: 0.2524693933400366, Learning Rate: 0.055755\n",
      "Epoch: 8850, MSE: 0.2524668431019508, Learning Rate: 0.05575\n",
      "Epoch: 8851, MSE: 0.2524642928142367, Learning Rate: 0.055745\n",
      "Epoch: 8852, MSE: 0.2524617424768944, Learning Rate: 0.055740000000000005\n",
      "Epoch: 8853, MSE: 0.25245919208992657, Learning Rate: 0.05573500000000001\n",
      "Epoch: 8854, MSE: 0.2524566416533318, Learning Rate: 0.05573\n",
      "Epoch: 8855, MSE: 0.2524540911671142, Learning Rate: 0.055725000000000004\n",
      "Epoch: 8856, MSE: 0.252451540631274, Learning Rate: 0.05571999999999999\n",
      "Epoch: 8857, MSE: 0.2524489900458114, Learning Rate: 0.05571500000000001\n",
      "Epoch: 8858, MSE: 0.2524464394107287, Learning Rate: 0.055709999999999996\n",
      "Epoch: 8859, MSE: 0.2524438887260265, Learning Rate: 0.055705000000000005\n",
      "Epoch: 8860, MSE: 0.25244133799170676, Learning Rate: 0.0557\n",
      "Epoch: 8861, MSE: 0.2524387872077696, Learning Rate: 0.05569500000000001\n",
      "Epoch: 8862, MSE: 0.2524362363742173, Learning Rate: 0.055689999999999996\n",
      "Epoch: 8863, MSE: 0.2524336854910498, Learning Rate: 0.05568500000000001\n",
      "Epoch: 8864, MSE: 0.2524311345582697, Learning Rate: 0.05568\n",
      "Epoch: 8865, MSE: 0.252428583575877, Learning Rate: 0.05567500000000001\n",
      "Epoch: 8866, MSE: 0.2524260325438737, Learning Rate: 0.05567\n",
      "Epoch: 8867, MSE: 0.252423481462261, Learning Rate: 0.055665\n",
      "Epoch: 8868, MSE: 0.2524209303310397, Learning Rate: 0.05566\n",
      "Epoch: 8869, MSE: 0.25241837915021165, Learning Rate: 0.055655\n",
      "Epoch: 8870, MSE: 0.2524158279197768, Learning Rate: 0.055650000000000005\n",
      "Epoch: 8871, MSE: 0.2524132766397372, Learning Rate: 0.055645\n",
      "Epoch: 8872, MSE: 0.2524107253100946, Learning Rate: 0.05564\n",
      "Epoch: 8873, MSE: 0.25240817393084897, Learning Rate: 0.055635000000000004\n",
      "Epoch: 8874, MSE: 0.25240562250200205, Learning Rate: 0.055630000000000006\n",
      "Epoch: 8875, MSE: 0.2524030710235556, Learning Rate: 0.05562500000000001\n",
      "Epoch: 8876, MSE: 0.25240051949550973, Learning Rate: 0.05562\n",
      "Epoch: 8877, MSE: 0.25239796791786734, Learning Rate: 0.055615\n",
      "Epoch: 8878, MSE: 0.25239541629062806, Learning Rate: 0.05561000000000001\n",
      "Epoch: 8879, MSE: 0.2523928646137937, Learning Rate: 0.055604999999999995\n",
      "Epoch: 8880, MSE: 0.25239031288736447, Learning Rate: 0.05560000000000001\n",
      "Epoch: 8881, MSE: 0.2523877611113434, Learning Rate: 0.055595\n",
      "Epoch: 8882, MSE: 0.2523852092857308, Learning Rate: 0.05559000000000001\n",
      "Epoch: 8883, MSE: 0.25238265741052707, Learning Rate: 0.055584999999999996\n",
      "Epoch: 8884, MSE: 0.25238010548573525, Learning Rate: 0.05558000000000001\n",
      "Epoch: 8885, MSE: 0.2523775535113554, Learning Rate: 0.055575\n",
      "Epoch: 8886, MSE: 0.25237500148738845, Learning Rate: 0.05557000000000001\n",
      "Epoch: 8887, MSE: 0.2523724494138364, Learning Rate: 0.055565\n",
      "Epoch: 8888, MSE: 0.2523698972907001, Learning Rate: 0.05556\n",
      "Epoch: 8889, MSE: 0.2523673451179807, Learning Rate: 0.055555\n",
      "Epoch: 8890, MSE: 0.25236479289567876, Learning Rate: 0.05555\n",
      "Epoch: 8891, MSE: 0.2523622406237973, Learning Rate: 0.055545000000000004\n",
      "Epoch: 8892, MSE: 0.252359688302336, Learning Rate: 0.055540000000000006\n",
      "Epoch: 8893, MSE: 0.2523571359312965, Learning Rate: 0.055535\n",
      "Epoch: 8894, MSE: 0.2523545835106802, Learning Rate: 0.05553\n",
      "Epoch: 8895, MSE: 0.25235203104048787, Learning Rate: 0.055525000000000005\n",
      "Epoch: 8896, MSE: 0.25234947852072115, Learning Rate: 0.05552000000000001\n",
      "Epoch: 8897, MSE: 0.25234692595138114, Learning Rate: 0.05551500000000001\n",
      "Epoch: 8898, MSE: 0.2523443733324695, Learning Rate: 0.05551\n",
      "Epoch: 8899, MSE: 0.2523418206639862, Learning Rate: 0.055505000000000006\n",
      "Epoch: 8900, MSE: 0.2523392679459334, Learning Rate: 0.055499999999999994\n",
      "Epoch: 8901, MSE: 0.25233671517831296, Learning Rate: 0.05549500000000001\n",
      "Epoch: 8902, MSE: 0.2523341623611242, Learning Rate: 0.05549\n",
      "Epoch: 8903, MSE: 0.25233160949437056, Learning Rate: 0.05548500000000001\n",
      "Epoch: 8904, MSE: 0.25232905657805177, Learning Rate: 0.05548\n",
      "Epoch: 8905, MSE: 0.2523265036121691, Learning Rate: 0.05547500000000001\n",
      "Epoch: 8906, MSE: 0.2523239505967248, Learning Rate: 0.05547\n",
      "Epoch: 8907, MSE: 0.25232139753171856, Learning Rate: 0.055465\n",
      "Epoch: 8908, MSE: 0.2523188444171531, Learning Rate: 0.05546\n",
      "Epoch: 8909, MSE: 0.25231629125302885, Learning Rate: 0.055455000000000004\n",
      "Epoch: 8910, MSE: 0.2523137380393478, Learning Rate: 0.05545\n",
      "Epoch: 8911, MSE: 0.2523111847761102, Learning Rate: 0.055445\n",
      "Epoch: 8912, MSE: 0.25230863146331745, Learning Rate: 0.05544\n",
      "Epoch: 8913, MSE: 0.2523060781009711, Learning Rate: 0.055435000000000005\n",
      "Epoch: 8914, MSE: 0.25230352468907213, Learning Rate: 0.05543000000000001\n",
      "Epoch: 8915, MSE: 0.2523009712276209, Learning Rate: 0.055425\n",
      "Epoch: 8916, MSE: 0.25229841771662126, Learning Rate: 0.055420000000000004\n",
      "Epoch: 8917, MSE: 0.25229586415607286, Learning Rate: 0.05541499999999999\n",
      "Epoch: 8918, MSE: 0.2522933105459759, Learning Rate: 0.05541000000000001\n",
      "Epoch: 8919, MSE: 0.2522907568863334, Learning Rate: 0.055404999999999996\n",
      "Epoch: 8920, MSE: 0.25228820317714556, Learning Rate: 0.055400000000000005\n",
      "Epoch: 8921, MSE: 0.25228564941841397, Learning Rate: 0.055395\n",
      "Epoch: 8922, MSE: 0.2522830956101392, Learning Rate: 0.05539000000000001\n",
      "Epoch: 8923, MSE: 0.25228054175232306, Learning Rate: 0.055385\n",
      "Epoch: 8924, MSE: 0.2522779878449671, Learning Rate: 0.05538000000000001\n",
      "Epoch: 8925, MSE: 0.25227543388807283, Learning Rate: 0.055375\n",
      "Epoch: 8926, MSE: 0.25227287988163977, Learning Rate: 0.05537000000000001\n",
      "Epoch: 8927, MSE: 0.252270325825671, Learning Rate: 0.055365\n",
      "Epoch: 8928, MSE: 0.25226777172016657, Learning Rate: 0.05536\n",
      "Epoch: 8929, MSE: 0.25226521756512793, Learning Rate: 0.055355\n",
      "Epoch: 8930, MSE: 0.25226266336055697, Learning Rate: 0.05535\n",
      "Epoch: 8931, MSE: 0.2522601091064543, Learning Rate: 0.055345000000000005\n",
      "Epoch: 8932, MSE: 0.25225755480282175, Learning Rate: 0.05534\n",
      "Epoch: 8933, MSE: 0.2522550004496597, Learning Rate: 0.055335\n",
      "Epoch: 8934, MSE: 0.25225244604696995, Learning Rate: 0.055330000000000004\n",
      "Epoch: 8935, MSE: 0.25224989159475447, Learning Rate: 0.055325000000000006\n",
      "Epoch: 8936, MSE: 0.25224733709301267, Learning Rate: 0.05532000000000001\n",
      "Epoch: 8937, MSE: 0.2522447825417469, Learning Rate: 0.055315\n",
      "Epoch: 8938, MSE: 0.2522422279409581, Learning Rate: 0.05531\n",
      "Epoch: 8939, MSE: 0.2522396732906487, Learning Rate: 0.05530500000000001\n",
      "Epoch: 8940, MSE: 0.25223711859081777, Learning Rate: 0.055299999999999995\n",
      "Epoch: 8941, MSE: 0.25223456384146803, Learning Rate: 0.05529500000000001\n",
      "Epoch: 8942, MSE: 0.2522320090426011, Learning Rate: 0.05529\n",
      "Epoch: 8943, MSE: 0.2522294541942169, Learning Rate: 0.05528500000000001\n",
      "Epoch: 8944, MSE: 0.25222689929631725, Learning Rate: 0.055279999999999996\n",
      "Epoch: 8945, MSE: 0.2522243443489039, Learning Rate: 0.05527500000000001\n",
      "Epoch: 8946, MSE: 0.2522217893519778, Learning Rate: 0.05527\n",
      "Epoch: 8947, MSE: 0.2522192343055396, Learning Rate: 0.055265\n",
      "Epoch: 8948, MSE: 0.25221667920959095, Learning Rate: 0.055260000000000004\n",
      "Epoch: 8949, MSE: 0.2522141240641336, Learning Rate: 0.055255\n",
      "Epoch: 8950, MSE: 0.252211568869168, Learning Rate: 0.05525\n",
      "Epoch: 8951, MSE: 0.25220901362469594, Learning Rate: 0.055245\n",
      "Epoch: 8952, MSE: 0.25220645833071825, Learning Rate: 0.055240000000000004\n",
      "Epoch: 8953, MSE: 0.2522039029872369, Learning Rate: 0.055235000000000006\n",
      "Epoch: 8954, MSE: 0.25220134759425217, Learning Rate: 0.05523\n",
      "Epoch: 8955, MSE: 0.2521987921517659, Learning Rate: 0.055225\n",
      "Epoch: 8956, MSE: 0.2521962366597793, Learning Rate: 0.055220000000000005\n",
      "Epoch: 8957, MSE: 0.2521936811182933, Learning Rate: 0.05521499999999999\n",
      "Epoch: 8958, MSE: 0.2521911255273098, Learning Rate: 0.05521000000000001\n",
      "Epoch: 8959, MSE: 0.25218856988682975, Learning Rate: 0.055205\n",
      "Epoch: 8960, MSE: 0.2521860141968541, Learning Rate: 0.055200000000000006\n",
      "Epoch: 8961, MSE: 0.2521834584573835, Learning Rate: 0.055194999999999994\n",
      "Epoch: 8962, MSE: 0.2521809026684209, Learning Rate: 0.05519000000000001\n",
      "Epoch: 8963, MSE: 0.252178346829967, Learning Rate: 0.055185\n",
      "Epoch: 8964, MSE: 0.2521757909420225, Learning Rate: 0.05518000000000001\n",
      "Epoch: 8965, MSE: 0.25217323500458844, Learning Rate: 0.055175\n",
      "Epoch: 8966, MSE: 0.2521706790176672, Learning Rate: 0.05517000000000001\n",
      "Epoch: 8967, MSE: 0.25216812298125835, Learning Rate: 0.055165\n",
      "Epoch: 8968, MSE: 0.252165566895364, Learning Rate: 0.05516\n",
      "Epoch: 8969, MSE: 0.2521630107599874, Learning Rate: 0.055155\n",
      "Epoch: 8970, MSE: 0.25216045457512715, Learning Rate: 0.055150000000000005\n",
      "Epoch: 8971, MSE: 0.2521578983407845, Learning Rate: 0.055145\n",
      "Epoch: 8972, MSE: 0.2521553420569619, Learning Rate: 0.05514\n",
      "Epoch: 8973, MSE: 0.25215278572366123, Learning Rate: 0.055135\n",
      "Epoch: 8974, MSE: 0.2521502293408813, Learning Rate: 0.055130000000000005\n",
      "Epoch: 8975, MSE: 0.2521476729086259, Learning Rate: 0.05512500000000001\n",
      "Epoch: 8976, MSE: 0.25214511642689463, Learning Rate: 0.05512\n",
      "Epoch: 8977, MSE: 0.2521425598956895, Learning Rate: 0.055115000000000004\n",
      "Epoch: 8978, MSE: 0.2521400033150118, Learning Rate: 0.05510999999999999\n",
      "Epoch: 8979, MSE: 0.2521374466848622, Learning Rate: 0.05510500000000001\n",
      "Epoch: 8980, MSE: 0.2521348900052428, Learning Rate: 0.055099999999999996\n",
      "Epoch: 8981, MSE: 0.25213233327615436, Learning Rate: 0.055095000000000005\n",
      "Epoch: 8982, MSE: 0.25212977649759827, Learning Rate: 0.05509\n",
      "Epoch: 8983, MSE: 0.252127219669576, Learning Rate: 0.05508500000000001\n",
      "Epoch: 8984, MSE: 0.25212466279208806, Learning Rate: 0.05508\n",
      "Epoch: 8985, MSE: 0.2521221058651365, Learning Rate: 0.05507500000000001\n",
      "Epoch: 8986, MSE: 0.2521195488887225, Learning Rate: 0.05507\n",
      "Epoch: 8987, MSE: 0.25211699186284725, Learning Rate: 0.055065\n",
      "Epoch: 8988, MSE: 0.25211443478751167, Learning Rate: 0.05506\n",
      "Epoch: 8989, MSE: 0.2521118776627167, Learning Rate: 0.055055\n",
      "Epoch: 8990, MSE: 0.25210932048846485, Learning Rate: 0.05505\n",
      "Epoch: 8991, MSE: 0.25210676326475695, Learning Rate: 0.055045000000000004\n",
      "Epoch: 8992, MSE: 0.2521042059915942, Learning Rate: 0.055040000000000006\n",
      "Epoch: 8993, MSE: 0.25210164866897644, Learning Rate: 0.055035\n",
      "Epoch: 8994, MSE: 0.25209909129690655, Learning Rate: 0.05503\n",
      "Epoch: 8995, MSE: 0.2520965338753863, Learning Rate: 0.055025000000000004\n",
      "Epoch: 8996, MSE: 0.2520939764044159, Learning Rate: 0.055020000000000006\n",
      "Epoch: 8997, MSE: 0.2520914188839975, Learning Rate: 0.055014999999999994\n",
      "Epoch: 8998, MSE: 0.2520888613141303, Learning Rate: 0.05501\n",
      "Epoch: 8999, MSE: 0.25208630369481755, Learning Rate: 0.055005\n",
      "Epoch: 9000, MSE: 0.25208374602606015, Learning Rate: 0.05500000000000001\n",
      "Epoch: 9001, MSE: 0.25208118830785897, Learning Rate: 0.054994999999999995\n",
      "Epoch: 9002, MSE: 0.2520786305402157, Learning Rate: 0.05499000000000001\n",
      "Epoch: 9003, MSE: 0.2520760727231314, Learning Rate: 0.054985\n",
      "Epoch: 9004, MSE: 0.252073514856607, Learning Rate: 0.05498000000000001\n",
      "Epoch: 9005, MSE: 0.25207095694064496, Learning Rate: 0.054974999999999996\n",
      "Epoch: 9006, MSE: 0.25206839897524547, Learning Rate: 0.05497000000000001\n",
      "Epoch: 9007, MSE: 0.25206584096041007, Learning Rate: 0.054965\n",
      "Epoch: 9008, MSE: 0.2520632828961397, Learning Rate: 0.05496\n",
      "Epoch: 9009, MSE: 0.25206072478243635, Learning Rate: 0.054955000000000004\n",
      "Epoch: 9010, MSE: 0.2520581666193006, Learning Rate: 0.05495\n",
      "Epoch: 9011, MSE: 0.2520556084067344, Learning Rate: 0.054945\n",
      "Epoch: 9012, MSE: 0.25205305014473867, Learning Rate: 0.05494\n",
      "Epoch: 9013, MSE: 0.25205049183331546, Learning Rate: 0.054935000000000005\n",
      "Epoch: 9014, MSE: 0.2520479334724641, Learning Rate: 0.05493000000000001\n",
      "Epoch: 9015, MSE: 0.25204537506218766, Learning Rate: 0.054925\n",
      "Epoch: 9016, MSE: 0.25204281660248706, Learning Rate: 0.054920000000000004\n",
      "Epoch: 9017, MSE: 0.25204025809336295, Learning Rate: 0.054915000000000005\n",
      "Epoch: 9018, MSE: 0.2520376995348169, Learning Rate: 0.054909999999999994\n",
      "Epoch: 9019, MSE: 0.2520351409268511, Learning Rate: 0.05490500000000001\n",
      "Epoch: 9020, MSE: 0.25203258226946595, Learning Rate: 0.0549\n",
      "Epoch: 9021, MSE: 0.25203002356266213, Learning Rate: 0.054895000000000006\n",
      "Epoch: 9022, MSE: 0.2520274648064421, Learning Rate: 0.054889999999999994\n",
      "Epoch: 9023, MSE: 0.25202490600080735, Learning Rate: 0.05488500000000001\n",
      "Epoch: 9024, MSE: 0.2520223471457577, Learning Rate: 0.05488\n",
      "Epoch: 9025, MSE: 0.2520197882412952, Learning Rate: 0.05487500000000001\n",
      "Epoch: 9026, MSE: 0.2520172292874219, Learning Rate: 0.05487\n",
      "Epoch: 9027, MSE: 0.2520146702841382, Learning Rate: 0.05486500000000001\n",
      "Epoch: 9028, MSE: 0.25201211123144523, Learning Rate: 0.05486\n",
      "Epoch: 9029, MSE: 0.2520095521293454, Learning Rate: 0.054855\n",
      "Epoch: 9030, MSE: 0.2520069929778383, Learning Rate: 0.05485\n",
      "Epoch: 9031, MSE: 0.2520044337769266, Learning Rate: 0.054845000000000005\n",
      "Epoch: 9032, MSE: 0.2520018745266109, Learning Rate: 0.05484\n",
      "Epoch: 9033, MSE: 0.25199931522689345, Learning Rate: 0.054835\n",
      "Epoch: 9034, MSE: 0.251996755877774, Learning Rate: 0.054830000000000004\n",
      "Epoch: 9035, MSE: 0.25199419647925453, Learning Rate: 0.054825000000000006\n",
      "Epoch: 9036, MSE: 0.2519916370313371, Learning Rate: 0.05482000000000001\n",
      "Epoch: 9037, MSE: 0.25198907753402267, Learning Rate: 0.054815\n",
      "Epoch: 9038, MSE: 0.25198651798731125, Learning Rate: 0.054810000000000005\n",
      "Epoch: 9039, MSE: 0.25198395839120624, Learning Rate: 0.05480499999999999\n",
      "Epoch: 9040, MSE: 0.25198139874570713, Learning Rate: 0.05480000000000001\n",
      "Epoch: 9041, MSE: 0.251978839050816, Learning Rate: 0.054794999999999996\n",
      "Epoch: 9042, MSE: 0.2519762793065337, Learning Rate: 0.054790000000000005\n",
      "Epoch: 9043, MSE: 0.25197371951286274, Learning Rate: 0.054785\n",
      "Epoch: 9044, MSE: 0.2519711596698032, Learning Rate: 0.05478000000000001\n",
      "Epoch: 9045, MSE: 0.25196859977735697, Learning Rate: 0.054775\n",
      "Epoch: 9046, MSE: 0.2519660398355249, Learning Rate: 0.05477000000000001\n",
      "Epoch: 9047, MSE: 0.2519634798443089, Learning Rate: 0.054765\n",
      "Epoch: 9048, MSE: 0.2519609198037094, Learning Rate: 0.05476\n",
      "Epoch: 9049, MSE: 0.25195835971372876, Learning Rate: 0.054755\n",
      "Epoch: 9050, MSE: 0.25195579957436687, Learning Rate: 0.05475\n",
      "Epoch: 9051, MSE: 0.25195323938562636, Learning Rate: 0.054745\n",
      "Epoch: 9052, MSE: 0.25195067914750824, Learning Rate: 0.054740000000000004\n",
      "Epoch: 9053, MSE: 0.2519481188600133, Learning Rate: 0.054735000000000006\n",
      "Epoch: 9054, MSE: 0.25194555852314326, Learning Rate: 0.05473\n",
      "Epoch: 9055, MSE: 0.25194299813689897, Learning Rate: 0.054725\n",
      "Epoch: 9056, MSE: 0.25194043770128194, Learning Rate: 0.054720000000000005\n",
      "Epoch: 9057, MSE: 0.251937877216295, Learning Rate: 0.05471500000000001\n",
      "Epoch: 9058, MSE: 0.2519353166819368, Learning Rate: 0.054709999999999995\n",
      "Epoch: 9059, MSE: 0.2519327560982109, Learning Rate: 0.054705000000000004\n",
      "Epoch: 9060, MSE: 0.2519301954651175, Learning Rate: 0.0547\n",
      "Epoch: 9061, MSE: 0.2519276347826575, Learning Rate: 0.05469500000000001\n",
      "Epoch: 9062, MSE: 0.2519250740508327, Learning Rate: 0.054689999999999996\n",
      "Epoch: 9063, MSE: 0.2519225132696449, Learning Rate: 0.05468500000000001\n",
      "Epoch: 9064, MSE: 0.25191995243909443, Learning Rate: 0.05468\n",
      "Epoch: 9065, MSE: 0.25191739155918313, Learning Rate: 0.05467500000000001\n",
      "Epoch: 9066, MSE: 0.2519148306299137, Learning Rate: 0.054669999999999996\n",
      "Epoch: 9067, MSE: 0.25191226965128494, Learning Rate: 0.05466500000000001\n",
      "Epoch: 9068, MSE: 0.25190970862329926, Learning Rate: 0.05466\n",
      "Epoch: 9069, MSE: 0.25190714754595794, Learning Rate: 0.054655\n",
      "Epoch: 9070, MSE: 0.25190458641926305, Learning Rate: 0.054650000000000004\n",
      "Epoch: 9071, MSE: 0.25190202524321426, Learning Rate: 0.054645\n",
      "Epoch: 9072, MSE: 0.2518994640178146, Learning Rate: 0.05464\n",
      "Epoch: 9073, MSE: 0.2518969027430647, Learning Rate: 0.054635\n",
      "Epoch: 9074, MSE: 0.2518943414189655, Learning Rate: 0.054630000000000005\n",
      "Epoch: 9075, MSE: 0.2518917800455185, Learning Rate: 0.05462500000000001\n",
      "Epoch: 9076, MSE: 0.251889218622725, Learning Rate: 0.05462\n",
      "Epoch: 9077, MSE: 0.2518866571505868, Learning Rate: 0.054615000000000004\n",
      "Epoch: 9078, MSE: 0.25188409562910463, Learning Rate: 0.054610000000000006\n",
      "Epoch: 9079, MSE: 0.25188153405828023, Learning Rate: 0.054604999999999994\n",
      "Epoch: 9080, MSE: 0.25187897243811475, Learning Rate: 0.05460000000000001\n",
      "Epoch: 9081, MSE: 0.2518764107686092, Learning Rate: 0.054595\n",
      "Epoch: 9082, MSE: 0.2518738490497653, Learning Rate: 0.05459000000000001\n",
      "Epoch: 9083, MSE: 0.2518712872815841, Learning Rate: 0.054584999999999995\n",
      "Epoch: 9084, MSE: 0.2518687254640671, Learning Rate: 0.05458000000000001\n",
      "Epoch: 9085, MSE: 0.25186616359721603, Learning Rate: 0.054575\n",
      "Epoch: 9086, MSE: 0.2518636016810314, Learning Rate: 0.05457000000000001\n",
      "Epoch: 9087, MSE: 0.25186103971551554, Learning Rate: 0.054565\n",
      "Epoch: 9088, MSE: 0.2518584777006683, Learning Rate: 0.05456\n",
      "Epoch: 9089, MSE: 0.2518559156364919, Learning Rate: 0.054555\n",
      "Epoch: 9090, MSE: 0.2518533535229888, Learning Rate: 0.05455\n",
      "Epoch: 9091, MSE: 0.25185079136015726, Learning Rate: 0.054545\n",
      "Epoch: 9092, MSE: 0.2518482291480019, Learning Rate: 0.054540000000000005\n",
      "Epoch: 9093, MSE: 0.2518456668865216, Learning Rate: 0.054535\n",
      "Epoch: 9094, MSE: 0.2518431045757192, Learning Rate: 0.05453\n",
      "Epoch: 9095, MSE: 0.2518405422155962, Learning Rate: 0.054525000000000004\n",
      "Epoch: 9096, MSE: 0.2518379798061523, Learning Rate: 0.054520000000000006\n",
      "Epoch: 9097, MSE: 0.2518354173473903, Learning Rate: 0.05451500000000001\n",
      "Epoch: 9098, MSE: 0.25183285483931056, Learning Rate: 0.054509999999999996\n",
      "Epoch: 9099, MSE: 0.2518302922819152, Learning Rate: 0.054505000000000005\n",
      "Epoch: 9100, MSE: 0.2518277296752052, Learning Rate: 0.05449999999999999\n",
      "Epoch: 9101, MSE: 0.25182516701918184, Learning Rate: 0.05449500000000001\n",
      "Epoch: 9102, MSE: 0.2518226043138462, Learning Rate: 0.05449\n",
      "Epoch: 9103, MSE: 0.2518200415592002, Learning Rate: 0.054485000000000006\n",
      "Epoch: 9104, MSE: 0.25181747875524485, Learning Rate: 0.05448\n",
      "Epoch: 9105, MSE: 0.2518149159019817, Learning Rate: 0.05447500000000001\n",
      "Epoch: 9106, MSE: 0.251812352999411, Learning Rate: 0.05447\n",
      "Epoch: 9107, MSE: 0.25180979004753645, Learning Rate: 0.05446500000000001\n",
      "Epoch: 9108, MSE: 0.25180722704635655, Learning Rate: 0.05446\n",
      "Epoch: 9109, MSE: 0.25180466399587453, Learning Rate: 0.054455\n",
      "Epoch: 9110, MSE: 0.25180210089609134, Learning Rate: 0.05445\n",
      "Epoch: 9111, MSE: 0.25179953774700814, Learning Rate: 0.054445\n",
      "Epoch: 9112, MSE: 0.25179697454862604, Learning Rate: 0.05444\n",
      "Epoch: 9113, MSE: 0.2517944113009471, Learning Rate: 0.054435000000000004\n",
      "Epoch: 9114, MSE: 0.25179184800397186, Learning Rate: 0.054430000000000006\n",
      "Epoch: 9115, MSE: 0.251789284657702, Learning Rate: 0.054425\n",
      "Epoch: 9116, MSE: 0.2517867212621383, Learning Rate: 0.05442\n",
      "Epoch: 9117, MSE: 0.25178415781728347, Learning Rate: 0.054415000000000005\n",
      "Epoch: 9118, MSE: 0.2517815943231371, Learning Rate: 0.05441000000000001\n",
      "Epoch: 9119, MSE: 0.2517790307797033, Learning Rate: 0.054404999999999995\n",
      "Epoch: 9120, MSE: 0.25177646718697927, Learning Rate: 0.054400000000000004\n",
      "Epoch: 9121, MSE: 0.25177390354496987, Learning Rate: 0.054395\n",
      "Epoch: 9122, MSE: 0.25177133985367495, Learning Rate: 0.05439000000000001\n",
      "Epoch: 9123, MSE: 0.2517687761130964, Learning Rate: 0.054384999999999996\n",
      "Epoch: 9124, MSE: 0.25176621232323504, Learning Rate: 0.05438000000000001\n",
      "Epoch: 9125, MSE: 0.2517636484840923, Learning Rate: 0.054375\n",
      "Epoch: 9126, MSE: 0.25176108459567004, Learning Rate: 0.05437000000000001\n",
      "Epoch: 9127, MSE: 0.251758520657969, Learning Rate: 0.054365\n",
      "Epoch: 9128, MSE: 0.25175595667099016, Learning Rate: 0.05436000000000001\n",
      "Epoch: 9129, MSE: 0.2517533926347367, Learning Rate: 0.054355\n",
      "Epoch: 9130, MSE: 0.2517508285492075, Learning Rate: 0.05435\n",
      "Epoch: 9131, MSE: 0.25174826441440523, Learning Rate: 0.054345000000000004\n",
      "Epoch: 9132, MSE: 0.25174570023033144, Learning Rate: 0.05434\n",
      "Epoch: 9133, MSE: 0.25174313599698717, Learning Rate: 0.054335\n",
      "Epoch: 9134, MSE: 0.25174057171437364, Learning Rate: 0.05433\n",
      "Epoch: 9135, MSE: 0.25173800738249275, Learning Rate: 0.054325000000000005\n",
      "Epoch: 9136, MSE: 0.25173544300134504, Learning Rate: 0.05432000000000001\n",
      "Epoch: 9137, MSE: 0.25173287857093235, Learning Rate: 0.054315\n",
      "Epoch: 9138, MSE: 0.25173031409125557, Learning Rate: 0.054310000000000004\n",
      "Epoch: 9139, MSE: 0.25172774956231675, Learning Rate: 0.054305000000000006\n",
      "Epoch: 9140, MSE: 0.25172518498411633, Learning Rate: 0.054299999999999994\n",
      "Epoch: 9141, MSE: 0.25172262035665693, Learning Rate: 0.05429500000000001\n",
      "Epoch: 9142, MSE: 0.2517200556799386, Learning Rate: 0.05429\n",
      "Epoch: 9143, MSE: 0.2517174909539643, Learning Rate: 0.05428500000000001\n",
      "Epoch: 9144, MSE: 0.25171492617873326, Learning Rate: 0.054279999999999995\n",
      "Epoch: 9145, MSE: 0.2517123613542485, Learning Rate: 0.05427500000000001\n",
      "Epoch: 9146, MSE: 0.25170979648051, Learning Rate: 0.05427\n",
      "Epoch: 9147, MSE: 0.2517072315575207, Learning Rate: 0.05426500000000001\n",
      "Epoch: 9148, MSE: 0.2517046665852809, Learning Rate: 0.05426\n",
      "Epoch: 9149, MSE: 0.2517021015637926, Learning Rate: 0.054255\n",
      "Epoch: 9150, MSE: 0.25169953649305676, Learning Rate: 0.05425\n",
      "Epoch: 9151, MSE: 0.2516969713730743, Learning Rate: 0.054245\n",
      "Epoch: 9152, MSE: 0.2516944062038473, Learning Rate: 0.054240000000000003\n",
      "Epoch: 9153, MSE: 0.2516918409853764, Learning Rate: 0.054235000000000005\n",
      "Epoch: 9154, MSE: 0.2516892757176642, Learning Rate: 0.05423\n",
      "Epoch: 9155, MSE: 0.25168671040071033, Learning Rate: 0.054225\n",
      "Epoch: 9156, MSE: 0.25168414503451775, Learning Rate: 0.054220000000000004\n",
      "Epoch: 9157, MSE: 0.25168157961908694, Learning Rate: 0.054215000000000006\n",
      "Epoch: 9158, MSE: 0.2516790141544198, Learning Rate: 0.05421000000000001\n",
      "Epoch: 9159, MSE: 0.25167644864051725, Learning Rate: 0.054204999999999996\n",
      "Epoch: 9160, MSE: 0.25167388307738026, Learning Rate: 0.054200000000000005\n",
      "Epoch: 9161, MSE: 0.2516713174650114, Learning Rate: 0.05419499999999999\n",
      "Epoch: 9162, MSE: 0.2516687518034107, Learning Rate: 0.05419000000000001\n",
      "Epoch: 9163, MSE: 0.2516661860925802, Learning Rate: 0.054185\n",
      "Epoch: 9164, MSE: 0.2516636203325213, Learning Rate: 0.054180000000000006\n",
      "Epoch: 9165, MSE: 0.2516610545232355, Learning Rate: 0.054175\n",
      "Epoch: 9166, MSE: 0.2516584886647237, Learning Rate: 0.05417000000000001\n",
      "Epoch: 9167, MSE: 0.25165592275698756, Learning Rate: 0.054165\n",
      "Epoch: 9168, MSE: 0.25165335680002854, Learning Rate: 0.054160000000000014\n",
      "Epoch: 9169, MSE: 0.2516507907938478, Learning Rate: 0.054155\n",
      "Epoch: 9170, MSE: 0.2516482247384466, Learning Rate: 0.054150000000000004\n",
      "Epoch: 9171, MSE: 0.2516456586338265, Learning Rate: 0.054145\n",
      "Epoch: 9172, MSE: 0.251643092479989, Learning Rate: 0.05414\n",
      "Epoch: 9173, MSE: 0.2516405262769349, Learning Rate: 0.054135\n",
      "Epoch: 9174, MSE: 0.2516379600246674, Learning Rate: 0.054130000000000005\n",
      "Epoch: 9175, MSE: 0.25163539372318483, Learning Rate: 0.054125000000000006\n",
      "Epoch: 9176, MSE: 0.2516328273724905, Learning Rate: 0.05412\n",
      "Epoch: 9177, MSE: 0.2516302609725857, Learning Rate: 0.054115\n",
      "Epoch: 9178, MSE: 0.25162769452347206, Learning Rate: 0.054110000000000005\n",
      "Epoch: 9179, MSE: 0.2516251280251493, Learning Rate: 0.05410500000000001\n",
      "Epoch: 9180, MSE: 0.251622561477621, Learning Rate: 0.054099999999999995\n",
      "Epoch: 9181, MSE: 0.2516199948808867, Learning Rate: 0.054095000000000004\n",
      "Epoch: 9182, MSE: 0.2516174282349486, Learning Rate: 0.05409\n",
      "Epoch: 9183, MSE: 0.2516148615398082, Learning Rate: 0.05408500000000001\n",
      "Epoch: 9184, MSE: 0.2516122947954669, Learning Rate: 0.054079999999999996\n",
      "Epoch: 9185, MSE: 0.2516097280019259, Learning Rate: 0.05407500000000001\n",
      "Epoch: 9186, MSE: 0.2516071611591863, Learning Rate: 0.05407\n",
      "Epoch: 9187, MSE: 0.2516045942672496, Learning Rate: 0.05406500000000001\n",
      "Epoch: 9188, MSE: 0.25160202732611714, Learning Rate: 0.05406\n",
      "Epoch: 9189, MSE: 0.25159946033579106, Learning Rate: 0.054055\n",
      "Epoch: 9190, MSE: 0.2515968932962718, Learning Rate: 0.05405\n",
      "Epoch: 9191, MSE: 0.2515943262075609, Learning Rate: 0.054045\n",
      "Epoch: 9192, MSE: 0.2515917590696601, Learning Rate: 0.054040000000000005\n",
      "Epoch: 9193, MSE: 0.25158919188257106, Learning Rate: 0.054035\n",
      "Epoch: 9194, MSE: 0.2515866246462937, Learning Rate: 0.05403\n",
      "Epoch: 9195, MSE: 0.2515840573608308, Learning Rate: 0.054025000000000004\n",
      "Epoch: 9196, MSE: 0.2515814900261828, Learning Rate: 0.054020000000000006\n",
      "Epoch: 9197, MSE: 0.25157892264235265, Learning Rate: 0.05401500000000001\n",
      "Epoch: 9198, MSE: 0.25157635520933996, Learning Rate: 0.05401\n",
      "Epoch: 9199, MSE: 0.2515737877271468, Learning Rate: 0.054005\n",
      "Epoch: 9200, MSE: 0.2515712201957748, Learning Rate: 0.054000000000000006\n",
      "Epoch: 9201, MSE: 0.25156865261522543, Learning Rate: 0.053994999999999994\n",
      "Epoch: 9202, MSE: 0.25156608498549976, Learning Rate: 0.05399000000000001\n",
      "Epoch: 9203, MSE: 0.251563517306599, Learning Rate: 0.053985\n",
      "Epoch: 9204, MSE: 0.2515609495785244, Learning Rate: 0.05398000000000001\n",
      "Epoch: 9205, MSE: 0.25155838180127793, Learning Rate: 0.053974999999999995\n",
      "Epoch: 9206, MSE: 0.25155581397486093, Learning Rate: 0.05397000000000001\n",
      "Epoch: 9207, MSE: 0.2515532460992738, Learning Rate: 0.053965\n",
      "Epoch: 9208, MSE: 0.25155067817451954, Learning Rate: 0.05396000000000001\n",
      "Epoch: 9209, MSE: 0.25154811020059853, Learning Rate: 0.053955\n",
      "Epoch: 9210, MSE: 0.2515455421775123, Learning Rate: 0.05395\n",
      "Epoch: 9211, MSE: 0.2515429741052622, Learning Rate: 0.053945\n",
      "Epoch: 9212, MSE: 0.25154040598384947, Learning Rate: 0.05394\n",
      "Epoch: 9213, MSE: 0.2515378378132757, Learning Rate: 0.053935000000000004\n",
      "Epoch: 9214, MSE: 0.25153526959354244, Learning Rate: 0.053930000000000006\n",
      "Epoch: 9215, MSE: 0.25153270132465033, Learning Rate: 0.053925\n",
      "Epoch: 9216, MSE: 0.2515301330066021, Learning Rate: 0.05392\n",
      "Epoch: 9217, MSE: 0.25152756463939835, Learning Rate: 0.053915000000000005\n",
      "Epoch: 9218, MSE: 0.25152499622304036, Learning Rate: 0.053910000000000007\n",
      "Epoch: 9219, MSE: 0.25152242775752987, Learning Rate: 0.05390500000000001\n",
      "Epoch: 9220, MSE: 0.25151985924286785, Learning Rate: 0.053899999999999997\n",
      "Epoch: 9221, MSE: 0.25151729067905565, Learning Rate: 0.053895000000000005\n",
      "Epoch: 9222, MSE: 0.25151472206609565, Learning Rate: 0.05388999999999999\n",
      "Epoch: 9223, MSE: 0.25151215340398886, Learning Rate: 0.05388500000000001\n",
      "Epoch: 9224, MSE: 0.25150958469273543, Learning Rate: 0.05388\n",
      "Epoch: 9225, MSE: 0.25150701593233754, Learning Rate: 0.053875000000000006\n",
      "Epoch: 9226, MSE: 0.251504447122797, Learning Rate: 0.05387\n",
      "Epoch: 9227, MSE: 0.251501878264115, Learning Rate: 0.05386500000000001\n",
      "Epoch: 9228, MSE: 0.2514993093562935, Learning Rate: 0.05386\n",
      "Epoch: 9229, MSE: 0.2514967403993326, Learning Rate: 0.053855\n",
      "Epoch: 9230, MSE: 0.25149417139323454, Learning Rate: 0.05385\n",
      "Epoch: 9231, MSE: 0.25149160233800033, Learning Rate: 0.053845000000000004\n",
      "Epoch: 9232, MSE: 0.25148903323363186, Learning Rate: 0.05384\n",
      "Epoch: 9233, MSE: 0.25148646408013026, Learning Rate: 0.053835\n",
      "Epoch: 9234, MSE: 0.2514838948774965, Learning Rate: 0.05383\n",
      "Epoch: 9235, MSE: 0.25148132562573294, Learning Rate: 0.053825000000000005\n",
      "Epoch: 9236, MSE: 0.2514787563248405, Learning Rate: 0.05382000000000001\n",
      "Epoch: 9237, MSE: 0.25147618697482, Learning Rate: 0.053815\n",
      "Epoch: 9238, MSE: 0.251473617575674, Learning Rate: 0.053810000000000004\n",
      "Epoch: 9239, MSE: 0.2514710481274027, Learning Rate: 0.05380499999999999\n",
      "Epoch: 9240, MSE: 0.2514684786300091, Learning Rate: 0.05380000000000001\n",
      "Epoch: 9241, MSE: 0.25146590908349237, Learning Rate: 0.053794999999999996\n",
      "Epoch: 9242, MSE: 0.25146333948785554, Learning Rate: 0.053790000000000004\n",
      "Epoch: 9243, MSE: 0.2514607698430999, Learning Rate: 0.053785\n",
      "Epoch: 9244, MSE: 0.2514582001492262, Learning Rate: 0.05378000000000001\n",
      "Epoch: 9245, MSE: 0.2514556304062365, Learning Rate: 0.053774999999999996\n",
      "Epoch: 9246, MSE: 0.25145306061413175, Learning Rate: 0.05377000000000001\n",
      "Epoch: 9247, MSE: 0.25145049077291376, Learning Rate: 0.053765\n",
      "Epoch: 9248, MSE: 0.2514479208825832, Learning Rate: 0.05376000000000001\n",
      "Epoch: 9249, MSE: 0.25144535094314197, Learning Rate: 0.053755\n",
      "Epoch: 9250, MSE: 0.25144278095459244, Learning Rate: 0.05375\n",
      "Epoch: 9251, MSE: 0.2514402109169345, Learning Rate: 0.053745\n",
      "Epoch: 9252, MSE: 0.2514376408301706, Learning Rate: 0.05374\n",
      "Epoch: 9253, MSE: 0.25143507069430043, Learning Rate: 0.053735000000000005\n",
      "Epoch: 9254, MSE: 0.251432500509328, Learning Rate: 0.05373\n",
      "Epoch: 9255, MSE: 0.25142993027525284, Learning Rate: 0.053725\n",
      "Epoch: 9256, MSE: 0.2514273599920768, Learning Rate: 0.053720000000000004\n",
      "Epoch: 9257, MSE: 0.2514247896598018, Learning Rate: 0.053715000000000006\n",
      "Epoch: 9258, MSE: 0.25142221927842895, Learning Rate: 0.05371000000000001\n",
      "Epoch: 9259, MSE: 0.25141964884795864, Learning Rate: 0.053705\n",
      "Epoch: 9260, MSE: 0.2514170783683943, Learning Rate: 0.0537\n",
      "Epoch: 9261, MSE: 0.25141450783973557, Learning Rate: 0.05369500000000001\n",
      "Epoch: 9262, MSE: 0.2514119372619845, Learning Rate: 0.053689999999999995\n",
      "Epoch: 9263, MSE: 0.25140936663514357, Learning Rate: 0.05368500000000001\n",
      "Epoch: 9264, MSE: 0.2514067959592123, Learning Rate: 0.05368\n",
      "Epoch: 9265, MSE: 0.2514042252341929, Learning Rate: 0.05367500000000001\n",
      "Epoch: 9266, MSE: 0.25140165446008667, Learning Rate: 0.053669999999999995\n",
      "Epoch: 9267, MSE: 0.25139908363689567, Learning Rate: 0.05366500000000001\n",
      "Epoch: 9268, MSE: 0.251396512764621, Learning Rate: 0.05366\n",
      "Epoch: 9269, MSE: 0.2513939418432644, Learning Rate: 0.05365500000000001\n",
      "Epoch: 9270, MSE: 0.25139137087282637, Learning Rate: 0.05365\n",
      "Epoch: 9271, MSE: 0.251388799853309, Learning Rate: 0.053645\n",
      "Epoch: 9272, MSE: 0.25138622878471323, Learning Rate: 0.05364\n",
      "Epoch: 9273, MSE: 0.2513836576670405, Learning Rate: 0.053635\n",
      "Epoch: 9274, MSE: 0.25138108650029345, Learning Rate: 0.053630000000000004\n",
      "Epoch: 9275, MSE: 0.25137851528447236, Learning Rate: 0.053625000000000006\n",
      "Epoch: 9276, MSE: 0.2513759440195785, Learning Rate: 0.05362\n",
      "Epoch: 9277, MSE: 0.251373372705614, Learning Rate: 0.053615\n",
      "Epoch: 9278, MSE: 0.25137080134257983, Learning Rate: 0.053610000000000005\n",
      "Epoch: 9279, MSE: 0.2513682299304769, Learning Rate: 0.05360500000000001\n",
      "Epoch: 9280, MSE: 0.251365658469308, Learning Rate: 0.05360000000000001\n",
      "Epoch: 9281, MSE: 0.251363086959074, Learning Rate: 0.053595\n",
      "Epoch: 9282, MSE: 0.25136051539977544, Learning Rate: 0.053590000000000006\n",
      "Epoch: 9283, MSE: 0.2513579437914147, Learning Rate: 0.053584999999999994\n",
      "Epoch: 9284, MSE: 0.25135537213399317, Learning Rate: 0.05358000000000001\n",
      "Epoch: 9285, MSE: 0.251352800427512, Learning Rate: 0.053575\n",
      "Epoch: 9286, MSE: 0.2513502286719728, Learning Rate: 0.053570000000000007\n",
      "Epoch: 9287, MSE: 0.2513476568673764, Learning Rate: 0.053565\n",
      "Epoch: 9288, MSE: 0.25134508501372516, Learning Rate: 0.05356000000000001\n",
      "Epoch: 9289, MSE: 0.25134251311102, Learning Rate: 0.053555\n",
      "Epoch: 9290, MSE: 0.25133994115926295, Learning Rate: 0.05355\n",
      "Epoch: 9291, MSE: 0.2513373691584542, Learning Rate: 0.053545\n",
      "Epoch: 9292, MSE: 0.25133479710859663, Learning Rate: 0.053540000000000004\n",
      "Epoch: 9293, MSE: 0.2513322250096904, Learning Rate: 0.053535\n",
      "Epoch: 9294, MSE: 0.2513296528617374, Learning Rate: 0.05353\n",
      "Epoch: 9295, MSE: 0.2513270806647393, Learning Rate: 0.053525\n",
      "Epoch: 9296, MSE: 0.2513245084186977, Learning Rate: 0.053520000000000005\n",
      "Epoch: 9297, MSE: 0.2513219361236137, Learning Rate: 0.05351500000000001\n",
      "Epoch: 9298, MSE: 0.25131936377948805, Learning Rate: 0.05351\n",
      "Epoch: 9299, MSE: 0.25131679138632307, Learning Rate: 0.053505000000000004\n",
      "Epoch: 9300, MSE: 0.2513142189441199, Learning Rate: 0.05349999999999999\n",
      "Epoch: 9301, MSE: 0.2513116464528809, Learning Rate: 0.05349500000000001\n",
      "Epoch: 9302, MSE: 0.2513090739126069, Learning Rate: 0.053489999999999996\n",
      "Epoch: 9303, MSE: 0.25130650132329824, Learning Rate: 0.053485000000000005\n",
      "Epoch: 9304, MSE: 0.2513039286849576, Learning Rate: 0.05348\n",
      "Epoch: 9305, MSE: 0.25130135599758574, Learning Rate: 0.05347500000000001\n",
      "Epoch: 9306, MSE: 0.2512987832611852, Learning Rate: 0.05347\n",
      "Epoch: 9307, MSE: 0.25129621047575545, Learning Rate: 0.05346500000000001\n",
      "Epoch: 9308, MSE: 0.251293637641301, Learning Rate: 0.05346\n",
      "Epoch: 9309, MSE: 0.2512910647578196, Learning Rate: 0.05345500000000001\n",
      "Epoch: 9310, MSE: 0.2512884918253159, Learning Rate: 0.05345\n",
      "Epoch: 9311, MSE: 0.2512859188437888, Learning Rate: 0.053445\n",
      "Epoch: 9312, MSE: 0.2512833458132422, Learning Rate: 0.05344\n",
      "Epoch: 9313, MSE: 0.25128077273367483, Learning Rate: 0.053435\n",
      "Epoch: 9314, MSE: 0.25127819960509057, Learning Rate: 0.053430000000000005\n",
      "Epoch: 9315, MSE: 0.2512756264274894, Learning Rate: 0.053425\n",
      "Epoch: 9316, MSE: 0.25127305320087384, Learning Rate: 0.05342\n",
      "Epoch: 9317, MSE: 0.25127047992524404, Learning Rate: 0.053415000000000004\n",
      "Epoch: 9318, MSE: 0.25126790660060205, Learning Rate: 0.053410000000000006\n",
      "Epoch: 9319, MSE: 0.2512653332269505, Learning Rate: 0.05340500000000001\n",
      "Epoch: 9320, MSE: 0.2512627598042879, Learning Rate: 0.0534\n",
      "Epoch: 9321, MSE: 0.2512601863326189, Learning Rate: 0.053395\n",
      "Epoch: 9322, MSE: 0.25125761281194336, Learning Rate: 0.05339000000000001\n",
      "Epoch: 9323, MSE: 0.2512550392422633, Learning Rate: 0.053384999999999995\n",
      "Epoch: 9324, MSE: 0.25125246562357906, Learning Rate: 0.05338000000000001\n",
      "Epoch: 9325, MSE: 0.25124989195589353, Learning Rate: 0.053375\n",
      "Epoch: 9326, MSE: 0.25124731823920704, Learning Rate: 0.05337000000000001\n",
      "Epoch: 9327, MSE: 0.25124474447352124, Learning Rate: 0.053364999999999996\n",
      "Epoch: 9328, MSE: 0.2512421706588388, Learning Rate: 0.05336000000000001\n",
      "Epoch: 9329, MSE: 0.2512395967951588, Learning Rate: 0.053355\n",
      "Epoch: 9330, MSE: 0.25123702288248484, Learning Rate: 0.05335\n",
      "Epoch: 9331, MSE: 0.25123444892081714, Learning Rate: 0.053345000000000004\n",
      "Epoch: 9332, MSE: 0.25123187491015847, Learning Rate: 0.05334\n",
      "Epoch: 9333, MSE: 0.25122930085050915, Learning Rate: 0.053335\n",
      "Epoch: 9334, MSE: 0.25122672674187096, Learning Rate: 0.05333\n",
      "Epoch: 9335, MSE: 0.25122415258424513, Learning Rate: 0.053325000000000004\n",
      "Epoch: 9336, MSE: 0.25122157837763304, Learning Rate: 0.053320000000000006\n",
      "Epoch: 9337, MSE: 0.2512190041220367, Learning Rate: 0.053315\n",
      "Epoch: 9338, MSE: 0.2512164298174573, Learning Rate: 0.05331\n",
      "Epoch: 9339, MSE: 0.2512138554638963, Learning Rate: 0.053305000000000005\n",
      "Epoch: 9340, MSE: 0.25121128106135543, Learning Rate: 0.05329999999999999\n",
      "Epoch: 9341, MSE: 0.2512087066098355, Learning Rate: 0.05329500000000001\n",
      "Epoch: 9342, MSE: 0.251206132109339, Learning Rate: 0.05329\n",
      "Epoch: 9343, MSE: 0.2512035575598659, Learning Rate: 0.053285000000000006\n",
      "Epoch: 9344, MSE: 0.25120098296141835, Learning Rate: 0.053279999999999994\n",
      "Epoch: 9345, MSE: 0.2511984083139991, Learning Rate: 0.05327500000000001\n",
      "Epoch: 9346, MSE: 0.25119583361760767, Learning Rate: 0.05327\n",
      "Epoch: 9347, MSE: 0.251193258872247, Learning Rate: 0.05326500000000001\n",
      "Epoch: 9348, MSE: 0.25119068407791645, Learning Rate: 0.05326\n",
      "Epoch: 9349, MSE: 0.2511881092346199, Learning Rate: 0.05325500000000001\n",
      "Epoch: 9350, MSE: 0.251185534342357, Learning Rate: 0.05325\n",
      "Epoch: 9351, MSE: 0.2511829594011307, Learning Rate: 0.053245\n",
      "Epoch: 9352, MSE: 0.25118038441094215, Learning Rate: 0.05324\n",
      "Epoch: 9353, MSE: 0.25117780937179224, Learning Rate: 0.053235000000000005\n",
      "Epoch: 9354, MSE: 0.251175234283682, Learning Rate: 0.05323\n",
      "Epoch: 9355, MSE: 0.25117265914661446, Learning Rate: 0.053225\n",
      "Epoch: 9356, MSE: 0.2511700839605889, Learning Rate: 0.05322\n",
      "Epoch: 9357, MSE: 0.2511675087256093, Learning Rate: 0.053215000000000005\n",
      "Epoch: 9358, MSE: 0.25116493344167556, Learning Rate: 0.05321000000000001\n",
      "Epoch: 9359, MSE: 0.25116235810878934, Learning Rate: 0.053205\n",
      "Epoch: 9360, MSE: 0.2511597827269521, Learning Rate: 0.053200000000000004\n",
      "Epoch: 9361, MSE: 0.25115720729616564, Learning Rate: 0.05319499999999999\n",
      "Epoch: 9362, MSE: 0.2511546318164313, Learning Rate: 0.05319000000000001\n",
      "Epoch: 9363, MSE: 0.25115205628775017, Learning Rate: 0.053184999999999996\n",
      "Epoch: 9364, MSE: 0.25114948071012483, Learning Rate: 0.053180000000000005\n",
      "Epoch: 9365, MSE: 0.2511469050835553, Learning Rate: 0.053175\n",
      "Epoch: 9366, MSE: 0.25114432940804354, Learning Rate: 0.05317000000000001\n",
      "Epoch: 9367, MSE: 0.25114175368359226, Learning Rate: 0.053165\n",
      "Epoch: 9368, MSE: 0.2511391779102008, Learning Rate: 0.05316000000000001\n",
      "Epoch: 9369, MSE: 0.2511366020878718, Learning Rate: 0.053155\n",
      "Epoch: 9370, MSE: 0.2511340262166078, Learning Rate: 0.05315\n",
      "Epoch: 9371, MSE: 0.25113145029640777, Learning Rate: 0.053145\n",
      "Epoch: 9372, MSE: 0.25112887432727526, Learning Rate: 0.05314\n",
      "Epoch: 9373, MSE: 0.25112629830921096, Learning Rate: 0.053135\n",
      "Epoch: 9374, MSE: 0.2511237222422159, Learning Rate: 0.053130000000000004\n",
      "Epoch: 9375, MSE: 0.2511211461262923, Learning Rate: 0.053125000000000006\n",
      "Epoch: 9376, MSE: 0.2511185699614421, Learning Rate: 0.05312\n",
      "Epoch: 9377, MSE: 0.2511159937476656, Learning Rate: 0.053115\n",
      "Epoch: 9378, MSE: 0.2511134174849648, Learning Rate: 0.053110000000000004\n",
      "Epoch: 9379, MSE: 0.251110841173341, Learning Rate: 0.053105000000000006\n",
      "Epoch: 9380, MSE: 0.2511082648127962, Learning Rate: 0.05310000000000001\n",
      "Epoch: 9381, MSE: 0.25110568840333125, Learning Rate: 0.053095\n",
      "Epoch: 9382, MSE: 0.25110311194494805, Learning Rate: 0.05309\n",
      "Epoch: 9383, MSE: 0.2511005354376473, Learning Rate: 0.05308500000000001\n",
      "Epoch: 9384, MSE: 0.2510979588814313, Learning Rate: 0.053079999999999995\n",
      "Epoch: 9385, MSE: 0.2510953822763022, Learning Rate: 0.05307500000000001\n",
      "Epoch: 9386, MSE: 0.2510928056222597, Learning Rate: 0.05307\n",
      "Epoch: 9387, MSE: 0.2510902289193065, Learning Rate: 0.05306500000000001\n",
      "Epoch: 9388, MSE: 0.2510876521674436, Learning Rate: 0.053059999999999996\n",
      "Epoch: 9389, MSE: 0.2510850753666733, Learning Rate: 0.05305500000000001\n",
      "Epoch: 9390, MSE: 0.25108249851699554, Learning Rate: 0.05305\n",
      "Epoch: 9391, MSE: 0.25107992161841325, Learning Rate: 0.053045\n",
      "Epoch: 9392, MSE: 0.2510773446709273, Learning Rate: 0.053040000000000004\n",
      "Epoch: 9393, MSE: 0.25107476767453946, Learning Rate: 0.053035\n",
      "Epoch: 9394, MSE: 0.25107219062925074, Learning Rate: 0.05303\n",
      "Epoch: 9395, MSE: 0.2510696135350628, Learning Rate: 0.053025\n",
      "Epoch: 9396, MSE: 0.2510670363919782, Learning Rate: 0.053020000000000005\n",
      "Epoch: 9397, MSE: 0.25106445919999715, Learning Rate: 0.05301500000000001\n",
      "Epoch: 9398, MSE: 0.25106188195912055, Learning Rate: 0.05301\n",
      "Epoch: 9399, MSE: 0.25105930466935106, Learning Rate: 0.053005000000000004\n",
      "Epoch: 9400, MSE: 0.25105672733069034, Learning Rate: 0.053000000000000005\n",
      "Epoch: 9401, MSE: 0.25105414994313907, Learning Rate: 0.052994999999999994\n",
      "Epoch: 9402, MSE: 0.25105157250669946, Learning Rate: 0.05299000000000001\n",
      "Epoch: 9403, MSE: 0.25104899502137273, Learning Rate: 0.052985\n",
      "Epoch: 9404, MSE: 0.2510464174871601, Learning Rate: 0.052980000000000006\n",
      "Epoch: 9405, MSE: 0.25104383990406304, Learning Rate: 0.052974999999999994\n",
      "Epoch: 9406, MSE: 0.2510412622720844, Learning Rate: 0.05297000000000001\n",
      "Epoch: 9407, MSE: 0.2510386845912234, Learning Rate: 0.052965\n",
      "Epoch: 9408, MSE: 0.2510361068614829, Learning Rate: 0.05296000000000001\n",
      "Epoch: 9409, MSE: 0.2510335290828648, Learning Rate: 0.052955\n",
      "Epoch: 9410, MSE: 0.251030951255369, Learning Rate: 0.05295000000000001\n",
      "Epoch: 9411, MSE: 0.2510283733789986, Learning Rate: 0.052945\n",
      "Epoch: 9412, MSE: 0.25102579545375436, Learning Rate: 0.05294\n",
      "Epoch: 9413, MSE: 0.25102321747963807, Learning Rate: 0.052935\n",
      "Epoch: 9414, MSE: 0.25102063945665104, Learning Rate: 0.052930000000000005\n",
      "Epoch: 9415, MSE: 0.251018061384795, Learning Rate: 0.052925\n",
      "Epoch: 9416, MSE: 0.2510154832640702, Learning Rate: 0.05292\n",
      "Epoch: 9417, MSE: 0.25101290509448027, Learning Rate: 0.052915000000000004\n",
      "Epoch: 9418, MSE: 0.2510103268760252, Learning Rate: 0.052910000000000006\n",
      "Epoch: 9419, MSE: 0.2510077486087069, Learning Rate: 0.05290500000000001\n",
      "Epoch: 9420, MSE: 0.2510051702925266, Learning Rate: 0.0529\n",
      "Epoch: 9421, MSE: 0.2510025919274872, Learning Rate: 0.052895000000000005\n",
      "Epoch: 9422, MSE: 0.25100001351358797, Learning Rate: 0.05288999999999999\n",
      "Epoch: 9423, MSE: 0.2509974350508311, Learning Rate: 0.05288500000000001\n",
      "Epoch: 9424, MSE: 0.2509948565392202, Learning Rate: 0.052879999999999996\n",
      "Epoch: 9425, MSE: 0.25099227797875373, Learning Rate: 0.052875000000000005\n",
      "Epoch: 9426, MSE: 0.250989699369435, Learning Rate: 0.05287\n",
      "Epoch: 9427, MSE: 0.25098712071126483, Learning Rate: 0.05286500000000001\n",
      "Epoch: 9428, MSE: 0.2509845420042451, Learning Rate: 0.05286\n",
      "Epoch: 9429, MSE: 0.2509819632483776, Learning Rate: 0.05285500000000001\n",
      "Epoch: 9430, MSE: 0.2509793844436628, Learning Rate: 0.05285\n",
      "Epoch: 9431, MSE: 0.25097680559010344, Learning Rate: 0.052845\n",
      "Epoch: 9432, MSE: 0.2509742266876999, Learning Rate: 0.05284\n",
      "Epoch: 9433, MSE: 0.2509716477364543, Learning Rate: 0.052835\n",
      "Epoch: 9434, MSE: 0.25096906873636815, Learning Rate: 0.05283\n",
      "Epoch: 9435, MSE: 0.25096648968744323, Learning Rate: 0.052825000000000004\n",
      "Epoch: 9436, MSE: 0.2509639105896801, Learning Rate: 0.052820000000000006\n",
      "Epoch: 9437, MSE: 0.25096133144308136, Learning Rate: 0.052815\n",
      "Epoch: 9438, MSE: 0.2509587522476475, Learning Rate: 0.05281\n",
      "Epoch: 9439, MSE: 0.250956173003381, Learning Rate: 0.052805000000000005\n",
      "Epoch: 9440, MSE: 0.25095359371028225, Learning Rate: 0.05280000000000001\n",
      "Epoch: 9441, MSE: 0.25095101436835443, Learning Rate: 0.052794999999999995\n",
      "Epoch: 9442, MSE: 0.25094843497759745, Learning Rate: 0.052790000000000004\n",
      "Epoch: 9443, MSE: 0.250945855538014, Learning Rate: 0.052785\n",
      "Epoch: 9444, MSE: 0.2509432760496048, Learning Rate: 0.05278000000000001\n",
      "Epoch: 9445, MSE: 0.25094069651237105, Learning Rate: 0.052774999999999996\n",
      "Epoch: 9446, MSE: 0.2509381169263152, Learning Rate: 0.05277000000000001\n",
      "Epoch: 9447, MSE: 0.25093553729143836, Learning Rate: 0.052765\n",
      "Epoch: 9448, MSE: 0.2509329576077424, Learning Rate: 0.05276000000000001\n",
      "Epoch: 9449, MSE: 0.25093037787522837, Learning Rate: 0.052754999999999996\n",
      "Epoch: 9450, MSE: 0.2509277980938973, Learning Rate: 0.05275000000000001\n",
      "Epoch: 9451, MSE: 0.2509252182637527, Learning Rate: 0.052745\n",
      "Epoch: 9452, MSE: 0.25092263838479306, Learning Rate: 0.05274\n",
      "Epoch: 9453, MSE: 0.25092005845702225, Learning Rate: 0.052735000000000004\n",
      "Epoch: 9454, MSE: 0.2509174784804421, Learning Rate: 0.05273\n",
      "Epoch: 9455, MSE: 0.25091489845505194, Learning Rate: 0.052725\n",
      "Epoch: 9456, MSE: 0.2509123183808541, Learning Rate: 0.05272\n",
      "Epoch: 9457, MSE: 0.25090973825785184, Learning Rate: 0.052715000000000005\n",
      "Epoch: 9458, MSE: 0.2509071580860445, Learning Rate: 0.05271000000000001\n",
      "Epoch: 9459, MSE: 0.2509045778654347, Learning Rate: 0.052705\n",
      "Epoch: 9460, MSE: 0.2509019975960232, Learning Rate: 0.052700000000000004\n",
      "Epoch: 9461, MSE: 0.2508994172778131, Learning Rate: 0.052695000000000006\n",
      "Epoch: 9462, MSE: 0.25089683691080383, Learning Rate: 0.052689999999999994\n",
      "Epoch: 9463, MSE: 0.25089425649499814, Learning Rate: 0.05268500000000001\n",
      "Epoch: 9464, MSE: 0.2508916760303972, Learning Rate: 0.05268\n",
      "Epoch: 9465, MSE: 0.25088909551700334, Learning Rate: 0.05267500000000001\n",
      "Epoch: 9466, MSE: 0.2508865149548168, Learning Rate: 0.052669999999999995\n",
      "Epoch: 9467, MSE: 0.2508839343438405, Learning Rate: 0.05266500000000001\n",
      "Epoch: 9468, MSE: 0.2508813536840743, Learning Rate: 0.05266\n",
      "Epoch: 9469, MSE: 0.2508787729755209, Learning Rate: 0.05265500000000001\n",
      "Epoch: 9470, MSE: 0.25087619221818147, Learning Rate: 0.05265\n",
      "Epoch: 9471, MSE: 0.2508736114120577, Learning Rate: 0.052645\n",
      "Epoch: 9472, MSE: 0.2508710305571516, Learning Rate: 0.05264\n",
      "Epoch: 9473, MSE: 0.2508684496534636, Learning Rate: 0.052635\n",
      "Epoch: 9474, MSE: 0.2508658687009959, Learning Rate: 0.05263\n",
      "Epoch: 9475, MSE: 0.25086328769974975, Learning Rate: 0.052625000000000005\n",
      "Epoch: 9476, MSE: 0.2508607066497277, Learning Rate: 0.05262\n",
      "Epoch: 9477, MSE: 0.25085812555092923, Learning Rate: 0.052615\n",
      "Epoch: 9478, MSE: 0.2508555444033581, Learning Rate: 0.052610000000000004\n",
      "Epoch: 9479, MSE: 0.2508529632070141, Learning Rate: 0.052605000000000006\n",
      "Epoch: 9480, MSE: 0.2508503819618996, Learning Rate: 0.05260000000000001\n",
      "Epoch: 9481, MSE: 0.2508478006680167, Learning Rate: 0.052594999999999996\n",
      "Epoch: 9482, MSE: 0.25084521932536535, Learning Rate: 0.052590000000000005\n",
      "Epoch: 9483, MSE: 0.25084263793394884, Learning Rate: 0.05258499999999999\n",
      "Epoch: 9484, MSE: 0.250840056493767, Learning Rate: 0.05258000000000001\n",
      "Epoch: 9485, MSE: 0.2508374750048226, Learning Rate: 0.052575\n",
      "Epoch: 9486, MSE: 0.25083489346711624, Learning Rate: 0.052570000000000006\n",
      "Epoch: 9487, MSE: 0.25083231188065136, Learning Rate: 0.052565\n",
      "Epoch: 9488, MSE: 0.25082973024542765, Learning Rate: 0.05256000000000001\n",
      "Epoch: 9489, MSE: 0.2508271485614458, Learning Rate: 0.052555\n",
      "Epoch: 9490, MSE: 0.25082456682870996, Learning Rate: 0.05255000000000001\n",
      "Epoch: 9491, MSE: 0.25082198504722053, Learning Rate: 0.052545\n",
      "Epoch: 9492, MSE: 0.2508194032169788, Learning Rate: 0.05254\n",
      "Epoch: 9493, MSE: 0.2508168213379859, Learning Rate: 0.052535\n",
      "Epoch: 9494, MSE: 0.2508142394102444, Learning Rate: 0.05253\n",
      "Epoch: 9495, MSE: 0.2508116574337553, Learning Rate: 0.052525\n",
      "Epoch: 9496, MSE: 0.2508090754085205, Learning Rate: 0.052520000000000004\n",
      "Epoch: 9497, MSE: 0.25080649333454075, Learning Rate: 0.052515000000000006\n",
      "Epoch: 9498, MSE: 0.2508039112118184, Learning Rate: 0.05251\n",
      "Epoch: 9499, MSE: 0.2508013290403544, Learning Rate: 0.052505\n",
      "Epoch: 9500, MSE: 0.250798746820151, Learning Rate: 0.052500000000000005\n",
      "Epoch: 9501, MSE: 0.2507961645512092, Learning Rate: 0.05249500000000001\n",
      "Epoch: 9502, MSE: 0.2507935822335304, Learning Rate: 0.052489999999999995\n",
      "Epoch: 9503, MSE: 0.2507909998671164, Learning Rate: 0.052485000000000004\n",
      "Epoch: 9504, MSE: 0.2507884174519689, Learning Rate: 0.05248\n",
      "Epoch: 9505, MSE: 0.2507858349880898, Learning Rate: 0.05247500000000001\n",
      "Epoch: 9506, MSE: 0.2507832524754794, Learning Rate: 0.052469999999999996\n",
      "Epoch: 9507, MSE: 0.2507806699141406, Learning Rate: 0.05246500000000001\n",
      "Epoch: 9508, MSE: 0.2507780873040741, Learning Rate: 0.05246\n",
      "Epoch: 9509, MSE: 0.2507755046452819, Learning Rate: 0.05245500000000001\n",
      "Epoch: 9510, MSE: 0.25077292193776507, Learning Rate: 0.05245\n",
      "Epoch: 9511, MSE: 0.25077033918152575, Learning Rate: 0.05244500000000001\n",
      "Epoch: 9512, MSE: 0.2507677563765645, Learning Rate: 0.05244\n",
      "Epoch: 9513, MSE: 0.25076517352288497, Learning Rate: 0.052435\n",
      "Epoch: 9514, MSE: 0.25076259062048617, Learning Rate: 0.052430000000000004\n",
      "Epoch: 9515, MSE: 0.250760007669371, Learning Rate: 0.052425\n",
      "Epoch: 9516, MSE: 0.25075742466954093, Learning Rate: 0.05242\n",
      "Epoch: 9517, MSE: 0.2507548416209973, Learning Rate: 0.052415\n",
      "Epoch: 9518, MSE: 0.250752258523742, Learning Rate: 0.052410000000000005\n",
      "Epoch: 9519, MSE: 0.25074967537777587, Learning Rate: 0.05240500000000001\n",
      "Epoch: 9520, MSE: 0.2507470921831021, Learning Rate: 0.0524\n",
      "Epoch: 9521, MSE: 0.25074450893972006, Learning Rate: 0.052395000000000004\n",
      "Epoch: 9522, MSE: 0.2507419256476322, Learning Rate: 0.052390000000000006\n",
      "Epoch: 9523, MSE: 0.2507393423068408, Learning Rate: 0.052384999999999994\n",
      "Epoch: 9524, MSE: 0.25073675891734687, Learning Rate: 0.05238000000000001\n",
      "Epoch: 9525, MSE: 0.2507341754791509, Learning Rate: 0.052375\n",
      "Epoch: 9526, MSE: 0.2507315919922571, Learning Rate: 0.05237000000000001\n",
      "Epoch: 9527, MSE: 0.25072900845666407, Learning Rate: 0.052364999999999995\n",
      "Epoch: 9528, MSE: 0.25072642487237523, Learning Rate: 0.05236000000000001\n",
      "Epoch: 9529, MSE: 0.2507238412393914, Learning Rate: 0.052355\n",
      "Epoch: 9530, MSE: 0.2507212575577149, Learning Rate: 0.05235000000000001\n",
      "Epoch: 9531, MSE: 0.25071867382734686, Learning Rate: 0.052345\n",
      "Epoch: 9532, MSE: 0.25071609004828743, Learning Rate: 0.05234\n",
      "Epoch: 9533, MSE: 0.2507135062205409, Learning Rate: 0.052335\n",
      "Epoch: 9534, MSE: 0.25071092234410725, Learning Rate: 0.05233\n",
      "Epoch: 9535, MSE: 0.2507083384189879, Learning Rate: 0.052325\n",
      "Epoch: 9536, MSE: 0.2507057544451849, Learning Rate: 0.052320000000000005\n",
      "Epoch: 9537, MSE: 0.25070317042269896, Learning Rate: 0.052315\n",
      "Epoch: 9538, MSE: 0.2507005863515334, Learning Rate: 0.05231\n",
      "Epoch: 9539, MSE: 0.2506980022316877, Learning Rate: 0.052305000000000004\n",
      "Epoch: 9540, MSE: 0.2506954180631645, Learning Rate: 0.052300000000000006\n",
      "Epoch: 9541, MSE: 0.25069283384596697, Learning Rate: 0.05229500000000001\n",
      "Epoch: 9542, MSE: 0.2506902495800928, Learning Rate: 0.052289999999999996\n",
      "Epoch: 9543, MSE: 0.2506876652655467, Learning Rate: 0.052285000000000005\n",
      "Epoch: 9544, MSE: 0.25068508090232966, Learning Rate: 0.05227999999999999\n",
      "Epoch: 9545, MSE: 0.25068249649044233, Learning Rate: 0.05227500000000001\n",
      "Epoch: 9546, MSE: 0.2506799120298871, Learning Rate: 0.05227\n",
      "Epoch: 9547, MSE: 0.25067732752066524, Learning Rate: 0.052265000000000006\n",
      "Epoch: 9548, MSE: 0.25067474296277814, Learning Rate: 0.05226\n",
      "Epoch: 9549, MSE: 0.25067215835622797, Learning Rate: 0.05225500000000001\n",
      "Epoch: 9550, MSE: 0.25066957370101606, Learning Rate: 0.05225\n",
      "Epoch: 9551, MSE: 0.25066698899714457, Learning Rate: 0.052245000000000014\n",
      "Epoch: 9552, MSE: 0.2506644042446125, Learning Rate: 0.05224\n",
      "Epoch: 9553, MSE: 0.2506618194434246, Learning Rate: 0.052235000000000004\n",
      "Epoch: 9554, MSE: 0.25065923459358047, Learning Rate: 0.05223\n",
      "Epoch: 9555, MSE: 0.2506566496950835, Learning Rate: 0.052225\n",
      "Epoch: 9556, MSE: 0.25065406474793267, Learning Rate: 0.05222\n",
      "Epoch: 9557, MSE: 0.2506514797521315, Learning Rate: 0.052215000000000004\n",
      "Epoch: 9558, MSE: 0.25064889470768115, Learning Rate: 0.052210000000000006\n",
      "Epoch: 9559, MSE: 0.2506463096145835, Learning Rate: 0.052205\n",
      "Epoch: 9560, MSE: 0.25064372447284, Learning Rate: 0.0522\n",
      "Epoch: 9561, MSE: 0.25064113928245074, Learning Rate: 0.052195000000000005\n",
      "Epoch: 9562, MSE: 0.25063855404341945, Learning Rate: 0.05219000000000001\n",
      "Epoch: 9563, MSE: 0.25063596875574623, Learning Rate: 0.052184999999999995\n",
      "Epoch: 9564, MSE: 0.250633383419434, Learning Rate: 0.052180000000000004\n",
      "Epoch: 9565, MSE: 0.2506307980344829, Learning Rate: 0.052175\n",
      "Epoch: 9566, MSE: 0.25062821260089513, Learning Rate: 0.05217000000000001\n",
      "Epoch: 9567, MSE: 0.2506256271186732, Learning Rate: 0.052164999999999996\n",
      "Epoch: 9568, MSE: 0.2506230415878167, Learning Rate: 0.05216000000000001\n",
      "Epoch: 9569, MSE: 0.25062045600832944, Learning Rate: 0.052155\n",
      "Epoch: 9570, MSE: 0.2506178703802107, Learning Rate: 0.05215000000000001\n",
      "Epoch: 9571, MSE: 0.250615284703464, Learning Rate: 0.052145\n",
      "Epoch: 9572, MSE: 0.2506126989780897, Learning Rate: 0.05214\n",
      "Epoch: 9573, MSE: 0.25061011320409027, Learning Rate: 0.052135\n",
      "Epoch: 9574, MSE: 0.250607527381467, Learning Rate: 0.05213\n",
      "Epoch: 9575, MSE: 0.25060494151022117, Learning Rate: 0.052125000000000005\n",
      "Epoch: 9576, MSE: 0.25060235559035476, Learning Rate: 0.05212\n",
      "Epoch: 9577, MSE: 0.25059976962186853, Learning Rate: 0.052115\n",
      "Epoch: 9578, MSE: 0.2505971836047651, Learning Rate: 0.052110000000000004\n",
      "Epoch: 9579, MSE: 0.25059459753904584, Learning Rate: 0.052105000000000005\n",
      "Epoch: 9580, MSE: 0.2505920114247118, Learning Rate: 0.05210000000000001\n",
      "Epoch: 9581, MSE: 0.2505894252617656, Learning Rate: 0.052095\n",
      "Epoch: 9582, MSE: 0.2505868390502074, Learning Rate: 0.05209\n",
      "Epoch: 9583, MSE: 0.2505842527900394, Learning Rate: 0.052085000000000006\n",
      "Epoch: 9584, MSE: 0.2505816664812639, Learning Rate: 0.052079999999999994\n",
      "Epoch: 9585, MSE: 0.2505790801238812, Learning Rate: 0.05207500000000001\n",
      "Epoch: 9586, MSE: 0.25057649371789403, Learning Rate: 0.05207\n",
      "Epoch: 9587, MSE: 0.2505739072633042, Learning Rate: 0.05206500000000001\n",
      "Epoch: 9588, MSE: 0.2505713207601124, Learning Rate: 0.052059999999999995\n",
      "Epoch: 9589, MSE: 0.25056873420831965, Learning Rate: 0.05205500000000001\n",
      "Epoch: 9590, MSE: 0.25056614760792895, Learning Rate: 0.05205\n",
      "Epoch: 9591, MSE: 0.2505635609589415, Learning Rate: 0.05204500000000001\n",
      "Epoch: 9592, MSE: 0.2505609742613579, Learning Rate: 0.05204\n",
      "Epoch: 9593, MSE: 0.2505583875151818, Learning Rate: 0.052035\n",
      "Epoch: 9594, MSE: 0.25055580072041356, Learning Rate: 0.05203\n",
      "Epoch: 9595, MSE: 0.25055321387705365, Learning Rate: 0.052025\n",
      "Epoch: 9596, MSE: 0.25055062698510605, Learning Rate: 0.052020000000000004\n",
      "Epoch: 9597, MSE: 0.25054804004456993, Learning Rate: 0.052015000000000006\n",
      "Epoch: 9598, MSE: 0.25054545305544823, Learning Rate: 0.05201\n",
      "Epoch: 9599, MSE: 0.2505428660177433, Learning Rate: 0.052005\n",
      "Epoch: 9600, MSE: 0.25054027893145464, Learning Rate: 0.052000000000000005\n",
      "Epoch: 9601, MSE: 0.250537691796586, Learning Rate: 0.051995000000000006\n",
      "Epoch: 9602, MSE: 0.25053510461313755, Learning Rate: 0.05199000000000001\n",
      "Epoch: 9603, MSE: 0.2505325173811112, Learning Rate: 0.051984999999999996\n",
      "Epoch: 9604, MSE: 0.25052993010051056, Learning Rate: 0.051980000000000005\n",
      "Epoch: 9605, MSE: 0.25052734277133276, Learning Rate: 0.05197499999999999\n",
      "Epoch: 9606, MSE: 0.25052475539358326, Learning Rate: 0.05197000000000001\n",
      "Epoch: 9607, MSE: 0.2505221679672622, Learning Rate: 0.051965\n",
      "Epoch: 9608, MSE: 0.25051958049237166, Learning Rate: 0.051960000000000006\n",
      "Epoch: 9609, MSE: 0.25051699296891305, Learning Rate: 0.051955\n",
      "Epoch: 9610, MSE: 0.2505144053968877, Learning Rate: 0.05195000000000001\n",
      "Epoch: 9611, MSE: 0.25051181777629705, Learning Rate: 0.051945\n",
      "Epoch: 9612, MSE: 0.25050923010714377, Learning Rate: 0.05194\n",
      "Epoch: 9613, MSE: 0.25050664238942877, Learning Rate: 0.051935\n",
      "Epoch: 9614, MSE: 0.2505040546231531, Learning Rate: 0.051930000000000004\n",
      "Epoch: 9615, MSE: 0.25050146680831953, Learning Rate: 0.051925\n",
      "Epoch: 9616, MSE: 0.2504988789449284, Learning Rate: 0.05192\n",
      "Epoch: 9617, MSE: 0.25049629103298304, Learning Rate: 0.051915\n",
      "Epoch: 9618, MSE: 0.25049370307248275, Learning Rate: 0.051910000000000005\n",
      "Epoch: 9619, MSE: 0.2504911150634309, Learning Rate: 0.05190500000000001\n",
      "Epoch: 9620, MSE: 0.2504885270058295, Learning Rate: 0.0519\n",
      "Epoch: 9621, MSE: 0.25048593889967846, Learning Rate: 0.051895000000000004\n",
      "Epoch: 9622, MSE: 0.2504833507449803, Learning Rate: 0.05188999999999999\n",
      "Epoch: 9623, MSE: 0.2504807625417364, Learning Rate: 0.05188500000000001\n",
      "Epoch: 9624, MSE: 0.25047817428994834, Learning Rate: 0.051879999999999996\n",
      "Epoch: 9625, MSE: 0.2504755859896193, Learning Rate: 0.051875000000000004\n",
      "Epoch: 9626, MSE: 0.250472997640748, Learning Rate: 0.05187\n",
      "Epoch: 9627, MSE: 0.25047040924333763, Learning Rate: 0.05186500000000001\n",
      "Epoch: 9628, MSE: 0.25046782079739044, Learning Rate: 0.051859999999999996\n",
      "Epoch: 9629, MSE: 0.25046523230290724, Learning Rate: 0.05185500000000001\n",
      "Epoch: 9630, MSE: 0.2504626437598891, Learning Rate: 0.05185\n",
      "Epoch: 9631, MSE: 0.25046005516833897, Learning Rate: 0.05184500000000001\n",
      "Epoch: 9632, MSE: 0.25045746652825734, Learning Rate: 0.05184\n",
      "Epoch: 9633, MSE: 0.25045487783964604, Learning Rate: 0.051835\n",
      "Epoch: 9634, MSE: 0.2504522891025077, Learning Rate: 0.05183\n",
      "Epoch: 9635, MSE: 0.25044970031684266, Learning Rate: 0.051825\n",
      "Epoch: 9636, MSE: 0.2504471114826531, Learning Rate: 0.051820000000000005\n",
      "Epoch: 9637, MSE: 0.25044452259994043, Learning Rate: 0.051815\n",
      "Epoch: 9638, MSE: 0.2504419336687065, Learning Rate: 0.05181\n",
      "Epoch: 9639, MSE: 0.25043934468895296, Learning Rate: 0.051805000000000004\n",
      "Epoch: 9640, MSE: 0.2504367556606807, Learning Rate: 0.051800000000000006\n",
      "Epoch: 9641, MSE: 0.2504341665838929, Learning Rate: 0.05179500000000001\n",
      "Epoch: 9642, MSE: 0.2504315774585902, Learning Rate: 0.05179\n",
      "Epoch: 9643, MSE: 0.25042898828477383, Learning Rate: 0.051785\n",
      "Epoch: 9644, MSE: 0.2504263990624457, Learning Rate: 0.05178000000000001\n",
      "Epoch: 9645, MSE: 0.2504238097916078, Learning Rate: 0.051774999999999995\n",
      "Epoch: 9646, MSE: 0.25042122047226123, Learning Rate: 0.05177000000000001\n",
      "Epoch: 9647, MSE: 0.25041863110440804, Learning Rate: 0.051765\n",
      "Epoch: 9648, MSE: 0.2504160416880496, Learning Rate: 0.05176000000000001\n",
      "Epoch: 9649, MSE: 0.25041345222318856, Learning Rate: 0.051754999999999995\n",
      "Epoch: 9650, MSE: 0.25041086270982466, Learning Rate: 0.05175000000000001\n",
      "Epoch: 9651, MSE: 0.2504082731479604, Learning Rate: 0.051745\n",
      "Epoch: 9652, MSE: 0.25040568353759884, Learning Rate: 0.05174000000000001\n",
      "Epoch: 9653, MSE: 0.25040309387873877, Learning Rate: 0.051735\n",
      "Epoch: 9654, MSE: 0.2504005041713848, Learning Rate: 0.05173\n",
      "Epoch: 9655, MSE: 0.25039791441553616, Learning Rate: 0.051725\n",
      "Epoch: 9656, MSE: 0.2503953246111954, Learning Rate: 0.05172\n",
      "Epoch: 9657, MSE: 0.25039273475836427, Learning Rate: 0.051715000000000004\n",
      "Epoch: 9658, MSE: 0.2503901448570447, Learning Rate: 0.051710000000000006\n",
      "Epoch: 9659, MSE: 0.25038755490723696, Learning Rate: 0.051705\n",
      "Epoch: 9660, MSE: 0.2503849649089449, Learning Rate: 0.0517\n",
      "Epoch: 9661, MSE: 0.25038237486216786, Learning Rate: 0.051695000000000005\n",
      "Epoch: 9662, MSE: 0.2503797847669098, Learning Rate: 0.05169000000000001\n",
      "Epoch: 9663, MSE: 0.2503771946231698, Learning Rate: 0.05168500000000001\n",
      "Epoch: 9664, MSE: 0.2503746044309512, Learning Rate: 0.05168\n",
      "Epoch: 9665, MSE: 0.25037201419025573, Learning Rate: 0.051675000000000006\n",
      "Epoch: 9666, MSE: 0.25036942390108285, Learning Rate: 0.051669999999999994\n",
      "Epoch: 9667, MSE: 0.2503668335634376, Learning Rate: 0.05166500000000001\n",
      "Epoch: 9668, MSE: 0.25036424317731887, Learning Rate: 0.05166\n",
      "Epoch: 9669, MSE: 0.25036165274273, Learning Rate: 0.051655000000000006\n",
      "Epoch: 9670, MSE: 0.2503590622596718, Learning Rate: 0.05165\n",
      "Epoch: 9671, MSE: 0.2503564717281457, Learning Rate: 0.05164500000000001\n",
      "Epoch: 9672, MSE: 0.2503538811481534, Learning Rate: 0.05164\n",
      "Epoch: 9673, MSE: 0.25035129051969723, Learning Rate: 0.051635\n",
      "Epoch: 9674, MSE: 0.25034869984277813, Learning Rate: 0.05163\n",
      "Epoch: 9675, MSE: 0.250346109117398, Learning Rate: 0.051625000000000004\n",
      "Epoch: 9676, MSE: 0.25034351834355895, Learning Rate: 0.05162\n",
      "Epoch: 9677, MSE: 0.25034092752126175, Learning Rate: 0.051615\n",
      "Epoch: 9678, MSE: 0.2503383366505089, Learning Rate: 0.05161\n",
      "Epoch: 9679, MSE: 0.25033574573130113, Learning Rate: 0.051605000000000005\n",
      "Epoch: 9680, MSE: 0.25033315476364043, Learning Rate: 0.05160000000000001\n",
      "Epoch: 9681, MSE: 0.2503305637475297, Learning Rate: 0.051595\n",
      "Epoch: 9682, MSE: 0.25032797268296786, Learning Rate: 0.051590000000000004\n",
      "Epoch: 9683, MSE: 0.25032538156995915, Learning Rate: 0.05158499999999999\n",
      "Epoch: 9684, MSE: 0.2503227904085038, Learning Rate: 0.05158000000000001\n",
      "Epoch: 9685, MSE: 0.2503201991986039, Learning Rate: 0.051574999999999996\n",
      "Epoch: 9686, MSE: 0.2503176079402617, Learning Rate: 0.051570000000000005\n",
      "Epoch: 9687, MSE: 0.250315016633477, Learning Rate: 0.051565\n",
      "Epoch: 9688, MSE: 0.2503124252782529, Learning Rate: 0.05156000000000001\n",
      "Epoch: 9689, MSE: 0.2503098338745915, Learning Rate: 0.051555\n",
      "Epoch: 9690, MSE: 0.2503072424224938, Learning Rate: 0.05155000000000001\n",
      "Epoch: 9691, MSE: 0.2503046509219609, Learning Rate: 0.051545\n",
      "Epoch: 9692, MSE: 0.250302059372995, Learning Rate: 0.05154000000000001\n",
      "Epoch: 9693, MSE: 0.250299467775598, Learning Rate: 0.051535\n",
      "Epoch: 9694, MSE: 0.2502968761297706, Learning Rate: 0.05153\n",
      "Epoch: 9695, MSE: 0.2502942844355157, Learning Rate: 0.051525\n",
      "Epoch: 9696, MSE: 0.250291692692834, Learning Rate: 0.05152\n",
      "Epoch: 9697, MSE: 0.2502891009017279, Learning Rate: 0.051515000000000005\n",
      "Epoch: 9698, MSE: 0.2502865090621983, Learning Rate: 0.05151\n",
      "Epoch: 9699, MSE: 0.2502839171742476, Learning Rate: 0.051505\n",
      "Epoch: 9700, MSE: 0.2502813252378765, Learning Rate: 0.051500000000000004\n",
      "Epoch: 9701, MSE: 0.25027873325308764, Learning Rate: 0.051495000000000006\n",
      "Epoch: 9702, MSE: 0.25027614121988195, Learning Rate: 0.05149000000000001\n",
      "Epoch: 9703, MSE: 0.2502735491382623, Learning Rate: 0.051485\n",
      "Epoch: 9704, MSE: 0.2502709570082287, Learning Rate: 0.05148\n",
      "Epoch: 9705, MSE: 0.2502683648297833, Learning Rate: 0.05147500000000001\n",
      "Epoch: 9706, MSE: 0.250265772602928, Learning Rate: 0.051469999999999995\n",
      "Epoch: 9707, MSE: 0.2502631803276647, Learning Rate: 0.05146500000000001\n",
      "Epoch: 9708, MSE: 0.25026058800399553, Learning Rate: 0.05146\n",
      "Epoch: 9709, MSE: 0.25025799563192025, Learning Rate: 0.05145500000000001\n",
      "Epoch: 9710, MSE: 0.2502554032114421, Learning Rate: 0.051449999999999996\n",
      "Epoch: 9711, MSE: 0.2502528107425628, Learning Rate: 0.05144500000000001\n",
      "Epoch: 9712, MSE: 0.2502502182252828, Learning Rate: 0.05144\n",
      "Epoch: 9713, MSE: 0.2502476256596049, Learning Rate: 0.051435\n",
      "Epoch: 9714, MSE: 0.2502450330455302, Learning Rate: 0.051430000000000003\n",
      "Epoch: 9715, MSE: 0.25024244038306065, Learning Rate: 0.051425\n",
      "Epoch: 9716, MSE: 0.250239847672198, Learning Rate: 0.05142\n",
      "Epoch: 9717, MSE: 0.2502372549129437, Learning Rate: 0.051415\n",
      "Epoch: 9718, MSE: 0.25023466210529943, Learning Rate: 0.051410000000000004\n",
      "Epoch: 9719, MSE: 0.2502320692492669, Learning Rate: 0.051405000000000006\n",
      "Epoch: 9720, MSE: 0.2502294763448474, Learning Rate: 0.0514\n",
      "Epoch: 9721, MSE: 0.2502268833920428, Learning Rate: 0.051395\n",
      "Epoch: 9722, MSE: 0.25022429039085514, Learning Rate: 0.051390000000000005\n",
      "Epoch: 9723, MSE: 0.25022169734128563, Learning Rate: 0.05138499999999999\n",
      "Epoch: 9724, MSE: 0.2502191042433367, Learning Rate: 0.05138000000000001\n",
      "Epoch: 9725, MSE: 0.25021651109700904, Learning Rate: 0.051375\n",
      "Epoch: 9726, MSE: 0.25021391790230446, Learning Rate: 0.051370000000000006\n",
      "Epoch: 9727, MSE: 0.2502113246592256, Learning Rate: 0.051364999999999994\n",
      "Epoch: 9728, MSE: 0.25020873136777316, Learning Rate: 0.05136000000000001\n",
      "Epoch: 9729, MSE: 0.2502061380279485, Learning Rate: 0.051355\n",
      "Epoch: 9730, MSE: 0.2502035446397546, Learning Rate: 0.05135000000000001\n",
      "Epoch: 9731, MSE: 0.2502009512031927, Learning Rate: 0.051345\n",
      "Epoch: 9732, MSE: 0.2501983577182635, Learning Rate: 0.05134000000000001\n",
      "Epoch: 9733, MSE: 0.2501957641849697, Learning Rate: 0.051335\n",
      "Epoch: 9734, MSE: 0.25019317060331236, Learning Rate: 0.05133\n",
      "Epoch: 9735, MSE: 0.25019057697329367, Learning Rate: 0.051325\n",
      "Epoch: 9736, MSE: 0.25018798329491454, Learning Rate: 0.051320000000000005\n",
      "Epoch: 9737, MSE: 0.2501853895681774, Learning Rate: 0.051315\n",
      "Epoch: 9738, MSE: 0.25018279579308367, Learning Rate: 0.05131\n",
      "Epoch: 9739, MSE: 0.25018020196963564, Learning Rate: 0.051305\n",
      "Epoch: 9740, MSE: 0.2501776080978329, Learning Rate: 0.051300000000000005\n",
      "Epoch: 9741, MSE: 0.25017501417768007, Learning Rate: 0.05129500000000001\n",
      "Epoch: 9742, MSE: 0.2501724202091771, Learning Rate: 0.05129\n",
      "Epoch: 9743, MSE: 0.2501698261923256, Learning Rate: 0.051285000000000004\n",
      "Epoch: 9744, MSE: 0.25016723212712727, Learning Rate: 0.05127999999999999\n",
      "Epoch: 9745, MSE: 0.25016463801358463, Learning Rate: 0.05127500000000001\n",
      "Epoch: 9746, MSE: 0.2501620438516985, Learning Rate: 0.051269999999999996\n",
      "Epoch: 9747, MSE: 0.25015944964147113, Learning Rate: 0.051265000000000005\n",
      "Epoch: 9748, MSE: 0.25015685538290366, Learning Rate: 0.05126\n",
      "Epoch: 9749, MSE: 0.25015426107599803, Learning Rate: 0.05125500000000001\n",
      "Epoch: 9750, MSE: 0.2501516667207573, Learning Rate: 0.05125\n",
      "Epoch: 9751, MSE: 0.2501490723171801, Learning Rate: 0.05124500000000001\n",
      "Epoch: 9752, MSE: 0.25014647786527033, Learning Rate: 0.05124\n",
      "Epoch: 9753, MSE: 0.2501438833650291, Learning Rate: 0.05123500000000001\n",
      "Epoch: 9754, MSE: 0.25014128881645864, Learning Rate: 0.05123\n",
      "Epoch: 9755, MSE: 0.25013869421955937, Learning Rate: 0.051225\n",
      "Epoch: 9756, MSE: 0.2501360995743345, Learning Rate: 0.05122\n",
      "Epoch: 9757, MSE: 0.250133504880784, Learning Rate: 0.051215000000000004\n",
      "Epoch: 9758, MSE: 0.25013091013891137, Learning Rate: 0.051210000000000006\n",
      "Epoch: 9759, MSE: 0.2501283153487174, Learning Rate: 0.051205\n",
      "Epoch: 9760, MSE: 0.25012572051020326, Learning Rate: 0.0512\n",
      "Epoch: 9761, MSE: 0.2501231256233718, Learning Rate: 0.051195000000000004\n",
      "Epoch: 9762, MSE: 0.25012053068822354, Learning Rate: 0.051190000000000006\n",
      "Epoch: 9763, MSE: 0.2501179357047618, Learning Rate: 0.05118500000000001\n",
      "Epoch: 9764, MSE: 0.2501153406729859, Learning Rate: 0.05118\n",
      "Epoch: 9765, MSE: 0.2501127455928994, Learning Rate: 0.051175\n",
      "Epoch: 9766, MSE: 0.2501101504645034, Learning Rate: 0.05117000000000001\n",
      "Epoch: 9767, MSE: 0.25010755528779993, Learning Rate: 0.051164999999999995\n",
      "Epoch: 9768, MSE: 0.2501049600627902, Learning Rate: 0.05116000000000001\n",
      "Epoch: 9769, MSE: 0.25010236478947545, Learning Rate: 0.051155\n",
      "Epoch: 9770, MSE: 0.25009976946785867, Learning Rate: 0.05115000000000001\n",
      "Epoch: 9771, MSE: 0.25009717409794097, Learning Rate: 0.051144999999999996\n",
      "Epoch: 9772, MSE: 0.25009457867972373, Learning Rate: 0.05114000000000001\n",
      "Epoch: 9773, MSE: 0.2500919832132081, Learning Rate: 0.051135\n",
      "Epoch: 9774, MSE: 0.25008938769839784, Learning Rate: 0.05113\n",
      "Epoch: 9775, MSE: 0.2500867921352926, Learning Rate: 0.051125000000000004\n",
      "Epoch: 9776, MSE: 0.25008419652389463, Learning Rate: 0.05112\n",
      "Epoch: 9777, MSE: 0.25008160086420633, Learning Rate: 0.051115\n",
      "Epoch: 9778, MSE: 0.25007900515622844, Learning Rate: 0.05111\n",
      "Epoch: 9779, MSE: 0.2500764093999635, Learning Rate: 0.051105000000000005\n",
      "Epoch: 9780, MSE: 0.25007381359541264, Learning Rate: 0.051100000000000007\n",
      "Epoch: 9781, MSE: 0.2500712177425774, Learning Rate: 0.051095\n",
      "Epoch: 9782, MSE: 0.2500686218414604, Learning Rate: 0.05109\n",
      "Epoch: 9783, MSE: 0.25006602589206184, Learning Rate: 0.051085000000000005\n",
      "Epoch: 9784, MSE: 0.2500634298943849, Learning Rate: 0.05107999999999999\n",
      "Epoch: 9785, MSE: 0.2500608338484307, Learning Rate: 0.05107500000000001\n",
      "Epoch: 9786, MSE: 0.25005823775420116, Learning Rate: 0.05107\n",
      "Epoch: 9787, MSE: 0.25005564161169747, Learning Rate: 0.051065000000000006\n",
      "Epoch: 9788, MSE: 0.25005304542092144, Learning Rate: 0.051059999999999994\n",
      "Epoch: 9789, MSE: 0.25005044918187447, Learning Rate: 0.05105500000000001\n",
      "Epoch: 9790, MSE: 0.25004785289455983, Learning Rate: 0.05105\n",
      "Epoch: 9791, MSE: 0.2500452565589779, Learning Rate: 0.05104500000000001\n",
      "Epoch: 9792, MSE: 0.2500426601751299, Learning Rate: 0.05104\n",
      "Epoch: 9793, MSE: 0.2500400637430193, Learning Rate: 0.05103500000000001\n",
      "Epoch: 9794, MSE: 0.2500374672626459, Learning Rate: 0.05103\n",
      "Epoch: 9795, MSE: 0.25003487073401237, Learning Rate: 0.051025\n",
      "Epoch: 9796, MSE: 0.25003227415712065, Learning Rate: 0.05102\n",
      "Epoch: 9797, MSE: 0.2500296775319718, Learning Rate: 0.051015000000000005\n",
      "Epoch: 9798, MSE: 0.2500270808585683, Learning Rate: 0.05101\n",
      "Epoch: 9799, MSE: 0.2500244841369108, Learning Rate: 0.051005\n",
      "Epoch: 9800, MSE: 0.25002188736700226, Learning Rate: 0.051000000000000004\n",
      "Epoch: 9801, MSE: 0.2500192905488432, Learning Rate: 0.050995000000000006\n",
      "Epoch: 9802, MSE: 0.25001669368243545, Learning Rate: 0.05099000000000001\n",
      "Epoch: 9803, MSE: 0.2500140967677819, Learning Rate: 0.050985\n",
      "Epoch: 9804, MSE: 0.25001149980488296, Learning Rate: 0.050980000000000004\n",
      "Epoch: 9805, MSE: 0.25000890279374144, Learning Rate: 0.05097499999999999\n",
      "Epoch: 9806, MSE: 0.25000630573435784, Learning Rate: 0.05097000000000001\n",
      "Epoch: 9807, MSE: 0.2500037086267353, Learning Rate: 0.050964999999999996\n",
      "Epoch: 9808, MSE: 0.2500011114708744, Learning Rate: 0.050960000000000005\n",
      "Epoch: 9809, MSE: 0.24999851426677652, Learning Rate: 0.050955\n",
      "Epoch: 9810, MSE: 0.2499959170144449, Learning Rate: 0.05095000000000001\n",
      "Epoch: 9811, MSE: 0.24999331971388009, Learning Rate: 0.050945\n",
      "Epoch: 9812, MSE: 0.24999072236508407, Learning Rate: 0.05094000000000001\n",
      "Epoch: 9813, MSE: 0.24998812496805847, Learning Rate: 0.050935\n",
      "Epoch: 9814, MSE: 0.24998552752280567, Learning Rate: 0.05093\n",
      "Epoch: 9815, MSE: 0.24998293002932606, Learning Rate: 0.050925\n",
      "Epoch: 9816, MSE: 0.24998033248762286, Learning Rate: 0.05092\n",
      "Epoch: 9817, MSE: 0.249977734897697, Learning Rate: 0.050915\n",
      "Epoch: 9818, MSE: 0.24997513725955006, Learning Rate: 0.050910000000000004\n",
      "Epoch: 9819, MSE: 0.24997253957318405, Learning Rate: 0.050905000000000006\n",
      "Epoch: 9820, MSE: 0.24996994183860044, Learning Rate: 0.0509\n",
      "Epoch: 9821, MSE: 0.2499673440558015, Learning Rate: 0.050895\n",
      "Epoch: 9822, MSE: 0.2499647462247882, Learning Rate: 0.050890000000000005\n",
      "Epoch: 9823, MSE: 0.24996214834556274, Learning Rate: 0.05088500000000001\n",
      "Epoch: 9824, MSE: 0.24995955041812631, Learning Rate: 0.050879999999999995\n",
      "Epoch: 9825, MSE: 0.24995695244248145, Learning Rate: 0.050875000000000004\n",
      "Epoch: 9826, MSE: 0.24995435441863034, Learning Rate: 0.05087\n",
      "Epoch: 9827, MSE: 0.24995175634657218, Learning Rate: 0.05086500000000001\n",
      "Epoch: 9828, MSE: 0.24994915822631159, Learning Rate: 0.050859999999999995\n",
      "Epoch: 9829, MSE: 0.2499465600578485, Learning Rate: 0.05085500000000001\n",
      "Epoch: 9830, MSE: 0.24994396184118572, Learning Rate: 0.05085\n",
      "Epoch: 9831, MSE: 0.2499413635763237, Learning Rate: 0.05084500000000001\n",
      "Epoch: 9832, MSE: 0.2499387652632656, Learning Rate: 0.050839999999999996\n",
      "Epoch: 9833, MSE: 0.2499361669020128, Learning Rate: 0.05083500000000001\n",
      "Epoch: 9834, MSE: 0.2499335684925666, Learning Rate: 0.05083\n",
      "Epoch: 9835, MSE: 0.24993097003492748, Learning Rate: 0.050825\n",
      "Epoch: 9836, MSE: 0.2499283715290993, Learning Rate: 0.050820000000000004\n",
      "Epoch: 9837, MSE: 0.24992577297508342, Learning Rate: 0.050815\n",
      "Epoch: 9838, MSE: 0.24992317437288072, Learning Rate: 0.05081\n",
      "Epoch: 9839, MSE: 0.2499205757224938, Learning Rate: 0.050805\n",
      "Epoch: 9840, MSE: 0.2499179770239234, Learning Rate: 0.050800000000000005\n",
      "Epoch: 9841, MSE: 0.24991537827717147, Learning Rate: 0.05079500000000001\n",
      "Epoch: 9842, MSE: 0.24991277948224103, Learning Rate: 0.05079\n",
      "Epoch: 9843, MSE: 0.2499101806391326, Learning Rate: 0.050785000000000004\n",
      "Epoch: 9844, MSE: 0.24990758174784763, Learning Rate: 0.050780000000000006\n",
      "Epoch: 9845, MSE: 0.24990498280838863, Learning Rate: 0.050774999999999994\n",
      "Epoch: 9846, MSE: 0.2499023838207571, Learning Rate: 0.05077000000000001\n",
      "Epoch: 9847, MSE: 0.24989978478495486, Learning Rate: 0.050765\n",
      "Epoch: 9848, MSE: 0.24989718570098388, Learning Rate: 0.050760000000000007\n",
      "Epoch: 9849, MSE: 0.24989458656884433, Learning Rate: 0.050754999999999995\n",
      "Epoch: 9850, MSE: 0.24989198738854096, Learning Rate: 0.05075000000000001\n",
      "Epoch: 9851, MSE: 0.24988938816007245, Learning Rate: 0.050745\n",
      "Epoch: 9852, MSE: 0.24988678888344248, Learning Rate: 0.05074000000000001\n",
      "Epoch: 9853, MSE: 0.24988418955865196, Learning Rate: 0.050735\n",
      "Epoch: 9854, MSE: 0.2498815901857026, Learning Rate: 0.05073\n",
      "Epoch: 9855, MSE: 0.24987899076459613, Learning Rate: 0.050725\n",
      "Epoch: 9856, MSE: 0.24987639129533482, Learning Rate: 0.05072\n",
      "Epoch: 9857, MSE: 0.24987379177791974, Learning Rate: 0.050715\n",
      "Epoch: 9858, MSE: 0.24987119221235385, Learning Rate: 0.050710000000000005\n",
      "Epoch: 9859, MSE: 0.2498685925986367, Learning Rate: 0.050705\n",
      "Epoch: 9860, MSE: 0.2498659929367715, Learning Rate: 0.0507\n",
      "Epoch: 9861, MSE: 0.24986339322676102, Learning Rate: 0.050695000000000004\n",
      "Epoch: 9862, MSE: 0.24986079346860435, Learning Rate: 0.050690000000000006\n",
      "Epoch: 9863, MSE: 0.24985819366230597, Learning Rate: 0.05068500000000001\n",
      "Epoch: 9864, MSE: 0.24985559380786576, Learning Rate: 0.050679999999999996\n",
      "Epoch: 9865, MSE: 0.24985299390528576, Learning Rate: 0.050675000000000005\n",
      "Epoch: 9866, MSE: 0.24985039395456787, Learning Rate: 0.05066999999999999\n",
      "Epoch: 9867, MSE: 0.24984779395571471, Learning Rate: 0.05066500000000001\n",
      "Epoch: 9868, MSE: 0.24984519390872678, Learning Rate: 0.05066\n",
      "Epoch: 9869, MSE: 0.2498425938136067, Learning Rate: 0.050655000000000006\n",
      "Epoch: 9870, MSE: 0.24983999367035556, Learning Rate: 0.05065\n",
      "Epoch: 9871, MSE: 0.2498373934789752, Learning Rate: 0.05064500000000001\n",
      "Epoch: 9872, MSE: 0.24983479323946745, Learning Rate: 0.05064\n",
      "Epoch: 9873, MSE: 0.24983219295183456, Learning Rate: 0.05063500000000001\n",
      "Epoch: 9874, MSE: 0.24982959261607815, Learning Rate: 0.05063\n",
      "Epoch: 9875, MSE: 0.249826992232199, Learning Rate: 0.050625\n",
      "Epoch: 9876, MSE: 0.2498243918002002, Learning Rate: 0.05062\n",
      "Epoch: 9877, MSE: 0.2498217913200823, Learning Rate: 0.050615\n",
      "Epoch: 9878, MSE: 0.24981919079184778, Learning Rate: 0.05061\n",
      "Epoch: 9879, MSE: 0.2498165902154979, Learning Rate: 0.050605000000000004\n",
      "Epoch: 9880, MSE: 0.2498139895910352, Learning Rate: 0.050600000000000006\n",
      "Epoch: 9881, MSE: 0.24981138891846122, Learning Rate: 0.050595\n",
      "Epoch: 9882, MSE: 0.24980878819777683, Learning Rate: 0.05059\n",
      "Epoch: 9883, MSE: 0.24980618742898472, Learning Rate: 0.050585000000000005\n",
      "Epoch: 9884, MSE: 0.24980358661208546, Learning Rate: 0.05058000000000001\n",
      "Epoch: 9885, MSE: 0.24980098574708298, Learning Rate: 0.050574999999999995\n",
      "Epoch: 9886, MSE: 0.2497983848339781, Learning Rate: 0.050570000000000004\n",
      "Epoch: 9887, MSE: 0.2497957838727704, Learning Rate: 0.050565\n",
      "Epoch: 9888, MSE: 0.24979318286346422, Learning Rate: 0.05056000000000001\n",
      "Epoch: 9889, MSE: 0.2497905818060608, Learning Rate: 0.050554999999999996\n",
      "Epoch: 9890, MSE: 0.24978798070056127, Learning Rate: 0.05055000000000001\n",
      "Epoch: 9891, MSE: 0.249785379546968, Learning Rate: 0.050545\n",
      "Epoch: 9892, MSE: 0.2497827783452825, Learning Rate: 0.05054000000000001\n",
      "Epoch: 9893, MSE: 0.2497801770955063, Learning Rate: 0.050535\n",
      "Epoch: 9894, MSE: 0.2497775757976414, Learning Rate: 0.05053000000000001\n",
      "Epoch: 9895, MSE: 0.24977497445169047, Learning Rate: 0.050525\n",
      "Epoch: 9896, MSE: 0.24977237305765296, Learning Rate: 0.05052\n",
      "Epoch: 9897, MSE: 0.24976977161553285, Learning Rate: 0.050515000000000004\n",
      "Epoch: 9898, MSE: 0.24976717012533062, Learning Rate: 0.05051\n",
      "Epoch: 9899, MSE: 0.24976456858704865, Learning Rate: 0.050505\n",
      "Epoch: 9900, MSE: 0.24976196700068878, Learning Rate: 0.0505\n",
      "Epoch: 9901, MSE: 0.24975936536625193, Learning Rate: 0.050495000000000005\n",
      "Epoch: 9902, MSE: 0.24975676368374153, Learning Rate: 0.05049000000000001\n",
      "Epoch: 9903, MSE: 0.24975416195315708, Learning Rate: 0.050485\n",
      "Epoch: 9904, MSE: 0.24975156017450184, Learning Rate: 0.050480000000000004\n",
      "Epoch: 9905, MSE: 0.24974895834777772, Learning Rate: 0.050475000000000006\n",
      "Epoch: 9906, MSE: 0.24974635647298585, Learning Rate: 0.050469999999999994\n",
      "Epoch: 9907, MSE: 0.2497437545501277, Learning Rate: 0.05046500000000001\n",
      "Epoch: 9908, MSE: 0.24974115257920582, Learning Rate: 0.05046\n",
      "Epoch: 9909, MSE: 0.2497385505602223, Learning Rate: 0.05045500000000001\n",
      "Epoch: 9910, MSE: 0.24973594849317748, Learning Rate: 0.050449999999999995\n",
      "Epoch: 9911, MSE: 0.24973334637807393, Learning Rate: 0.05044500000000001\n",
      "Epoch: 9912, MSE: 0.249730744214914, Learning Rate: 0.05044\n",
      "Epoch: 9913, MSE: 0.24972814200369806, Learning Rate: 0.05043500000000001\n",
      "Epoch: 9914, MSE: 0.24972553974442982, Learning Rate: 0.05043\n",
      "Epoch: 9915, MSE: 0.24972293743710872, Learning Rate: 0.050425\n",
      "Epoch: 9916, MSE: 0.24972033508173844, Learning Rate: 0.05042\n",
      "Epoch: 9917, MSE: 0.24971773267831981, Learning Rate: 0.050415\n",
      "Epoch: 9918, MSE: 0.24971513022685546, Learning Rate: 0.05041\n",
      "Epoch: 9919, MSE: 0.24971252772734526, Learning Rate: 0.050405000000000005\n",
      "Epoch: 9920, MSE: 0.24970992517979315, Learning Rate: 0.0504\n",
      "Epoch: 9921, MSE: 0.2497073225842, Learning Rate: 0.050395\n",
      "Epoch: 9922, MSE: 0.2497047199405672, Learning Rate: 0.050390000000000004\n",
      "Epoch: 9923, MSE: 0.2497021172488979, Learning Rate: 0.050385000000000006\n",
      "Epoch: 9924, MSE: 0.24969951450919203, Learning Rate: 0.05038000000000001\n",
      "Epoch: 9925, MSE: 0.2496969117214523, Learning Rate: 0.050374999999999996\n",
      "Epoch: 9926, MSE: 0.2496943088856809, Learning Rate: 0.050370000000000005\n",
      "Epoch: 9927, MSE: 0.24969170600187912, Learning Rate: 0.05036499999999999\n",
      "Epoch: 9928, MSE: 0.24968910307004766, Learning Rate: 0.05036000000000001\n",
      "Epoch: 9929, MSE: 0.24968650009019042, Learning Rate: 0.050355\n",
      "Epoch: 9930, MSE: 0.24968389706230792, Learning Rate: 0.050350000000000006\n",
      "Epoch: 9931, MSE: 0.24968129398640265, Learning Rate: 0.050345\n",
      "Epoch: 9932, MSE: 0.24967869086247535, Learning Rate: 0.05034000000000001\n",
      "Epoch: 9933, MSE: 0.2496760876905286, Learning Rate: 0.050335\n",
      "Epoch: 9934, MSE: 0.24967348447056326, Learning Rate: 0.050330000000000014\n",
      "Epoch: 9935, MSE: 0.24967088120258238, Learning Rate: 0.050325\n",
      "Epoch: 9936, MSE: 0.2496682778865873, Learning Rate: 0.050320000000000004\n",
      "Epoch: 9937, MSE: 0.24966567452257932, Learning Rate: 0.050315\n",
      "Epoch: 9938, MSE: 0.24966307111056085, Learning Rate: 0.05031\n",
      "Epoch: 9939, MSE: 0.2496604676505326, Learning Rate: 0.050305\n",
      "Epoch: 9940, MSE: 0.24965786414249794, Learning Rate: 0.050300000000000004\n",
      "Epoch: 9941, MSE: 0.24965526058645807, Learning Rate: 0.050295000000000006\n",
      "Epoch: 9942, MSE: 0.2496526569824139, Learning Rate: 0.05029\n",
      "Epoch: 9943, MSE: 0.2496500533303678, Learning Rate: 0.050285\n",
      "Epoch: 9944, MSE: 0.2496474496303216, Learning Rate: 0.050280000000000005\n",
      "Epoch: 9945, MSE: 0.24964484588227825, Learning Rate: 0.05027500000000001\n",
      "Epoch: 9946, MSE: 0.24964224208623717, Learning Rate: 0.050269999999999995\n",
      "Epoch: 9947, MSE: 0.24963963824220237, Learning Rate: 0.050265000000000004\n",
      "Epoch: 9948, MSE: 0.24963703435017381, Learning Rate: 0.05026\n",
      "Epoch: 9949, MSE: 0.2496344304101544, Learning Rate: 0.05025500000000001\n",
      "Epoch: 9950, MSE: 0.24963182642214599, Learning Rate: 0.050249999999999996\n",
      "Epoch: 9951, MSE: 0.24962922238614893, Learning Rate: 0.05024500000000001\n",
      "Epoch: 9952, MSE: 0.24962661830216726, Learning Rate: 0.05024\n",
      "Epoch: 9953, MSE: 0.24962401417020094, Learning Rate: 0.05023500000000001\n",
      "Epoch: 9954, MSE: 0.2496214099902523, Learning Rate: 0.05023\n",
      "Epoch: 9955, MSE: 0.249618805762324, Learning Rate: 0.050225\n",
      "Epoch: 9956, MSE: 0.24961620148641658, Learning Rate: 0.05022\n",
      "Epoch: 9957, MSE: 0.24961359716253245, Learning Rate: 0.050215\n",
      "Epoch: 9958, MSE: 0.24961099279067386, Learning Rate: 0.050210000000000005\n",
      "Epoch: 9959, MSE: 0.2496083883708413, Learning Rate: 0.050205\n",
      "Epoch: 9960, MSE: 0.24960578390303734, Learning Rate: 0.0502\n",
      "Epoch: 9961, MSE: 0.24960317938726376, Learning Rate: 0.050195000000000004\n",
      "Epoch: 9962, MSE: 0.2496005748235235, Learning Rate: 0.050190000000000005\n",
      "Epoch: 9963, MSE: 0.24959797021181607, Learning Rate: 0.05018500000000001\n",
      "Epoch: 9964, MSE: 0.24959536555214484, Learning Rate: 0.05018\n",
      "Epoch: 9965, MSE: 0.24959276084450968, Learning Rate: 0.050175\n",
      "Epoch: 9966, MSE: 0.24959015608891597, Learning Rate: 0.050170000000000006\n",
      "Epoch: 9967, MSE: 0.24958755128536184, Learning Rate: 0.050164999999999994\n",
      "Epoch: 9968, MSE: 0.24958494643385185, Learning Rate: 0.05016000000000001\n",
      "Epoch: 9969, MSE: 0.24958234153438685, Learning Rate: 0.050155\n",
      "Epoch: 9970, MSE: 0.24957973658696705, Learning Rate: 0.05015000000000001\n",
      "Epoch: 9971, MSE: 0.24957713159159645, Learning Rate: 0.050144999999999995\n",
      "Epoch: 9972, MSE: 0.24957452654827617, Learning Rate: 0.05014000000000001\n",
      "Epoch: 9973, MSE: 0.2495719214570073, Learning Rate: 0.050135\n",
      "Epoch: 9974, MSE: 0.24956931631779242, Learning Rate: 0.05013000000000001\n",
      "Epoch: 9975, MSE: 0.24956671113063314, Learning Rate: 0.050125\n",
      "Epoch: 9976, MSE: 0.24956410589553116, Learning Rate: 0.05012\n",
      "Epoch: 9977, MSE: 0.24956150061248847, Learning Rate: 0.050115\n",
      "Epoch: 9978, MSE: 0.24955889528150696, Learning Rate: 0.05011\n",
      "Epoch: 9979, MSE: 0.24955628990258755, Learning Rate: 0.050105000000000004\n",
      "Epoch: 9980, MSE: 0.249553684475733, Learning Rate: 0.050100000000000006\n",
      "Epoch: 9981, MSE: 0.24955107900094542, Learning Rate: 0.050095\n",
      "Epoch: 9982, MSE: 0.24954847347822498, Learning Rate: 0.05009\n",
      "Epoch: 9983, MSE: 0.2495458679075756, Learning Rate: 0.050085000000000005\n",
      "Epoch: 9984, MSE: 0.249543262288997, Learning Rate: 0.050080000000000006\n",
      "Epoch: 9985, MSE: 0.2495406566224927, Learning Rate: 0.05007500000000001\n",
      "Epoch: 9986, MSE: 0.24953805090806377, Learning Rate: 0.050069999999999996\n",
      "Epoch: 9987, MSE: 0.24953544514571221, Learning Rate: 0.050065000000000005\n",
      "Epoch: 9988, MSE: 0.24953283933543943, Learning Rate: 0.05005999999999999\n",
      "Epoch: 9989, MSE: 0.2495302334772475, Learning Rate: 0.05005500000000001\n",
      "Epoch: 9990, MSE: 0.24952762757113836, Learning Rate: 0.05005\n",
      "Epoch: 9991, MSE: 0.24952502161711354, Learning Rate: 0.050045000000000006\n",
      "Epoch: 9992, MSE: 0.24952241561517485, Learning Rate: 0.05004\n",
      "Epoch: 9993, MSE: 0.24951980956532527, Learning Rate: 0.05003500000000001\n",
      "Epoch: 9994, MSE: 0.24951720346756512, Learning Rate: 0.05003\n",
      "Epoch: 9995, MSE: 0.24951459732189588, Learning Rate: 0.050025\n",
      "Epoch: 9996, MSE: 0.24951199112832084, Learning Rate: 0.05002\n",
      "Epoch: 9997, MSE: 0.24950938488684116, Learning Rate: 0.050015000000000004\n",
      "Epoch: 9998, MSE: 0.2495067785974583, Learning Rate: 0.05001\n",
      "Epoch: 9999, MSE: 0.2495041722601754, Learning Rate: 0.050005\n",
      "Epoch: 10000, MSE: 0.24950156587499245, Learning Rate: 0.05\n",
      "Epoch: 10001, MSE: 0.24949895944191247, Learning Rate: 0.049995000000000005\n",
      "Epoch: 10002, MSE: 0.24949635296093678, Learning Rate: 0.04999000000000001\n",
      "Epoch: 10003, MSE: 0.24949374643206737, Learning Rate: 0.049985\n",
      "Epoch: 10004, MSE: 0.24949113985530616, Learning Rate: 0.049980000000000004\n",
      "Epoch: 10005, MSE: 0.24948853323065479, Learning Rate: 0.049975000000000006\n",
      "Epoch: 10006, MSE: 0.24948592655811447, Learning Rate: 0.04997000000000001\n",
      "Epoch: 10007, MSE: 0.24948331983768882, Learning Rate: 0.04996500000000001\n",
      "Epoch: 10008, MSE: 0.24948071306937744, Learning Rate: 0.049960000000000004\n",
      "Epoch: 10009, MSE: 0.24947810625318345, Learning Rate: 0.049955000000000006\n",
      "Epoch: 10010, MSE: 0.24947549938910965, Learning Rate: 0.04995000000000001\n",
      "Epoch: 10011, MSE: 0.24947289247715598, Learning Rate: 0.049944999999999996\n",
      "Epoch: 10012, MSE: 0.24947028551732436, Learning Rate: 0.04994\n",
      "Epoch: 10013, MSE: 0.24946767850961768, Learning Rate: 0.049935\n",
      "Epoch: 10014, MSE: 0.24946507145403735, Learning Rate: 0.04993\n",
      "Epoch: 10015, MSE: 0.2494624643505858, Learning Rate: 0.049925\n",
      "Epoch: 10016, MSE: 0.24945985719926325, Learning Rate: 0.04992\n",
      "Epoch: 10017, MSE: 0.24945725000007238, Learning Rate: 0.049915\n",
      "Epoch: 10018, MSE: 0.2494546427530158, Learning Rate: 0.04991\n",
      "Epoch: 10019, MSE: 0.24945203545809402, Learning Rate: 0.049905000000000005\n",
      "Epoch: 10020, MSE: 0.2494494281153095, Learning Rate: 0.0499\n",
      "Epoch: 10021, MSE: 0.24944682072466454, Learning Rate: 0.049895\n",
      "Epoch: 10022, MSE: 0.24944421328616076, Learning Rate: 0.049890000000000004\n",
      "Epoch: 10023, MSE: 0.24944160579979885, Learning Rate: 0.049885000000000006\n",
      "Epoch: 10024, MSE: 0.24943899826558188, Learning Rate: 0.04988000000000001\n",
      "Epoch: 10025, MSE: 0.24943639068351142, Learning Rate: 0.049875\n",
      "Epoch: 10026, MSE: 0.24943378305358874, Learning Rate: 0.049870000000000005\n",
      "Epoch: 10027, MSE: 0.24943117537581644, Learning Rate: 0.04986500000000001\n",
      "Epoch: 10028, MSE: 0.24942856765019683, Learning Rate: 0.04986000000000001\n",
      "Epoch: 10029, MSE: 0.24942595987672914, Learning Rate: 0.04985500000000001\n",
      "Epoch: 10030, MSE: 0.2494233520554182, Learning Rate: 0.049850000000000005\n",
      "Epoch: 10031, MSE: 0.24942074418626473, Learning Rate: 0.049845\n",
      "Epoch: 10032, MSE: 0.24941813626926987, Learning Rate: 0.049839999999999995\n",
      "Epoch: 10033, MSE: 0.24941552830443658, Learning Rate: 0.049835\n",
      "Epoch: 10034, MSE: 0.24941292029176595, Learning Rate: 0.04983\n",
      "Epoch: 10035, MSE: 0.2494103122312603, Learning Rate: 0.049825\n",
      "Epoch: 10036, MSE: 0.2494077041229205, Learning Rate: 0.04982\n",
      "Epoch: 10037, MSE: 0.24940509596674987, Learning Rate: 0.049815\n",
      "Epoch: 10038, MSE: 0.2494024877627491, Learning Rate: 0.04981\n",
      "Epoch: 10039, MSE: 0.2493998795109202, Learning Rate: 0.049805\n",
      "Epoch: 10040, MSE: 0.24939727121126606, Learning Rate: 0.049800000000000004\n",
      "Epoch: 10041, MSE: 0.24939466286378698, Learning Rate: 0.049795000000000006\n",
      "Epoch: 10042, MSE: 0.2493920544684853, Learning Rate: 0.04979\n",
      "Epoch: 10043, MSE: 0.2493894460253631, Learning Rate: 0.049785\n",
      "Epoch: 10044, MSE: 0.24938683753442273, Learning Rate: 0.049780000000000005\n",
      "Epoch: 10045, MSE: 0.2493842289956652, Learning Rate: 0.04977500000000001\n",
      "Epoch: 10046, MSE: 0.24938162040909242, Learning Rate: 0.04977000000000001\n",
      "Epoch: 10047, MSE: 0.24937901177470626, Learning Rate: 0.049765000000000004\n",
      "Epoch: 10048, MSE: 0.24937640309250914, Learning Rate: 0.049760000000000006\n",
      "Epoch: 10049, MSE: 0.24937379436250248, Learning Rate: 0.04975500000000001\n",
      "Epoch: 10050, MSE: 0.2493711855846885, Learning Rate: 0.04975000000000001\n",
      "Epoch: 10051, MSE: 0.24936857675906848, Learning Rate: 0.049745\n",
      "Epoch: 10052, MSE: 0.2493659678856438, Learning Rate: 0.04974\n",
      "Epoch: 10053, MSE: 0.24936335896441658, Learning Rate: 0.049735\n",
      "Epoch: 10054, MSE: 0.24936074999539082, Learning Rate: 0.049729999999999996\n",
      "Epoch: 10055, MSE: 0.24935814097856537, Learning Rate: 0.049725\n",
      "Epoch: 10056, MSE: 0.24935553191394366, Learning Rate: 0.04972\n",
      "Epoch: 10057, MSE: 0.24935292280152668, Learning Rate: 0.049715\n",
      "Epoch: 10058, MSE: 0.24935031364131763, Learning Rate: 0.049710000000000004\n",
      "Epoch: 10059, MSE: 0.2493477044333167, Learning Rate: 0.049705\n",
      "Epoch: 10060, MSE: 0.24934509517752723, Learning Rate: 0.0497\n",
      "Epoch: 10061, MSE: 0.24934248587394947, Learning Rate: 0.049695\n",
      "Epoch: 10062, MSE: 0.24933987652258777, Learning Rate: 0.049690000000000005\n",
      "Epoch: 10063, MSE: 0.2493372671234411, Learning Rate: 0.04968500000000001\n",
      "Epoch: 10064, MSE: 0.24933465767651314, Learning Rate: 0.04968\n",
      "Epoch: 10065, MSE: 0.24933204818180466, Learning Rate: 0.049675000000000004\n",
      "Epoch: 10066, MSE: 0.249329438639319, Learning Rate: 0.049670000000000006\n",
      "Epoch: 10067, MSE: 0.24932682904905595, Learning Rate: 0.04966500000000001\n",
      "Epoch: 10068, MSE: 0.24932421941101848, Learning Rate: 0.04966000000000001\n",
      "Epoch: 10069, MSE: 0.24932160972520945, Learning Rate: 0.049655000000000005\n",
      "Epoch: 10070, MSE: 0.24931899999162957, Learning Rate: 0.04965000000000001\n",
      "Epoch: 10071, MSE: 0.2493163902102806, Learning Rate: 0.049644999999999995\n",
      "Epoch: 10072, MSE: 0.24931378038116458, Learning Rate: 0.04964\n",
      "Epoch: 10073, MSE: 0.24931117050428322, Learning Rate: 0.049635\n",
      "Epoch: 10074, MSE: 0.24930856057963904, Learning Rate: 0.04963\n",
      "Epoch: 10075, MSE: 0.24930595060723246, Learning Rate: 0.049625\n",
      "Epoch: 10076, MSE: 0.24930334058706743, Learning Rate: 0.04962\n",
      "Epoch: 10077, MSE: 0.2493007305191445, Learning Rate: 0.049615\n",
      "Epoch: 10078, MSE: 0.2492981204034654, Learning Rate: 0.04961\n",
      "Epoch: 10079, MSE: 0.24929551024003216, Learning Rate: 0.049605\n",
      "Epoch: 10080, MSE: 0.249292900028847, Learning Rate: 0.049600000000000005\n",
      "Epoch: 10081, MSE: 0.2492902897699122, Learning Rate: 0.049595\n",
      "Epoch: 10082, MSE: 0.24928767946322788, Learning Rate: 0.04959\n",
      "Epoch: 10083, MSE: 0.24928506910879783, Learning Rate: 0.049585000000000004\n",
      "Epoch: 10084, MSE: 0.2492824587066222, Learning Rate: 0.049580000000000006\n",
      "Epoch: 10085, MSE: 0.24927984825670454, Learning Rate: 0.04957500000000001\n",
      "Epoch: 10086, MSE: 0.24927723775904595, Learning Rate: 0.04957\n",
      "Epoch: 10087, MSE: 0.2492746272136479, Learning Rate: 0.049565000000000005\n",
      "Epoch: 10088, MSE: 0.24927201662051274, Learning Rate: 0.04956000000000001\n",
      "Epoch: 10089, MSE: 0.24926940597964192, Learning Rate: 0.04955500000000001\n",
      "Epoch: 10090, MSE: 0.249266795291038, Learning Rate: 0.04955000000000001\n",
      "Epoch: 10091, MSE: 0.24926418455470242, Learning Rate: 0.049545\n",
      "Epoch: 10092, MSE: 0.24926157377063624, Learning Rate: 0.04954\n",
      "Epoch: 10093, MSE: 0.24925896293884367, Learning Rate: 0.049534999999999996\n",
      "Epoch: 10094, MSE: 0.2492563520593243, Learning Rate: 0.04953\n",
      "Epoch: 10095, MSE: 0.2492537411320805, Learning Rate: 0.049525\n",
      "Epoch: 10096, MSE: 0.24925113015711417, Learning Rate: 0.04952\n",
      "Epoch: 10097, MSE: 0.249248519134428, Learning Rate: 0.049515\n",
      "Epoch: 10098, MSE: 0.24924590806402344, Learning Rate: 0.04951\n",
      "Epoch: 10099, MSE: 0.2492432969459012, Learning Rate: 0.049505\n",
      "Epoch: 10100, MSE: 0.24924068578006514, Learning Rate: 0.0495\n",
      "Epoch: 10101, MSE: 0.24923807456651623, Learning Rate: 0.049495000000000004\n",
      "Epoch: 10102, MSE: 0.24923546330525523, Learning Rate: 0.049490000000000006\n",
      "Epoch: 10103, MSE: 0.24923285199628553, Learning Rate: 0.049485\n",
      "Epoch: 10104, MSE: 0.2492302406396081, Learning Rate: 0.04948\n",
      "Epoch: 10105, MSE: 0.2492276292352255, Learning Rate: 0.049475000000000005\n",
      "Epoch: 10106, MSE: 0.24922501778314, Learning Rate: 0.04947000000000001\n",
      "Epoch: 10107, MSE: 0.24922240628335138, Learning Rate: 0.04946500000000001\n",
      "Epoch: 10108, MSE: 0.24921979473586406, Learning Rate: 0.049460000000000004\n",
      "Epoch: 10109, MSE: 0.2492171831406782, Learning Rate: 0.049455000000000006\n",
      "Epoch: 10110, MSE: 0.2492145714977964, Learning Rate: 0.04945000000000001\n",
      "Epoch: 10111, MSE: 0.24921195980722044, Learning Rate: 0.049444999999999996\n",
      "Epoch: 10112, MSE: 0.24920934806895206, Learning Rate: 0.04944\n",
      "Epoch: 10113, MSE: 0.24920673628299353, Learning Rate: 0.049435\n",
      "Epoch: 10114, MSE: 0.2492041244493458, Learning Rate: 0.04943\n",
      "Epoch: 10115, MSE: 0.24920151256801162, Learning Rate: 0.049425\n",
      "Epoch: 10116, MSE: 0.2491989006389924, Learning Rate: 0.04942\n",
      "Epoch: 10117, MSE: 0.2491962886622909, Learning Rate: 0.049415\n",
      "Epoch: 10118, MSE: 0.249193676637908, Learning Rate: 0.04941\n",
      "Epoch: 10119, MSE: 0.24919106456584533, Learning Rate: 0.049405000000000004\n",
      "Epoch: 10120, MSE: 0.24918845244610563, Learning Rate: 0.0494\n",
      "Epoch: 10121, MSE: 0.24918584027869042, Learning Rate: 0.049395\n",
      "Epoch: 10122, MSE: 0.2491832280636033, Learning Rate: 0.04939\n",
      "Epoch: 10123, MSE: 0.24918061580084266, Learning Rate: 0.049385000000000005\n",
      "Epoch: 10124, MSE: 0.24917800349041289, Learning Rate: 0.04938000000000001\n",
      "Epoch: 10125, MSE: 0.24917539113231524, Learning Rate: 0.049375\n",
      "Epoch: 10126, MSE: 0.24917277872655136, Learning Rate: 0.049370000000000004\n",
      "Epoch: 10127, MSE: 0.24917016627312308, Learning Rate: 0.049365000000000006\n",
      "Epoch: 10128, MSE: 0.24916755377203303, Learning Rate: 0.04936000000000001\n",
      "Epoch: 10129, MSE: 0.2491649412232825, Learning Rate: 0.04935500000000001\n",
      "Epoch: 10130, MSE: 0.24916232862687335, Learning Rate: 0.049350000000000005\n",
      "Epoch: 10131, MSE: 0.2491597159828074, Learning Rate: 0.04934500000000001\n",
      "Epoch: 10132, MSE: 0.24915710329108814, Learning Rate: 0.049339999999999995\n",
      "Epoch: 10133, MSE: 0.24915449055171432, Learning Rate: 0.049335\n",
      "Epoch: 10134, MSE: 0.24915187776469008, Learning Rate: 0.04933\n",
      "Epoch: 10135, MSE: 0.2491492649300172, Learning Rate: 0.049325\n",
      "Epoch: 10136, MSE: 0.2491466520476973, Learning Rate: 0.04932\n",
      "Epoch: 10137, MSE: 0.24914403911773172, Learning Rate: 0.049315\n",
      "Epoch: 10138, MSE: 0.24914142614012266, Learning Rate: 0.04931\n",
      "Epoch: 10139, MSE: 0.24913881311487215, Learning Rate: 0.049305\n",
      "Epoch: 10140, MSE: 0.2491362000419824, Learning Rate: 0.049300000000000004\n",
      "Epoch: 10141, MSE: 0.2491335869214549, Learning Rate: 0.049295000000000005\n",
      "Epoch: 10142, MSE: 0.24913097375329157, Learning Rate: 0.04929\n",
      "Epoch: 10143, MSE: 0.249128360537494, Learning Rate: 0.049285\n",
      "Epoch: 10144, MSE: 0.24912574727406545, Learning Rate: 0.049280000000000004\n",
      "Epoch: 10145, MSE: 0.2491231339630054, Learning Rate: 0.049275000000000006\n",
      "Epoch: 10146, MSE: 0.24912052060431827, Learning Rate: 0.04927000000000001\n",
      "Epoch: 10147, MSE: 0.24911790719800384, Learning Rate: 0.049265\n",
      "Epoch: 10148, MSE: 0.24911529374406582, Learning Rate: 0.049260000000000005\n",
      "Epoch: 10149, MSE: 0.24911268024250546, Learning Rate: 0.04925500000000001\n",
      "Epoch: 10150, MSE: 0.2491100666933235, Learning Rate: 0.04925000000000001\n",
      "Epoch: 10151, MSE: 0.2491074530965229, Learning Rate: 0.04924500000000001\n",
      "Epoch: 10152, MSE: 0.24910483945210637, Learning Rate: 0.04924\n",
      "Epoch: 10153, MSE: 0.24910222576007454, Learning Rate: 0.049235\n",
      "Epoch: 10154, MSE: 0.24909961202042924, Learning Rate: 0.049229999999999996\n",
      "Epoch: 10155, MSE: 0.24909699823317252, Learning Rate: 0.049225\n",
      "Epoch: 10156, MSE: 0.24909438439830797, Learning Rate: 0.04922\n",
      "Epoch: 10157, MSE: 0.24909177051583511, Learning Rate: 0.049215\n",
      "Epoch: 10158, MSE: 0.24908915658575642, Learning Rate: 0.049210000000000004\n",
      "Epoch: 10159, MSE: 0.24908654260807475, Learning Rate: 0.049205\n",
      "Epoch: 10160, MSE: 0.24908392858279133, Learning Rate: 0.0492\n",
      "Epoch: 10161, MSE: 0.2490813145099085, Learning Rate: 0.049195\n",
      "Epoch: 10162, MSE: 0.2490787003894279, Learning Rate: 0.049190000000000005\n",
      "Epoch: 10163, MSE: 0.2490760862213508, Learning Rate: 0.049185000000000006\n",
      "Epoch: 10164, MSE: 0.24907347200567992, Learning Rate: 0.04918\n",
      "Epoch: 10165, MSE: 0.24907085774241686, Learning Rate: 0.049175\n",
      "Epoch: 10166, MSE: 0.2490682434315634, Learning Rate: 0.049170000000000005\n",
      "Epoch: 10167, MSE: 0.24906562907312274, Learning Rate: 0.04916500000000001\n",
      "Epoch: 10168, MSE: 0.24906301466709413, Learning Rate: 0.04916000000000001\n",
      "Epoch: 10169, MSE: 0.24906040021348225, Learning Rate: 0.049155000000000004\n",
      "Epoch: 10170, MSE: 0.24905778571228723, Learning Rate: 0.049150000000000006\n",
      "Epoch: 10171, MSE: 0.24905517116351214, Learning Rate: 0.04914500000000001\n",
      "Epoch: 10172, MSE: 0.24905255656715736, Learning Rate: 0.049139999999999996\n",
      "Epoch: 10173, MSE: 0.24904994192322605, Learning Rate: 0.049135\n",
      "Epoch: 10174, MSE: 0.24904732723172088, Learning Rate: 0.04913\n",
      "Epoch: 10175, MSE: 0.24904471249264104, Learning Rate: 0.049125\n",
      "Epoch: 10176, MSE: 0.24904209770599103, Learning Rate: 0.04912\n",
      "Epoch: 10177, MSE: 0.2490394828717714, Learning Rate: 0.049115\n",
      "Epoch: 10178, MSE: 0.24903686798998495, Learning Rate: 0.04911\n",
      "Epoch: 10179, MSE: 0.24903425306063307, Learning Rate: 0.049105\n",
      "Epoch: 10180, MSE: 0.24903163808371676, Learning Rate: 0.049100000000000005\n",
      "Epoch: 10181, MSE: 0.24902902305924052, Learning Rate: 0.049095\n",
      "Epoch: 10182, MSE: 0.24902640798720313, Learning Rate: 0.04909\n",
      "Epoch: 10183, MSE: 0.24902379286760865, Learning Rate: 0.049085000000000004\n",
      "Epoch: 10184, MSE: 0.24902117770045834, Learning Rate: 0.049080000000000006\n",
      "Epoch: 10185, MSE: 0.24901856248575413, Learning Rate: 0.04907500000000001\n",
      "Epoch: 10186, MSE: 0.24901594722349799, Learning Rate: 0.04907\n",
      "Epoch: 10187, MSE: 0.24901333191369185, Learning Rate: 0.049065000000000004\n",
      "Epoch: 10188, MSE: 0.2490107165563373, Learning Rate: 0.049060000000000006\n",
      "Epoch: 10189, MSE: 0.24900810115143676, Learning Rate: 0.04905500000000001\n",
      "Epoch: 10190, MSE: 0.24900548569899217, Learning Rate: 0.04905000000000001\n",
      "Epoch: 10191, MSE: 0.2490028701990044, Learning Rate: 0.049045000000000005\n",
      "Epoch: 10192, MSE: 0.24900025465147685, Learning Rate: 0.04904\n",
      "Epoch: 10193, MSE: 0.24899763905641054, Learning Rate: 0.049034999999999995\n",
      "Epoch: 10194, MSE: 0.24899502341380783, Learning Rate: 0.04903\n",
      "Epoch: 10195, MSE: 0.24899240772366954, Learning Rate: 0.049025\n",
      "Epoch: 10196, MSE: 0.24898979198599996, Learning Rate: 0.04902\n",
      "Epoch: 10197, MSE: 0.24898717620079863, Learning Rate: 0.049015\n",
      "Epoch: 10198, MSE: 0.2489845603680685, Learning Rate: 0.04901\n",
      "Epoch: 10199, MSE: 0.248981944487811, Learning Rate: 0.049005\n",
      "Epoch: 10200, MSE: 0.24897932856002888, Learning Rate: 0.049\n",
      "Epoch: 10201, MSE: 0.24897671258472356, Learning Rate: 0.048995000000000004\n",
      "Epoch: 10202, MSE: 0.2489740965618969, Learning Rate: 0.048990000000000006\n",
      "Epoch: 10203, MSE: 0.24897148049155, Learning Rate: 0.048985\n",
      "Epoch: 10204, MSE: 0.24896886437368773, Learning Rate: 0.04898\n",
      "Epoch: 10205, MSE: 0.24896624820830904, Learning Rate: 0.048975000000000005\n",
      "Epoch: 10206, MSE: 0.24896363199541638, Learning Rate: 0.04897000000000001\n",
      "Epoch: 10207, MSE: 0.24896101573501234, Learning Rate: 0.04896500000000001\n",
      "Epoch: 10208, MSE: 0.24895839942709896, Learning Rate: 0.048960000000000004\n",
      "Epoch: 10209, MSE: 0.2489557830716775, Learning Rate: 0.048955000000000005\n",
      "Epoch: 10210, MSE: 0.24895316666874986, Learning Rate: 0.04895000000000001\n",
      "Epoch: 10211, MSE: 0.24895055021831858, Learning Rate: 0.04894500000000001\n",
      "Epoch: 10212, MSE: 0.2489479337203859, Learning Rate: 0.04894\n",
      "Epoch: 10213, MSE: 0.24894531717495258, Learning Rate: 0.048935\n",
      "Epoch: 10214, MSE: 0.2489427005820215, Learning Rate: 0.04893\n",
      "Epoch: 10215, MSE: 0.24894008394159392, Learning Rate: 0.048924999999999996\n",
      "Epoch: 10216, MSE: 0.24893746725367275, Learning Rate: 0.04892\n",
      "Epoch: 10217, MSE: 0.2489348505182586, Learning Rate: 0.048915\n",
      "Epoch: 10218, MSE: 0.2489322337353548, Learning Rate: 0.04891\n",
      "Epoch: 10219, MSE: 0.24892961690496213, Learning Rate: 0.048905000000000004\n",
      "Epoch: 10220, MSE: 0.24892700002708287, Learning Rate: 0.0489\n",
      "Epoch: 10221, MSE: 0.24892438310171894, Learning Rate: 0.048895\n",
      "Epoch: 10222, MSE: 0.24892176612887285, Learning Rate: 0.04889\n",
      "Epoch: 10223, MSE: 0.24891914910854557, Learning Rate: 0.048885000000000005\n",
      "Epoch: 10224, MSE: 0.2489165320407394, Learning Rate: 0.04888000000000001\n",
      "Epoch: 10225, MSE: 0.24891391492545759, Learning Rate: 0.048875\n",
      "Epoch: 10226, MSE: 0.24891129776269985, Learning Rate: 0.048870000000000004\n",
      "Epoch: 10227, MSE: 0.24890868055246965, Learning Rate: 0.048865000000000006\n",
      "Epoch: 10228, MSE: 0.24890606329476805, Learning Rate: 0.04886000000000001\n",
      "Epoch: 10229, MSE: 0.2489034459895973, Learning Rate: 0.04885500000000001\n",
      "Epoch: 10230, MSE: 0.2489008286369594, Learning Rate: 0.048850000000000005\n",
      "Epoch: 10231, MSE: 0.248898211236857, Learning Rate: 0.048845000000000006\n",
      "Epoch: 10232, MSE: 0.2488955937892914, Learning Rate: 0.048839999999999995\n",
      "Epoch: 10233, MSE: 0.24889297629426396, Learning Rate: 0.048834999999999996\n",
      "Epoch: 10234, MSE: 0.24889035875177715, Learning Rate: 0.04883\n",
      "Epoch: 10235, MSE: 0.248887741161833, Learning Rate: 0.048825\n",
      "Epoch: 10236, MSE: 0.2488851235244335, Learning Rate: 0.04882\n",
      "Epoch: 10237, MSE: 0.24888250583958055, Learning Rate: 0.048815\n",
      "Epoch: 10238, MSE: 0.24887988810727582, Learning Rate: 0.04881\n",
      "Epoch: 10239, MSE: 0.24887727032752158, Learning Rate: 0.048805\n",
      "Epoch: 10240, MSE: 0.24887465250031926, Learning Rate: 0.0488\n",
      "Epoch: 10241, MSE: 0.2488720346256721, Learning Rate: 0.048795000000000005\n",
      "Epoch: 10242, MSE: 0.24886941670358115, Learning Rate: 0.04879\n",
      "Epoch: 10243, MSE: 0.24886679873404755, Learning Rate: 0.048785\n",
      "Epoch: 10244, MSE: 0.24886418071707372, Learning Rate: 0.048780000000000004\n",
      "Epoch: 10245, MSE: 0.24886156265266327, Learning Rate: 0.048775000000000006\n",
      "Epoch: 10246, MSE: 0.2488589445408159, Learning Rate: 0.04877000000000001\n",
      "Epoch: 10247, MSE: 0.24885632638153501, Learning Rate: 0.048765\n",
      "Epoch: 10248, MSE: 0.24885370817482128, Learning Rate: 0.048760000000000005\n",
      "Epoch: 10249, MSE: 0.24885108992067748, Learning Rate: 0.04875500000000001\n",
      "Epoch: 10250, MSE: 0.24884847161910617, Learning Rate: 0.04875000000000001\n",
      "Epoch: 10251, MSE: 0.24884585327010883, Learning Rate: 0.04874500000000001\n",
      "Epoch: 10252, MSE: 0.24884323487368618, Learning Rate: 0.048740000000000006\n",
      "Epoch: 10253, MSE: 0.2488406164298419, Learning Rate: 0.048735\n",
      "Epoch: 10254, MSE: 0.24883799793857664, Learning Rate: 0.048729999999999996\n",
      "Epoch: 10255, MSE: 0.24883537939989328, Learning Rate: 0.048725\n",
      "Epoch: 10256, MSE: 0.24883276081379344, Learning Rate: 0.04872\n",
      "Epoch: 10257, MSE: 0.24883014218027882, Learning Rate: 0.048715\n",
      "Epoch: 10258, MSE: 0.2488275234993519, Learning Rate: 0.04871\n",
      "Epoch: 10259, MSE: 0.24882490477101404, Learning Rate: 0.048705\n",
      "Epoch: 10260, MSE: 0.24882228599526793, Learning Rate: 0.0487\n",
      "Epoch: 10261, MSE: 0.24881966717211526, Learning Rate: 0.048695\n",
      "Epoch: 10262, MSE: 0.24881704830155726, Learning Rate: 0.048690000000000004\n",
      "Epoch: 10263, MSE: 0.24881442938359716, Learning Rate: 0.048685000000000006\n",
      "Epoch: 10264, MSE: 0.24881181041823522, Learning Rate: 0.04868\n",
      "Epoch: 10265, MSE: 0.24880919140547486, Learning Rate: 0.048675\n",
      "Epoch: 10266, MSE: 0.24880657234531767, Learning Rate: 0.048670000000000005\n",
      "Epoch: 10267, MSE: 0.2488039532377655, Learning Rate: 0.04866500000000001\n",
      "Epoch: 10268, MSE: 0.24880133408282043, Learning Rate: 0.04866000000000001\n",
      "Epoch: 10269, MSE: 0.2487987148804846, Learning Rate: 0.048655000000000004\n",
      "Epoch: 10270, MSE: 0.24879609563075938, Learning Rate: 0.048650000000000006\n",
      "Epoch: 10271, MSE: 0.248793476333647, Learning Rate: 0.04864500000000001\n",
      "Epoch: 10272, MSE: 0.24879085698914916, Learning Rate: 0.04864000000000001\n",
      "Epoch: 10273, MSE: 0.24878823759726876, Learning Rate: 0.048635\n",
      "Epoch: 10274, MSE: 0.24878561815800698, Learning Rate: 0.04863\n",
      "Epoch: 10275, MSE: 0.24878299867136552, Learning Rate: 0.048625\n",
      "Epoch: 10276, MSE: 0.24878037913734713, Learning Rate: 0.04862\n",
      "Epoch: 10277, MSE: 0.24877775955595344, Learning Rate: 0.048615\n",
      "Epoch: 10278, MSE: 0.24877513992718683, Learning Rate: 0.04861\n",
      "Epoch: 10279, MSE: 0.2487725202510477, Learning Rate: 0.048605\n",
      "Epoch: 10280, MSE: 0.24876990052753978, Learning Rate: 0.048600000000000004\n",
      "Epoch: 10281, MSE: 0.24876728075666407, Learning Rate: 0.048595\n",
      "Epoch: 10282, MSE: 0.2487646609384237, Learning Rate: 0.04859\n",
      "Epoch: 10283, MSE: 0.24876204107281913, Learning Rate: 0.048585\n",
      "Epoch: 10284, MSE: 0.2487594211598533, Learning Rate: 0.048580000000000005\n",
      "Epoch: 10285, MSE: 0.2487568011995276, Learning Rate: 0.04857500000000001\n",
      "Epoch: 10286, MSE: 0.2487541811918442, Learning Rate: 0.04857\n",
      "Epoch: 10287, MSE: 0.2487515611368057, Learning Rate: 0.048565000000000004\n",
      "Epoch: 10288, MSE: 0.24874894103441303, Learning Rate: 0.048560000000000006\n",
      "Epoch: 10289, MSE: 0.24874632088466925, Learning Rate: 0.04855500000000001\n",
      "Epoch: 10290, MSE: 0.2487437006875756, Learning Rate: 0.04855000000000001\n",
      "Epoch: 10291, MSE: 0.2487410804431333, Learning Rate: 0.048545000000000005\n",
      "Epoch: 10292, MSE: 0.2487384601513455, Learning Rate: 0.04854000000000001\n",
      "Epoch: 10293, MSE: 0.24873583981221484, Learning Rate: 0.048534999999999995\n",
      "Epoch: 10294, MSE: 0.24873321942574153, Learning Rate: 0.04853\n",
      "Epoch: 10295, MSE: 0.24873059899192815, Learning Rate: 0.048525\n",
      "Epoch: 10296, MSE: 0.2487279785107777, Learning Rate: 0.04852\n",
      "Epoch: 10297, MSE: 0.24872535798229095, Learning Rate: 0.048515\n",
      "Epoch: 10298, MSE: 0.24872273740647027, Learning Rate: 0.04851\n",
      "Epoch: 10299, MSE: 0.2487201167833175, Learning Rate: 0.048505\n",
      "Epoch: 10300, MSE: 0.24871749611283522, Learning Rate: 0.0485\n",
      "Epoch: 10301, MSE: 0.24871487539502454, Learning Rate: 0.048495\n",
      "Epoch: 10302, MSE: 0.24871225462988794, Learning Rate: 0.048490000000000005\n",
      "Epoch: 10303, MSE: 0.24870963381742645, Learning Rate: 0.048485\n",
      "Epoch: 10304, MSE: 0.24870701295764377, Learning Rate: 0.04848\n",
      "Epoch: 10305, MSE: 0.2487043920505409, Learning Rate: 0.048475000000000004\n",
      "Epoch: 10306, MSE: 0.24870177109612, Learning Rate: 0.048470000000000006\n",
      "Epoch: 10307, MSE: 0.24869915009438326, Learning Rate: 0.04846500000000001\n",
      "Epoch: 10308, MSE: 0.24869652904533213, Learning Rate: 0.04846\n",
      "Epoch: 10309, MSE: 0.2486939079489689, Learning Rate: 0.048455000000000005\n",
      "Epoch: 10310, MSE: 0.24869128680529537, Learning Rate: 0.04845000000000001\n",
      "Epoch: 10311, MSE: 0.24868866561431363, Learning Rate: 0.04844500000000001\n",
      "Epoch: 10312, MSE: 0.24868604437602582, Learning Rate: 0.04844000000000001\n",
      "Epoch: 10313, MSE: 0.24868342309043362, Learning Rate: 0.048435\n",
      "Epoch: 10314, MSE: 0.24868080175753968, Learning Rate: 0.04843\n",
      "Epoch: 10315, MSE: 0.24867818037734402, Learning Rate: 0.048424999999999996\n",
      "Epoch: 10316, MSE: 0.24867555894985127, Learning Rate: 0.04842\n",
      "Epoch: 10317, MSE: 0.24867293747506236, Learning Rate: 0.048415\n",
      "Epoch: 10318, MSE: 0.24867031595297867, Learning Rate: 0.04841\n",
      "Epoch: 10319, MSE: 0.2486676943836029, Learning Rate: 0.048405000000000004\n",
      "Epoch: 10320, MSE: 0.24866507276693703, Learning Rate: 0.0484\n",
      "Epoch: 10321, MSE: 0.24866245110298255, Learning Rate: 0.048395\n",
      "Epoch: 10322, MSE: 0.24865982939174228, Learning Rate: 0.04839\n",
      "Epoch: 10323, MSE: 0.24865720763321708, Learning Rate: 0.048385000000000004\n",
      "Epoch: 10324, MSE: 0.24865458582740915, Learning Rate: 0.048380000000000006\n",
      "Epoch: 10325, MSE: 0.24865196397432215, Learning Rate: 0.048375\n",
      "Epoch: 10326, MSE: 0.24864934207395573, Learning Rate: 0.04837\n",
      "Epoch: 10327, MSE: 0.2486467201263131, Learning Rate: 0.048365000000000005\n",
      "Epoch: 10328, MSE: 0.2486440981313961, Learning Rate: 0.04836000000000001\n",
      "Epoch: 10329, MSE: 0.24864147608920698, Learning Rate: 0.04835500000000001\n",
      "Epoch: 10330, MSE: 0.24863885399974717, Learning Rate: 0.048350000000000004\n",
      "Epoch: 10331, MSE: 0.24863623186301945, Learning Rate: 0.048345000000000006\n",
      "Epoch: 10332, MSE: 0.24863360967902481, Learning Rate: 0.04834000000000001\n",
      "Epoch: 10333, MSE: 0.24863098744776585, Learning Rate: 0.048334999999999996\n",
      "Epoch: 10334, MSE: 0.24862836516924428, Learning Rate: 0.04833\n",
      "Epoch: 10335, MSE: 0.24862574284346273, Learning Rate: 0.048325\n",
      "Epoch: 10336, MSE: 0.24862312047042215, Learning Rate: 0.04832\n",
      "Epoch: 10337, MSE: 0.2486204980501255, Learning Rate: 0.048315\n",
      "Epoch: 10338, MSE: 0.24861787558257442, Learning Rate: 0.04831\n",
      "Epoch: 10339, MSE: 0.2486152530677705, Learning Rate: 0.048305\n",
      "Epoch: 10340, MSE: 0.2486126305057168, Learning Rate: 0.0483\n",
      "Epoch: 10341, MSE: 0.24861000789641471, Learning Rate: 0.048295000000000005\n",
      "Epoch: 10342, MSE: 0.24860738523986556, Learning Rate: 0.04829\n",
      "Epoch: 10343, MSE: 0.24860476253607255, Learning Rate: 0.048285\n",
      "Epoch: 10344, MSE: 0.24860213978503626, Learning Rate: 0.04828\n",
      "Epoch: 10345, MSE: 0.24859951698676094, Learning Rate: 0.048275000000000005\n",
      "Epoch: 10346, MSE: 0.24859689414124594, Learning Rate: 0.04827000000000001\n",
      "Epoch: 10347, MSE: 0.24859427124849484, Learning Rate: 0.048265\n",
      "Epoch: 10348, MSE: 0.2485916483085097, Learning Rate: 0.048260000000000004\n",
      "Epoch: 10349, MSE: 0.24858902532129146, Learning Rate: 0.048255000000000006\n",
      "Epoch: 10350, MSE: 0.24858640228684373, Learning Rate: 0.04825000000000001\n",
      "Epoch: 10351, MSE: 0.2485837792051672, Learning Rate: 0.04824500000000001\n",
      "Epoch: 10352, MSE: 0.24858115607626363, Learning Rate: 0.048240000000000005\n",
      "Epoch: 10353, MSE: 0.24857853290013726, Learning Rate: 0.048235\n",
      "Epoch: 10354, MSE: 0.24857590967678667, Learning Rate: 0.048229999999999995\n",
      "Epoch: 10355, MSE: 0.2485732864062161, Learning Rate: 0.048225\n",
      "Epoch: 10356, MSE: 0.24857066308842798, Learning Rate: 0.04822\n",
      "Epoch: 10357, MSE: 0.24856803972342306, Learning Rate: 0.048215\n",
      "Epoch: 10358, MSE: 0.2485654163112039, Learning Rate: 0.04821\n",
      "Epoch: 10359, MSE: 0.24856279285177174, Learning Rate: 0.048205\n",
      "Epoch: 10360, MSE: 0.24856016934513014, Learning Rate: 0.0482\n",
      "Epoch: 10361, MSE: 0.24855754579127912, Learning Rate: 0.048195\n",
      "Epoch: 10362, MSE: 0.24855492219022268, Learning Rate: 0.048190000000000004\n",
      "Epoch: 10363, MSE: 0.2485522985419622, Learning Rate: 0.048185000000000006\n",
      "Epoch: 10364, MSE: 0.24854967484649862, Learning Rate: 0.04818\n",
      "Epoch: 10365, MSE: 0.24854705110383543, Learning Rate: 0.048175\n",
      "Epoch: 10366, MSE: 0.24854442731397386, Learning Rate: 0.048170000000000004\n",
      "Epoch: 10367, MSE: 0.24854180347691537, Learning Rate: 0.048165000000000006\n",
      "Epoch: 10368, MSE: 0.24853917959266278, Learning Rate: 0.04816000000000001\n",
      "Epoch: 10369, MSE: 0.24853655566121854, Learning Rate: 0.048155\n",
      "Epoch: 10370, MSE: 0.2485339316825836, Learning Rate: 0.048150000000000005\n",
      "Epoch: 10371, MSE: 0.24853130765675982, Learning Rate: 0.04814500000000001\n",
      "Epoch: 10372, MSE: 0.24852868358375155, Learning Rate: 0.04814000000000001\n",
      "Epoch: 10373, MSE: 0.24852605946355816, Learning Rate: 0.048135\n",
      "Epoch: 10374, MSE: 0.24852343529618243, Learning Rate: 0.04813\n",
      "Epoch: 10375, MSE: 0.2485208110816272, Learning Rate: 0.048125\n",
      "Epoch: 10376, MSE: 0.24851818681989277, Learning Rate: 0.048119999999999996\n",
      "Epoch: 10377, MSE: 0.2485155625109837, Learning Rate: 0.048115\n",
      "Epoch: 10378, MSE: 0.24851293815489928, Learning Rate: 0.04811\n",
      "Epoch: 10379, MSE: 0.24851031375164304, Learning Rate: 0.048105\n",
      "Epoch: 10380, MSE: 0.2485076893012179, Learning Rate: 0.048100000000000004\n",
      "Epoch: 10381, MSE: 0.24850506480362355, Learning Rate: 0.048095\n",
      "Epoch: 10382, MSE: 0.248502440258864, Learning Rate: 0.04809\n",
      "Epoch: 10383, MSE: 0.2484998156669394, Learning Rate: 0.048085\n",
      "Epoch: 10384, MSE: 0.2484971910278537, Learning Rate: 0.048080000000000005\n",
      "Epoch: 10385, MSE: 0.2484945663416081, Learning Rate: 0.04807500000000001\n",
      "Epoch: 10386, MSE: 0.24849194160820426, Learning Rate: 0.04807\n",
      "Epoch: 10387, MSE: 0.24848931682764472, Learning Rate: 0.048065000000000004\n",
      "Epoch: 10388, MSE: 0.24848669199993137, Learning Rate: 0.048060000000000005\n",
      "Epoch: 10389, MSE: 0.24848406712506618, Learning Rate: 0.04805500000000001\n",
      "Epoch: 10390, MSE: 0.24848144220305052, Learning Rate: 0.04805000000000001\n",
      "Epoch: 10391, MSE: 0.24847881723388807, Learning Rate: 0.048045000000000004\n",
      "Epoch: 10392, MSE: 0.2484761922175793, Learning Rate: 0.048040000000000006\n",
      "Epoch: 10393, MSE: 0.24847356715412652, Learning Rate: 0.04803500000000001\n",
      "Epoch: 10394, MSE: 0.24847094204353232, Learning Rate: 0.048029999999999996\n",
      "Epoch: 10395, MSE: 0.2484683168857989, Learning Rate: 0.048025\n",
      "Epoch: 10396, MSE: 0.24846569168092789, Learning Rate: 0.04802\n",
      "Epoch: 10397, MSE: 0.2484630664289208, Learning Rate: 0.048015\n",
      "Epoch: 10398, MSE: 0.24846044112978022, Learning Rate: 0.04801\n",
      "Epoch: 10399, MSE: 0.24845781578350828, Learning Rate: 0.048005\n",
      "Epoch: 10400, MSE: 0.2484551903901065, Learning Rate: 0.048\n",
      "Epoch: 10401, MSE: 0.2484525649495775, Learning Rate: 0.047995\n",
      "Epoch: 10402, MSE: 0.24844993946192268, Learning Rate: 0.047990000000000005\n",
      "Epoch: 10403, MSE: 0.2484473139271453, Learning Rate: 0.047985\n",
      "Epoch: 10404, MSE: 0.24844468834524522, Learning Rate: 0.04798\n",
      "Epoch: 10405, MSE: 0.24844206271622685, Learning Rate: 0.047975000000000004\n",
      "Epoch: 10406, MSE: 0.24843943704009133, Learning Rate: 0.047970000000000006\n",
      "Epoch: 10407, MSE: 0.24843681131683998, Learning Rate: 0.04796500000000001\n",
      "Epoch: 10408, MSE: 0.248434185546475, Learning Rate: 0.04796\n",
      "Epoch: 10409, MSE: 0.24843155972899889, Learning Rate: 0.047955000000000005\n",
      "Epoch: 10410, MSE: 0.24842893386441453, Learning Rate: 0.047950000000000007\n",
      "Epoch: 10411, MSE: 0.24842630795272236, Learning Rate: 0.04794500000000001\n",
      "Epoch: 10412, MSE: 0.24842368199392506, Learning Rate: 0.04794000000000001\n",
      "Epoch: 10413, MSE: 0.24842105598802475, Learning Rate: 0.047935000000000005\n",
      "Epoch: 10414, MSE: 0.2484184299350231, Learning Rate: 0.04793\n",
      "Epoch: 10415, MSE: 0.24841580383492348, Learning Rate: 0.047924999999999995\n",
      "Epoch: 10416, MSE: 0.24841317768772625, Learning Rate: 0.04792\n",
      "Epoch: 10417, MSE: 0.24841055149343408, Learning Rate: 0.047915\n",
      "Epoch: 10418, MSE: 0.2484079252520487, Learning Rate: 0.04791\n",
      "Epoch: 10419, MSE: 0.24840529896357325, Learning Rate: 0.047905\n",
      "Epoch: 10420, MSE: 0.24840267262800828, Learning Rate: 0.0479\n",
      "Epoch: 10421, MSE: 0.24840004624535744, Learning Rate: 0.047895\n",
      "Epoch: 10422, MSE: 0.2483974198156215, Learning Rate: 0.04789\n",
      "Epoch: 10423, MSE: 0.2483947933388026, Learning Rate: 0.047885000000000004\n",
      "Epoch: 10424, MSE: 0.24839216681490367, Learning Rate: 0.047880000000000006\n",
      "Epoch: 10425, MSE: 0.24838954024392607, Learning Rate: 0.047875\n",
      "Epoch: 10426, MSE: 0.2483869136258715, Learning Rate: 0.04787\n",
      "Epoch: 10427, MSE: 0.24838428696074213, Learning Rate: 0.047865000000000005\n",
      "Epoch: 10428, MSE: 0.24838166024854108, Learning Rate: 0.04786000000000001\n",
      "Epoch: 10429, MSE: 0.24837903348926943, Learning Rate: 0.04785500000000001\n",
      "Epoch: 10430, MSE: 0.2483764066829292, Learning Rate: 0.047850000000000004\n",
      "Epoch: 10431, MSE: 0.2483737798295234, Learning Rate: 0.047845000000000006\n",
      "Epoch: 10432, MSE: 0.2483711529290526, Learning Rate: 0.04784000000000001\n",
      "Epoch: 10433, MSE: 0.24836852598151998, Learning Rate: 0.04783500000000001\n",
      "Epoch: 10434, MSE: 0.248365898986927, Learning Rate: 0.04783\n",
      "Epoch: 10435, MSE: 0.24836327194527602, Learning Rate: 0.047825\n",
      "Epoch: 10436, MSE: 0.24836064485656914, Learning Rate: 0.04782\n",
      "Epoch: 10437, MSE: 0.24835801772080793, Learning Rate: 0.047814999999999996\n",
      "Epoch: 10438, MSE: 0.24835539053799532, Learning Rate: 0.04781\n",
      "Epoch: 10439, MSE: 0.24835276330813227, Learning Rate: 0.047805\n",
      "Epoch: 10440, MSE: 0.24835013603122164, Learning Rate: 0.0478\n",
      "Epoch: 10441, MSE: 0.24834750870726505, Learning Rate: 0.047795000000000004\n",
      "Epoch: 10442, MSE: 0.2483448813362651, Learning Rate: 0.04779\n",
      "Epoch: 10443, MSE: 0.2483422539182236, Learning Rate: 0.047785\n",
      "Epoch: 10444, MSE: 0.248339626453142, Learning Rate: 0.04778\n",
      "Epoch: 10445, MSE: 0.24833699894102287, Learning Rate: 0.047775000000000005\n",
      "Epoch: 10446, MSE: 0.24833437138186806, Learning Rate: 0.04777000000000001\n",
      "Epoch: 10447, MSE: 0.24833174377568032, Learning Rate: 0.047765\n",
      "Epoch: 10448, MSE: 0.2483291161224612, Learning Rate: 0.047760000000000004\n",
      "Epoch: 10449, MSE: 0.24832648842221203, Learning Rate: 0.047755000000000006\n",
      "Epoch: 10450, MSE: 0.24832386067493603, Learning Rate: 0.04775000000000001\n",
      "Epoch: 10451, MSE: 0.24832123288063462, Learning Rate: 0.04774500000000001\n",
      "Epoch: 10452, MSE: 0.24831860503931, Learning Rate: 0.047740000000000005\n",
      "Epoch: 10453, MSE: 0.24831597715096523, Learning Rate: 0.04773500000000001\n",
      "Epoch: 10454, MSE: 0.24831334921560028, Learning Rate: 0.047729999999999995\n",
      "Epoch: 10455, MSE: 0.24831072123321837, Learning Rate: 0.047725\n",
      "Epoch: 10456, MSE: 0.24830809320382213, Learning Rate: 0.04772\n",
      "Epoch: 10457, MSE: 0.24830546512741297, Learning Rate: 0.047715\n",
      "Epoch: 10458, MSE: 0.24830283700399253, Learning Rate: 0.04771\n",
      "Epoch: 10459, MSE: 0.2483002088335644, Learning Rate: 0.047705\n",
      "Epoch: 10460, MSE: 0.24829758061612808, Learning Rate: 0.0477\n",
      "Epoch: 10461, MSE: 0.2482949523516887, Learning Rate: 0.047695\n",
      "Epoch: 10462, MSE: 0.24829232404024565, Learning Rate: 0.04769\n",
      "Epoch: 10463, MSE: 0.2482896956818023, Learning Rate: 0.047685000000000005\n",
      "Epoch: 10464, MSE: 0.24828706727636055, Learning Rate: 0.04768\n",
      "Epoch: 10465, MSE: 0.2482844388239226, Learning Rate: 0.047675\n",
      "Epoch: 10466, MSE: 0.24828181032449026, Learning Rate: 0.047670000000000004\n",
      "Epoch: 10467, MSE: 0.24827918177806582, Learning Rate: 0.047665000000000006\n",
      "Epoch: 10468, MSE: 0.24827655318465125, Learning Rate: 0.04766000000000001\n",
      "Epoch: 10469, MSE: 0.24827392454424838, Learning Rate: 0.047655\n",
      "Epoch: 10470, MSE: 0.24827129585685953, Learning Rate: 0.047650000000000005\n",
      "Epoch: 10471, MSE: 0.24826866712248707, Learning Rate: 0.04764500000000001\n",
      "Epoch: 10472, MSE: 0.24826603834113214, Learning Rate: 0.04764000000000001\n",
      "Epoch: 10473, MSE: 0.2482634095127982, Learning Rate: 0.04763500000000001\n",
      "Epoch: 10474, MSE: 0.2482607806374862, Learning Rate: 0.04763\n",
      "Epoch: 10475, MSE: 0.248258151715198, Learning Rate: 0.047625\n",
      "Epoch: 10476, MSE: 0.24825552274593699, Learning Rate: 0.047619999999999996\n",
      "Epoch: 10477, MSE: 0.24825289372970394, Learning Rate: 0.047615\n",
      "Epoch: 10478, MSE: 0.24825026466650152, Learning Rate: 0.04761\n",
      "Epoch: 10479, MSE: 0.24824763555633164, Learning Rate: 0.047605\n",
      "Epoch: 10480, MSE: 0.24824500639919647, Learning Rate: 0.0476\n",
      "Epoch: 10481, MSE: 0.24824237719509837, Learning Rate: 0.047595\n",
      "Epoch: 10482, MSE: 0.24823974794403925, Learning Rate: 0.04759\n",
      "Epoch: 10483, MSE: 0.2482371186460207, Learning Rate: 0.047585\n",
      "Epoch: 10484, MSE: 0.24823448930104489, Learning Rate: 0.047580000000000004\n",
      "Epoch: 10485, MSE: 0.24823185990911498, Learning Rate: 0.047575000000000006\n",
      "Epoch: 10486, MSE: 0.248229230470231, Learning Rate: 0.04757\n",
      "Epoch: 10487, MSE: 0.2482266009843976, Learning Rate: 0.047565\n",
      "Epoch: 10488, MSE: 0.24822397145161404, Learning Rate: 0.047560000000000005\n",
      "Epoch: 10489, MSE: 0.24822134187188477, Learning Rate: 0.04755500000000001\n",
      "Epoch: 10490, MSE: 0.24821871224521141, Learning Rate: 0.04755000000000001\n",
      "Epoch: 10491, MSE: 0.24821608257159486, Learning Rate: 0.047545000000000004\n",
      "Epoch: 10492, MSE: 0.24821345285103777, Learning Rate: 0.047540000000000006\n",
      "Epoch: 10493, MSE: 0.24821082308354328, Learning Rate: 0.04753500000000001\n",
      "Epoch: 10494, MSE: 0.24820819326911145, Learning Rate: 0.047529999999999996\n",
      "Epoch: 10495, MSE: 0.24820556340774613, Learning Rate: 0.047525\n",
      "Epoch: 10496, MSE: 0.24820293349944908, Learning Rate: 0.04752\n",
      "Epoch: 10497, MSE: 0.24820030354422176, Learning Rate: 0.047515\n",
      "Epoch: 10498, MSE: 0.2481976735420663, Learning Rate: 0.04751\n",
      "Epoch: 10499, MSE: 0.24819504349298482, Learning Rate: 0.047505\n",
      "Epoch: 10500, MSE: 0.24819241339697998, Learning Rate: 0.0475\n",
      "Epoch: 10501, MSE: 0.24818978325405336, Learning Rate: 0.047495\n",
      "Epoch: 10502, MSE: 0.24818715306420727, Learning Rate: 0.047490000000000004\n",
      "Epoch: 10503, MSE: 0.24818452282744438, Learning Rate: 0.047485\n",
      "Epoch: 10504, MSE: 0.24818189254376566, Learning Rate: 0.04748\n",
      "Epoch: 10505, MSE: 0.24817926221317327, Learning Rate: 0.047475\n",
      "Epoch: 10506, MSE: 0.24817663183567004, Learning Rate: 0.047470000000000005\n",
      "Epoch: 10507, MSE: 0.24817400141125734, Learning Rate: 0.04746500000000001\n",
      "Epoch: 10508, MSE: 0.24817137093993785, Learning Rate: 0.04746\n",
      "Epoch: 10509, MSE: 0.2481687404217137, Learning Rate: 0.047455000000000004\n",
      "Epoch: 10510, MSE: 0.24816610985658624, Learning Rate: 0.047450000000000006\n",
      "Epoch: 10511, MSE: 0.2481634792445584, Learning Rate: 0.04744500000000001\n",
      "Epoch: 10512, MSE: 0.24816084858563192, Learning Rate: 0.04744000000000001\n",
      "Epoch: 10513, MSE: 0.24815821787980852, Learning Rate: 0.047435000000000005\n",
      "Epoch: 10514, MSE: 0.2481555871270905, Learning Rate: 0.04743000000000001\n",
      "Epoch: 10515, MSE: 0.24815295632748083, Learning Rate: 0.047424999999999995\n",
      "Epoch: 10516, MSE: 0.24815032548098015, Learning Rate: 0.04742\n",
      "Epoch: 10517, MSE: 0.24814769458759167, Learning Rate: 0.047415\n",
      "Epoch: 10518, MSE: 0.24814506364731698, Learning Rate: 0.04741\n",
      "Epoch: 10519, MSE: 0.248142432660158, Learning Rate: 0.047405\n",
      "Epoch: 10520, MSE: 0.2481398016261172, Learning Rate: 0.0474\n",
      "Epoch: 10521, MSE: 0.24813717054519718, Learning Rate: 0.047395\n",
      "Epoch: 10522, MSE: 0.24813453941739883, Learning Rate: 0.04739\n",
      "Epoch: 10523, MSE: 0.24813190824272469, Learning Rate: 0.047385000000000004\n",
      "Epoch: 10524, MSE: 0.24812927702117693, Learning Rate: 0.047380000000000005\n",
      "Epoch: 10525, MSE: 0.2481266457527581, Learning Rate: 0.047375\n",
      "Epoch: 10526, MSE: 0.24812401443747012, Learning Rate: 0.04737\n",
      "Epoch: 10527, MSE: 0.24812138307531462, Learning Rate: 0.047365000000000004\n",
      "Epoch: 10528, MSE: 0.24811875166629446, Learning Rate: 0.047360000000000006\n",
      "Epoch: 10529, MSE: 0.2481161202104109, Learning Rate: 0.04735500000000001\n",
      "Epoch: 10530, MSE: 0.24811348870766659, Learning Rate: 0.04735\n",
      "Epoch: 10531, MSE: 0.2481108571580624, Learning Rate: 0.047345000000000005\n",
      "Epoch: 10532, MSE: 0.24810822556160253, Learning Rate: 0.04734000000000001\n",
      "Epoch: 10533, MSE: 0.24810559391828785, Learning Rate: 0.04733500000000001\n",
      "Epoch: 10534, MSE: 0.24810296222812053, Learning Rate: 0.04733000000000001\n",
      "Epoch: 10535, MSE: 0.2481003304911027, Learning Rate: 0.047325\n",
      "Epoch: 10536, MSE: 0.24809769870723689, Learning Rate: 0.04732\n",
      "Epoch: 10537, MSE: 0.24809506687652422, Learning Rate: 0.047314999999999996\n",
      "Epoch: 10538, MSE: 0.24809243499896785, Learning Rate: 0.04731\n",
      "Epoch: 10539, MSE: 0.24808980307456974, Learning Rate: 0.047305\n",
      "Epoch: 10540, MSE: 0.2480871711033309, Learning Rate: 0.0473\n",
      "Epoch: 10541, MSE: 0.2480845390852557, Learning Rate: 0.047295000000000004\n",
      "Epoch: 10542, MSE: 0.24808190702034325, Learning Rate: 0.04729\n",
      "Epoch: 10543, MSE: 0.24807927490859807, Learning Rate: 0.047285\n",
      "Epoch: 10544, MSE: 0.24807664275002117, Learning Rate: 0.04728\n",
      "Epoch: 10545, MSE: 0.2480740105446151, Learning Rate: 0.047275000000000005\n",
      "Epoch: 10546, MSE: 0.248071378292381, Learning Rate: 0.047270000000000006\n",
      "Epoch: 10547, MSE: 0.24806874599332282, Learning Rate: 0.047265\n",
      "Epoch: 10548, MSE: 0.24806611364744116, Learning Rate: 0.04726\n",
      "Epoch: 10549, MSE: 0.24806348125473823, Learning Rate: 0.047255000000000005\n",
      "Epoch: 10550, MSE: 0.2480608488152166, Learning Rate: 0.04725000000000001\n",
      "Epoch: 10551, MSE: 0.2480582163288779, Learning Rate: 0.04724500000000001\n",
      "Epoch: 10552, MSE: 0.24805558379572593, Learning Rate: 0.047240000000000004\n",
      "Epoch: 10553, MSE: 0.2480529512157605, Learning Rate: 0.047235000000000006\n",
      "Epoch: 10554, MSE: 0.24805031858898474, Learning Rate: 0.04723000000000001\n",
      "Epoch: 10555, MSE: 0.2480476859154008, Learning Rate: 0.047224999999999996\n",
      "Epoch: 10556, MSE: 0.248045053195011, Learning Rate: 0.04722\n",
      "Epoch: 10557, MSE: 0.24804242042781663, Learning Rate: 0.047215\n",
      "Epoch: 10558, MSE: 0.24803978761382053, Learning Rate: 0.04721\n",
      "Epoch: 10559, MSE: 0.24803715475302462, Learning Rate: 0.047205\n",
      "Epoch: 10560, MSE: 0.2480345218454313, Learning Rate: 0.0472\n",
      "Epoch: 10561, MSE: 0.2480318888910424, Learning Rate: 0.047195\n",
      "Epoch: 10562, MSE: 0.24802925588985977, Learning Rate: 0.04719\n",
      "Epoch: 10563, MSE: 0.24802662284188556, Learning Rate: 0.047185000000000005\n",
      "Epoch: 10564, MSE: 0.24802398974712275, Learning Rate: 0.04718\n",
      "Epoch: 10565, MSE: 0.24802135660557287, Learning Rate: 0.047175\n",
      "Epoch: 10566, MSE: 0.24801872341723685, Learning Rate: 0.047170000000000004\n",
      "Epoch: 10567, MSE: 0.24801609018211973, Learning Rate: 0.047165000000000006\n",
      "Epoch: 10568, MSE: 0.24801345690022045, Learning Rate: 0.04716000000000001\n",
      "Epoch: 10569, MSE: 0.24801082357154322, Learning Rate: 0.047155\n",
      "Epoch: 10570, MSE: 0.24800819019608947, Learning Rate: 0.047150000000000004\n",
      "Epoch: 10571, MSE: 0.24800555677386088, Learning Rate: 0.047145000000000006\n",
      "Epoch: 10572, MSE: 0.2480029233048606, Learning Rate: 0.04714000000000001\n",
      "Epoch: 10573, MSE: 0.24800028978908997, Learning Rate: 0.04713500000000001\n",
      "Epoch: 10574, MSE: 0.24799765622655082, Learning Rate: 0.047130000000000005\n",
      "Epoch: 10575, MSE: 0.2479950226172472, Learning Rate: 0.047125\n",
      "Epoch: 10576, MSE: 0.24799238896117884, Learning Rate: 0.047119999999999995\n",
      "Epoch: 10577, MSE: 0.24798975525834882, Learning Rate: 0.047115\n",
      "Epoch: 10578, MSE: 0.2479871215087597, Learning Rate: 0.04711\n",
      "Epoch: 10579, MSE: 0.247984487712413, Learning Rate: 0.047105\n",
      "Epoch: 10580, MSE: 0.24798185386931068, Learning Rate: 0.0471\n",
      "Epoch: 10581, MSE: 0.2479792199794554, Learning Rate: 0.047095\n",
      "Epoch: 10582, MSE: 0.24797658604284933, Learning Rate: 0.04709\n",
      "Epoch: 10583, MSE: 0.24797395205949502, Learning Rate: 0.047085\n",
      "Epoch: 10584, MSE: 0.2479713180293929, Learning Rate: 0.047080000000000004\n",
      "Epoch: 10585, MSE: 0.24796868395254695, Learning Rate: 0.047075000000000006\n",
      "Epoch: 10586, MSE: 0.24796604982895754, Learning Rate: 0.04707\n",
      "Epoch: 10587, MSE: 0.24796341565862878, Learning Rate: 0.047065\n",
      "Epoch: 10588, MSE: 0.24796078144156142, Learning Rate: 0.047060000000000005\n",
      "Epoch: 10589, MSE: 0.24795814717775735, Learning Rate: 0.04705500000000001\n",
      "Epoch: 10590, MSE: 0.2479555128672204, Learning Rate: 0.04705000000000001\n",
      "Epoch: 10591, MSE: 0.24795287850995124, Learning Rate: 0.047045000000000003\n",
      "Epoch: 10592, MSE: 0.24795024410595215, Learning Rate: 0.047040000000000005\n",
      "Epoch: 10593, MSE: 0.24794760965522566, Learning Rate: 0.04703500000000001\n",
      "Epoch: 10594, MSE: 0.2479449751577736, Learning Rate: 0.04703000000000001\n",
      "Epoch: 10595, MSE: 0.24794234061359866, Learning Rate: 0.047025\n",
      "Epoch: 10596, MSE: 0.24793970602270216, Learning Rate: 0.04702\n",
      "Epoch: 10597, MSE: 0.24793707138508703, Learning Rate: 0.047015\n",
      "Epoch: 10598, MSE: 0.24793443670075452, Learning Rate: 0.047009999999999996\n",
      "Epoch: 10599, MSE: 0.24793180196970813, Learning Rate: 0.047005\n",
      "Epoch: 10600, MSE: 0.2479291671919486, Learning Rate: 0.047\n",
      "Epoch: 10601, MSE: 0.24792653236747847, Learning Rate: 0.046995\n",
      "Epoch: 10602, MSE: 0.24792389749630028, Learning Rate: 0.046990000000000004\n",
      "Epoch: 10603, MSE: 0.24792126257841593, Learning Rate: 0.046985\n",
      "Epoch: 10604, MSE: 0.24791862761382732, Learning Rate: 0.04698\n",
      "Epoch: 10605, MSE: 0.24791599260253652, Learning Rate: 0.046975\n",
      "Epoch: 10606, MSE: 0.24791335754454683, Learning Rate: 0.046970000000000005\n",
      "Epoch: 10607, MSE: 0.24791072243985873, Learning Rate: 0.04696500000000001\n",
      "Epoch: 10608, MSE: 0.24790808728847552, Learning Rate: 0.04696\n",
      "Epoch: 10609, MSE: 0.24790545209039858, Learning Rate: 0.046955000000000004\n",
      "Epoch: 10610, MSE: 0.2479028168456303, Learning Rate: 0.046950000000000006\n",
      "Epoch: 10611, MSE: 0.2479001815541736, Learning Rate: 0.04694500000000001\n",
      "Epoch: 10612, MSE: 0.24789754621602986, Learning Rate: 0.04694000000000001\n",
      "Epoch: 10613, MSE: 0.24789491083120244, Learning Rate: 0.046935000000000004\n",
      "Epoch: 10614, MSE: 0.24789227539969041, Learning Rate: 0.046930000000000006\n",
      "Epoch: 10615, MSE: 0.24788963992149857, Learning Rate: 0.046924999999999994\n",
      "Epoch: 10616, MSE: 0.24788700439662845, Learning Rate: 0.046919999999999996\n",
      "Epoch: 10617, MSE: 0.24788436882508263, Learning Rate: 0.046915\n",
      "Epoch: 10618, MSE: 0.24788173320686227, Learning Rate: 0.04691\n",
      "Epoch: 10619, MSE: 0.2478790975419701, Learning Rate: 0.046905\n",
      "Epoch: 10620, MSE: 0.2478764618304079, Learning Rate: 0.0469\n",
      "Epoch: 10621, MSE: 0.24787382607217925, Learning Rate: 0.046895\n",
      "Epoch: 10622, MSE: 0.24787119026728405, Learning Rate: 0.04689\n",
      "Epoch: 10623, MSE: 0.2478685544157256, Learning Rate: 0.046885\n",
      "Epoch: 10624, MSE: 0.2478659185175063, Learning Rate: 0.046880000000000005\n",
      "Epoch: 10625, MSE: 0.24786328257262843, Learning Rate: 0.046875\n",
      "Epoch: 10626, MSE: 0.24786064658109278, Learning Rate: 0.04687\n",
      "Epoch: 10627, MSE: 0.24785801054290257, Learning Rate: 0.046865000000000004\n",
      "Epoch: 10628, MSE: 0.24785537445806038, Learning Rate: 0.046860000000000006\n",
      "Epoch: 10629, MSE: 0.2478527383265678, Learning Rate: 0.04685500000000001\n",
      "Epoch: 10630, MSE: 0.24785010214842676, Learning Rate: 0.04685\n",
      "Epoch: 10631, MSE: 0.24784746592363952, Learning Rate: 0.046845000000000005\n",
      "Epoch: 10632, MSE: 0.24784482965220866, Learning Rate: 0.04684000000000001\n",
      "Epoch: 10633, MSE: 0.24784219333413615, Learning Rate: 0.04683500000000001\n",
      "Epoch: 10634, MSE: 0.24783955696942378, Learning Rate: 0.04683000000000001\n",
      "Epoch: 10635, MSE: 0.2478369205580739, Learning Rate: 0.046825000000000006\n",
      "Epoch: 10636, MSE: 0.24783428410008873, Learning Rate: 0.04682\n",
      "Epoch: 10637, MSE: 0.2478316475954706, Learning Rate: 0.046814999999999996\n",
      "Epoch: 10638, MSE: 0.24782901104422142, Learning Rate: 0.04681\n",
      "Epoch: 10639, MSE: 0.24782637444634323, Learning Rate: 0.046805\n",
      "Epoch: 10640, MSE: 0.24782373780183817, Learning Rate: 0.0468\n",
      "Epoch: 10641, MSE: 0.2478211011107093, Learning Rate: 0.046795\n",
      "Epoch: 10642, MSE: 0.24781846437295796, Learning Rate: 0.04679\n",
      "Epoch: 10643, MSE: 0.24781582758858542, Learning Rate: 0.046785\n",
      "Epoch: 10644, MSE: 0.24781319075759556, Learning Rate: 0.04678\n",
      "Epoch: 10645, MSE: 0.24781055387999043, Learning Rate: 0.046775000000000004\n",
      "Epoch: 10646, MSE: 0.24780791695577087, Learning Rate: 0.046770000000000006\n",
      "Epoch: 10647, MSE: 0.24780527998494029, Learning Rate: 0.046765\n",
      "Epoch: 10648, MSE: 0.24780264296749963, Learning Rate: 0.04676\n",
      "Epoch: 10649, MSE: 0.24780000590345216, Learning Rate: 0.046755000000000005\n",
      "Epoch: 10650, MSE: 0.24779736879279937, Learning Rate: 0.04675000000000001\n",
      "Epoch: 10651, MSE: 0.24779473163554433, Learning Rate: 0.04674500000000001\n",
      "Epoch: 10652, MSE: 0.24779209443168793, Learning Rate: 0.046740000000000004\n",
      "Epoch: 10653, MSE: 0.2477894571812335, Learning Rate: 0.046735000000000006\n",
      "Epoch: 10654, MSE: 0.24778681988418236, Learning Rate: 0.04673000000000001\n",
      "Epoch: 10655, MSE: 0.2477841825405371, Learning Rate: 0.04672500000000001\n",
      "Epoch: 10656, MSE: 0.2477815451502997, Learning Rate: 0.04672\n",
      "Epoch: 10657, MSE: 0.24777890771347189, Learning Rate: 0.046715\n",
      "Epoch: 10658, MSE: 0.24777627023005727, Learning Rate: 0.04671\n",
      "Epoch: 10659, MSE: 0.24777363270005692, Learning Rate: 0.046704999999999997\n",
      "Epoch: 10660, MSE: 0.2477709951234729, Learning Rate: 0.0467\n",
      "Epoch: 10661, MSE: 0.24776835750030746, Learning Rate: 0.046695\n",
      "Epoch: 10662, MSE: 0.2477657198305638, Learning Rate: 0.04669\n",
      "Epoch: 10663, MSE: 0.24776308211424286, Learning Rate: 0.046685000000000004\n",
      "Epoch: 10664, MSE: 0.24776044435134634, Learning Rate: 0.04668\n",
      "Epoch: 10665, MSE: 0.24775780654187857, Learning Rate: 0.046675\n",
      "Epoch: 10666, MSE: 0.24775516868583997, Learning Rate: 0.04667\n",
      "Epoch: 10667, MSE: 0.24775253078323242, Learning Rate: 0.046665000000000005\n",
      "Epoch: 10668, MSE: 0.2477498928340605, Learning Rate: 0.04666000000000001\n",
      "Epoch: 10669, MSE: 0.24774725483832366, Learning Rate: 0.046655\n",
      "Epoch: 10670, MSE: 0.24774461679602489, Learning Rate: 0.046650000000000004\n",
      "Epoch: 10671, MSE: 0.24774197870716735, Learning Rate: 0.046645000000000006\n",
      "Epoch: 10672, MSE: 0.24773934057175276, Learning Rate: 0.04664000000000001\n",
      "Epoch: 10673, MSE: 0.2477367023897818, Learning Rate: 0.04663500000000001\n",
      "Epoch: 10674, MSE: 0.2477340641612587, Learning Rate: 0.046630000000000005\n",
      "Epoch: 10675, MSE: 0.24773142588618502, Learning Rate: 0.04662500000000001\n",
      "Epoch: 10676, MSE: 0.24772878756456268, Learning Rate: 0.046619999999999995\n",
      "Epoch: 10677, MSE: 0.2477261491963933, Learning Rate: 0.046615\n",
      "Epoch: 10678, MSE: 0.24772351078168015, Learning Rate: 0.04661\n",
      "Epoch: 10679, MSE: 0.24772087232042478, Learning Rate: 0.046605\n",
      "Epoch: 10680, MSE: 0.24771823381262953, Learning Rate: 0.0466\n",
      "Epoch: 10681, MSE: 0.24771559525829703, Learning Rate: 0.046595\n",
      "Epoch: 10682, MSE: 0.24771295665742865, Learning Rate: 0.04659\n",
      "Epoch: 10683, MSE: 0.247710318010027, Learning Rate: 0.046585\n",
      "Epoch: 10684, MSE: 0.24770767931609358, Learning Rate: 0.04658\n",
      "Epoch: 10685, MSE: 0.24770504057563175, Learning Rate: 0.046575000000000005\n",
      "Epoch: 10686, MSE: 0.24770240178864342, Learning Rate: 0.04657\n",
      "Epoch: 10687, MSE: 0.24769976295512958, Learning Rate: 0.046565\n",
      "Epoch: 10688, MSE: 0.24769712407509398, Learning Rate: 0.046560000000000004\n",
      "Epoch: 10689, MSE: 0.24769448514853812, Learning Rate: 0.046555000000000006\n",
      "Epoch: 10690, MSE: 0.24769184617546428, Learning Rate: 0.04655000000000001\n",
      "Epoch: 10691, MSE: 0.24768920715587425, Learning Rate: 0.046545\n",
      "Epoch: 10692, MSE: 0.2476865680897707, Learning Rate: 0.046540000000000005\n",
      "Epoch: 10693, MSE: 0.24768392897715555, Learning Rate: 0.04653500000000001\n",
      "Epoch: 10694, MSE: 0.24768128981803145, Learning Rate: 0.04653000000000001\n",
      "Epoch: 10695, MSE: 0.24767865061239988, Learning Rate: 0.04652500000000001\n",
      "Epoch: 10696, MSE: 0.2476760113602632, Learning Rate: 0.04652\n",
      "Epoch: 10697, MSE: 0.2476733720616243, Learning Rate: 0.046515\n",
      "Epoch: 10698, MSE: 0.2476707327164842, Learning Rate: 0.046509999999999996\n",
      "Epoch: 10699, MSE: 0.24766809332484635, Learning Rate: 0.046505\n",
      "Epoch: 10700, MSE: 0.24766545388671196, Learning Rate: 0.0465\n",
      "Epoch: 10701, MSE: 0.24766281440208354, Learning Rate: 0.046495\n",
      "Epoch: 10702, MSE: 0.24766017487096353, Learning Rate: 0.046490000000000004\n",
      "Epoch: 10703, MSE: 0.24765753529335388, Learning Rate: 0.046485\n",
      "Epoch: 10704, MSE: 0.24765489566925689, Learning Rate: 0.04648\n",
      "Epoch: 10705, MSE: 0.24765225599867494, Learning Rate: 0.046475\n",
      "Epoch: 10706, MSE: 0.24764961628160959, Learning Rate: 0.046470000000000004\n",
      "Epoch: 10707, MSE: 0.24764697651806386, Learning Rate: 0.046465000000000006\n",
      "Epoch: 10708, MSE: 0.247644336708039, Learning Rate: 0.04646\n",
      "Epoch: 10709, MSE: 0.24764169685153717, Learning Rate: 0.046455\n",
      "Epoch: 10710, MSE: 0.24763905694856211, Learning Rate: 0.046450000000000005\n",
      "Epoch: 10711, MSE: 0.2476364169991146, Learning Rate: 0.04644500000000001\n",
      "Epoch: 10712, MSE: 0.24763377700319708, Learning Rate: 0.04644000000000001\n",
      "Epoch: 10713, MSE: 0.24763113696081204, Learning Rate: 0.046435000000000004\n",
      "Epoch: 10714, MSE: 0.24762849687196195, Learning Rate: 0.046430000000000006\n",
      "Epoch: 10715, MSE: 0.24762585673664772, Learning Rate: 0.04642500000000001\n",
      "Epoch: 10716, MSE: 0.24762321655487354, Learning Rate: 0.046419999999999996\n",
      "Epoch: 10717, MSE: 0.24762057632664008, Learning Rate: 0.046415\n",
      "Epoch: 10718, MSE: 0.24761793605194976, Learning Rate: 0.04641\n",
      "Epoch: 10719, MSE: 0.2476152957308048, Learning Rate: 0.046405\n",
      "Epoch: 10720, MSE: 0.2476126553632079, Learning Rate: 0.0464\n",
      "Epoch: 10721, MSE: 0.24761001494916118, Learning Rate: 0.046395\n",
      "Epoch: 10722, MSE: 0.2476073744886662, Learning Rate: 0.04639\n",
      "Epoch: 10723, MSE: 0.24760473398172572, Learning Rate: 0.046385\n",
      "Epoch: 10724, MSE: 0.2476020934283416, Learning Rate: 0.046380000000000005\n",
      "Epoch: 10725, MSE: 0.2475994528285167, Learning Rate: 0.046375\n",
      "Epoch: 10726, MSE: 0.24759681218225246, Learning Rate: 0.04637\n",
      "Epoch: 10727, MSE: 0.2475941714895515, Learning Rate: 0.046365\n",
      "Epoch: 10728, MSE: 0.2475915307504156, Learning Rate: 0.046360000000000005\n",
      "Epoch: 10729, MSE: 0.24758888996484812, Learning Rate: 0.04635500000000001\n",
      "Epoch: 10730, MSE: 0.24758624913284985, Learning Rate: 0.04635\n",
      "Epoch: 10731, MSE: 0.24758360825442322, Learning Rate: 0.046345000000000004\n",
      "Epoch: 10732, MSE: 0.2475809673295712, Learning Rate: 0.046340000000000006\n",
      "Epoch: 10733, MSE: 0.24757832635829535, Learning Rate: 0.04633500000000001\n",
      "Epoch: 10734, MSE: 0.247575685340598, Learning Rate: 0.04633000000000001\n",
      "Epoch: 10735, MSE: 0.24757304427648197, Learning Rate: 0.046325000000000005\n",
      "Epoch: 10736, MSE: 0.24757040316594886, Learning Rate: 0.04632\n",
      "Epoch: 10737, MSE: 0.2475677620090008, Learning Rate: 0.046314999999999995\n",
      "Epoch: 10738, MSE: 0.24756512080564036, Learning Rate: 0.04631\n",
      "Epoch: 10739, MSE: 0.24756247955586924, Learning Rate: 0.046305\n",
      "Epoch: 10740, MSE: 0.24755983825969025, Learning Rate: 0.0463\n",
      "Epoch: 10741, MSE: 0.2475571969171057, Learning Rate: 0.046295\n",
      "Epoch: 10742, MSE: 0.24755455552811706, Learning Rate: 0.04629\n",
      "Epoch: 10743, MSE: 0.24755191409272675, Learning Rate: 0.046285\n",
      "Epoch: 10744, MSE: 0.24754927261093795, Learning Rate: 0.04628\n",
      "Epoch: 10745, MSE: 0.24754663108275138, Learning Rate: 0.046275000000000004\n",
      "Epoch: 10746, MSE: 0.24754398950817008, Learning Rate: 0.046270000000000006\n",
      "Epoch: 10747, MSE: 0.24754134788719645, Learning Rate: 0.046265\n",
      "Epoch: 10748, MSE: 0.24753870621983182, Learning Rate: 0.04626\n",
      "Epoch: 10749, MSE: 0.24753606450608004, Learning Rate: 0.046255000000000004\n",
      "Epoch: 10750, MSE: 0.24753342274594192, Learning Rate: 0.046250000000000006\n",
      "Epoch: 10751, MSE: 0.24753078093941924, Learning Rate: 0.04624500000000001\n",
      "Epoch: 10752, MSE: 0.24752813908651528, Learning Rate: 0.04624\n",
      "Epoch: 10753, MSE: 0.24752549718723257, Learning Rate: 0.046235000000000005\n",
      "Epoch: 10754, MSE: 0.24752285524157241, Learning Rate: 0.04623000000000001\n",
      "Epoch: 10755, MSE: 0.24752021324953716, Learning Rate: 0.04622500000000001\n",
      "Epoch: 10756, MSE: 0.24751757121113005, Learning Rate: 0.04622000000000001\n",
      "Epoch: 10757, MSE: 0.24751492912635134, Learning Rate: 0.046215\n",
      "Epoch: 10758, MSE: 0.2475122869952048, Learning Rate: 0.04621\n",
      "Epoch: 10759, MSE: 0.24750964481769325, Learning Rate: 0.046204999999999996\n",
      "Epoch: 10760, MSE: 0.24750700259381653, Learning Rate: 0.0462\n",
      "Epoch: 10761, MSE: 0.24750436032357934, Learning Rate: 0.046195\n",
      "Epoch: 10762, MSE: 0.24750171800698256, Learning Rate: 0.04619\n",
      "Epoch: 10763, MSE: 0.247499075644028, Learning Rate: 0.046185000000000004\n",
      "Epoch: 10764, MSE: 0.24749643323471968, Learning Rate: 0.04618\n",
      "Epoch: 10765, MSE: 0.2474937907790579, Learning Rate: 0.046175\n",
      "Epoch: 10766, MSE: 0.24749114827704588, Learning Rate: 0.04617\n",
      "Epoch: 10767, MSE: 0.24748850572868564, Learning Rate: 0.046165000000000005\n",
      "Epoch: 10768, MSE: 0.24748586313397913, Learning Rate: 0.04616000000000001\n",
      "Epoch: 10769, MSE: 0.24748322049292953, Learning Rate: 0.046155\n",
      "Epoch: 10770, MSE: 0.24748057780553756, Learning Rate: 0.046150000000000004\n",
      "Epoch: 10771, MSE: 0.24747793507180693, Learning Rate: 0.046145000000000005\n",
      "Epoch: 10772, MSE: 0.24747529229173904, Learning Rate: 0.04614000000000001\n",
      "Epoch: 10773, MSE: 0.24747264946533606, Learning Rate: 0.04613500000000001\n",
      "Epoch: 10774, MSE: 0.2474700065926012, Learning Rate: 0.046130000000000004\n",
      "Epoch: 10775, MSE: 0.24746736367353533, Learning Rate: 0.046125000000000006\n",
      "Epoch: 10776, MSE: 0.24746472070814196, Learning Rate: 0.04612000000000001\n",
      "Epoch: 10777, MSE: 0.24746207769642187, Learning Rate: 0.046114999999999996\n",
      "Epoch: 10778, MSE: 0.24745943463837897, Learning Rate: 0.04611\n",
      "Epoch: 10779, MSE: 0.24745679153401434, Learning Rate: 0.046105\n",
      "Epoch: 10780, MSE: 0.24745414838332958, Learning Rate: 0.0461\n",
      "Epoch: 10781, MSE: 0.24745150518632833, Learning Rate: 0.046095\n",
      "Epoch: 10782, MSE: 0.24744886194301258, Learning Rate: 0.04609\n",
      "Epoch: 10783, MSE: 0.24744621865338448, Learning Rate: 0.046085\n",
      "Epoch: 10784, MSE: 0.24744357531744596, Learning Rate: 0.04608\n",
      "Epoch: 10785, MSE: 0.24744093193519906, Learning Rate: 0.046075000000000005\n",
      "Epoch: 10786, MSE: 0.24743828850664693, Learning Rate: 0.04607\n",
      "Epoch: 10787, MSE: 0.24743564503179, Learning Rate: 0.046065\n",
      "Epoch: 10788, MSE: 0.24743300151063283, Learning Rate: 0.046060000000000004\n",
      "Epoch: 10789, MSE: 0.24743035794317686, Learning Rate: 0.046055000000000006\n",
      "Epoch: 10790, MSE: 0.24742771432942276, Learning Rate: 0.04605000000000001\n",
      "Epoch: 10791, MSE: 0.24742507066937544, Learning Rate: 0.046045\n",
      "Epoch: 10792, MSE: 0.24742242696303507, Learning Rate: 0.046040000000000005\n",
      "Epoch: 10793, MSE: 0.24741978321040484, Learning Rate: 0.046035000000000006\n",
      "Epoch: 10794, MSE: 0.24741713941148583, Learning Rate: 0.04603000000000001\n",
      "Epoch: 10795, MSE: 0.24741449556628148, Learning Rate: 0.04602500000000001\n",
      "Epoch: 10796, MSE: 0.24741185167479418, Learning Rate: 0.046020000000000005\n",
      "Epoch: 10797, MSE: 0.24740920773702604, Learning Rate: 0.046015\n",
      "Epoch: 10798, MSE: 0.24740656375297831, Learning Rate: 0.046009999999999995\n",
      "Epoch: 10799, MSE: 0.24740391972265338, Learning Rate: 0.046005\n",
      "Epoch: 10800, MSE: 0.24740127564605519, Learning Rate: 0.046\n",
      "Epoch: 10801, MSE: 0.24739863152318411, Learning Rate: 0.045995\n",
      "Epoch: 10802, MSE: 0.2473959873540433, Learning Rate: 0.04599\n",
      "Epoch: 10803, MSE: 0.24739334313863443, Learning Rate: 0.045985\n",
      "Epoch: 10804, MSE: 0.24739069887696039, Learning Rate: 0.04598\n",
      "Epoch: 10805, MSE: 0.2473880545690234, Learning Rate: 0.045975\n",
      "Epoch: 10806, MSE: 0.2473854102148252, Learning Rate: 0.045970000000000004\n",
      "Epoch: 10807, MSE: 0.24738276581436774, Learning Rate: 0.045965000000000006\n",
      "Epoch: 10808, MSE: 0.24738012136765447, Learning Rate: 0.04596\n",
      "Epoch: 10809, MSE: 0.2473774768746873, Learning Rate: 0.045955\n",
      "Epoch: 10810, MSE: 0.24737483233546717, Learning Rate: 0.045950000000000005\n",
      "Epoch: 10811, MSE: 0.24737218774999778, Learning Rate: 0.04594500000000001\n",
      "Epoch: 10812, MSE: 0.24736954311828122, Learning Rate: 0.04594000000000001\n",
      "Epoch: 10813, MSE: 0.24736689844031817, Learning Rate: 0.045935000000000004\n",
      "Epoch: 10814, MSE: 0.2473642537161125, Learning Rate: 0.045930000000000006\n",
      "Epoch: 10815, MSE: 0.24736160894566714, Learning Rate: 0.04592500000000001\n",
      "Epoch: 10816, MSE: 0.2473589641289825, Learning Rate: 0.04592000000000001\n",
      "Epoch: 10817, MSE: 0.24735631926606153, Learning Rate: 0.045915\n",
      "Epoch: 10818, MSE: 0.24735367435690758, Learning Rate: 0.04591\n",
      "Epoch: 10819, MSE: 0.2473510294015211, Learning Rate: 0.045905\n",
      "Epoch: 10820, MSE: 0.2473483843999058, Learning Rate: 0.045899999999999996\n",
      "Epoch: 10821, MSE: 0.24734573935206236, Learning Rate: 0.045895\n",
      "Epoch: 10822, MSE: 0.2473430942579946, Learning Rate: 0.04589\n",
      "Epoch: 10823, MSE: 0.2473404491177042, Learning Rate: 0.045885\n",
      "Epoch: 10824, MSE: 0.24733780393119253, Learning Rate: 0.045880000000000004\n",
      "Epoch: 10825, MSE: 0.24733515869846295, Learning Rate: 0.045875\n",
      "Epoch: 10826, MSE: 0.2473325134195185, Learning Rate: 0.04587\n",
      "Epoch: 10827, MSE: 0.247329868094359, Learning Rate: 0.045865\n",
      "Epoch: 10828, MSE: 0.24732722272298907, Learning Rate: 0.045860000000000005\n",
      "Epoch: 10829, MSE: 0.24732457730540894, Learning Rate: 0.04585500000000001\n",
      "Epoch: 10830, MSE: 0.24732193184162302, Learning Rate: 0.04585\n",
      "Epoch: 10831, MSE: 0.24731928633163222, Learning Rate: 0.045845000000000004\n",
      "Epoch: 10832, MSE: 0.2473166407754383, Learning Rate: 0.045840000000000006\n",
      "Epoch: 10833, MSE: 0.24731399517304473, Learning Rate: 0.04583500000000001\n",
      "Epoch: 10834, MSE: 0.24731134952445333, Learning Rate: 0.04583000000000001\n",
      "Epoch: 10835, MSE: 0.2473087038296666, Learning Rate: 0.045825000000000005\n",
      "Epoch: 10836, MSE: 0.24730605808868614, Learning Rate: 0.04582000000000001\n",
      "Epoch: 10837, MSE: 0.24730341230151387, Learning Rate: 0.045814999999999995\n",
      "Epoch: 10838, MSE: 0.2473007664681547, Learning Rate: 0.04581\n",
      "Epoch: 10839, MSE: 0.24729812058860748, Learning Rate: 0.045805\n",
      "Epoch: 10840, MSE: 0.24729547466287655, Learning Rate: 0.0458\n",
      "Epoch: 10841, MSE: 0.24729282869096395, Learning Rate: 0.045795\n",
      "Epoch: 10842, MSE: 0.24729018267287073, Learning Rate: 0.04579\n",
      "Epoch: 10843, MSE: 0.2472875366086006, Learning Rate: 0.045785\n",
      "Epoch: 10844, MSE: 0.24728489049815527, Learning Rate: 0.04578\n",
      "Epoch: 10845, MSE: 0.24728224434153667, Learning Rate: 0.045775\n",
      "Epoch: 10846, MSE: 0.24727959813874759, Learning Rate: 0.045770000000000005\n",
      "Epoch: 10847, MSE: 0.24727695188978968, Learning Rate: 0.045765\n",
      "Epoch: 10848, MSE: 0.24727430559466643, Learning Rate: 0.04576\n",
      "Epoch: 10849, MSE: 0.24727165925337954, Learning Rate: 0.045755000000000004\n",
      "Epoch: 10850, MSE: 0.24726901286592964, Learning Rate: 0.045750000000000006\n",
      "Epoch: 10851, MSE: 0.24726636643232086, Learning Rate: 0.04574500000000001\n",
      "Epoch: 10852, MSE: 0.24726371995255583, Learning Rate: 0.04574\n",
      "Epoch: 10853, MSE: 0.24726107342663564, Learning Rate: 0.045735000000000005\n",
      "Epoch: 10854, MSE: 0.24725842685456287, Learning Rate: 0.04573000000000001\n",
      "Epoch: 10855, MSE: 0.24725578023633984, Learning Rate: 0.04572500000000001\n",
      "Epoch: 10856, MSE: 0.24725313357196857, Learning Rate: 0.04572000000000001\n",
      "Epoch: 10857, MSE: 0.24725048686145143, Learning Rate: 0.045715\n",
      "Epoch: 10858, MSE: 0.24724784010479156, Learning Rate: 0.04571\n",
      "Epoch: 10859, MSE: 0.24724519330199005, Learning Rate: 0.045704999999999996\n",
      "Epoch: 10860, MSE: 0.24724254645305033, Learning Rate: 0.0457\n",
      "Epoch: 10861, MSE: 0.24723989955797326, Learning Rate: 0.045695\n",
      "Epoch: 10862, MSE: 0.24723725261676222, Learning Rate: 0.04569\n",
      "Epoch: 10863, MSE: 0.24723460562941912, Learning Rate: 0.045685\n",
      "Epoch: 10864, MSE: 0.2472319585959459, Learning Rate: 0.04568\n",
      "Epoch: 10865, MSE: 0.24722931151634614, Learning Rate: 0.045675\n",
      "Epoch: 10866, MSE: 0.24722666439062008, Learning Rate: 0.04567\n",
      "Epoch: 10867, MSE: 0.247224017218772, Learning Rate: 0.045665000000000004\n",
      "Epoch: 10868, MSE: 0.24722137000080235, Learning Rate: 0.045660000000000006\n",
      "Epoch: 10869, MSE: 0.2472187227367145, Learning Rate: 0.045655\n",
      "Epoch: 10870, MSE: 0.2472160754265111, Learning Rate: 0.04565\n",
      "Epoch: 10871, MSE: 0.24721342807019334, Learning Rate: 0.045645000000000005\n",
      "Epoch: 10872, MSE: 0.24721078066776453, Learning Rate: 0.04564000000000001\n",
      "Epoch: 10873, MSE: 0.24720813321922613, Learning Rate: 0.04563500000000001\n",
      "Epoch: 10874, MSE: 0.24720548572458095, Learning Rate: 0.045630000000000004\n",
      "Epoch: 10875, MSE: 0.24720283818383124, Learning Rate: 0.045625000000000006\n",
      "Epoch: 10876, MSE: 0.2472001905969784, Learning Rate: 0.04562000000000001\n",
      "Epoch: 10877, MSE: 0.24719754296402577, Learning Rate: 0.04561500000000001\n",
      "Epoch: 10878, MSE: 0.2471948952849754, Learning Rate: 0.04561\n",
      "Epoch: 10879, MSE: 0.24719224755983027, Learning Rate: 0.045605\n",
      "Epoch: 10880, MSE: 0.24718959978859117, Learning Rate: 0.0456\n",
      "Epoch: 10881, MSE: 0.2471869519712616, Learning Rate: 0.045595\n",
      "Epoch: 10882, MSE: 0.24718430410784203, Learning Rate: 0.04559\n",
      "Epoch: 10883, MSE: 0.2471816561983374, Learning Rate: 0.045585\n",
      "Epoch: 10884, MSE: 0.24717900824274777, Learning Rate: 0.04558\n",
      "Epoch: 10885, MSE: 0.247176360241077, Learning Rate: 0.045575000000000004\n",
      "Epoch: 10886, MSE: 0.24717371219332585, Learning Rate: 0.04557\n",
      "Epoch: 10887, MSE: 0.2471710640994985, Learning Rate: 0.045565\n",
      "Epoch: 10888, MSE: 0.2471684159595957, Learning Rate: 0.04556\n",
      "Epoch: 10889, MSE: 0.24716576777362018, Learning Rate: 0.045555000000000005\n",
      "Epoch: 10890, MSE: 0.24716311954157416, Learning Rate: 0.04555000000000001\n",
      "Epoch: 10891, MSE: 0.24716047126346002, Learning Rate: 0.045545\n",
      "Epoch: 10892, MSE: 0.24715782293928032, Learning Rate: 0.045540000000000004\n",
      "Epoch: 10893, MSE: 0.24715517456903763, Learning Rate: 0.045535000000000006\n",
      "Epoch: 10894, MSE: 0.24715252615273284, Learning Rate: 0.04553000000000001\n",
      "Epoch: 10895, MSE: 0.24714987769036947, Learning Rate: 0.04552500000000001\n",
      "Epoch: 10896, MSE: 0.24714722918194995, Learning Rate: 0.045520000000000005\n",
      "Epoch: 10897, MSE: 0.2471445806274761, Learning Rate: 0.04551500000000001\n",
      "Epoch: 10898, MSE: 0.24714193202694945, Learning Rate: 0.045509999999999995\n",
      "Epoch: 10899, MSE: 0.24713928338037322, Learning Rate: 0.045505\n",
      "Epoch: 10900, MSE: 0.2471366346877501, Learning Rate: 0.0455\n",
      "Epoch: 10901, MSE: 0.24713398594908179, Learning Rate: 0.045495\n",
      "Epoch: 10902, MSE: 0.24713133716437036, Learning Rate: 0.04549\n",
      "Epoch: 10903, MSE: 0.24712868833361865, Learning Rate: 0.045485\n",
      "Epoch: 10904, MSE: 0.24712603945682846, Learning Rate: 0.04548\n",
      "Epoch: 10905, MSE: 0.24712339053400195, Learning Rate: 0.045475\n",
      "Epoch: 10906, MSE: 0.24712074156514222, Learning Rate: 0.045470000000000003\n",
      "Epoch: 10907, MSE: 0.24711809255025094, Learning Rate: 0.045465000000000005\n",
      "Epoch: 10908, MSE: 0.24711544348933076, Learning Rate: 0.04546\n",
      "Epoch: 10909, MSE: 0.2471127943823841, Learning Rate: 0.045455\n",
      "Epoch: 10910, MSE: 0.24711014522941313, Learning Rate: 0.045450000000000004\n",
      "Epoch: 10911, MSE: 0.24710749603041915, Learning Rate: 0.045445000000000006\n",
      "Epoch: 10912, MSE: 0.2471048467854055, Learning Rate: 0.04544000000000001\n",
      "Epoch: 10913, MSE: 0.24710219749437506, Learning Rate: 0.045435\n",
      "Epoch: 10914, MSE: 0.24709954815732907, Learning Rate: 0.045430000000000005\n",
      "Epoch: 10915, MSE: 0.2470968987742697, Learning Rate: 0.04542500000000001\n",
      "Epoch: 10916, MSE: 0.24709424934520025, Learning Rate: 0.04542000000000001\n",
      "Epoch: 10917, MSE: 0.24709159987012247, Learning Rate: 0.04541500000000001\n",
      "Epoch: 10918, MSE: 0.24708895034903874, Learning Rate: 0.04541\n",
      "Epoch: 10919, MSE: 0.2470863007819518, Learning Rate: 0.045405\n",
      "Epoch: 10920, MSE: 0.24708365116886202, Learning Rate: 0.045399999999999996\n",
      "Epoch: 10921, MSE: 0.24708100150977408, Learning Rate: 0.045395\n",
      "Epoch: 10922, MSE: 0.24707835180468912, Learning Rate: 0.04539\n",
      "Epoch: 10923, MSE: 0.24707570205360968, Learning Rate: 0.045385\n",
      "Epoch: 10924, MSE: 0.24707305225653847, Learning Rate: 0.045380000000000004\n",
      "Epoch: 10925, MSE: 0.2470704024134771, Learning Rate: 0.045375\n",
      "Epoch: 10926, MSE: 0.24706775252442784, Learning Rate: 0.04537\n",
      "Epoch: 10927, MSE: 0.24706510258939393, Learning Rate: 0.045365\n",
      "Epoch: 10928, MSE: 0.247062452608377, Learning Rate: 0.045360000000000004\n",
      "Epoch: 10929, MSE: 0.24705980258137952, Learning Rate: 0.045355000000000006\n",
      "Epoch: 10930, MSE: 0.24705715250840274, Learning Rate: 0.04535\n",
      "Epoch: 10931, MSE: 0.2470545023894511, Learning Rate: 0.045345\n",
      "Epoch: 10932, MSE: 0.24705185222452564, Learning Rate: 0.045340000000000005\n",
      "Epoch: 10933, MSE: 0.24704920201362895, Learning Rate: 0.04533500000000001\n",
      "Epoch: 10934, MSE: 0.24704655175676302, Learning Rate: 0.04533000000000001\n",
      "Epoch: 10935, MSE: 0.2470439014539302, Learning Rate: 0.045325000000000004\n",
      "Epoch: 10936, MSE: 0.24704125110513306, Learning Rate: 0.045320000000000006\n",
      "Epoch: 10937, MSE: 0.24703860071037445, Learning Rate: 0.04531500000000001\n",
      "Epoch: 10938, MSE: 0.24703595026965453, Learning Rate: 0.045309999999999996\n",
      "Epoch: 10939, MSE: 0.24703329978297922, Learning Rate: 0.045305\n",
      "Epoch: 10940, MSE: 0.2470306492503468, Learning Rate: 0.0453\n",
      "Epoch: 10941, MSE: 0.24702799867176303, Learning Rate: 0.045295\n",
      "Epoch: 10942, MSE: 0.24702534804722806, Learning Rate: 0.04529\n",
      "Epoch: 10943, MSE: 0.24702269737674498, Learning Rate: 0.045285\n",
      "Epoch: 10944, MSE: 0.2470200466603156, Learning Rate: 0.04528\n",
      "Epoch: 10945, MSE: 0.24701739589794253, Learning Rate: 0.045275\n",
      "Epoch: 10946, MSE: 0.24701474508962945, Learning Rate: 0.045270000000000005\n",
      "Epoch: 10947, MSE: 0.2470120942353764, Learning Rate: 0.045265\n",
      "Epoch: 10948, MSE: 0.24700944333518746, Learning Rate: 0.04526\n",
      "Epoch: 10949, MSE: 0.2470067923890636, Learning Rate: 0.045255000000000004\n",
      "Epoch: 10950, MSE: 0.2470041413970088, Learning Rate: 0.045250000000000005\n",
      "Epoch: 10951, MSE: 0.24700149035902394, Learning Rate: 0.04524500000000001\n",
      "Epoch: 10952, MSE: 0.24699883927511118, Learning Rate: 0.04524\n",
      "Epoch: 10953, MSE: 0.24699618814527335, Learning Rate: 0.045235000000000004\n",
      "Epoch: 10954, MSE: 0.24699353696951395, Learning Rate: 0.045230000000000006\n",
      "Epoch: 10955, MSE: 0.24699088574783348, Learning Rate: 0.04522500000000001\n",
      "Epoch: 10956, MSE: 0.24698823448023538, Learning Rate: 0.04522000000000001\n",
      "Epoch: 10957, MSE: 0.2469855831667215, Learning Rate: 0.045215000000000005\n",
      "Epoch: 10958, MSE: 0.24698293180729414, Learning Rate: 0.04521\n",
      "Epoch: 10959, MSE: 0.2469802804019561, Learning Rate: 0.045204999999999995\n",
      "Epoch: 10960, MSE: 0.24697762895070902, Learning Rate: 0.0452\n",
      "Epoch: 10961, MSE: 0.24697497745355565, Learning Rate: 0.045195\n",
      "Epoch: 10962, MSE: 0.2469723259104988, Learning Rate: 0.04519\n",
      "Epoch: 10963, MSE: 0.2469696743215391, Learning Rate: 0.045185\n",
      "Epoch: 10964, MSE: 0.24696702268668067, Learning Rate: 0.04518\n",
      "Epoch: 10965, MSE: 0.2469643710059256, Learning Rate: 0.045175\n",
      "Epoch: 10966, MSE: 0.24696171927927552, Learning Rate: 0.04517\n",
      "Epoch: 10967, MSE: 0.24695906750673305, Learning Rate: 0.045165000000000004\n",
      "Epoch: 10968, MSE: 0.24695641568830073, Learning Rate: 0.045160000000000006\n",
      "Epoch: 10969, MSE: 0.24695376382397993, Learning Rate: 0.045155\n",
      "Epoch: 10970, MSE: 0.24695111191377492, Learning Rate: 0.04515\n",
      "Epoch: 10971, MSE: 0.2469484599576858, Learning Rate: 0.045145000000000005\n",
      "Epoch: 10972, MSE: 0.2469458079557161, Learning Rate: 0.045140000000000007\n",
      "Epoch: 10973, MSE: 0.2469431559078686, Learning Rate: 0.04513500000000001\n",
      "Epoch: 10974, MSE: 0.24694050381414548, Learning Rate: 0.04513\n",
      "Epoch: 10975, MSE: 0.2469378516745476, Learning Rate: 0.045125000000000005\n",
      "Epoch: 10976, MSE: 0.24693519948907938, Learning Rate: 0.04512000000000001\n",
      "Epoch: 10977, MSE: 0.24693254725774133, Learning Rate: 0.04511500000000001\n",
      "Epoch: 10978, MSE: 0.2469298949805374, Learning Rate: 0.04511\n",
      "Epoch: 10979, MSE: 0.24692724265746802, Learning Rate: 0.045105\n",
      "Epoch: 10980, MSE: 0.2469245902885367, Learning Rate: 0.0451\n",
      "Epoch: 10981, MSE: 0.24692193787374647, Learning Rate: 0.045094999999999996\n",
      "Epoch: 10982, MSE: 0.24691928541309927, Learning Rate: 0.04509\n",
      "Epoch: 10983, MSE: 0.246916632906596, Learning Rate: 0.045085\n",
      "Epoch: 10984, MSE: 0.2469139803542404, Learning Rate: 0.04508\n",
      "Epoch: 10985, MSE: 0.24691132775603508, Learning Rate: 0.045075000000000004\n",
      "Epoch: 10986, MSE: 0.24690867511198103, Learning Rate: 0.04507\n",
      "Epoch: 10987, MSE: 0.2469060224220817, Learning Rate: 0.045065\n",
      "Epoch: 10988, MSE: 0.24690336968633878, Learning Rate: 0.04506\n",
      "Epoch: 10989, MSE: 0.24690071690475593, Learning Rate: 0.045055000000000005\n",
      "Epoch: 10990, MSE: 0.2468980640773334, Learning Rate: 0.04505000000000001\n",
      "Epoch: 10991, MSE: 0.24689541120407493, Learning Rate: 0.045045\n",
      "Epoch: 10992, MSE: 0.24689275828498267, Learning Rate: 0.045040000000000004\n",
      "Epoch: 10993, MSE: 0.2468901053200586, Learning Rate: 0.045035000000000006\n",
      "Epoch: 10994, MSE: 0.2468874523093063, Learning Rate: 0.04503000000000001\n",
      "Epoch: 10995, MSE: 0.2468847992527262, Learning Rate: 0.04502500000000001\n",
      "Epoch: 10996, MSE: 0.24688214615032136, Learning Rate: 0.045020000000000004\n",
      "Epoch: 10997, MSE: 0.24687949300209436, Learning Rate: 0.045015000000000006\n",
      "Epoch: 10998, MSE: 0.24687683980804873, Learning Rate: 0.045009999999999994\n",
      "Epoch: 10999, MSE: 0.2468741865681847, Learning Rate: 0.045004999999999996\n",
      "Epoch: 11000, MSE: 0.2468715332825054, Learning Rate: 0.045\n",
      "Epoch: 11001, MSE: 0.24686887995101384, Learning Rate: 0.044995\n",
      "Epoch: 11002, MSE: 0.24686622657371135, Learning Rate: 0.04499\n",
      "Epoch: 11003, MSE: 0.24686357315060098, Learning Rate: 0.044985\n",
      "Epoch: 11004, MSE: 0.24686091968168536, Learning Rate: 0.04498\n",
      "Epoch: 11005, MSE: 0.24685826616696563, Learning Rate: 0.044975\n",
      "Epoch: 11006, MSE: 0.24685561260644553, Learning Rate: 0.04497\n",
      "Epoch: 11007, MSE: 0.24685295900012705, Learning Rate: 0.044965000000000005\n",
      "Epoch: 11008, MSE: 0.24685030534801095, Learning Rate: 0.04496\n",
      "Epoch: 11009, MSE: 0.24684765165010233, Learning Rate: 0.044955\n",
      "Epoch: 11010, MSE: 0.2468449979064007, Learning Rate: 0.044950000000000004\n",
      "Epoch: 11011, MSE: 0.24684234411691128, Learning Rate: 0.044945000000000006\n",
      "Epoch: 11012, MSE: 0.24683969028163402, Learning Rate: 0.04494000000000001\n",
      "Epoch: 11013, MSE: 0.24683703640057247, Learning Rate: 0.044935\n",
      "Epoch: 11014, MSE: 0.24683438247372827, Learning Rate: 0.044930000000000005\n",
      "Epoch: 11015, MSE: 0.24683172850110513, Learning Rate: 0.04492500000000001\n",
      "Epoch: 11016, MSE: 0.24682907448270408, Learning Rate: 0.04492000000000001\n",
      "Epoch: 11017, MSE: 0.246826420418528, Learning Rate: 0.04491500000000001\n",
      "Epoch: 11018, MSE: 0.24682376630857955, Learning Rate: 0.044910000000000005\n",
      "Epoch: 11019, MSE: 0.24682111215286004, Learning Rate: 0.044905\n",
      "Epoch: 11020, MSE: 0.2468184579513723, Learning Rate: 0.044899999999999995\n",
      "Epoch: 11021, MSE: 0.24681580370411987, Learning Rate: 0.044895\n",
      "Epoch: 11022, MSE: 0.24681314941110327, Learning Rate: 0.04489\n",
      "Epoch: 11023, MSE: 0.24681049507232672, Learning Rate: 0.044885\n",
      "Epoch: 11024, MSE: 0.24680784068779113, Learning Rate: 0.04488\n",
      "Epoch: 11025, MSE: 0.24680518625749842, Learning Rate: 0.044875\n",
      "Epoch: 11026, MSE: 0.24680253178145267, Learning Rate: 0.04487\n",
      "Epoch: 11027, MSE: 0.24679987725965544, Learning Rate: 0.044865\n",
      "Epoch: 11028, MSE: 0.24679722269210932, Learning Rate: 0.044860000000000004\n",
      "Epoch: 11029, MSE: 0.246794568078816, Learning Rate: 0.044855000000000006\n",
      "Epoch: 11030, MSE: 0.24679191341977874, Learning Rate: 0.04485\n",
      "Epoch: 11031, MSE: 0.24678925871499874, Learning Rate: 0.044845\n",
      "Epoch: 11032, MSE: 0.24678660396447968, Learning Rate: 0.044840000000000005\n",
      "Epoch: 11033, MSE: 0.24678394916822294, Learning Rate: 0.04483500000000001\n",
      "Epoch: 11034, MSE: 0.24678129432623208, Learning Rate: 0.04483000000000001\n",
      "Epoch: 11035, MSE: 0.24677863943850742, Learning Rate: 0.044825000000000004\n",
      "Epoch: 11036, MSE: 0.2467759845050538, Learning Rate: 0.044820000000000006\n",
      "Epoch: 11037, MSE: 0.24677332952587144, Learning Rate: 0.04481500000000001\n",
      "Epoch: 11038, MSE: 0.24677067450096324, Learning Rate: 0.04481000000000001\n",
      "Epoch: 11039, MSE: 0.2467680194303334, Learning Rate: 0.044805\n",
      "Epoch: 11040, MSE: 0.24676536431398208, Learning Rate: 0.0448\n",
      "Epoch: 11041, MSE: 0.24676270915191215, Learning Rate: 0.044795\n",
      "Epoch: 11042, MSE: 0.24676005394412673, Learning Rate: 0.044789999999999996\n",
      "Epoch: 11043, MSE: 0.24675739869062785, Learning Rate: 0.044785\n",
      "Epoch: 11044, MSE: 0.24675474339141681, Learning Rate: 0.04478\n",
      "Epoch: 11045, MSE: 0.2467520880464982, Learning Rate: 0.044775\n",
      "Epoch: 11046, MSE: 0.2467494326558723, Learning Rate: 0.044770000000000004\n",
      "Epoch: 11047, MSE: 0.2467467772195427, Learning Rate: 0.044765\n",
      "Epoch: 11048, MSE: 0.24674412173751067, Learning Rate: 0.04476\n",
      "Epoch: 11049, MSE: 0.24674146620978013, Learning Rate: 0.044755\n",
      "Epoch: 11050, MSE: 0.24673881063635159, Learning Rate: 0.044750000000000005\n",
      "Epoch: 11051, MSE: 0.24673615501722945, Learning Rate: 0.04474500000000001\n",
      "Epoch: 11052, MSE: 0.2467334993524146, Learning Rate: 0.04474\n",
      "Epoch: 11053, MSE: 0.2467308436419096, Learning Rate: 0.044735000000000004\n",
      "Epoch: 11054, MSE: 0.24672818788571801, Learning Rate: 0.044730000000000006\n",
      "Epoch: 11055, MSE: 0.24672553208384068, Learning Rate: 0.04472500000000001\n",
      "Epoch: 11056, MSE: 0.24672287623628078, Learning Rate: 0.04472000000000001\n",
      "Epoch: 11057, MSE: 0.24672022034304072, Learning Rate: 0.044715000000000005\n",
      "Epoch: 11058, MSE: 0.24671756440412207, Learning Rate: 0.04471000000000001\n",
      "Epoch: 11059, MSE: 0.24671490841952906, Learning Rate: 0.044704999999999995\n",
      "Epoch: 11060, MSE: 0.24671225238926145, Learning Rate: 0.0447\n",
      "Epoch: 11061, MSE: 0.2467095963133243, Learning Rate: 0.044695\n",
      "Epoch: 11062, MSE: 0.24670694019171796, Learning Rate: 0.04469\n",
      "Epoch: 11063, MSE: 0.24670428402444572, Learning Rate: 0.044685\n",
      "Epoch: 11064, MSE: 0.24670162781151014, Learning Rate: 0.04468\n",
      "Epoch: 11065, MSE: 0.24669897155291243, Learning Rate: 0.044675\n",
      "Epoch: 11066, MSE: 0.24669631524865634, Learning Rate: 0.04467\n",
      "Epoch: 11067, MSE: 0.2466936588987447, Learning Rate: 0.044665\n",
      "Epoch: 11068, MSE: 0.24669100250317752, Learning Rate: 0.044660000000000005\n",
      "Epoch: 11069, MSE: 0.2466883460619592, Learning Rate: 0.044655\n",
      "Epoch: 11070, MSE: 0.24668568957509127, Learning Rate: 0.04465\n",
      "Epoch: 11071, MSE: 0.24668303304257685, Learning Rate: 0.044645000000000004\n",
      "Epoch: 11072, MSE: 0.2466803764644175, Learning Rate: 0.044640000000000006\n",
      "Epoch: 11073, MSE: 0.24667771984061543, Learning Rate: 0.04463500000000001\n",
      "Epoch: 11074, MSE: 0.24667506317117446, Learning Rate: 0.04463\n",
      "Epoch: 11075, MSE: 0.24667240645609584, Learning Rate: 0.044625000000000005\n",
      "Epoch: 11076, MSE: 0.24666974969538216, Learning Rate: 0.04462000000000001\n",
      "Epoch: 11077, MSE: 0.24666709288903602, Learning Rate: 0.04461500000000001\n",
      "Epoch: 11078, MSE: 0.24666443603705923, Learning Rate: 0.04461000000000001\n",
      "Epoch: 11079, MSE: 0.24666177913945528, Learning Rate: 0.044605\n",
      "Epoch: 11080, MSE: 0.24665912219622502, Learning Rate: 0.0446\n",
      "Epoch: 11081, MSE: 0.24665646520737233, Learning Rate: 0.044594999999999996\n",
      "Epoch: 11082, MSE: 0.24665380817289864, Learning Rate: 0.04459\n",
      "Epoch: 11083, MSE: 0.24665115109280702, Learning Rate: 0.044585\n",
      "Epoch: 11084, MSE: 0.24664849396709895, Learning Rate: 0.04458\n",
      "Epoch: 11085, MSE: 0.24664583679577728, Learning Rate: 0.044575000000000004\n",
      "Epoch: 11086, MSE: 0.24664317957884524, Learning Rate: 0.04457\n",
      "Epoch: 11087, MSE: 0.24664052231630493, Learning Rate: 0.044565\n",
      "Epoch: 11088, MSE: 0.24663786500815726, Learning Rate: 0.04456\n",
      "Epoch: 11089, MSE: 0.2466352076544057, Learning Rate: 0.044555000000000004\n",
      "Epoch: 11090, MSE: 0.2466325502550534, Learning Rate: 0.044550000000000006\n",
      "Epoch: 11091, MSE: 0.24662989281010106, Learning Rate: 0.044545\n",
      "Epoch: 11092, MSE: 0.24662723531955236, Learning Rate: 0.04454\n",
      "Epoch: 11093, MSE: 0.2466245777834096, Learning Rate: 0.044535000000000005\n",
      "Epoch: 11094, MSE: 0.2466219202016749, Learning Rate: 0.04453000000000001\n",
      "Epoch: 11095, MSE: 0.24661926257435013, Learning Rate: 0.04452500000000001\n",
      "Epoch: 11096, MSE: 0.24661660490143886, Learning Rate: 0.044520000000000004\n",
      "Epoch: 11097, MSE: 0.2466139471829425, Learning Rate: 0.044515000000000006\n",
      "Epoch: 11098, MSE: 0.2466112894188647, Learning Rate: 0.04451000000000001\n",
      "Epoch: 11099, MSE: 0.24660863160920599, Learning Rate: 0.044504999999999996\n",
      "Epoch: 11100, MSE: 0.24660597375397003, Learning Rate: 0.0445\n",
      "Epoch: 11101, MSE: 0.2466033158531588, Learning Rate: 0.044495\n",
      "Epoch: 11102, MSE: 0.24660065790677554, Learning Rate: 0.04449\n",
      "Epoch: 11103, MSE: 0.24659799991482168, Learning Rate: 0.044485\n",
      "Epoch: 11104, MSE: 0.24659534187729915, Learning Rate: 0.04448\n",
      "Epoch: 11105, MSE: 0.24659268379421181, Learning Rate: 0.044475\n",
      "Epoch: 11106, MSE: 0.24659002566556176, Learning Rate: 0.04447\n",
      "Epoch: 11107, MSE: 0.24658736749135038, Learning Rate: 0.044465000000000005\n",
      "Epoch: 11108, MSE: 0.24658470927158097, Learning Rate: 0.04446\n",
      "Epoch: 11109, MSE: 0.24658205100625613, Learning Rate: 0.044455\n",
      "Epoch: 11110, MSE: 0.24657939269537724, Learning Rate: 0.04445\n",
      "Epoch: 11111, MSE: 0.24657673433894745, Learning Rate: 0.044445000000000005\n",
      "Epoch: 11112, MSE: 0.24657407593696928, Learning Rate: 0.04444000000000001\n",
      "Epoch: 11113, MSE: 0.2465714174894445, Learning Rate: 0.044435\n",
      "Epoch: 11114, MSE: 0.24656875899637626, Learning Rate: 0.044430000000000004\n",
      "Epoch: 11115, MSE: 0.2465661004577658, Learning Rate: 0.044425000000000006\n",
      "Epoch: 11116, MSE: 0.24656344187361703, Learning Rate: 0.04442000000000001\n",
      "Epoch: 11117, MSE: 0.24656078324393155, Learning Rate: 0.04441500000000001\n",
      "Epoch: 11118, MSE: 0.24655812456871165, Learning Rate: 0.044410000000000005\n",
      "Epoch: 11119, MSE: 0.2465554658479604, Learning Rate: 0.044405\n",
      "Epoch: 11120, MSE: 0.24655280708167998, Learning Rate: 0.044399999999999995\n",
      "Epoch: 11121, MSE: 0.2465501482698725, Learning Rate: 0.044395\n",
      "Epoch: 11122, MSE: 0.24654748941253987, Learning Rate: 0.04439\n",
      "Epoch: 11123, MSE: 0.24654483050968612, Learning Rate: 0.044385\n",
      "Epoch: 11124, MSE: 0.2465421715613115, Learning Rate: 0.04438\n",
      "Epoch: 11125, MSE: 0.24653951256742057, Learning Rate: 0.044375\n",
      "Epoch: 11126, MSE: 0.24653685352801474, Learning Rate: 0.04437\n",
      "Epoch: 11127, MSE: 0.24653419444309596, Learning Rate: 0.044365\n",
      "Epoch: 11128, MSE: 0.2465315353126668, Learning Rate: 0.044360000000000004\n",
      "Epoch: 11129, MSE: 0.2465288761367306, Learning Rate: 0.044355000000000006\n",
      "Epoch: 11130, MSE: 0.24652621691528914, Learning Rate: 0.04435\n",
      "Epoch: 11131, MSE: 0.24652355764834513, Learning Rate: 0.044345\n",
      "Epoch: 11132, MSE: 0.246520898335901, Learning Rate: 0.044340000000000004\n",
      "Epoch: 11133, MSE: 0.24651823897795824, Learning Rate: 0.044335000000000006\n",
      "Epoch: 11134, MSE: 0.24651557957452053, Learning Rate: 0.04433000000000001\n",
      "Epoch: 11135, MSE: 0.24651292012558929, Learning Rate: 0.044325\n",
      "Epoch: 11136, MSE: 0.24651026063116752, Learning Rate: 0.044320000000000005\n",
      "Epoch: 11137, MSE: 0.24650760109125744, Learning Rate: 0.04431500000000001\n",
      "Epoch: 11138, MSE: 0.24650494150586186, Learning Rate: 0.04431000000000001\n",
      "Epoch: 11139, MSE: 0.2465022818749825, Learning Rate: 0.04430500000000001\n",
      "Epoch: 11140, MSE: 0.2464996221986225, Learning Rate: 0.0443\n",
      "Epoch: 11141, MSE: 0.24649696247678402, Learning Rate: 0.044295\n",
      "Epoch: 11142, MSE: 0.2464943027094688, Learning Rate: 0.044289999999999996\n",
      "Epoch: 11143, MSE: 0.2464916428966809, Learning Rate: 0.044285\n",
      "Epoch: 11144, MSE: 0.24648898303842096, Learning Rate: 0.04428\n",
      "Epoch: 11145, MSE: 0.24648632313469176, Learning Rate: 0.044275\n",
      "Epoch: 11146, MSE: 0.24648366318549683, Learning Rate: 0.044270000000000004\n",
      "Epoch: 11147, MSE: 0.24648100319083732, Learning Rate: 0.044265\n",
      "Epoch: 11148, MSE: 0.24647834315071715, Learning Rate: 0.04426\n",
      "Epoch: 11149, MSE: 0.2464756830651371, Learning Rate: 0.044255\n",
      "Epoch: 11150, MSE: 0.24647302293410076, Learning Rate: 0.044250000000000005\n",
      "Epoch: 11151, MSE: 0.24647036275761003, Learning Rate: 0.04424500000000001\n",
      "Epoch: 11152, MSE: 0.246467702535667, Learning Rate: 0.04424\n",
      "Epoch: 11153, MSE: 0.2464650422682752, Learning Rate: 0.044235000000000003\n",
      "Epoch: 11154, MSE: 0.24646238195543602, Learning Rate: 0.044230000000000005\n",
      "Epoch: 11155, MSE: 0.2464597215971525, Learning Rate: 0.04422500000000001\n",
      "Epoch: 11156, MSE: 0.24645706119342659, Learning Rate: 0.04422000000000001\n",
      "Epoch: 11157, MSE: 0.24645440074426112, Learning Rate: 0.044215000000000004\n",
      "Epoch: 11158, MSE: 0.2464517402496589, Learning Rate: 0.044210000000000006\n",
      "Epoch: 11159, MSE: 0.24644907970962088, Learning Rate: 0.04420500000000001\n",
      "Epoch: 11160, MSE: 0.2464464191241511, Learning Rate: 0.044199999999999996\n",
      "Epoch: 11161, MSE: 0.24644375849325115, Learning Rate: 0.044195\n",
      "Epoch: 11162, MSE: 0.24644109781692392, Learning Rate: 0.04419\n",
      "Epoch: 11163, MSE: 0.2464384370951714, Learning Rate: 0.044185\n",
      "Epoch: 11164, MSE: 0.24643577632799665, Learning Rate: 0.04418\n",
      "Epoch: 11165, MSE: 0.24643311551540092, Learning Rate: 0.044175\n",
      "Epoch: 11166, MSE: 0.24643045465738828, Learning Rate: 0.04417\n",
      "Epoch: 11167, MSE: 0.24642779375395935, Learning Rate: 0.044165\n",
      "Epoch: 11168, MSE: 0.2464251328051182, Learning Rate: 0.044160000000000005\n",
      "Epoch: 11169, MSE: 0.2464224718108661, Learning Rate: 0.044155\n",
      "Epoch: 11170, MSE: 0.24641981077120662, Learning Rate: 0.04415\n",
      "Epoch: 11171, MSE: 0.24641714968614137, Learning Rate: 0.044145000000000004\n",
      "Epoch: 11172, MSE: 0.24641448855567255, Learning Rate: 0.044140000000000006\n",
      "Epoch: 11173, MSE: 0.2464118273798034, Learning Rate: 0.04413500000000001\n",
      "Epoch: 11174, MSE: 0.24640916615853553, Learning Rate: 0.04413\n",
      "Epoch: 11175, MSE: 0.24640650489187282, Learning Rate: 0.044125000000000004\n",
      "Epoch: 11176, MSE: 0.24640384357981648, Learning Rate: 0.044120000000000006\n",
      "Epoch: 11177, MSE: 0.24640118222236818, Learning Rate: 0.04411500000000001\n",
      "Epoch: 11178, MSE: 0.24639852081953212, Learning Rate: 0.04411000000000001\n",
      "Epoch: 11179, MSE: 0.24639585937130987, Learning Rate: 0.044105000000000005\n",
      "Epoch: 11180, MSE: 0.2463931978777045, Learning Rate: 0.0441\n",
      "Epoch: 11181, MSE: 0.24639053633871666, Learning Rate: 0.044094999999999995\n",
      "Epoch: 11182, MSE: 0.2463878747543521, Learning Rate: 0.04409\n",
      "Epoch: 11183, MSE: 0.24638521312461023, Learning Rate: 0.044085\n",
      "Epoch: 11184, MSE: 0.24638255144949447, Learning Rate: 0.04408\n",
      "Epoch: 11185, MSE: 0.2463798897290079, Learning Rate: 0.044075\n",
      "Epoch: 11186, MSE: 0.24637722796315153, Learning Rate: 0.04407\n",
      "Epoch: 11187, MSE: 0.24637456615192987, Learning Rate: 0.044065\n",
      "Epoch: 11188, MSE: 0.24637190429534314, Learning Rate: 0.04406\n",
      "Epoch: 11189, MSE: 0.24636924239339497, Learning Rate: 0.044055000000000004\n",
      "Epoch: 11190, MSE: 0.2463665804460882, Learning Rate: 0.044050000000000006\n",
      "Epoch: 11191, MSE: 0.24636391845342434, Learning Rate: 0.044045\n",
      "Epoch: 11192, MSE: 0.24636125641540646, Learning Rate: 0.04404\n",
      "Epoch: 11193, MSE: 0.2463585943320368, Learning Rate: 0.044035000000000005\n",
      "Epoch: 11194, MSE: 0.2463559322033174, Learning Rate: 0.04403000000000001\n",
      "Epoch: 11195, MSE: 0.24635327002925206, Learning Rate: 0.04402500000000001\n",
      "Epoch: 11196, MSE: 0.24635060780984167, Learning Rate: 0.044020000000000004\n",
      "Epoch: 11197, MSE: 0.24634794554509007, Learning Rate: 0.044015000000000006\n",
      "Epoch: 11198, MSE: 0.2463452832349984, Learning Rate: 0.04401000000000001\n",
      "Epoch: 11199, MSE: 0.24634262087956912, Learning Rate: 0.04400500000000001\n",
      "Epoch: 11200, MSE: 0.24633995847880566, Learning Rate: 0.044\n",
      "Epoch: 11201, MSE: 0.24633729603271085, Learning Rate: 0.043995\n",
      "Epoch: 11202, MSE: 0.2463346335412855, Learning Rate: 0.04399\n",
      "Epoch: 11203, MSE: 0.24633197100453283, Learning Rate: 0.043984999999999996\n",
      "Epoch: 11204, MSE: 0.24632930842245612, Learning Rate: 0.04398\n",
      "Epoch: 11205, MSE: 0.24632664579505703, Learning Rate: 0.043975\n",
      "Epoch: 11206, MSE: 0.2463239831223375, Learning Rate: 0.04397\n",
      "Epoch: 11207, MSE: 0.24632132040430096, Learning Rate: 0.043965000000000004\n",
      "Epoch: 11208, MSE: 0.2463186576409499, Learning Rate: 0.04396\n",
      "Epoch: 11209, MSE: 0.2463159948322852, Learning Rate: 0.043955\n",
      "Epoch: 11210, MSE: 0.24631333197831168, Learning Rate: 0.04395\n",
      "Epoch: 11211, MSE: 0.24631066907903013, Learning Rate: 0.043945000000000005\n",
      "Epoch: 11212, MSE: 0.24630800613444345, Learning Rate: 0.04394000000000001\n",
      "Epoch: 11213, MSE: 0.24630534314455454, Learning Rate: 0.043935\n",
      "Epoch: 11214, MSE: 0.2463026801093652, Learning Rate: 0.043930000000000004\n",
      "Epoch: 11215, MSE: 0.2463000170288782, Learning Rate: 0.043925000000000006\n",
      "Epoch: 11216, MSE: 0.24629735390309582, Learning Rate: 0.04392000000000001\n",
      "Epoch: 11217, MSE: 0.24629469073202126, Learning Rate: 0.04391500000000001\n",
      "Epoch: 11218, MSE: 0.24629202751565638, Learning Rate: 0.043910000000000005\n",
      "Epoch: 11219, MSE: 0.2462893642540029, Learning Rate: 0.043905000000000007\n",
      "Epoch: 11220, MSE: 0.24628670094706404, Learning Rate: 0.043899999999999995\n",
      "Epoch: 11221, MSE: 0.24628403759484316, Learning Rate: 0.043894999999999997\n",
      "Epoch: 11222, MSE: 0.2462813741973418, Learning Rate: 0.04389\n",
      "Epoch: 11223, MSE: 0.24627871075456184, Learning Rate: 0.043885\n",
      "Epoch: 11224, MSE: 0.24627604726650698, Learning Rate: 0.04388\n",
      "Epoch: 11225, MSE: 0.24627338373317886, Learning Rate: 0.043875\n",
      "Epoch: 11226, MSE: 0.24627072015458001, Learning Rate: 0.04387\n",
      "Epoch: 11227, MSE: 0.24626805653071313, Learning Rate: 0.043865\n",
      "Epoch: 11228, MSE: 0.24626539286158014, Learning Rate: 0.04386\n",
      "Epoch: 11229, MSE: 0.24626272914718547, Learning Rate: 0.043855000000000005\n",
      "Epoch: 11230, MSE: 0.24626006538752934, Learning Rate: 0.04385\n",
      "Epoch: 11231, MSE: 0.2462574015826151, Learning Rate: 0.043845\n",
      "Epoch: 11232, MSE: 0.2462547377324449, Learning Rate: 0.043840000000000004\n",
      "Epoch: 11233, MSE: 0.24625207383702094, Learning Rate: 0.043835000000000006\n",
      "Epoch: 11234, MSE: 0.24624940989634717, Learning Rate: 0.04383000000000001\n",
      "Epoch: 11235, MSE: 0.24624674591042514, Learning Rate: 0.043825\n",
      "Epoch: 11236, MSE: 0.24624408187925675, Learning Rate: 0.043820000000000005\n",
      "Epoch: 11237, MSE: 0.24624141780284453, Learning Rate: 0.04381500000000001\n",
      "Epoch: 11238, MSE: 0.24623875368119263, Learning Rate: 0.04381000000000001\n",
      "Epoch: 11239, MSE: 0.24623608951430223, Learning Rate: 0.04380500000000001\n",
      "Epoch: 11240, MSE: 0.24623342530217557, Learning Rate: 0.0438\n",
      "Epoch: 11241, MSE: 0.2462307610448146, Learning Rate: 0.043795\n",
      "Epoch: 11242, MSE: 0.24622809674222387, Learning Rate: 0.043789999999999996\n",
      "Epoch: 11243, MSE: 0.2462254323944041, Learning Rate: 0.043785\n",
      "Epoch: 11244, MSE: 0.24622276800135845, Learning Rate: 0.04378\n",
      "Epoch: 11245, MSE: 0.24622010356308885, Learning Rate: 0.043775\n",
      "Epoch: 11246, MSE: 0.24621743907959934, Learning Rate: 0.04377\n",
      "Epoch: 11247, MSE: 0.2462147745508908, Learning Rate: 0.043765\n",
      "Epoch: 11248, MSE: 0.2462121099769657, Learning Rate: 0.04376\n",
      "Epoch: 11249, MSE: 0.24620944535782724, Learning Rate: 0.043755\n",
      "Epoch: 11250, MSE: 0.24620678069347712, Learning Rate: 0.043750000000000004\n",
      "Epoch: 11251, MSE: 0.24620411598391945, Learning Rate: 0.043745000000000006\n",
      "Epoch: 11252, MSE: 0.24620145122915474, Learning Rate: 0.04374\n",
      "Epoch: 11253, MSE: 0.24619878642918733, Learning Rate: 0.043735\n",
      "Epoch: 11254, MSE: 0.24619612158401838, Learning Rate: 0.043730000000000005\n",
      "Epoch: 11255, MSE: 0.24619345669365061, Learning Rate: 0.04372500000000001\n",
      "Epoch: 11256, MSE: 0.24619079175808664, Learning Rate: 0.04372000000000001\n",
      "Epoch: 11257, MSE: 0.24618812677732857, Learning Rate: 0.043715000000000004\n",
      "Epoch: 11258, MSE: 0.24618546175137937, Learning Rate: 0.043710000000000006\n",
      "Epoch: 11259, MSE: 0.24618279668024154, Learning Rate: 0.04370500000000001\n",
      "Epoch: 11260, MSE: 0.2461801315639176, Learning Rate: 0.04370000000000001\n",
      "Epoch: 11261, MSE: 0.2461774664024094, Learning Rate: 0.043695\n",
      "Epoch: 11262, MSE: 0.24617480119572052, Learning Rate: 0.04369\n",
      "Epoch: 11263, MSE: 0.24617213594385276, Learning Rate: 0.043685\n",
      "Epoch: 11264, MSE: 0.2461694706468082, Learning Rate: 0.04368\n",
      "Epoch: 11265, MSE: 0.24616680530459065, Learning Rate: 0.043675\n",
      "Epoch: 11266, MSE: 0.24616413991720087, Learning Rate: 0.04367\n",
      "Epoch: 11267, MSE: 0.2461614744846431, Learning Rate: 0.043665\n",
      "Epoch: 11268, MSE: 0.2461588090069188, Learning Rate: 0.043660000000000004\n",
      "Epoch: 11269, MSE: 0.24615614348403048, Learning Rate: 0.043655\n",
      "Epoch: 11270, MSE: 0.24615347791598083, Learning Rate: 0.04365\n",
      "Epoch: 11271, MSE: 0.24615081230277208, Learning Rate: 0.043645\n",
      "Epoch: 11272, MSE: 0.2461481466444071, Learning Rate: 0.043640000000000005\n",
      "Epoch: 11273, MSE: 0.24614548094088787, Learning Rate: 0.04363500000000001\n",
      "Epoch: 11274, MSE: 0.24614281519221784, Learning Rate: 0.04363\n",
      "Epoch: 11275, MSE: 0.2461401493983988, Learning Rate: 0.043625000000000004\n",
      "Epoch: 11276, MSE: 0.24613748355943346, Learning Rate: 0.043620000000000006\n",
      "Epoch: 11277, MSE: 0.2461348176753242, Learning Rate: 0.04361500000000001\n",
      "Epoch: 11278, MSE: 0.24613215174607334, Learning Rate: 0.04361000000000001\n",
      "Epoch: 11279, MSE: 0.24612948577168367, Learning Rate: 0.043605000000000005\n",
      "Epoch: 11280, MSE: 0.2461268197521574, Learning Rate: 0.04360000000000001\n",
      "Epoch: 11281, MSE: 0.24612415368749832, Learning Rate: 0.043594999999999995\n",
      "Epoch: 11282, MSE: 0.24612148757770652, Learning Rate: 0.04359\n",
      "Epoch: 11283, MSE: 0.24611882142278618, Learning Rate: 0.043585\n",
      "Epoch: 11284, MSE: 0.2461161552227395, Learning Rate: 0.04358\n",
      "Epoch: 11285, MSE: 0.2461134889775694, Learning Rate: 0.043575\n",
      "Epoch: 11286, MSE: 0.24611082268727746, Learning Rate: 0.04357\n",
      "Epoch: 11287, MSE: 0.24610815635186642, Learning Rate: 0.043565\n",
      "Epoch: 11288, MSE: 0.24610548997133894, Learning Rate: 0.04356\n",
      "Epoch: 11289, MSE: 0.246102823545698, Learning Rate: 0.043555\n",
      "Epoch: 11290, MSE: 0.24610015707494537, Learning Rate: 0.043550000000000005\n",
      "Epoch: 11291, MSE: 0.24609749055908461, Learning Rate: 0.043545\n",
      "Epoch: 11292, MSE: 0.24609482399811736, Learning Rate: 0.04354\n",
      "Epoch: 11293, MSE: 0.24609215739204526, Learning Rate: 0.043535000000000004\n",
      "Epoch: 11294, MSE: 0.24608949074087236, Learning Rate: 0.043530000000000006\n",
      "Epoch: 11295, MSE: 0.24608682404460058, Learning Rate: 0.04352500000000001\n",
      "Epoch: 11296, MSE: 0.24608415730323288, Learning Rate: 0.04352\n",
      "Epoch: 11297, MSE: 0.24608149051677083, Learning Rate: 0.043515000000000005\n",
      "Epoch: 11298, MSE: 0.24607882368521747, Learning Rate: 0.04351000000000001\n",
      "Epoch: 11299, MSE: 0.24607615680857556, Learning Rate: 0.04350500000000001\n",
      "Epoch: 11300, MSE: 0.24607348988684719, Learning Rate: 0.04350000000000001\n",
      "Epoch: 11301, MSE: 0.24607082292003532, Learning Rate: 0.043495\n",
      "Epoch: 11302, MSE: 0.24606815590814135, Learning Rate: 0.04349\n",
      "Epoch: 11303, MSE: 0.24606548885116913, Learning Rate: 0.043484999999999996\n",
      "Epoch: 11304, MSE: 0.24606282174912025, Learning Rate: 0.04348\n",
      "Epoch: 11305, MSE: 0.24606015460199823, Learning Rate: 0.043475\n",
      "Epoch: 11306, MSE: 0.24605748740980454, Learning Rate: 0.04347\n",
      "Epoch: 11307, MSE: 0.24605482017254265, Learning Rate: 0.043465000000000004\n",
      "Epoch: 11308, MSE: 0.2460521528902134, Learning Rate: 0.04346\n",
      "Epoch: 11309, MSE: 0.2460494855628218, Learning Rate: 0.043455\n",
      "Epoch: 11310, MSE: 0.24604681819036844, Learning Rate: 0.04345\n",
      "Epoch: 11311, MSE: 0.24604415077285627, Learning Rate: 0.043445000000000004\n",
      "Epoch: 11312, MSE: 0.24604148331028858, Learning Rate: 0.043440000000000006\n",
      "Epoch: 11313, MSE: 0.24603881580266682, Learning Rate: 0.043435\n",
      "Epoch: 11314, MSE: 0.24603614824999412, Learning Rate: 0.04343\n",
      "Epoch: 11315, MSE: 0.24603348065227204, Learning Rate: 0.043425000000000005\n",
      "Epoch: 11316, MSE: 0.24603081300950458, Learning Rate: 0.04342000000000001\n",
      "Epoch: 11317, MSE: 0.24602814532169315, Learning Rate: 0.04341500000000001\n",
      "Epoch: 11318, MSE: 0.246025477588841, Learning Rate: 0.043410000000000004\n",
      "Epoch: 11319, MSE: 0.2460228098109502, Learning Rate: 0.043405000000000006\n",
      "Epoch: 11320, MSE: 0.24602014198802344, Learning Rate: 0.04340000000000001\n",
      "Epoch: 11321, MSE: 0.2460174741200629, Learning Rate: 0.043394999999999996\n",
      "Epoch: 11322, MSE: 0.24601480620707195, Learning Rate: 0.04339\n",
      "Epoch: 11323, MSE: 0.24601213824905183, Learning Rate: 0.043385\n",
      "Epoch: 11324, MSE: 0.24600947024600628, Learning Rate: 0.04338\n",
      "Epoch: 11325, MSE: 0.24600680219793739, Learning Rate: 0.043375\n",
      "Epoch: 11326, MSE: 0.24600413410484703, Learning Rate: 0.04337\n",
      "Epoch: 11327, MSE: 0.24600146596673939, Learning Rate: 0.043365\n",
      "Epoch: 11328, MSE: 0.24599879778361544, Learning Rate: 0.04336\n",
      "Epoch: 11329, MSE: 0.24599612955547714, Learning Rate: 0.043355000000000005\n",
      "Epoch: 11330, MSE: 0.2459934612823287, Learning Rate: 0.04335\n",
      "Epoch: 11331, MSE: 0.24599079296417312, Learning Rate: 0.043345\n",
      "Epoch: 11332, MSE: 0.24598812460101088, Learning Rate: 0.043340000000000004\n",
      "Epoch: 11333, MSE: 0.2459854561928454, Learning Rate: 0.043335000000000005\n",
      "Epoch: 11334, MSE: 0.24598278773967933, Learning Rate: 0.04333000000000001\n",
      "Epoch: 11335, MSE: 0.24598011924151508, Learning Rate: 0.043325\n",
      "Epoch: 11336, MSE: 0.24597745069835483, Learning Rate: 0.043320000000000004\n",
      "Epoch: 11337, MSE: 0.24597478211020188, Learning Rate: 0.043315000000000006\n",
      "Epoch: 11338, MSE: 0.2459721134770588, Learning Rate: 0.04331000000000001\n",
      "Epoch: 11339, MSE: 0.24596944479892696, Learning Rate: 0.04330500000000001\n",
      "Epoch: 11340, MSE: 0.2459667760758102, Learning Rate: 0.043300000000000005\n",
      "Epoch: 11341, MSE: 0.24596410730771004, Learning Rate: 0.043295\n",
      "Epoch: 11342, MSE: 0.24596143849462965, Learning Rate: 0.043289999999999995\n",
      "Epoch: 11343, MSE: 0.24595876963657137, Learning Rate: 0.043285\n",
      "Epoch: 11344, MSE: 0.24595610073353744, Learning Rate: 0.04328\n",
      "Epoch: 11345, MSE: 0.24595343178553114, Learning Rate: 0.043275\n",
      "Epoch: 11346, MSE: 0.24595076279255443, Learning Rate: 0.04327\n",
      "Epoch: 11347, MSE: 0.24594809375460994, Learning Rate: 0.043265\n",
      "Epoch: 11348, MSE: 0.24594542467169958, Learning Rate: 0.04326\n",
      "Epoch: 11349, MSE: 0.2459427555438273, Learning Rate: 0.043255\n",
      "Epoch: 11350, MSE: 0.2459400863709945, Learning Rate: 0.043250000000000004\n",
      "Epoch: 11351, MSE: 0.24593741715320389, Learning Rate: 0.043245000000000006\n",
      "Epoch: 11352, MSE: 0.24593474789045855, Learning Rate: 0.04324\n",
      "Epoch: 11353, MSE: 0.245932078582761, Learning Rate: 0.043235\n",
      "Epoch: 11354, MSE: 0.2459294092301128, Learning Rate: 0.043230000000000005\n",
      "Epoch: 11355, MSE: 0.24592673983251725, Learning Rate: 0.043225000000000006\n",
      "Epoch: 11356, MSE: 0.24592407038997668, Learning Rate: 0.04322000000000001\n",
      "Epoch: 11357, MSE: 0.2459214009024941, Learning Rate: 0.043215\n",
      "Epoch: 11358, MSE: 0.24591873137007153, Learning Rate: 0.043210000000000005\n",
      "Epoch: 11359, MSE: 0.24591606179271183, Learning Rate: 0.04320500000000001\n",
      "Epoch: 11360, MSE: 0.24591339217041733, Learning Rate: 0.04320000000000001\n",
      "Epoch: 11361, MSE: 0.24591072250319035, Learning Rate: 0.043195\n",
      "Epoch: 11362, MSE: 0.2459080527910332, Learning Rate: 0.04319\n",
      "Epoch: 11363, MSE: 0.24590538303394954, Learning Rate: 0.043185\n",
      "Epoch: 11364, MSE: 0.24590271323194152, Learning Rate: 0.043179999999999996\n",
      "Epoch: 11365, MSE: 0.24590004338501034, Learning Rate: 0.043175\n",
      "Epoch: 11366, MSE: 0.24589737349316101, Learning Rate: 0.04317\n",
      "Epoch: 11367, MSE: 0.24589470355639442, Learning Rate: 0.043165\n",
      "Epoch: 11368, MSE: 0.24589203357471304, Learning Rate: 0.043160000000000004\n",
      "Epoch: 11369, MSE: 0.24588936354811938, Learning Rate: 0.043155\n",
      "Epoch: 11370, MSE: 0.24588669347661748, Learning Rate: 0.04315\n",
      "Epoch: 11371, MSE: 0.24588402336020768, Learning Rate: 0.043145\n",
      "Epoch: 11372, MSE: 0.2458813531988947, Learning Rate: 0.043140000000000005\n",
      "Epoch: 11373, MSE: 0.24587868299267904, Learning Rate: 0.04313500000000001\n",
      "Epoch: 11374, MSE: 0.2458760127415653, Learning Rate: 0.04313\n",
      "Epoch: 11375, MSE: 0.2458733424455537, Learning Rate: 0.043125000000000004\n",
      "Epoch: 11376, MSE: 0.24587067210464927, Learning Rate: 0.043120000000000006\n",
      "Epoch: 11377, MSE: 0.24586800171885262, Learning Rate: 0.04311500000000001\n",
      "Epoch: 11378, MSE: 0.24586533128816743, Learning Rate: 0.04311000000000001\n",
      "Epoch: 11379, MSE: 0.24586266081259597, Learning Rate: 0.043105000000000004\n",
      "Epoch: 11380, MSE: 0.24585999029213992, Learning Rate: 0.043100000000000006\n",
      "Epoch: 11381, MSE: 0.24585731972680291, Learning Rate: 0.04309500000000001\n",
      "Epoch: 11382, MSE: 0.2458546491165879, Learning Rate: 0.043089999999999996\n",
      "Epoch: 11383, MSE: 0.24585197846149628, Learning Rate: 0.043085\n",
      "Epoch: 11384, MSE: 0.24584930776153094, Learning Rate: 0.04308\n",
      "Epoch: 11385, MSE: 0.245846637016695, Learning Rate: 0.043075\n",
      "Epoch: 11386, MSE: 0.24584396622699012, Learning Rate: 0.04307\n",
      "Epoch: 11387, MSE: 0.24584129539241906, Learning Rate: 0.043065\n",
      "Epoch: 11388, MSE: 0.245838624512985, Learning Rate: 0.04306\n",
      "Epoch: 11389, MSE: 0.24583595358868965, Learning Rate: 0.043055\n",
      "Epoch: 11390, MSE: 0.24583328261953688, Learning Rate: 0.043050000000000005\n",
      "Epoch: 11391, MSE: 0.24583061160552772, Learning Rate: 0.043045\n",
      "Epoch: 11392, MSE: 0.2458279405466659, Learning Rate: 0.04304\n",
      "Epoch: 11393, MSE: 0.24582526944295266, Learning Rate: 0.043035000000000004\n",
      "Epoch: 11394, MSE: 0.24582259829439268, Learning Rate: 0.043030000000000006\n",
      "Epoch: 11395, MSE: 0.24581992710098605, Learning Rate: 0.04302500000000001\n",
      "Epoch: 11396, MSE: 0.24581725586273678, Learning Rate: 0.04302\n",
      "Epoch: 11397, MSE: 0.24581458457964725, Learning Rate: 0.043015000000000005\n",
      "Epoch: 11398, MSE: 0.2458119132517205, Learning Rate: 0.04301000000000001\n",
      "Epoch: 11399, MSE: 0.245809241878958, Learning Rate: 0.04300500000000001\n",
      "Epoch: 11400, MSE: 0.2458065704613631, Learning Rate: 0.04300000000000001\n",
      "Epoch: 11401, MSE: 0.24580389899893765, Learning Rate: 0.042995000000000005\n",
      "Epoch: 11402, MSE: 0.2458012274916849, Learning Rate: 0.04299\n",
      "Epoch: 11403, MSE: 0.24579855593960717, Learning Rate: 0.042984999999999995\n",
      "Epoch: 11404, MSE: 0.24579588434270686, Learning Rate: 0.04298\n",
      "Epoch: 11405, MSE: 0.24579321270098703, Learning Rate: 0.042975\n",
      "Epoch: 11406, MSE: 0.24579054101445008, Learning Rate: 0.04297\n",
      "Epoch: 11407, MSE: 0.24578786928309812, Learning Rate: 0.042965\n",
      "Epoch: 11408, MSE: 0.24578519750693392, Learning Rate: 0.04296\n",
      "Epoch: 11409, MSE: 0.24578252568596046, Learning Rate: 0.042955\n",
      "Epoch: 11410, MSE: 0.24577985382017917, Learning Rate: 0.04295\n",
      "Epoch: 11411, MSE: 0.24577718190959444, Learning Rate: 0.042945000000000004\n",
      "Epoch: 11412, MSE: 0.24577450995420735, Learning Rate: 0.042940000000000006\n",
      "Epoch: 11413, MSE: 0.2457718379540214, Learning Rate: 0.042935\n",
      "Epoch: 11414, MSE: 0.24576916590903794, Learning Rate: 0.04293\n",
      "Epoch: 11415, MSE: 0.24576649381926188, Learning Rate: 0.042925000000000005\n",
      "Epoch: 11416, MSE: 0.24576382168469252, Learning Rate: 0.04292000000000001\n",
      "Epoch: 11417, MSE: 0.2457611495053357, Learning Rate: 0.04291500000000001\n",
      "Epoch: 11418, MSE: 0.2457584772811913, Learning Rate: 0.042910000000000004\n",
      "Epoch: 11419, MSE: 0.2457558050122631, Learning Rate: 0.042905000000000006\n",
      "Epoch: 11420, MSE: 0.2457531326985542, Learning Rate: 0.04290000000000001\n",
      "Epoch: 11421, MSE: 0.2457504603400657, Learning Rate: 0.04289500000000001\n",
      "Epoch: 11422, MSE: 0.24574778793680185, Learning Rate: 0.04289\n",
      "Epoch: 11423, MSE: 0.24574511548876424, Learning Rate: 0.042885\n",
      "Epoch: 11424, MSE: 0.2457424429959557, Learning Rate: 0.04288\n",
      "Epoch: 11425, MSE: 0.2457397704583791, Learning Rate: 0.042874999999999996\n",
      "Epoch: 11426, MSE: 0.2457370978760361, Learning Rate: 0.04287\n",
      "Epoch: 11427, MSE: 0.24573442524893013, Learning Rate: 0.042865\n",
      "Epoch: 11428, MSE: 0.24573175257706287, Learning Rate: 0.04286\n",
      "Epoch: 11429, MSE: 0.245729079860439, Learning Rate: 0.042855000000000004\n",
      "Epoch: 11430, MSE: 0.24572640709905824, Learning Rate: 0.04285\n",
      "Epoch: 11431, MSE: 0.24572373429292474, Learning Rate: 0.042845\n",
      "Epoch: 11432, MSE: 0.24572106144204134, Learning Rate: 0.04284\n",
      "Epoch: 11433, MSE: 0.2457183885464097, Learning Rate: 0.042835000000000005\n",
      "Epoch: 11434, MSE: 0.2457157156060327, Learning Rate: 0.04283000000000001\n",
      "Epoch: 11435, MSE: 0.24571304262091428, Learning Rate: 0.042825\n",
      "Epoch: 11436, MSE: 0.24571036959105477, Learning Rate: 0.042820000000000004\n",
      "Epoch: 11437, MSE: 0.2457076965164584, Learning Rate: 0.042815000000000006\n",
      "Epoch: 11438, MSE: 0.24570502339712702, Learning Rate: 0.04281000000000001\n",
      "Epoch: 11439, MSE: 0.24570235023306394, Learning Rate: 0.04280500000000001\n",
      "Epoch: 11440, MSE: 0.24569967702426967, Learning Rate: 0.042800000000000005\n",
      "Epoch: 11441, MSE: 0.24569700377074985, Learning Rate: 0.04279500000000001\n",
      "Epoch: 11442, MSE: 0.24569433047250433, Learning Rate: 0.042789999999999995\n",
      "Epoch: 11443, MSE: 0.24569165712953744, Learning Rate: 0.042785\n",
      "Epoch: 11444, MSE: 0.2456889837418511, Learning Rate: 0.04278\n",
      "Epoch: 11445, MSE: 0.24568631030944837, Learning Rate: 0.042775\n",
      "Epoch: 11446, MSE: 0.24568363683233096, Learning Rate: 0.04277\n",
      "Epoch: 11447, MSE: 0.24568096331050235, Learning Rate: 0.042765\n",
      "Epoch: 11448, MSE: 0.24567828974396488, Learning Rate: 0.04276\n",
      "Epoch: 11449, MSE: 0.24567561613272032, Learning Rate: 0.042755\n",
      "Epoch: 11450, MSE: 0.24567294247677265, Learning Rate: 0.04275\n",
      "Epoch: 11451, MSE: 0.2456702687761236, Learning Rate: 0.042745000000000005\n",
      "Epoch: 11452, MSE: 0.24566759503077565, Learning Rate: 0.04274\n",
      "Epoch: 11453, MSE: 0.24566492124073216, Learning Rate: 0.042735\n",
      "Epoch: 11454, MSE: 0.24566224740599496, Learning Rate: 0.042730000000000004\n",
      "Epoch: 11455, MSE: 0.24565957352656642, Learning Rate: 0.042725000000000006\n",
      "Epoch: 11456, MSE: 0.2456568996024505, Learning Rate: 0.04272000000000001\n",
      "Epoch: 11457, MSE: 0.24565422563364858, Learning Rate: 0.042715\n",
      "Epoch: 11458, MSE: 0.24565155162016314, Learning Rate: 0.042710000000000005\n",
      "Epoch: 11459, MSE: 0.24564887756199774, Learning Rate: 0.04270500000000001\n",
      "Epoch: 11460, MSE: 0.24564620345915505, Learning Rate: 0.04270000000000001\n",
      "Epoch: 11461, MSE: 0.24564352931163583, Learning Rate: 0.04269500000000001\n",
      "Epoch: 11462, MSE: 0.24564085511944453, Learning Rate: 0.04269\n",
      "Epoch: 11463, MSE: 0.24563818088258313, Learning Rate: 0.042685\n",
      "Epoch: 11464, MSE: 0.24563550660105463, Learning Rate: 0.042679999999999996\n",
      "Epoch: 11465, MSE: 0.24563283227486, Learning Rate: 0.042675\n",
      "Epoch: 11466, MSE: 0.24563015790400447, Learning Rate: 0.04267\n",
      "Epoch: 11467, MSE: 0.24562748348848915, Learning Rate: 0.042665\n",
      "Epoch: 11468, MSE: 0.2456248090283165, Learning Rate: 0.042660000000000003\n",
      "Epoch: 11469, MSE: 0.24562213452348886, Learning Rate: 0.042655\n",
      "Epoch: 11470, MSE: 0.24561945997401013, Learning Rate: 0.04265\n",
      "Epoch: 11471, MSE: 0.24561678537988135, Learning Rate: 0.042645\n",
      "Epoch: 11472, MSE: 0.24561411074110645, Learning Rate: 0.042640000000000004\n",
      "Epoch: 11473, MSE: 0.24561143605768745, Learning Rate: 0.042635000000000006\n",
      "Epoch: 11474, MSE: 0.2456087613296267, Learning Rate: 0.04263\n",
      "Epoch: 11475, MSE: 0.24560608655692742, Learning Rate: 0.042625\n",
      "Epoch: 11476, MSE: 0.2456034117395916, Learning Rate: 0.042620000000000005\n",
      "Epoch: 11477, MSE: 0.24560073687762224, Learning Rate: 0.04261500000000001\n",
      "Epoch: 11478, MSE: 0.24559806197102124, Learning Rate: 0.04261000000000001\n",
      "Epoch: 11479, MSE: 0.24559538701979322, Learning Rate: 0.042605000000000004\n",
      "Epoch: 11480, MSE: 0.2455927120239381, Learning Rate: 0.042600000000000006\n",
      "Epoch: 11481, MSE: 0.24559003698346032, Learning Rate: 0.04259500000000001\n",
      "Epoch: 11482, MSE: 0.24558736189836217, Learning Rate: 0.042589999999999996\n",
      "Epoch: 11483, MSE: 0.24558468676864542, Learning Rate: 0.042585\n",
      "Epoch: 11484, MSE: 0.24558201159431312, Learning Rate: 0.04258\n",
      "Epoch: 11485, MSE: 0.2455793363753685, Learning Rate: 0.042575\n",
      "Epoch: 11486, MSE: 0.2455766611118141, Learning Rate: 0.04257\n",
      "Epoch: 11487, MSE: 0.24557398580365153, Learning Rate: 0.042565\n",
      "Epoch: 11488, MSE: 0.24557131045088393, Learning Rate: 0.04256\n",
      "Epoch: 11489, MSE: 0.24556863505351376, Learning Rate: 0.042555\n",
      "Epoch: 11490, MSE: 0.2455659596115445, Learning Rate: 0.042550000000000004\n",
      "Epoch: 11491, MSE: 0.24556328412497822, Learning Rate: 0.042545\n",
      "Epoch: 11492, MSE: 0.2455606085938168, Learning Rate: 0.04254\n",
      "Epoch: 11493, MSE: 0.24555793301806372, Learning Rate: 0.042535\n",
      "Epoch: 11494, MSE: 0.2455552573977217, Learning Rate: 0.042530000000000005\n",
      "Epoch: 11495, MSE: 0.245552581732793, Learning Rate: 0.04252500000000001\n",
      "Epoch: 11496, MSE: 0.24554990602327942, Learning Rate: 0.04252\n",
      "Epoch: 11497, MSE: 0.24554723026918512, Learning Rate: 0.042515000000000004\n",
      "Epoch: 11498, MSE: 0.24554455447051213, Learning Rate: 0.042510000000000006\n",
      "Epoch: 11499, MSE: 0.24554187862726262, Learning Rate: 0.04250500000000001\n",
      "Epoch: 11500, MSE: 0.24553920273943994, Learning Rate: 0.04250000000000001\n",
      "Epoch: 11501, MSE: 0.2455365268070459, Learning Rate: 0.042495000000000005\n",
      "Epoch: 11502, MSE: 0.2455338508300838, Learning Rate: 0.04249000000000001\n",
      "Epoch: 11503, MSE: 0.24553117480855538, Learning Rate: 0.042484999999999995\n",
      "Epoch: 11504, MSE: 0.24552849874246455, Learning Rate: 0.04248\n",
      "Epoch: 11505, MSE: 0.24552582263181244, Learning Rate: 0.042475\n",
      "Epoch: 11506, MSE: 0.24552314647660312, Learning Rate: 0.04247\n",
      "Epoch: 11507, MSE: 0.24552047027683863, Learning Rate: 0.042465\n",
      "Epoch: 11508, MSE: 0.24551779403252078, Learning Rate: 0.04246\n",
      "Epoch: 11509, MSE: 0.24551511774365398, Learning Rate: 0.042455\n",
      "Epoch: 11510, MSE: 0.24551244141023917, Learning Rate: 0.04245\n",
      "Epoch: 11511, MSE: 0.2455097650322795, Learning Rate: 0.042445000000000004\n",
      "Epoch: 11512, MSE: 0.24550708860977838, Learning Rate: 0.042440000000000005\n",
      "Epoch: 11513, MSE: 0.24550441214273713, Learning Rate: 0.042435\n",
      "Epoch: 11514, MSE: 0.24550173563115907, Learning Rate: 0.04243\n",
      "Epoch: 11515, MSE: 0.24549905907504732, Learning Rate: 0.042425000000000004\n",
      "Epoch: 11516, MSE: 0.2454963824744032, Learning Rate: 0.042420000000000006\n",
      "Epoch: 11517, MSE: 0.24549370582923094, Learning Rate: 0.04241500000000001\n",
      "Epoch: 11518, MSE: 0.24549102913953125, Learning Rate: 0.04241\n",
      "Epoch: 11519, MSE: 0.2454883524053082, Learning Rate: 0.042405000000000005\n",
      "Epoch: 11520, MSE: 0.24548567562656468, Learning Rate: 0.04240000000000001\n",
      "Epoch: 11521, MSE: 0.24548299880330193, Learning Rate: 0.04239500000000001\n",
      "Epoch: 11522, MSE: 0.245480321935524, Learning Rate: 0.04239000000000001\n",
      "Epoch: 11523, MSE: 0.2454776450232326, Learning Rate: 0.042385\n",
      "Epoch: 11524, MSE: 0.24547496806643027, Learning Rate: 0.04238\n",
      "Epoch: 11525, MSE: 0.2454722910651208, Learning Rate: 0.042374999999999996\n",
      "Epoch: 11526, MSE: 0.24546961401930525, Learning Rate: 0.04237\n",
      "Epoch: 11527, MSE: 0.24546693692898736, Learning Rate: 0.042365\n",
      "Epoch: 11528, MSE: 0.24546425979416908, Learning Rate: 0.04236\n",
      "Epoch: 11529, MSE: 0.24546158261485337, Learning Rate: 0.042355000000000004\n",
      "Epoch: 11530, MSE: 0.24545890539104342, Learning Rate: 0.04235\n",
      "Epoch: 11531, MSE: 0.24545622812274076, Learning Rate: 0.042345\n",
      "Epoch: 11532, MSE: 0.2454535508099491, Learning Rate: 0.04234\n",
      "Epoch: 11533, MSE: 0.24545087345267, Learning Rate: 0.042335000000000005\n",
      "Epoch: 11534, MSE: 0.2454481960509075, Learning Rate: 0.042330000000000007\n",
      "Epoch: 11535, MSE: 0.24544551860466243, Learning Rate: 0.042325\n",
      "Epoch: 11536, MSE: 0.24544284111393916, Learning Rate: 0.04232\n",
      "Epoch: 11537, MSE: 0.24544016357873893, Learning Rate: 0.042315000000000005\n",
      "Epoch: 11538, MSE: 0.24543748599906545, Learning Rate: 0.04231000000000001\n",
      "Epoch: 11539, MSE: 0.24543480837492043, Learning Rate: 0.04230500000000001\n",
      "Epoch: 11540, MSE: 0.24543213070630754, Learning Rate: 0.042300000000000004\n",
      "Epoch: 11541, MSE: 0.24542945299322866, Learning Rate: 0.042295000000000006\n",
      "Epoch: 11542, MSE: 0.245426775235687, Learning Rate: 0.04229000000000001\n",
      "Epoch: 11543, MSE: 0.24542409743368437, Learning Rate: 0.042284999999999996\n",
      "Epoch: 11544, MSE: 0.24542141958722435, Learning Rate: 0.04228\n",
      "Epoch: 11545, MSE: 0.24541874169630826, Learning Rate: 0.042275\n",
      "Epoch: 11546, MSE: 0.2454160637609406, Learning Rate: 0.04227\n",
      "Epoch: 11547, MSE: 0.2454133857811227, Learning Rate: 0.042265\n",
      "Epoch: 11548, MSE: 0.24541070775685728, Learning Rate: 0.04226\n",
      "Epoch: 11549, MSE: 0.2454080296881472, Learning Rate: 0.042255\n",
      "Epoch: 11550, MSE: 0.24540535157499557, Learning Rate: 0.04225\n",
      "Epoch: 11551, MSE: 0.24540267341740435, Learning Rate: 0.042245000000000005\n",
      "Epoch: 11552, MSE: 0.24539999521537628, Learning Rate: 0.04224\n",
      "Epoch: 11553, MSE: 0.24539731696891454, Learning Rate: 0.042235\n",
      "Epoch: 11554, MSE: 0.24539463867802114, Learning Rate: 0.042230000000000004\n",
      "Epoch: 11555, MSE: 0.24539196034269917, Learning Rate: 0.042225000000000006\n",
      "Epoch: 11556, MSE: 0.24538928196295084, Learning Rate: 0.04222000000000001\n",
      "Epoch: 11557, MSE: 0.24538660353877925, Learning Rate: 0.042215\n",
      "Epoch: 11558, MSE: 0.24538392507018705, Learning Rate: 0.042210000000000004\n",
      "Epoch: 11559, MSE: 0.2453812465571769, Learning Rate: 0.042205000000000006\n",
      "Epoch: 11560, MSE: 0.2453785679997507, Learning Rate: 0.04220000000000001\n",
      "Epoch: 11561, MSE: 0.24537588939791208, Learning Rate: 0.04219500000000001\n",
      "Epoch: 11562, MSE: 0.24537321075166255, Learning Rate: 0.042190000000000005\n",
      "Epoch: 11563, MSE: 0.24537053206100612, Learning Rate: 0.042185\n",
      "Epoch: 11564, MSE: 0.2453678533259441, Learning Rate: 0.042179999999999995\n",
      "Epoch: 11565, MSE: 0.24536517454648082, Learning Rate: 0.042175\n",
      "Epoch: 11566, MSE: 0.24536249572261756, Learning Rate: 0.04217\n",
      "Epoch: 11567, MSE: 0.24535981685435704, Learning Rate: 0.042165\n",
      "Epoch: 11568, MSE: 0.2453571379417027, Learning Rate: 0.04216\n",
      "Epoch: 11569, MSE: 0.2453544589846571, Learning Rate: 0.042155\n",
      "Epoch: 11570, MSE: 0.24535177998322158, Learning Rate: 0.04215\n",
      "Epoch: 11571, MSE: 0.24534910093740095, Learning Rate: 0.042145\n",
      "Epoch: 11572, MSE: 0.24534642184719588, Learning Rate: 0.042140000000000004\n",
      "Epoch: 11573, MSE: 0.2453437427126097, Learning Rate: 0.042135000000000006\n",
      "Epoch: 11574, MSE: 0.24534106353364576, Learning Rate: 0.04213\n",
      "Epoch: 11575, MSE: 0.245338384310306, Learning Rate: 0.042125\n",
      "Epoch: 11576, MSE: 0.24533570504259278, Learning Rate: 0.042120000000000005\n",
      "Epoch: 11577, MSE: 0.24533302573050952, Learning Rate: 0.04211500000000001\n",
      "Epoch: 11578, MSE: 0.24533034637405873, Learning Rate: 0.04211000000000001\n",
      "Epoch: 11579, MSE: 0.24532766697324274, Learning Rate: 0.042105000000000004\n",
      "Epoch: 11580, MSE: 0.24532498752806464, Learning Rate: 0.042100000000000005\n",
      "Epoch: 11581, MSE: 0.2453223080385266, Learning Rate: 0.04209500000000001\n",
      "Epoch: 11582, MSE: 0.24531962850463176, Learning Rate: 0.04209000000000001\n",
      "Epoch: 11583, MSE: 0.24531694892638234, Learning Rate: 0.042085\n",
      "Epoch: 11584, MSE: 0.2453142693037813, Learning Rate: 0.04208\n",
      "Epoch: 11585, MSE: 0.24531158963683108, Learning Rate: 0.042075\n",
      "Epoch: 11586, MSE: 0.2453089099255341, Learning Rate: 0.042069999999999996\n",
      "Epoch: 11587, MSE: 0.2453062301698948, Learning Rate: 0.042065\n",
      "Epoch: 11588, MSE: 0.24530355036991283, Learning Rate: 0.04206\n",
      "Epoch: 11589, MSE: 0.24530087052559407, Learning Rate: 0.042055\n",
      "Epoch: 11590, MSE: 0.24529819063693853, Learning Rate: 0.042050000000000004\n",
      "Epoch: 11591, MSE: 0.2452955107039498, Learning Rate: 0.042045\n",
      "Epoch: 11592, MSE: 0.2452928307266314, Learning Rate: 0.04204\n",
      "Epoch: 11593, MSE: 0.2452901507049854, Learning Rate: 0.042035\n",
      "Epoch: 11594, MSE: 0.24528747063901327, Learning Rate: 0.042030000000000005\n",
      "Epoch: 11595, MSE: 0.24528479052872013, Learning Rate: 0.04202500000000001\n",
      "Epoch: 11596, MSE: 0.2452821103741069, Learning Rate: 0.04202\n",
      "Epoch: 11597, MSE: 0.24527943017517612, Learning Rate: 0.042015000000000004\n",
      "Epoch: 11598, MSE: 0.24527674993193146, Learning Rate: 0.042010000000000006\n",
      "Epoch: 11599, MSE: 0.24527406964437481, Learning Rate: 0.04200500000000001\n",
      "Epoch: 11600, MSE: 0.2452713893125094, Learning Rate: 0.04200000000000001\n",
      "Epoch: 11601, MSE: 0.2452687089363371, Learning Rate: 0.041995000000000005\n",
      "Epoch: 11602, MSE: 0.2452660285158625, Learning Rate: 0.041990000000000006\n",
      "Epoch: 11603, MSE: 0.24526334805108563, Learning Rate: 0.041984999999999995\n",
      "Epoch: 11604, MSE: 0.24526066754201117, Learning Rate: 0.041979999999999996\n",
      "Epoch: 11605, MSE: 0.24525798698864099, Learning Rate: 0.041975\n",
      "Epoch: 11606, MSE: 0.24525530639097776, Learning Rate: 0.04197\n",
      "Epoch: 11607, MSE: 0.24525262574902462, Learning Rate: 0.041965\n",
      "Epoch: 11608, MSE: 0.24524994506278305, Learning Rate: 0.04196\n",
      "Epoch: 11609, MSE: 0.245247264332257, Learning Rate: 0.041955\n",
      "Epoch: 11610, MSE: 0.24524458355744852, Learning Rate: 0.04195\n",
      "Epoch: 11611, MSE: 0.24524190273836108, Learning Rate: 0.041945\n",
      "Epoch: 11612, MSE: 0.24523922187499647, Learning Rate: 0.041940000000000005\n",
      "Epoch: 11613, MSE: 0.24523654096735706, Learning Rate: 0.041935\n",
      "Epoch: 11614, MSE: 0.24523386001544684, Learning Rate: 0.04193\n",
      "Epoch: 11615, MSE: 0.2452311790192678, Learning Rate: 0.041925000000000004\n",
      "Epoch: 11616, MSE: 0.24522849797882232, Learning Rate: 0.041920000000000006\n",
      "Epoch: 11617, MSE: 0.245225816894114, Learning Rate: 0.04191500000000001\n",
      "Epoch: 11618, MSE: 0.2452231357651444, Learning Rate: 0.04191\n",
      "Epoch: 11619, MSE: 0.2452204545919168, Learning Rate: 0.041905000000000005\n",
      "Epoch: 11620, MSE: 0.24521777337443434, Learning Rate: 0.04190000000000001\n",
      "Epoch: 11621, MSE: 0.2452150921126983, Learning Rate: 0.04189500000000001\n",
      "Epoch: 11622, MSE: 0.2452124108067121, Learning Rate: 0.04189000000000001\n",
      "Epoch: 11623, MSE: 0.2452097294564794, Learning Rate: 0.041885\n",
      "Epoch: 11624, MSE: 0.24520704806200103, Learning Rate: 0.04188\n",
      "Epoch: 11625, MSE: 0.24520436662328152, Learning Rate: 0.041874999999999996\n",
      "Epoch: 11626, MSE: 0.24520168514032237, Learning Rate: 0.04187\n",
      "Epoch: 11627, MSE: 0.2451990036131269, Learning Rate: 0.041865\n",
      "Epoch: 11628, MSE: 0.2451963220416972, Learning Rate: 0.04186\n",
      "Epoch: 11629, MSE: 0.2451936404260361, Learning Rate: 0.041855\n",
      "Epoch: 11630, MSE: 0.24519095876614658, Learning Rate: 0.04185\n",
      "Epoch: 11631, MSE: 0.24518827706203195, Learning Rate: 0.041845\n",
      "Epoch: 11632, MSE: 0.24518559531369333, Learning Rate: 0.04184\n",
      "Epoch: 11633, MSE: 0.24518291352113458, Learning Rate: 0.041835000000000004\n",
      "Epoch: 11634, MSE: 0.24518023168435804, Learning Rate: 0.041830000000000006\n",
      "Epoch: 11635, MSE: 0.2451775498033667, Learning Rate: 0.041825\n",
      "Epoch: 11636, MSE: 0.24517486787816206, Learning Rate: 0.04182\n",
      "Epoch: 11637, MSE: 0.2451721859087481, Learning Rate: 0.041815000000000005\n",
      "Epoch: 11638, MSE: 0.24516950389512776, Learning Rate: 0.04181000000000001\n",
      "Epoch: 11639, MSE: 0.2451668218373027, Learning Rate: 0.04180500000000001\n",
      "Epoch: 11640, MSE: 0.24516413973527654, Learning Rate: 0.041800000000000004\n",
      "Epoch: 11641, MSE: 0.24516145758905072, Learning Rate: 0.041795000000000006\n",
      "Epoch: 11642, MSE: 0.24515877539862907, Learning Rate: 0.04179000000000001\n",
      "Epoch: 11643, MSE: 0.2451560931640132, Learning Rate: 0.04178500000000001\n",
      "Epoch: 11644, MSE: 0.24515341088520753, Learning Rate: 0.04178\n",
      "Epoch: 11645, MSE: 0.2451507285622133, Learning Rate: 0.041775\n",
      "Epoch: 11646, MSE: 0.2451480461950338, Learning Rate: 0.04177\n",
      "Epoch: 11647, MSE: 0.24514536378367105, Learning Rate: 0.041765\n",
      "Epoch: 11648, MSE: 0.24514268132812897, Learning Rate: 0.04176\n",
      "Epoch: 11649, MSE: 0.24513999882840956, Learning Rate: 0.041755\n",
      "Epoch: 11650, MSE: 0.24513731628451563, Learning Rate: 0.04175\n",
      "Epoch: 11651, MSE: 0.2451346336964497, Learning Rate: 0.041745000000000004\n",
      "Epoch: 11652, MSE: 0.24513195106421445, Learning Rate: 0.04174\n",
      "Epoch: 11653, MSE: 0.2451292683878122, Learning Rate: 0.041735\n",
      "Epoch: 11654, MSE: 0.24512658566724602, Learning Rate: 0.04173\n",
      "Epoch: 11655, MSE: 0.24512390290251998, Learning Rate: 0.041725000000000005\n",
      "Epoch: 11656, MSE: 0.24512122009363452, Learning Rate: 0.04172000000000001\n",
      "Epoch: 11657, MSE: 0.2451185372405937, Learning Rate: 0.041715\n",
      "Epoch: 11658, MSE: 0.24511585434339994, Learning Rate: 0.041710000000000004\n",
      "Epoch: 11659, MSE: 0.24511317140205585, Learning Rate: 0.041705000000000006\n",
      "Epoch: 11660, MSE: 0.24511048841656474, Learning Rate: 0.04170000000000001\n",
      "Epoch: 11661, MSE: 0.24510780538692764, Learning Rate: 0.04169500000000001\n",
      "Epoch: 11662, MSE: 0.24510512231314904, Learning Rate: 0.041690000000000005\n",
      "Epoch: 11663, MSE: 0.24510243919523053, Learning Rate: 0.04168500000000001\n",
      "Epoch: 11664, MSE: 0.24509975603317605, Learning Rate: 0.041679999999999995\n",
      "Epoch: 11665, MSE: 0.2450970728269872, Learning Rate: 0.041675\n",
      "Epoch: 11666, MSE: 0.2450943895766674, Learning Rate: 0.04167\n",
      "Epoch: 11667, MSE: 0.2450917062822186, Learning Rate: 0.041665\n",
      "Epoch: 11668, MSE: 0.24508902294364354, Learning Rate: 0.04166\n",
      "Epoch: 11669, MSE: 0.24508633956094586, Learning Rate: 0.041655\n",
      "Epoch: 11670, MSE: 0.24508365613412783, Learning Rate: 0.04165\n",
      "Epoch: 11671, MSE: 0.24508097266319162, Learning Rate: 0.041645\n",
      "Epoch: 11672, MSE: 0.2450782891481412, Learning Rate: 0.04164\n",
      "Epoch: 11673, MSE: 0.2450756055889772, Learning Rate: 0.041635000000000005\n",
      "Epoch: 11674, MSE: 0.24507292198570405, Learning Rate: 0.04163\n",
      "Epoch: 11675, MSE: 0.24507023833832411, Learning Rate: 0.041625\n",
      "Epoch: 11676, MSE: 0.2450675546468406, Learning Rate: 0.041620000000000004\n",
      "Epoch: 11677, MSE: 0.2450648709112546, Learning Rate: 0.041615000000000006\n",
      "Epoch: 11678, MSE: 0.24506218713157016, Learning Rate: 0.04161000000000001\n",
      "Epoch: 11679, MSE: 0.24505950330779028, Learning Rate: 0.041605\n",
      "Epoch: 11680, MSE: 0.2450568194399159, Learning Rate: 0.041600000000000005\n",
      "Epoch: 11681, MSE: 0.24505413552795224, Learning Rate: 0.04159500000000001\n",
      "Epoch: 11682, MSE: 0.2450514515718997, Learning Rate: 0.04159000000000001\n",
      "Epoch: 11683, MSE: 0.24504876757176283, Learning Rate: 0.04158500000000001\n",
      "Epoch: 11684, MSE: 0.24504608352754378, Learning Rate: 0.04158\n",
      "Epoch: 11685, MSE: 0.24504339943924347, Learning Rate: 0.041575\n",
      "Epoch: 11686, MSE: 0.24504071530686738, Learning Rate: 0.041569999999999996\n",
      "Epoch: 11687, MSE: 0.24503803113041728, Learning Rate: 0.041565\n",
      "Epoch: 11688, MSE: 0.2450353469098942, Learning Rate: 0.04156\n",
      "Epoch: 11689, MSE: 0.24503266264530366, Learning Rate: 0.041555\n",
      "Epoch: 11690, MSE: 0.24502997833664636, Learning Rate: 0.041550000000000004\n",
      "Epoch: 11691, MSE: 0.24502729398392592, Learning Rate: 0.041545\n",
      "Epoch: 11692, MSE: 0.2450246095871449, Learning Rate: 0.04154\n",
      "Epoch: 11693, MSE: 0.2450219251463066, Learning Rate: 0.041535\n",
      "Epoch: 11694, MSE: 0.24501924066141226, Learning Rate: 0.041530000000000004\n",
      "Epoch: 11695, MSE: 0.2450165561324656, Learning Rate: 0.041525000000000006\n",
      "Epoch: 11696, MSE: 0.245013871559469, Learning Rate: 0.04152\n",
      "Epoch: 11697, MSE: 0.2450111869424255, Learning Rate: 0.041515\n",
      "Epoch: 11698, MSE: 0.24500850228133803, Learning Rate: 0.041510000000000005\n",
      "Epoch: 11699, MSE: 0.24500581757620896, Learning Rate: 0.04150500000000001\n",
      "Epoch: 11700, MSE: 0.24500313282704098, Learning Rate: 0.04150000000000001\n",
      "Epoch: 11701, MSE: 0.24500044803383667, Learning Rate: 0.041495000000000004\n",
      "Epoch: 11702, MSE: 0.24499776319659933, Learning Rate: 0.041490000000000006\n",
      "Epoch: 11703, MSE: 0.2449950783153311, Learning Rate: 0.04148500000000001\n",
      "Epoch: 11704, MSE: 0.24499239339003495, Learning Rate: 0.041479999999999996\n",
      "Epoch: 11705, MSE: 0.24498970842071416, Learning Rate: 0.041475\n",
      "Epoch: 11706, MSE: 0.2449870234073705, Learning Rate: 0.04147\n",
      "Epoch: 11707, MSE: 0.24498433835000719, Learning Rate: 0.041465\n",
      "Epoch: 11708, MSE: 0.24498165324862692, Learning Rate: 0.04146\n",
      "Epoch: 11709, MSE: 0.24497896810323258, Learning Rate: 0.041455\n",
      "Epoch: 11710, MSE: 0.2449762829138266, Learning Rate: 0.04145\n",
      "Epoch: 11711, MSE: 0.24497359768041144, Learning Rate: 0.041445\n",
      "Epoch: 11712, MSE: 0.24497091240299138, Learning Rate: 0.041440000000000005\n",
      "Epoch: 11713, MSE: 0.24496822708156726, Learning Rate: 0.041435\n",
      "Epoch: 11714, MSE: 0.24496554171614246, Learning Rate: 0.04143\n",
      "Epoch: 11715, MSE: 0.24496285630672, Learning Rate: 0.041425000000000003\n",
      "Epoch: 11716, MSE: 0.24496017085330268, Learning Rate: 0.041420000000000005\n",
      "Epoch: 11717, MSE: 0.2449574853558931, Learning Rate: 0.04141500000000001\n",
      "Epoch: 11718, MSE: 0.2449547998144931, Learning Rate: 0.04141\n",
      "Epoch: 11719, MSE: 0.24495211422910695, Learning Rate: 0.041405000000000004\n",
      "Epoch: 11720, MSE: 0.2449494285997372, Learning Rate: 0.041400000000000006\n",
      "Epoch: 11721, MSE: 0.24494674292638552, Learning Rate: 0.04139500000000001\n",
      "Epoch: 11722, MSE: 0.2449440572090551, Learning Rate: 0.04139000000000001\n",
      "Epoch: 11723, MSE: 0.24494137144774875, Learning Rate: 0.041385000000000005\n",
      "Epoch: 11724, MSE: 0.24493868564246976, Learning Rate: 0.04138\n",
      "Epoch: 11725, MSE: 0.24493599979322042, Learning Rate: 0.041374999999999995\n",
      "Epoch: 11726, MSE: 0.24493331390000214, Learning Rate: 0.04137\n",
      "Epoch: 11727, MSE: 0.24493062796282064, Learning Rate: 0.041365\n",
      "Epoch: 11728, MSE: 0.24492794198167628, Learning Rate: 0.04136\n",
      "Epoch: 11729, MSE: 0.24492525595657202, Learning Rate: 0.041355\n",
      "Epoch: 11730, MSE: 0.24492256988751174, Learning Rate: 0.04135\n",
      "Epoch: 11731, MSE: 0.2449198837744973, Learning Rate: 0.041345\n",
      "Epoch: 11732, MSE: 0.24491719761753178, Learning Rate: 0.04134\n",
      "Epoch: 11733, MSE: 0.24491451141661771, Learning Rate: 0.041335000000000004\n",
      "Epoch: 11734, MSE: 0.24491182517175822, Learning Rate: 0.041330000000000006\n",
      "Epoch: 11735, MSE: 0.2449091388829554, Learning Rate: 0.041325\n",
      "Epoch: 11736, MSE: 0.2449064525502126, Learning Rate: 0.04132\n",
      "Epoch: 11737, MSE: 0.24490376617353332, Learning Rate: 0.041315000000000004\n",
      "Epoch: 11738, MSE: 0.24490107975291847, Learning Rate: 0.041310000000000006\n",
      "Epoch: 11739, MSE: 0.2448983932883713, Learning Rate: 0.04130500000000001\n",
      "Epoch: 11740, MSE: 0.24489570677989544, Learning Rate: 0.0413\n",
      "Epoch: 11741, MSE: 0.24489302022749296, Learning Rate: 0.041295000000000005\n",
      "Epoch: 11742, MSE: 0.24489033363116736, Learning Rate: 0.04129000000000001\n",
      "Epoch: 11743, MSE: 0.24488764699092064, Learning Rate: 0.04128500000000001\n",
      "Epoch: 11744, MSE: 0.2448849603067552, Learning Rate: 0.04128\n",
      "Epoch: 11745, MSE: 0.24488227357867512, Learning Rate: 0.041275\n",
      "Epoch: 11746, MSE: 0.24487958680668215, Learning Rate: 0.04127\n",
      "Epoch: 11747, MSE: 0.24487689999077977, Learning Rate: 0.041264999999999996\n",
      "Epoch: 11748, MSE: 0.244874213130969, Learning Rate: 0.04126\n",
      "Epoch: 11749, MSE: 0.24487152622725492, Learning Rate: 0.041255\n",
      "Epoch: 11750, MSE: 0.24486883927963876, Learning Rate: 0.04125\n",
      "Epoch: 11751, MSE: 0.24486615228812392, Learning Rate: 0.041245000000000004\n",
      "Epoch: 11752, MSE: 0.24486346525271283, Learning Rate: 0.04124\n",
      "Epoch: 11753, MSE: 0.24486077817340882, Learning Rate: 0.041235\n",
      "Epoch: 11754, MSE: 0.24485809105021367, Learning Rate: 0.04123\n",
      "Epoch: 11755, MSE: 0.24485540388313123, Learning Rate: 0.041225000000000005\n",
      "Epoch: 11756, MSE: 0.24485271667216374, Learning Rate: 0.04122000000000001\n",
      "Epoch: 11757, MSE: 0.2448500294173139, Learning Rate: 0.041215\n",
      "Epoch: 11758, MSE: 0.2448473421185841, Learning Rate: 0.041210000000000004\n",
      "Epoch: 11759, MSE: 0.2448446547759781, Learning Rate: 0.041205000000000006\n",
      "Epoch: 11760, MSE: 0.24484196738949796, Learning Rate: 0.04120000000000001\n",
      "Epoch: 11761, MSE: 0.24483927995914617, Learning Rate: 0.04119500000000001\n",
      "Epoch: 11762, MSE: 0.2448365924849268, Learning Rate: 0.041190000000000004\n",
      "Epoch: 11763, MSE: 0.24483390496684138, Learning Rate: 0.041185000000000006\n",
      "Epoch: 11764, MSE: 0.24483121740489242, Learning Rate: 0.04118000000000001\n",
      "Epoch: 11765, MSE: 0.24482852979908382, Learning Rate: 0.041174999999999996\n",
      "Epoch: 11766, MSE: 0.24482584214941805, Learning Rate: 0.04117\n",
      "Epoch: 11767, MSE: 0.24482315445589775, Learning Rate: 0.041165\n",
      "Epoch: 11768, MSE: 0.2448204667185249, Learning Rate: 0.04116\n",
      "Epoch: 11769, MSE: 0.24481777893730328, Learning Rate: 0.041155\n",
      "Epoch: 11770, MSE: 0.2448150911122354, Learning Rate: 0.04115\n",
      "Epoch: 11771, MSE: 0.2448124032433243, Learning Rate: 0.041145\n",
      "Epoch: 11772, MSE: 0.24480971533057178, Learning Rate: 0.04114\n",
      "Epoch: 11773, MSE: 0.24480702737398177, Learning Rate: 0.041135000000000005\n",
      "Epoch: 11774, MSE: 0.24480433937355658, Learning Rate: 0.04113\n",
      "Epoch: 11775, MSE: 0.24480165132929832, Learning Rate: 0.041125\n",
      "Epoch: 11776, MSE: 0.24479896324121056, Learning Rate: 0.041120000000000004\n",
      "Epoch: 11777, MSE: 0.2447962751092958, Learning Rate: 0.041115000000000006\n",
      "Epoch: 11778, MSE: 0.24479358693355793, Learning Rate: 0.04111000000000001\n",
      "Epoch: 11779, MSE: 0.24479089871399773, Learning Rate: 0.041105\n",
      "Epoch: 11780, MSE: 0.24478821045061927, Learning Rate: 0.041100000000000005\n",
      "Epoch: 11781, MSE: 0.24478552214342425, Learning Rate: 0.041095000000000007\n",
      "Epoch: 11782, MSE: 0.24478283379241716, Learning Rate: 0.04109000000000001\n",
      "Epoch: 11783, MSE: 0.2447801453975992, Learning Rate: 0.04108500000000001\n",
      "Epoch: 11784, MSE: 0.24477745695897438, Learning Rate: 0.041080000000000005\n",
      "Epoch: 11785, MSE: 0.24477476847654453, Learning Rate: 0.041075\n",
      "Epoch: 11786, MSE: 0.24477207995031275, Learning Rate: 0.041069999999999995\n",
      "Epoch: 11787, MSE: 0.24476939138028192, Learning Rate: 0.041065\n",
      "Epoch: 11788, MSE: 0.2447667027664545, Learning Rate: 0.04106\n",
      "Epoch: 11789, MSE: 0.24476401410883403, Learning Rate: 0.041055\n",
      "Epoch: 11790, MSE: 0.24476132540742224, Learning Rate: 0.04105\n",
      "Epoch: 11791, MSE: 0.24475863666222253, Learning Rate: 0.041045\n",
      "Epoch: 11792, MSE: 0.2447559478732378, Learning Rate: 0.04104\n",
      "Epoch: 11793, MSE: 0.2447532590404696, Learning Rate: 0.041035\n",
      "Epoch: 11794, MSE: 0.24475057016392396, Learning Rate: 0.041030000000000004\n",
      "Epoch: 11795, MSE: 0.24474788124359903, Learning Rate: 0.041025000000000006\n",
      "Epoch: 11796, MSE: 0.24474519227950156, Learning Rate: 0.04102\n",
      "Epoch: 11797, MSE: 0.24474250327163244, Learning Rate: 0.041015\n",
      "Epoch: 11798, MSE: 0.24473981421999497, Learning Rate: 0.041010000000000005\n",
      "Epoch: 11799, MSE: 0.24473712512459087, Learning Rate: 0.04100500000000001\n",
      "Epoch: 11800, MSE: 0.24473443598542471, Learning Rate: 0.04100000000000001\n",
      "Epoch: 11801, MSE: 0.24473174680249796, Learning Rate: 0.040995000000000004\n",
      "Epoch: 11802, MSE: 0.24472905757581412, Learning Rate: 0.040990000000000006\n",
      "Epoch: 11803, MSE: 0.24472636830537564, Learning Rate: 0.04098500000000001\n",
      "Epoch: 11804, MSE: 0.24472367899118497, Learning Rate: 0.04098000000000001\n",
      "Epoch: 11805, MSE: 0.24472098963324548, Learning Rate: 0.040975\n",
      "Epoch: 11806, MSE: 0.24471830023156035, Learning Rate: 0.04097\n",
      "Epoch: 11807, MSE: 0.24471561078613105, Learning Rate: 0.040965\n",
      "Epoch: 11808, MSE: 0.2447129212969615, Learning Rate: 0.040959999999999996\n",
      "Epoch: 11809, MSE: 0.2447102317640542, Learning Rate: 0.040955\n",
      "Epoch: 11810, MSE: 0.24470754218741167, Learning Rate: 0.04095\n",
      "Epoch: 11811, MSE: 0.24470485256703672, Learning Rate: 0.040945\n",
      "Epoch: 11812, MSE: 0.24470216290293278, Learning Rate: 0.040940000000000004\n",
      "Epoch: 11813, MSE: 0.2446994731951017, Learning Rate: 0.040935\n",
      "Epoch: 11814, MSE: 0.244696783443547, Learning Rate: 0.04093\n",
      "Epoch: 11815, MSE: 0.2446940936482715, Learning Rate: 0.040925\n",
      "Epoch: 11816, MSE: 0.24469140380927715, Learning Rate: 0.040920000000000005\n",
      "Epoch: 11817, MSE: 0.24468871392656782, Learning Rate: 0.04091500000000001\n",
      "Epoch: 11818, MSE: 0.24468602400014508, Learning Rate: 0.04091\n",
      "Epoch: 11819, MSE: 0.24468333403001327, Learning Rate: 0.040905000000000004\n",
      "Epoch: 11820, MSE: 0.24468064401617387, Learning Rate: 0.040900000000000006\n",
      "Epoch: 11821, MSE: 0.24467795395863068, Learning Rate: 0.04089500000000001\n",
      "Epoch: 11822, MSE: 0.24467526385738567, Learning Rate: 0.04089000000000001\n",
      "Epoch: 11823, MSE: 0.24467257371244222, Learning Rate: 0.040885000000000005\n",
      "Epoch: 11824, MSE: 0.2446698835238033, Learning Rate: 0.04088000000000001\n",
      "Epoch: 11825, MSE: 0.24466719329147044, Learning Rate: 0.040874999999999995\n",
      "Epoch: 11826, MSE: 0.24466450301544712, Learning Rate: 0.04087\n",
      "Epoch: 11827, MSE: 0.24466181269573725, Learning Rate: 0.040865\n",
      "Epoch: 11828, MSE: 0.24465912233234238, Learning Rate: 0.04086\n",
      "Epoch: 11829, MSE: 0.24465643192526554, Learning Rate: 0.040855\n",
      "Epoch: 11830, MSE: 0.24465374147450938, Learning Rate: 0.04085\n",
      "Epoch: 11831, MSE: 0.24465105098007728, Learning Rate: 0.040845\n",
      "Epoch: 11832, MSE: 0.24464836044197166, Learning Rate: 0.04084\n",
      "Epoch: 11833, MSE: 0.24464566986019592, Learning Rate: 0.040835\n",
      "Epoch: 11834, MSE: 0.24464297923475206, Learning Rate: 0.040830000000000005\n",
      "Epoch: 11835, MSE: 0.24464028856564263, Learning Rate: 0.040825\n",
      "Epoch: 11836, MSE: 0.2446375978528717, Learning Rate: 0.04082\n",
      "Epoch: 11837, MSE: 0.24463490709644103, Learning Rate: 0.040815000000000004\n",
      "Epoch: 11838, MSE: 0.24463221629635332, Learning Rate: 0.040810000000000006\n",
      "Epoch: 11839, MSE: 0.24462952545261304, Learning Rate: 0.04080500000000001\n",
      "Epoch: 11840, MSE: 0.2446268345652206, Learning Rate: 0.0408\n",
      "Epoch: 11841, MSE: 0.24462414363418084, Learning Rate: 0.040795000000000005\n",
      "Epoch: 11842, MSE: 0.24462145265949548, Learning Rate: 0.04079000000000001\n",
      "Epoch: 11843, MSE: 0.24461876164116714, Learning Rate: 0.04078500000000001\n",
      "Epoch: 11844, MSE: 0.24461607057919954, Learning Rate: 0.04078000000000001\n",
      "Epoch: 11845, MSE: 0.24461337947359435, Learning Rate: 0.040775\n",
      "Epoch: 11846, MSE: 0.24461068832435626, Learning Rate: 0.04077\n",
      "Epoch: 11847, MSE: 0.24460799713148587, Learning Rate: 0.040764999999999996\n",
      "Epoch: 11848, MSE: 0.2446053058949868, Learning Rate: 0.04076\n",
      "Epoch: 11849, MSE: 0.24460261461486246, Learning Rate: 0.040755\n",
      "Epoch: 11850, MSE: 0.24459992329111593, Learning Rate: 0.04075\n",
      "Epoch: 11851, MSE: 0.24459723192374894, Learning Rate: 0.040745\n",
      "Epoch: 11852, MSE: 0.2445945405127646, Learning Rate: 0.04074\n",
      "Epoch: 11853, MSE: 0.2445918490581658, Learning Rate: 0.040735\n",
      "Epoch: 11854, MSE: 0.2445891575599558, Learning Rate: 0.04073\n",
      "Epoch: 11855, MSE: 0.24458646601813736, Learning Rate: 0.040725000000000004\n",
      "Epoch: 11856, MSE: 0.2445837744327128, Learning Rate: 0.040720000000000006\n",
      "Epoch: 11857, MSE: 0.24458108280368404, Learning Rate: 0.040715\n",
      "Epoch: 11858, MSE: 0.2445783911310565, Learning Rate: 0.04071\n",
      "Epoch: 11859, MSE: 0.24457569941483093, Learning Rate: 0.040705000000000005\n",
      "Epoch: 11860, MSE: 0.24457300765501055, Learning Rate: 0.04070000000000001\n",
      "Epoch: 11861, MSE: 0.24457031585159814, Learning Rate: 0.04069500000000001\n",
      "Epoch: 11862, MSE: 0.24456762400459714, Learning Rate: 0.040690000000000004\n",
      "Epoch: 11863, MSE: 0.24456493211400968, Learning Rate: 0.040685000000000006\n",
      "Epoch: 11864, MSE: 0.24456224017983919, Learning Rate: 0.04068000000000001\n",
      "Epoch: 11865, MSE: 0.24455954820208847, Learning Rate: 0.040674999999999996\n",
      "Epoch: 11866, MSE: 0.24455685618075965, Learning Rate: 0.04067\n",
      "Epoch: 11867, MSE: 0.2445541641158556, Learning Rate: 0.040665\n",
      "Epoch: 11868, MSE: 0.2445514720073803, Learning Rate: 0.04066\n",
      "Epoch: 11869, MSE: 0.2445487798553354, Learning Rate: 0.040655\n",
      "Epoch: 11870, MSE: 0.24454608765972427, Learning Rate: 0.04065\n",
      "Epoch: 11871, MSE: 0.24454339542054954, Learning Rate: 0.040645\n",
      "Epoch: 11872, MSE: 0.2445407031378135, Learning Rate: 0.04064\n",
      "Epoch: 11873, MSE: 0.2445380108115201, Learning Rate: 0.040635000000000004\n",
      "Epoch: 11874, MSE: 0.24453531844167153, Learning Rate: 0.04063\n",
      "Epoch: 11875, MSE: 0.2445326260282714, Learning Rate: 0.040625\n",
      "Epoch: 11876, MSE: 0.2445299335713215, Learning Rate: 0.04062\n",
      "Epoch: 11877, MSE: 0.24452724107082463, Learning Rate: 0.040615000000000005\n",
      "Epoch: 11878, MSE: 0.24452454852678443, Learning Rate: 0.04061000000000001\n",
      "Epoch: 11879, MSE: 0.2445218559392035, Learning Rate: 0.040605\n",
      "Epoch: 11880, MSE: 0.24451916330808407, Learning Rate: 0.040600000000000004\n",
      "Epoch: 11881, MSE: 0.244516470633429, Learning Rate: 0.040595000000000006\n",
      "Epoch: 11882, MSE: 0.24451377791524256, Learning Rate: 0.04059000000000001\n",
      "Epoch: 11883, MSE: 0.24451108515352588, Learning Rate: 0.04058500000000001\n",
      "Epoch: 11884, MSE: 0.24450839234828323, Learning Rate: 0.040580000000000005\n",
      "Epoch: 11885, MSE: 0.2445056994995158, Learning Rate: 0.04057500000000001\n",
      "Epoch: 11886, MSE: 0.24450300660722768, Learning Rate: 0.040569999999999995\n",
      "Epoch: 11887, MSE: 0.2445003136714215, Learning Rate: 0.040565\n",
      "Epoch: 11888, MSE: 0.2444976206920999, Learning Rate: 0.04056\n",
      "Epoch: 11889, MSE: 0.24449492766926573, Learning Rate: 0.040555\n",
      "Epoch: 11890, MSE: 0.24449223460292244, Learning Rate: 0.04055\n",
      "Epoch: 11891, MSE: 0.2444895414930718, Learning Rate: 0.040545\n",
      "Epoch: 11892, MSE: 0.2444868483397168, Learning Rate: 0.04054\n",
      "Epoch: 11893, MSE: 0.24448415514286137, Learning Rate: 0.040535\n",
      "Epoch: 11894, MSE: 0.24448146190250727, Learning Rate: 0.040530000000000004\n",
      "Epoch: 11895, MSE: 0.24447876861865742, Learning Rate: 0.040525000000000005\n",
      "Epoch: 11896, MSE: 0.2444760752913151, Learning Rate: 0.04052\n",
      "Epoch: 11897, MSE: 0.24447338192048335, Learning Rate: 0.040515\n",
      "Epoch: 11898, MSE: 0.2444706885061641, Learning Rate: 0.040510000000000004\n",
      "Epoch: 11899, MSE: 0.24446799504836206, Learning Rate: 0.040505000000000006\n",
      "Epoch: 11900, MSE: 0.24446530154707746, Learning Rate: 0.04050000000000001\n",
      "Epoch: 11901, MSE: 0.24446260800231465, Learning Rate: 0.040495\n",
      "Epoch: 11902, MSE: 0.24445991441407686, Learning Rate: 0.040490000000000005\n",
      "Epoch: 11903, MSE: 0.2444572207823651, Learning Rate: 0.04048500000000001\n",
      "Epoch: 11904, MSE: 0.2444545271071842, Learning Rate: 0.04048000000000001\n",
      "Epoch: 11905, MSE: 0.24445183338853727, Learning Rate: 0.04047500000000001\n",
      "Epoch: 11906, MSE: 0.24444913962642523, Learning Rate: 0.04047\n",
      "Epoch: 11907, MSE: 0.24444644582085168, Learning Rate: 0.040465\n",
      "Epoch: 11908, MSE: 0.24444375197182022, Learning Rate: 0.040459999999999996\n",
      "Epoch: 11909, MSE: 0.24444105807933345, Learning Rate: 0.040455\n",
      "Epoch: 11910, MSE: 0.24443836414339337, Learning Rate: 0.04045\n",
      "Epoch: 11911, MSE: 0.24443567016400355, Learning Rate: 0.040445\n",
      "Epoch: 11912, MSE: 0.24443297614116694, Learning Rate: 0.040440000000000004\n",
      "Epoch: 11913, MSE: 0.24443028207488568, Learning Rate: 0.040435\n",
      "Epoch: 11914, MSE: 0.24442758796516384, Learning Rate: 0.04043\n",
      "Epoch: 11915, MSE: 0.24442489381200258, Learning Rate: 0.040425\n",
      "Epoch: 11916, MSE: 0.2444221996154057, Learning Rate: 0.040420000000000005\n",
      "Epoch: 11917, MSE: 0.24441950537537707, Learning Rate: 0.040415000000000006\n",
      "Epoch: 11918, MSE: 0.2444168110919176, Learning Rate: 0.04041\n",
      "Epoch: 11919, MSE: 0.24441411676503175, Learning Rate: 0.040405\n",
      "Epoch: 11920, MSE: 0.24441142239472136, Learning Rate: 0.040400000000000005\n",
      "Epoch: 11921, MSE: 0.2444087279809894, Learning Rate: 0.04039500000000001\n",
      "Epoch: 11922, MSE: 0.24440603352383933, Learning Rate: 0.04039000000000001\n",
      "Epoch: 11923, MSE: 0.2444033390232737, Learning Rate: 0.040385000000000004\n",
      "Epoch: 11924, MSE: 0.24440064447929533, Learning Rate: 0.040380000000000006\n",
      "Epoch: 11925, MSE: 0.24439794989190677, Learning Rate: 0.04037500000000001\n",
      "Epoch: 11926, MSE: 0.24439525526111136, Learning Rate: 0.040369999999999996\n",
      "Epoch: 11927, MSE: 0.24439256058691208, Learning Rate: 0.040365\n",
      "Epoch: 11928, MSE: 0.2443898658693115, Learning Rate: 0.04036\n",
      "Epoch: 11929, MSE: 0.24438717110831223, Learning Rate: 0.040355\n",
      "Epoch: 11930, MSE: 0.24438447630391727, Learning Rate: 0.04035\n",
      "Epoch: 11931, MSE: 0.2443817814561297, Learning Rate: 0.040345\n",
      "Epoch: 11932, MSE: 0.2443790865649519, Learning Rate: 0.04034\n",
      "Epoch: 11933, MSE: 0.24437639163038766, Learning Rate: 0.040335\n",
      "Epoch: 11934, MSE: 0.24437369665243924, Learning Rate: 0.040330000000000005\n",
      "Epoch: 11935, MSE: 0.24437100163110986, Learning Rate: 0.040325\n",
      "Epoch: 11936, MSE: 0.2443683065664012, Learning Rate: 0.04032\n",
      "Epoch: 11937, MSE: 0.2443656114583178, Learning Rate: 0.040315000000000004\n",
      "Epoch: 11938, MSE: 0.2443629163068615, Learning Rate: 0.040310000000000006\n",
      "Epoch: 11939, MSE: 0.24436022111203598, Learning Rate: 0.04030500000000001\n",
      "Epoch: 11940, MSE: 0.2443575258738429, Learning Rate: 0.0403\n",
      "Epoch: 11941, MSE: 0.24435483059228588, Learning Rate: 0.040295000000000004\n",
      "Epoch: 11942, MSE: 0.24435213526736818, Learning Rate: 0.040290000000000006\n",
      "Epoch: 11943, MSE: 0.24434943989909208, Learning Rate: 0.04028500000000001\n",
      "Epoch: 11944, MSE: 0.24434674448746052, Learning Rate: 0.04028000000000001\n",
      "Epoch: 11945, MSE: 0.24434404903247608, Learning Rate: 0.040275000000000005\n",
      "Epoch: 11946, MSE: 0.24434135353414246, Learning Rate: 0.04027\n",
      "Epoch: 11947, MSE: 0.24433865799246215, Learning Rate: 0.040264999999999995\n",
      "Epoch: 11948, MSE: 0.2443359624074372, Learning Rate: 0.04026\n",
      "Epoch: 11949, MSE: 0.24433326677907174, Learning Rate: 0.040255\n",
      "Epoch: 11950, MSE: 0.24433057110736786, Learning Rate: 0.04025\n",
      "Epoch: 11951, MSE: 0.24432787539232884, Learning Rate: 0.040245\n",
      "Epoch: 11952, MSE: 0.24432517963395764, Learning Rate: 0.04024\n",
      "Epoch: 11953, MSE: 0.24432248383225677, Learning Rate: 0.040235\n",
      "Epoch: 11954, MSE: 0.24431978798722961, Learning Rate: 0.04023\n",
      "Epoch: 11955, MSE: 0.24431709209887814, Learning Rate: 0.040225000000000004\n",
      "Epoch: 11956, MSE: 0.24431439616720615, Learning Rate: 0.040220000000000006\n",
      "Epoch: 11957, MSE: 0.2443117001922152, Learning Rate: 0.040215\n",
      "Epoch: 11958, MSE: 0.2443090041739105, Learning Rate: 0.04021\n",
      "Epoch: 11959, MSE: 0.24430630811229356, Learning Rate: 0.040205000000000005\n",
      "Epoch: 11960, MSE: 0.24430361200736597, Learning Rate: 0.04020000000000001\n",
      "Epoch: 11961, MSE: 0.24430091585913313, Learning Rate: 0.04019500000000001\n",
      "Epoch: 11962, MSE: 0.2442982196675963, Learning Rate: 0.040190000000000003\n",
      "Epoch: 11963, MSE: 0.24429552343275812, Learning Rate: 0.040185000000000005\n",
      "Epoch: 11964, MSE: 0.2442928271546224, Learning Rate: 0.04018000000000001\n",
      "Epoch: 11965, MSE: 0.24429013083319281, Learning Rate: 0.04017500000000001\n",
      "Epoch: 11966, MSE: 0.2442874344684706, Learning Rate: 0.04017\n",
      "Epoch: 11967, MSE: 0.24428473806045914, Learning Rate: 0.040165\n",
      "Epoch: 11968, MSE: 0.24428204160916117, Learning Rate: 0.04016\n",
      "Epoch: 11969, MSE: 0.24427934511457988, Learning Rate: 0.040154999999999996\n",
      "Epoch: 11970, MSE: 0.24427664857671869, Learning Rate: 0.04015\n",
      "Epoch: 11971, MSE: 0.24427395199557847, Learning Rate: 0.040145\n",
      "Epoch: 11972, MSE: 0.24427125537116523, Learning Rate: 0.04014\n",
      "Epoch: 11973, MSE: 0.24426855870348, Learning Rate: 0.040135000000000004\n",
      "Epoch: 11974, MSE: 0.2442658619925253, Learning Rate: 0.04013\n",
      "Epoch: 11975, MSE: 0.24426316523830402, Learning Rate: 0.040125\n",
      "Epoch: 11976, MSE: 0.2442604684408203, Learning Rate: 0.04012\n",
      "Epoch: 11977, MSE: 0.2442577716000761, Learning Rate: 0.040115000000000005\n",
      "Epoch: 11978, MSE: 0.2442550747160747, Learning Rate: 0.04011000000000001\n",
      "Epoch: 11979, MSE: 0.24425237778881853, Learning Rate: 0.040105\n",
      "Epoch: 11980, MSE: 0.24424968081831142, Learning Rate: 0.040100000000000004\n",
      "Epoch: 11981, MSE: 0.24424698380455478, Learning Rate: 0.040095000000000006\n",
      "Epoch: 11982, MSE: 0.24424428674755347, Learning Rate: 0.04009000000000001\n",
      "Epoch: 11983, MSE: 0.24424158964730838, Learning Rate: 0.04008500000000001\n",
      "Epoch: 11984, MSE: 0.24423889250382358, Learning Rate: 0.040080000000000005\n",
      "Epoch: 11985, MSE: 0.24423619531710172, Learning Rate: 0.040075000000000006\n",
      "Epoch: 11986, MSE: 0.24423349808714548, Learning Rate: 0.040069999999999995\n",
      "Epoch: 11987, MSE: 0.2442308008139587, Learning Rate: 0.040064999999999996\n",
      "Epoch: 11988, MSE: 0.2442281034975429, Learning Rate: 0.04006\n",
      "Epoch: 11989, MSE: 0.2442254061379016, Learning Rate: 0.040055\n",
      "Epoch: 11990, MSE: 0.24422270873503804, Learning Rate: 0.04005\n",
      "Epoch: 11991, MSE: 0.24422001128895413, Learning Rate: 0.040045\n",
      "Epoch: 11992, MSE: 0.24421731379965422, Learning Rate: 0.04004\n",
      "Epoch: 11993, MSE: 0.24421461626714008, Learning Rate: 0.040035\n",
      "Epoch: 11994, MSE: 0.24421191869141545, Learning Rate: 0.04003\n",
      "Epoch: 11995, MSE: 0.24420922107248164, Learning Rate: 0.040025000000000005\n",
      "Epoch: 11996, MSE: 0.244206523410344, Learning Rate: 0.04002\n",
      "Epoch: 11997, MSE: 0.24420382570500251, Learning Rate: 0.040015\n",
      "Epoch: 11998, MSE: 0.24420112795646287, Learning Rate: 0.040010000000000004\n",
      "Epoch: 11999, MSE: 0.24419843016472687, Learning Rate: 0.040005000000000006\n",
      "Epoch: 12000, MSE: 0.24419573232979724, Learning Rate: 0.04000000000000001\n",
      "Epoch: 12001, MSE: 0.2441930344516763, Learning Rate: 0.039995\n",
      "Epoch: 12002, MSE: 0.24419033653036779, Learning Rate: 0.039990000000000005\n",
      "Epoch: 12003, MSE: 0.24418763856587491, Learning Rate: 0.03998500000000001\n",
      "Epoch: 12004, MSE: 0.24418494055820028, Learning Rate: 0.03998000000000001\n",
      "Epoch: 12005, MSE: 0.24418224250734694, Learning Rate: 0.03997500000000001\n",
      "Epoch: 12006, MSE: 0.24417954441331624, Learning Rate: 0.039970000000000006\n",
      "Epoch: 12007, MSE: 0.24417684627611258, Learning Rate: 0.039965\n",
      "Epoch: 12008, MSE: 0.2441741480957392, Learning Rate: 0.039959999999999996\n",
      "Epoch: 12009, MSE: 0.2441714498721982, Learning Rate: 0.039955\n",
      "Epoch: 12010, MSE: 0.24416875160549364, Learning Rate: 0.03995\n",
      "Epoch: 12011, MSE: 0.24416605329562635, Learning Rate: 0.039945\n",
      "Epoch: 12012, MSE: 0.24416335494260155, Learning Rate: 0.03994\n",
      "Epoch: 12013, MSE: 0.24416065654642038, Learning Rate: 0.039935\n",
      "Epoch: 12014, MSE: 0.2441579581070866, Learning Rate: 0.03993\n",
      "Epoch: 12015, MSE: 0.24415525962460383, Learning Rate: 0.039925\n",
      "Epoch: 12016, MSE: 0.244152561098973, Learning Rate: 0.039920000000000004\n",
      "Epoch: 12017, MSE: 0.24414986253019788, Learning Rate: 0.039915000000000006\n",
      "Epoch: 12018, MSE: 0.24414716391828276, Learning Rate: 0.03991\n",
      "Epoch: 12019, MSE: 0.2441444652632292, Learning Rate: 0.039905\n",
      "Epoch: 12020, MSE: 0.2441417665650396, Learning Rate: 0.039900000000000005\n",
      "Epoch: 12021, MSE: 0.24413906782371828, Learning Rate: 0.03989500000000001\n",
      "Epoch: 12022, MSE: 0.24413636903926703, Learning Rate: 0.03989000000000001\n",
      "Epoch: 12023, MSE: 0.2441336702116894, Learning Rate: 0.039885000000000004\n",
      "Epoch: 12024, MSE: 0.24413097134098938, Learning Rate: 0.039880000000000006\n",
      "Epoch: 12025, MSE: 0.24412827242716756, Learning Rate: 0.03987500000000001\n",
      "Epoch: 12026, MSE: 0.24412557347022862, Learning Rate: 0.03987000000000001\n",
      "Epoch: 12027, MSE: 0.2441228744701742, Learning Rate: 0.039865\n",
      "Epoch: 12028, MSE: 0.24412017542700865, Learning Rate: 0.03986\n",
      "Epoch: 12029, MSE: 0.24411747634073325, Learning Rate: 0.039855\n",
      "Epoch: 12030, MSE: 0.24411477721135214, Learning Rate: 0.03985\n",
      "Epoch: 12031, MSE: 0.24411207803886867, Learning Rate: 0.039845\n",
      "Epoch: 12032, MSE: 0.24410937882328385, Learning Rate: 0.03984\n",
      "Epoch: 12033, MSE: 0.24410667956460277, Learning Rate: 0.039835\n",
      "Epoch: 12034, MSE: 0.2441039802628267, Learning Rate: 0.039830000000000004\n",
      "Epoch: 12035, MSE: 0.24410128091795918, Learning Rate: 0.039825\n",
      "Epoch: 12036, MSE: 0.24409858153000394, Learning Rate: 0.03982\n",
      "Epoch: 12037, MSE: 0.24409588209896302, Learning Rate: 0.039815\n",
      "Epoch: 12038, MSE: 0.24409318262483906, Learning Rate: 0.039810000000000005\n",
      "Epoch: 12039, MSE: 0.24409048310763565, Learning Rate: 0.03980500000000001\n",
      "Epoch: 12040, MSE: 0.2440877835473552, Learning Rate: 0.0398\n",
      "Epoch: 12041, MSE: 0.24408508394400158, Learning Rate: 0.039795000000000004\n",
      "Epoch: 12042, MSE: 0.24408238429757667, Learning Rate: 0.039790000000000006\n",
      "Epoch: 12043, MSE: 0.2440796846080841, Learning Rate: 0.03978500000000001\n",
      "Epoch: 12044, MSE: 0.2440769848755263, Learning Rate: 0.03978000000000001\n",
      "Epoch: 12045, MSE: 0.24407428509990678, Learning Rate: 0.039775000000000005\n",
      "Epoch: 12046, MSE: 0.24407158528122777, Learning Rate: 0.03977000000000001\n",
      "Epoch: 12047, MSE: 0.24406888541949232, Learning Rate: 0.039764999999999995\n",
      "Epoch: 12048, MSE: 0.24406618551470452, Learning Rate: 0.03976\n",
      "Epoch: 12049, MSE: 0.24406348556686583, Learning Rate: 0.039755\n",
      "Epoch: 12050, MSE: 0.2440607855759796, Learning Rate: 0.03975\n",
      "Epoch: 12051, MSE: 0.2440580855420496, Learning Rate: 0.039745\n",
      "Epoch: 12052, MSE: 0.2440553854650771, Learning Rate: 0.03974\n",
      "Epoch: 12053, MSE: 0.24405268534506688, Learning Rate: 0.039735\n",
      "Epoch: 12054, MSE: 0.2440499851820207, Learning Rate: 0.03973\n",
      "Epoch: 12055, MSE: 0.2440472849759425, Learning Rate: 0.039725\n",
      "Epoch: 12056, MSE: 0.24404458472683313, Learning Rate: 0.039720000000000005\n",
      "Epoch: 12057, MSE: 0.24404188443469804, Learning Rate: 0.039715\n",
      "Epoch: 12058, MSE: 0.24403918409953912, Learning Rate: 0.03971\n",
      "Epoch: 12059, MSE: 0.24403648372135883, Learning Rate: 0.039705000000000004\n",
      "Epoch: 12060, MSE: 0.2440337833001609, Learning Rate: 0.039700000000000006\n",
      "Epoch: 12061, MSE: 0.24403108283594777, Learning Rate: 0.03969500000000001\n",
      "Epoch: 12062, MSE: 0.24402838232872268, Learning Rate: 0.03969\n",
      "Epoch: 12063, MSE: 0.24402568177848816, Learning Rate: 0.039685000000000005\n",
      "Epoch: 12064, MSE: 0.24402298118524823, Learning Rate: 0.03968000000000001\n",
      "Epoch: 12065, MSE: 0.24402028054900468, Learning Rate: 0.03967500000000001\n",
      "Epoch: 12066, MSE: 0.2440175798697611, Learning Rate: 0.03967000000000001\n",
      "Epoch: 12067, MSE: 0.24401487914751988, Learning Rate: 0.039665\n",
      "Epoch: 12068, MSE: 0.24401217838228417, Learning Rate: 0.03966\n",
      "Epoch: 12069, MSE: 0.2440094775740573, Learning Rate: 0.039654999999999996\n",
      "Epoch: 12070, MSE: 0.24400677672284185, Learning Rate: 0.03965\n",
      "Epoch: 12071, MSE: 0.24400407582864062, Learning Rate: 0.039645\n",
      "Epoch: 12072, MSE: 0.24400137489145718, Learning Rate: 0.03964\n",
      "Epoch: 12073, MSE: 0.24399867391129437, Learning Rate: 0.039635000000000004\n",
      "Epoch: 12074, MSE: 0.24399597288815403, Learning Rate: 0.03963\n",
      "Epoch: 12075, MSE: 0.24399327182204028, Learning Rate: 0.039625\n",
      "Epoch: 12076, MSE: 0.24399057071295666, Learning Rate: 0.03962\n",
      "Epoch: 12077, MSE: 0.24398786956090368, Learning Rate: 0.039615000000000004\n",
      "Epoch: 12078, MSE: 0.24398516836588793, Learning Rate: 0.039610000000000006\n",
      "Epoch: 12079, MSE: 0.24398246712790922, Learning Rate: 0.039605\n",
      "Epoch: 12080, MSE: 0.24397976584697104, Learning Rate: 0.0396\n",
      "Epoch: 12081, MSE: 0.2439770645230775, Learning Rate: 0.039595000000000005\n",
      "Epoch: 12082, MSE: 0.24397436315623092, Learning Rate: 0.03959000000000001\n",
      "Epoch: 12083, MSE: 0.24397166174643428, Learning Rate: 0.03958500000000001\n",
      "Epoch: 12084, MSE: 0.2439689602936907, Learning Rate: 0.039580000000000004\n",
      "Epoch: 12085, MSE: 0.2439662587980026, Learning Rate: 0.039575000000000006\n",
      "Epoch: 12086, MSE: 0.24396355725937374, Learning Rate: 0.03957000000000001\n",
      "Epoch: 12087, MSE: 0.24396085567780632, Learning Rate: 0.039564999999999996\n",
      "Epoch: 12088, MSE: 0.24395815405330373, Learning Rate: 0.03956\n",
      "Epoch: 12089, MSE: 0.24395545238586913, Learning Rate: 0.039555\n",
      "Epoch: 12090, MSE: 0.24395275067550537, Learning Rate: 0.03955\n",
      "Epoch: 12091, MSE: 0.24395004892221436, Learning Rate: 0.039545\n",
      "Epoch: 12092, MSE: 0.24394734712600102, Learning Rate: 0.03954\n",
      "Epoch: 12093, MSE: 0.24394464528686677, Learning Rate: 0.039535\n",
      "Epoch: 12094, MSE: 0.24394194340481473, Learning Rate: 0.03953\n",
      "Epoch: 12095, MSE: 0.2439392414798485, Learning Rate: 0.039525000000000005\n",
      "Epoch: 12096, MSE: 0.24393653951197083, Learning Rate: 0.03952\n",
      "Epoch: 12097, MSE: 0.24393383750118466, Learning Rate: 0.039515\n",
      "Epoch: 12098, MSE: 0.24393113544749265, Learning Rate: 0.03951\n",
      "Epoch: 12099, MSE: 0.24392843335089853, Learning Rate: 0.039505000000000005\n",
      "Epoch: 12100, MSE: 0.2439257312114041, Learning Rate: 0.03950000000000001\n",
      "Epoch: 12101, MSE: 0.2439230290290134, Learning Rate: 0.039495\n",
      "Epoch: 12102, MSE: 0.24392032680372908, Learning Rate: 0.039490000000000004\n",
      "Epoch: 12103, MSE: 0.24391762453555427, Learning Rate: 0.039485000000000006\n",
      "Epoch: 12104, MSE: 0.24391492222449127, Learning Rate: 0.03948000000000001\n",
      "Epoch: 12105, MSE: 0.24391221987054398, Learning Rate: 0.03947500000000001\n",
      "Epoch: 12106, MSE: 0.24390951747371414, Learning Rate: 0.039470000000000005\n",
      "Epoch: 12107, MSE: 0.2439068150340055, Learning Rate: 0.039465\n",
      "Epoch: 12108, MSE: 0.24390411255142183, Learning Rate: 0.039459999999999995\n",
      "Epoch: 12109, MSE: 0.24390141002596502, Learning Rate: 0.039455\n",
      "Epoch: 12110, MSE: 0.24389870745763798, Learning Rate: 0.03945\n",
      "Epoch: 12111, MSE: 0.24389600484644447, Learning Rate: 0.039445\n",
      "Epoch: 12112, MSE: 0.24389330219238659, Learning Rate: 0.03944\n",
      "Epoch: 12113, MSE: 0.24389059949546765, Learning Rate: 0.039435\n",
      "Epoch: 12114, MSE: 0.24388789675569106, Learning Rate: 0.03943\n",
      "Epoch: 12115, MSE: 0.24388519397305924, Learning Rate: 0.039425\n",
      "Epoch: 12116, MSE: 0.24388249114757582, Learning Rate: 0.039420000000000004\n",
      "Epoch: 12117, MSE: 0.2438797882792426, Learning Rate: 0.039415000000000006\n",
      "Epoch: 12118, MSE: 0.24387708536806368, Learning Rate: 0.03941\n",
      "Epoch: 12119, MSE: 0.24387438241404238, Learning Rate: 0.039405\n",
      "Epoch: 12120, MSE: 0.24387167941717974, Learning Rate: 0.039400000000000004\n",
      "Epoch: 12121, MSE: 0.24386897637748123, Learning Rate: 0.039395000000000006\n",
      "Epoch: 12122, MSE: 0.24386627329494717, Learning Rate: 0.03939000000000001\n",
      "Epoch: 12123, MSE: 0.2438635701695835, Learning Rate: 0.039385\n",
      "Epoch: 12124, MSE: 0.24386086700139034, Learning Rate: 0.039380000000000005\n",
      "Epoch: 12125, MSE: 0.24385816379037242, Learning Rate: 0.03937500000000001\n",
      "Epoch: 12126, MSE: 0.24385546053653276, Learning Rate: 0.03937000000000001\n",
      "Epoch: 12127, MSE: 0.24385275723987362, Learning Rate: 0.03936500000000001\n",
      "Epoch: 12128, MSE: 0.24385005390039896, Learning Rate: 0.03936\n",
      "Epoch: 12129, MSE: 0.24384735051811038, Learning Rate: 0.039355\n",
      "Epoch: 12130, MSE: 0.24384464709301107, Learning Rate: 0.039349999999999996\n",
      "Epoch: 12131, MSE: 0.24384194362510517, Learning Rate: 0.039345\n",
      "Epoch: 12132, MSE: 0.24383924011439512, Learning Rate: 0.03934\n",
      "Epoch: 12133, MSE: 0.2438365365608834, Learning Rate: 0.039335\n",
      "Epoch: 12134, MSE: 0.24383383296457423, Learning Rate: 0.039330000000000004\n",
      "Epoch: 12135, MSE: 0.24383112932546883, Learning Rate: 0.039325\n",
      "Epoch: 12136, MSE: 0.2438284256435715, Learning Rate: 0.03932\n",
      "Epoch: 12137, MSE: 0.2438257219188848, Learning Rate: 0.039315\n",
      "Epoch: 12138, MSE: 0.24382301815141236, Learning Rate: 0.039310000000000005\n",
      "Epoch: 12139, MSE: 0.24382031434115647, Learning Rate: 0.03930500000000001\n",
      "Epoch: 12140, MSE: 0.24381761048811984, Learning Rate: 0.0393\n",
      "Epoch: 12141, MSE: 0.2438149065923064, Learning Rate: 0.039295000000000004\n",
      "Epoch: 12142, MSE: 0.2438122026537178, Learning Rate: 0.039290000000000005\n",
      "Epoch: 12143, MSE: 0.24380949867235877, Learning Rate: 0.03928500000000001\n",
      "Epoch: 12144, MSE: 0.243806794648231, Learning Rate: 0.03928000000000001\n",
      "Epoch: 12145, MSE: 0.24380409058133815, Learning Rate: 0.039275000000000004\n",
      "Epoch: 12146, MSE: 0.24380138647168348, Learning Rate: 0.039270000000000006\n",
      "Epoch: 12147, MSE: 0.24379868231926882, Learning Rate: 0.03926500000000001\n",
      "Epoch: 12148, MSE: 0.24379597812409798, Learning Rate: 0.039259999999999996\n",
      "Epoch: 12149, MSE: 0.24379327388617386, Learning Rate: 0.039255\n",
      "Epoch: 12150, MSE: 0.24379056960549886, Learning Rate: 0.03925\n",
      "Epoch: 12151, MSE: 0.24378786528207824, Learning Rate: 0.039245\n",
      "Epoch: 12152, MSE: 0.24378516091591151, Learning Rate: 0.03924\n",
      "Epoch: 12153, MSE: 0.24378245650700467, Learning Rate: 0.039235\n",
      "Epoch: 12154, MSE: 0.24377975205535923, Learning Rate: 0.03923\n",
      "Epoch: 12155, MSE: 0.24377704756097826, Learning Rate: 0.039225\n",
      "Epoch: 12156, MSE: 0.24377434302386544, Learning Rate: 0.039220000000000005\n",
      "Epoch: 12157, MSE: 0.24377163844402294, Learning Rate: 0.039215\n",
      "Epoch: 12158, MSE: 0.24376893382145465, Learning Rate: 0.03921\n",
      "Epoch: 12159, MSE: 0.24376622915616208, Learning Rate: 0.039205000000000004\n",
      "Epoch: 12160, MSE: 0.24376352444815047, Learning Rate: 0.039200000000000006\n",
      "Epoch: 12161, MSE: 0.24376081969742108, Learning Rate: 0.03919500000000001\n",
      "Epoch: 12162, MSE: 0.24375811490397806, Learning Rate: 0.03919\n",
      "Epoch: 12163, MSE: 0.2437554100678237, Learning Rate: 0.039185000000000005\n",
      "Epoch: 12164, MSE: 0.24375270518896014, Learning Rate: 0.039180000000000006\n",
      "Epoch: 12165, MSE: 0.24375000026739227, Learning Rate: 0.03917500000000001\n",
      "Epoch: 12166, MSE: 0.24374729530312175, Learning Rate: 0.03917000000000001\n",
      "Epoch: 12167, MSE: 0.2437445902961532, Learning Rate: 0.039165000000000005\n",
      "Epoch: 12168, MSE: 0.24374188524648738, Learning Rate: 0.03916\n",
      "Epoch: 12169, MSE: 0.2437391801541289, Learning Rate: 0.039154999999999995\n",
      "Epoch: 12170, MSE: 0.2437364750190802, Learning Rate: 0.03915\n",
      "Epoch: 12171, MSE: 0.243733769841344, Learning Rate: 0.039145\n",
      "Epoch: 12172, MSE: 0.24373106462092467, Learning Rate: 0.03914\n",
      "Epoch: 12173, MSE: 0.24372835935782325, Learning Rate: 0.039135\n",
      "Epoch: 12174, MSE: 0.24372565405204477, Learning Rate: 0.03913\n",
      "Epoch: 12175, MSE: 0.24372294870359057, Learning Rate: 0.039125\n",
      "Epoch: 12176, MSE: 0.2437202433124648, Learning Rate: 0.03912\n",
      "Epoch: 12177, MSE: 0.24371753787866987, Learning Rate: 0.039115000000000004\n",
      "Epoch: 12178, MSE: 0.2437148324022094, Learning Rate: 0.039110000000000006\n",
      "Epoch: 12179, MSE: 0.2437121268830854, Learning Rate: 0.039105\n",
      "Epoch: 12180, MSE: 0.24370942132130233, Learning Rate: 0.0391\n",
      "Epoch: 12181, MSE: 0.24370671571686187, Learning Rate: 0.039095000000000005\n",
      "Epoch: 12182, MSE: 0.24370401006976702, Learning Rate: 0.03909000000000001\n",
      "Epoch: 12183, MSE: 0.24370130438002202, Learning Rate: 0.03908500000000001\n",
      "Epoch: 12184, MSE: 0.2436985986476286, Learning Rate: 0.039080000000000004\n",
      "Epoch: 12185, MSE: 0.24369589287259077, Learning Rate: 0.039075000000000006\n",
      "Epoch: 12186, MSE: 0.2436931870549115, Learning Rate: 0.03907000000000001\n",
      "Epoch: 12187, MSE: 0.2436904811945938, Learning Rate: 0.03906500000000001\n",
      "Epoch: 12188, MSE: 0.24368777529163943, Learning Rate: 0.03906\n",
      "Epoch: 12189, MSE: 0.24368506934605277, Learning Rate: 0.039055\n",
      "Epoch: 12190, MSE: 0.24368236335783633, Learning Rate: 0.03905\n",
      "Epoch: 12191, MSE: 0.24367965732699318, Learning Rate: 0.039044999999999996\n",
      "Epoch: 12192, MSE: 0.24367695125352687, Learning Rate: 0.03904\n",
      "Epoch: 12193, MSE: 0.24367424513743943, Learning Rate: 0.039035\n",
      "Epoch: 12194, MSE: 0.24367153897873584, Learning Rate: 0.03903\n",
      "Epoch: 12195, MSE: 0.24366883277741688, Learning Rate: 0.039025000000000004\n",
      "Epoch: 12196, MSE: 0.24366612653348593, Learning Rate: 0.03902\n",
      "Epoch: 12197, MSE: 0.24366342024694757, Learning Rate: 0.039015\n",
      "Epoch: 12198, MSE: 0.2436607139178027, Learning Rate: 0.03901\n",
      "Epoch: 12199, MSE: 0.2436580075460561, Learning Rate: 0.039005000000000005\n",
      "Epoch: 12200, MSE: 0.24365530113171022, Learning Rate: 0.03900000000000001\n",
      "Epoch: 12201, MSE: 0.24365259467476805, Learning Rate: 0.038995\n",
      "Epoch: 12202, MSE: 0.24364988817523286, Learning Rate: 0.038990000000000004\n",
      "Epoch: 12203, MSE: 0.24364718163310703, Learning Rate: 0.038985000000000006\n",
      "Epoch: 12204, MSE: 0.24364447504839395, Learning Rate: 0.03898000000000001\n",
      "Epoch: 12205, MSE: 0.24364176842109658, Learning Rate: 0.03897500000000001\n",
      "Epoch: 12206, MSE: 0.2436390617512194, Learning Rate: 0.038970000000000005\n",
      "Epoch: 12207, MSE: 0.2436363550387633, Learning Rate: 0.03896500000000001\n",
      "Epoch: 12208, MSE: 0.24363364828373243, Learning Rate: 0.038959999999999995\n",
      "Epoch: 12209, MSE: 0.24363094148612935, Learning Rate: 0.038955\n",
      "Epoch: 12210, MSE: 0.24362823464595673, Learning Rate: 0.03895\n",
      "Epoch: 12211, MSE: 0.24362552776321958, Learning Rate: 0.038945\n",
      "Epoch: 12212, MSE: 0.243622820837919, Learning Rate: 0.03894\n",
      "Epoch: 12213, MSE: 0.24362011387005816, Learning Rate: 0.038935\n",
      "Epoch: 12214, MSE: 0.2436174068596414, Learning Rate: 0.03893\n",
      "Epoch: 12215, MSE: 0.2436146998066699, Learning Rate: 0.038925\n",
      "Epoch: 12216, MSE: 0.24361199271114917, Learning Rate: 0.03892\n",
      "Epoch: 12217, MSE: 0.24360928557307981, Learning Rate: 0.038915000000000005\n",
      "Epoch: 12218, MSE: 0.24360657839246605, Learning Rate: 0.03891\n",
      "Epoch: 12219, MSE: 0.24360387116931104, Learning Rate: 0.038905\n",
      "Epoch: 12220, MSE: 0.24360116390361716, Learning Rate: 0.038900000000000004\n",
      "Epoch: 12221, MSE: 0.24359845659538756, Learning Rate: 0.038895000000000006\n",
      "Epoch: 12222, MSE: 0.24359574924462735, Learning Rate: 0.03889000000000001\n",
      "Epoch: 12223, MSE: 0.24359304185133632, Learning Rate: 0.038885\n",
      "Epoch: 12224, MSE: 0.2435903344155191, Learning Rate: 0.038880000000000005\n",
      "Epoch: 12225, MSE: 0.24358762693717956, Learning Rate: 0.03887500000000001\n",
      "Epoch: 12226, MSE: 0.24358491941631946, Learning Rate: 0.03887000000000001\n",
      "Epoch: 12227, MSE: 0.24358221185294185, Learning Rate: 0.03886500000000001\n",
      "Epoch: 12228, MSE: 0.2435795042470508, Learning Rate: 0.03886\n",
      "Epoch: 12229, MSE: 0.2435767965986481, Learning Rate: 0.038855\n",
      "Epoch: 12230, MSE: 0.24357408890773793, Learning Rate: 0.038849999999999996\n",
      "Epoch: 12231, MSE: 0.24357138117432295, Learning Rate: 0.038845\n",
      "Epoch: 12232, MSE: 0.24356867339840593, Learning Rate: 0.03884\n",
      "Epoch: 12233, MSE: 0.24356596557998975, Learning Rate: 0.038835\n",
      "Epoch: 12234, MSE: 0.24356325771907916, Learning Rate: 0.03883\n",
      "Epoch: 12235, MSE: 0.2435605498156747, Learning Rate: 0.038825\n",
      "Epoch: 12236, MSE: 0.2435578418697811, Learning Rate: 0.03882\n",
      "Epoch: 12237, MSE: 0.24355513388140082, Learning Rate: 0.038815\n",
      "Epoch: 12238, MSE: 0.24355242585053782, Learning Rate: 0.038810000000000004\n",
      "Epoch: 12239, MSE: 0.24354971777719395, Learning Rate: 0.038805000000000006\n",
      "Epoch: 12240, MSE: 0.24354700966137235, Learning Rate: 0.0388\n",
      "Epoch: 12241, MSE: 0.24354430150307696, Learning Rate: 0.038795\n",
      "Epoch: 12242, MSE: 0.24354159330231004, Learning Rate: 0.038790000000000005\n",
      "Epoch: 12243, MSE: 0.24353888505907514, Learning Rate: 0.03878500000000001\n",
      "Epoch: 12244, MSE: 0.24353617677337588, Learning Rate: 0.03878000000000001\n",
      "Epoch: 12245, MSE: 0.2435334684452135, Learning Rate: 0.038775000000000004\n",
      "Epoch: 12246, MSE: 0.2435307600745931, Learning Rate: 0.038770000000000006\n",
      "Epoch: 12247, MSE: 0.24352805166151623, Learning Rate: 0.03876500000000001\n",
      "Epoch: 12248, MSE: 0.2435253432059866, Learning Rate: 0.038759999999999996\n",
      "Epoch: 12249, MSE: 0.24352263470800775, Learning Rate: 0.038755\n",
      "Epoch: 12250, MSE: 0.2435199261675818, Learning Rate: 0.03875\n",
      "Epoch: 12251, MSE: 0.24351721758471243, Learning Rate: 0.038745\n",
      "Epoch: 12252, MSE: 0.2435145089594026, Learning Rate: 0.03874\n",
      "Epoch: 12253, MSE: 0.24351180029165492, Learning Rate: 0.038735\n",
      "Epoch: 12254, MSE: 0.24350909158147346, Learning Rate: 0.03873\n",
      "Epoch: 12255, MSE: 0.24350638282886006, Learning Rate: 0.038725\n",
      "Epoch: 12256, MSE: 0.24350367403381912, Learning Rate: 0.038720000000000004\n",
      "Epoch: 12257, MSE: 0.24350096519635273, Learning Rate: 0.038715\n",
      "Epoch: 12258, MSE: 0.24349825631646385, Learning Rate: 0.03871\n",
      "Epoch: 12259, MSE: 0.24349554739415685, Learning Rate: 0.038705\n",
      "Epoch: 12260, MSE: 0.2434928384294331, Learning Rate: 0.038700000000000005\n",
      "Epoch: 12261, MSE: 0.24349012942229728, Learning Rate: 0.03869500000000001\n",
      "Epoch: 12262, MSE: 0.24348742037275092, Learning Rate: 0.03869\n",
      "Epoch: 12263, MSE: 0.24348471128079843, Learning Rate: 0.038685000000000004\n",
      "Epoch: 12264, MSE: 0.2434820021464419, Learning Rate: 0.038680000000000006\n",
      "Epoch: 12265, MSE: 0.24347929296968462, Learning Rate: 0.03867500000000001\n",
      "Epoch: 12266, MSE: 0.24347658375053038, Learning Rate: 0.03867000000000001\n",
      "Epoch: 12267, MSE: 0.24347387448898247, Learning Rate: 0.038665000000000005\n",
      "Epoch: 12268, MSE: 0.24347116518504178, Learning Rate: 0.03866000000000001\n",
      "Epoch: 12269, MSE: 0.24346845583871418, Learning Rate: 0.038654999999999995\n",
      "Epoch: 12270, MSE: 0.24346574645000085, Learning Rate: 0.03865\n",
      "Epoch: 12271, MSE: 0.24346303701890545, Learning Rate: 0.038645\n",
      "Epoch: 12272, MSE: 0.24346032754543118, Learning Rate: 0.03864\n",
      "Epoch: 12273, MSE: 0.24345761802958096, Learning Rate: 0.038635\n",
      "Epoch: 12274, MSE: 0.24345490847135803, Learning Rate: 0.03863\n",
      "Epoch: 12275, MSE: 0.24345219887076552, Learning Rate: 0.038625\n",
      "Epoch: 12276, MSE: 0.24344948922780657, Learning Rate: 0.03862\n",
      "Epoch: 12277, MSE: 0.24344677954248403, Learning Rate: 0.038615000000000003\n",
      "Epoch: 12278, MSE: 0.24344406981480046, Learning Rate: 0.038610000000000005\n",
      "Epoch: 12279, MSE: 0.24344136004476036, Learning Rate: 0.038605\n",
      "Epoch: 12280, MSE: 0.24343865023236605, Learning Rate: 0.0386\n",
      "Epoch: 12281, MSE: 0.2434359403776202, Learning Rate: 0.038595000000000004\n",
      "Epoch: 12282, MSE: 0.24343323048052645, Learning Rate: 0.038590000000000006\n",
      "Epoch: 12283, MSE: 0.2434305205410875, Learning Rate: 0.03858500000000001\n",
      "Epoch: 12284, MSE: 0.24342781055930635, Learning Rate: 0.03858\n",
      "Epoch: 12285, MSE: 0.2434251005351868, Learning Rate: 0.038575000000000005\n",
      "Epoch: 12286, MSE: 0.243422390468732, Learning Rate: 0.03857000000000001\n",
      "Epoch: 12287, MSE: 0.24341968035994394, Learning Rate: 0.03856500000000001\n",
      "Epoch: 12288, MSE: 0.24341697020882672, Learning Rate: 0.03856000000000001\n",
      "Epoch: 12289, MSE: 0.24341426001538344, Learning Rate: 0.038555\n",
      "Epoch: 12290, MSE: 0.2434115497796159, Learning Rate: 0.03855\n",
      "Epoch: 12291, MSE: 0.24340883950152908, Learning Rate: 0.038544999999999996\n",
      "Epoch: 12292, MSE: 0.2434061291811242, Learning Rate: 0.03854\n",
      "Epoch: 12293, MSE: 0.2434034188184071, Learning Rate: 0.038535\n",
      "Epoch: 12294, MSE: 0.243400708413377, Learning Rate: 0.03853\n",
      "Epoch: 12295, MSE: 0.24339799796604003, Learning Rate: 0.038525000000000004\n",
      "Epoch: 12296, MSE: 0.24339528747639838, Learning Rate: 0.03852\n",
      "Epoch: 12297, MSE: 0.24339257694445557, Learning Rate: 0.038515\n",
      "Epoch: 12298, MSE: 0.243389866370214, Learning Rate: 0.03851\n",
      "Epoch: 12299, MSE: 0.24338715575367648, Learning Rate: 0.038505000000000005\n",
      "Epoch: 12300, MSE: 0.24338444509484694, Learning Rate: 0.038500000000000006\n",
      "Epoch: 12301, MSE: 0.24338173439372815, Learning Rate: 0.038495\n",
      "Epoch: 12302, MSE: 0.24337902365032374, Learning Rate: 0.03849\n",
      "Epoch: 12303, MSE: 0.2433763128646362, Learning Rate: 0.038485000000000005\n",
      "Epoch: 12304, MSE: 0.2433736020366685, Learning Rate: 0.03848000000000001\n",
      "Epoch: 12305, MSE: 0.2433708911664243, Learning Rate: 0.03847500000000001\n",
      "Epoch: 12306, MSE: 0.2433681802539062, Learning Rate: 0.038470000000000004\n",
      "Epoch: 12307, MSE: 0.24336546929911743, Learning Rate: 0.038465000000000006\n",
      "Epoch: 12308, MSE: 0.24336275830206186, Learning Rate: 0.03846000000000001\n",
      "Epoch: 12309, MSE: 0.24336004726274152, Learning Rate: 0.038454999999999996\n",
      "Epoch: 12310, MSE: 0.24335733618116034, Learning Rate: 0.03845\n",
      "Epoch: 12311, MSE: 0.2433546250573212, Learning Rate: 0.038445\n",
      "Epoch: 12312, MSE: 0.2433519138912263, Learning Rate: 0.03844\n",
      "Epoch: 12313, MSE: 0.24334920268287968, Learning Rate: 0.038435\n",
      "Epoch: 12314, MSE: 0.24334649143228484, Learning Rate: 0.03843\n",
      "Epoch: 12315, MSE: 0.24334378013944433, Learning Rate: 0.038425\n",
      "Epoch: 12316, MSE: 0.24334106880436132, Learning Rate: 0.03842\n",
      "Epoch: 12317, MSE: 0.24333835742703824, Learning Rate: 0.038415000000000005\n",
      "Epoch: 12318, MSE: 0.24333564600747926, Learning Rate: 0.03841\n",
      "Epoch: 12319, MSE: 0.24333293454568775, Learning Rate: 0.038405\n",
      "Epoch: 12320, MSE: 0.2433302230416652, Learning Rate: 0.038400000000000004\n",
      "Epoch: 12321, MSE: 0.2433275114954158, Learning Rate: 0.038395000000000006\n",
      "Epoch: 12322, MSE: 0.24332479990694328, Learning Rate: 0.03839000000000001\n",
      "Epoch: 12323, MSE: 0.24332208827624952, Learning Rate: 0.038385\n",
      "Epoch: 12324, MSE: 0.24331937660333816, Learning Rate: 0.038380000000000004\n",
      "Epoch: 12325, MSE: 0.24331666488821213, Learning Rate: 0.038375000000000006\n",
      "Epoch: 12326, MSE: 0.2433139531308758, Learning Rate: 0.03837000000000001\n",
      "Epoch: 12327, MSE: 0.24331124133133009, Learning Rate: 0.03836500000000001\n",
      "Epoch: 12328, MSE: 0.24330852948958015, Learning Rate: 0.038360000000000005\n",
      "Epoch: 12329, MSE: 0.24330581760562853, Learning Rate: 0.038355\n",
      "Epoch: 12330, MSE: 0.24330310567947702, Learning Rate: 0.038349999999999995\n",
      "Epoch: 12331, MSE: 0.2433003937111303, Learning Rate: 0.038345\n",
      "Epoch: 12332, MSE: 0.24329768170059135, Learning Rate: 0.03834\n",
      "Epoch: 12333, MSE: 0.24329496964786215, Learning Rate: 0.038335\n",
      "Epoch: 12334, MSE: 0.24329225755294756, Learning Rate: 0.03833\n",
      "Epoch: 12335, MSE: 0.24328954541584905, Learning Rate: 0.038325\n",
      "Epoch: 12336, MSE: 0.2432868332365711, Learning Rate: 0.03832\n",
      "Epoch: 12337, MSE: 0.24328412101511535, Learning Rate: 0.038315\n",
      "Epoch: 12338, MSE: 0.24328140875148627, Learning Rate: 0.038310000000000004\n",
      "Epoch: 12339, MSE: 0.24327869644568723, Learning Rate: 0.038305000000000006\n",
      "Epoch: 12340, MSE: 0.2432759840977201, Learning Rate: 0.0383\n",
      "Epoch: 12341, MSE: 0.2432732717075879, Learning Rate: 0.038295\n",
      "Epoch: 12342, MSE: 0.24327055927529564, Learning Rate: 0.038290000000000005\n",
      "Epoch: 12343, MSE: 0.24326784680084443, Learning Rate: 0.038285000000000007\n",
      "Epoch: 12344, MSE: 0.2432651342842385, Learning Rate: 0.03828000000000001\n",
      "Epoch: 12345, MSE: 0.24326242172548082, Learning Rate: 0.038275\n",
      "Epoch: 12346, MSE: 0.2432597091245741, Learning Rate: 0.038270000000000005\n",
      "Epoch: 12347, MSE: 0.24325699648152221, Learning Rate: 0.03826500000000001\n",
      "Epoch: 12348, MSE: 0.24325428379632766, Learning Rate: 0.03826000000000001\n",
      "Epoch: 12349, MSE: 0.24325157106899345, Learning Rate: 0.038255\n",
      "Epoch: 12350, MSE: 0.24324885829952292, Learning Rate: 0.03825\n",
      "Epoch: 12351, MSE: 0.2432461454879207, Learning Rate: 0.038245\n",
      "Epoch: 12352, MSE: 0.24324343263418727, Learning Rate: 0.038239999999999996\n",
      "Epoch: 12353, MSE: 0.24324071973832784, Learning Rate: 0.038235\n",
      "Epoch: 12354, MSE: 0.2432380068003449, Learning Rate: 0.03823\n",
      "Epoch: 12355, MSE: 0.2432352938202407, Learning Rate: 0.038225\n",
      "Epoch: 12356, MSE: 0.24323258079801985, Learning Rate: 0.038220000000000004\n",
      "Epoch: 12357, MSE: 0.24322986773368455, Learning Rate: 0.038215\n",
      "Epoch: 12358, MSE: 0.2432271546272386, Learning Rate: 0.03821\n",
      "Epoch: 12359, MSE: 0.24322444147868427, Learning Rate: 0.038205\n",
      "Epoch: 12360, MSE: 0.24322172828802555, Learning Rate: 0.038200000000000005\n",
      "Epoch: 12361, MSE: 0.2432190150552649, Learning Rate: 0.03819500000000001\n",
      "Epoch: 12362, MSE: 0.24321630178040607, Learning Rate: 0.03819\n",
      "Epoch: 12363, MSE: 0.2432135884634521, Learning Rate: 0.038185000000000004\n",
      "Epoch: 12364, MSE: 0.24321087510440573, Learning Rate: 0.038180000000000006\n",
      "Epoch: 12365, MSE: 0.24320816170327078, Learning Rate: 0.03817500000000001\n",
      "Epoch: 12366, MSE: 0.24320544826004975, Learning Rate: 0.03817000000000001\n",
      "Epoch: 12367, MSE: 0.24320273477474552, Learning Rate: 0.038165000000000004\n",
      "Epoch: 12368, MSE: 0.24320002124736276, Learning Rate: 0.038160000000000006\n",
      "Epoch: 12369, MSE: 0.24319730767790337, Learning Rate: 0.038154999999999994\n",
      "Epoch: 12370, MSE: 0.24319459406636992, Learning Rate: 0.038149999999999996\n",
      "Epoch: 12371, MSE: 0.24319188041276688, Learning Rate: 0.038145\n",
      "Epoch: 12372, MSE: 0.2431891667170975, Learning Rate: 0.03814\n",
      "Epoch: 12373, MSE: 0.2431864529793639, Learning Rate: 0.038135\n",
      "Epoch: 12374, MSE: 0.24318373919956957, Learning Rate: 0.03813\n",
      "Epoch: 12375, MSE: 0.24318102537771866, Learning Rate: 0.038125\n",
      "Epoch: 12376, MSE: 0.24317831151381278, Learning Rate: 0.03812\n",
      "Epoch: 12377, MSE: 0.24317559760785568, Learning Rate: 0.038115\n",
      "Epoch: 12378, MSE: 0.24317288365985107, Learning Rate: 0.038110000000000005\n",
      "Epoch: 12379, MSE: 0.24317016966980168, Learning Rate: 0.038105\n",
      "Epoch: 12380, MSE: 0.2431674556377097, Learning Rate: 0.0381\n",
      "Epoch: 12381, MSE: 0.24316474156358014, Learning Rate: 0.038095000000000004\n",
      "Epoch: 12382, MSE: 0.24316202744741547, Learning Rate: 0.038090000000000006\n",
      "Epoch: 12383, MSE: 0.24315931328921775, Learning Rate: 0.03808500000000001\n",
      "Epoch: 12384, MSE: 0.24315659908899184, Learning Rate: 0.03808\n",
      "Epoch: 12385, MSE: 0.24315388484673947, Learning Rate: 0.038075000000000005\n",
      "Epoch: 12386, MSE: 0.24315117056246535, Learning Rate: 0.03807000000000001\n",
      "Epoch: 12387, MSE: 0.2431484562361707, Learning Rate: 0.03806500000000001\n",
      "Epoch: 12388, MSE: 0.24314574186786084, Learning Rate: 0.03806000000000001\n",
      "Epoch: 12389, MSE: 0.24314302745753666, Learning Rate: 0.038055000000000005\n",
      "Epoch: 12390, MSE: 0.24314031300520356, Learning Rate: 0.03805\n",
      "Epoch: 12391, MSE: 0.24313759851086353, Learning Rate: 0.038044999999999995\n",
      "Epoch: 12392, MSE: 0.24313488397451932, Learning Rate: 0.03804\n",
      "Epoch: 12393, MSE: 0.24313216939617474, Learning Rate: 0.038035\n",
      "Epoch: 12394, MSE: 0.24312945477583336, Learning Rate: 0.03803\n",
      "Epoch: 12395, MSE: 0.2431267401134974, Learning Rate: 0.038025\n",
      "Epoch: 12396, MSE: 0.2431240254091706, Learning Rate: 0.03802\n",
      "Epoch: 12397, MSE: 0.24312131066285603, Learning Rate: 0.038015\n",
      "Epoch: 12398, MSE: 0.24311859587455728, Learning Rate: 0.03801\n",
      "Epoch: 12399, MSE: 0.2431158810442763, Learning Rate: 0.038005000000000004\n",
      "Epoch: 12400, MSE: 0.24311316617201748, Learning Rate: 0.038000000000000006\n",
      "Epoch: 12401, MSE: 0.24311045125778333, Learning Rate: 0.037995\n",
      "Epoch: 12402, MSE: 0.24310773630157814, Learning Rate: 0.03799\n",
      "Epoch: 12403, MSE: 0.2431050213034032, Learning Rate: 0.037985000000000005\n",
      "Epoch: 12404, MSE: 0.24310230626326362, Learning Rate: 0.03798000000000001\n",
      "Epoch: 12405, MSE: 0.243099591181161, Learning Rate: 0.03797500000000001\n",
      "Epoch: 12406, MSE: 0.24309687605709984, Learning Rate: 0.037970000000000004\n",
      "Epoch: 12407, MSE: 0.24309416089108243, Learning Rate: 0.037965000000000006\n",
      "Epoch: 12408, MSE: 0.24309144568311192, Learning Rate: 0.03796000000000001\n",
      "Epoch: 12409, MSE: 0.24308873043319243, Learning Rate: 0.03795500000000001\n",
      "Epoch: 12410, MSE: 0.24308601514132644, Learning Rate: 0.03795\n",
      "Epoch: 12411, MSE: 0.24308329980751606, Learning Rate: 0.037945\n",
      "Epoch: 12412, MSE: 0.24308058443176675, Learning Rate: 0.03794\n",
      "Epoch: 12413, MSE: 0.24307786901408024, Learning Rate: 0.037934999999999997\n",
      "Epoch: 12414, MSE: 0.24307515355446, Learning Rate: 0.03793\n",
      "Epoch: 12415, MSE: 0.24307243805290943, Learning Rate: 0.037925\n",
      "Epoch: 12416, MSE: 0.24306972250943135, Learning Rate: 0.03792\n",
      "Epoch: 12417, MSE: 0.24306700692402894, Learning Rate: 0.037915000000000004\n",
      "Epoch: 12418, MSE: 0.24306429129670604, Learning Rate: 0.03791\n",
      "Epoch: 12419, MSE: 0.24306157562746547, Learning Rate: 0.037905\n",
      "Epoch: 12420, MSE: 0.2430588599163097, Learning Rate: 0.0379\n",
      "Epoch: 12421, MSE: 0.24305614416324267, Learning Rate: 0.037895000000000005\n",
      "Epoch: 12422, MSE: 0.24305342836826813, Learning Rate: 0.03789000000000001\n",
      "Epoch: 12423, MSE: 0.2430507125313879, Learning Rate: 0.037885\n",
      "Epoch: 12424, MSE: 0.24304799665260615, Learning Rate: 0.037880000000000004\n",
      "Epoch: 12425, MSE: 0.2430452807319257, Learning Rate: 0.037875000000000006\n",
      "Epoch: 12426, MSE: 0.24304256476935018, Learning Rate: 0.03787000000000001\n",
      "Epoch: 12427, MSE: 0.24303984876488252, Learning Rate: 0.03786500000000001\n",
      "Epoch: 12428, MSE: 0.24303713271852495, Learning Rate: 0.037860000000000005\n",
      "Epoch: 12429, MSE: 0.24303441663028275, Learning Rate: 0.03785500000000001\n",
      "Epoch: 12430, MSE: 0.2430317005001576, Learning Rate: 0.037849999999999995\n",
      "Epoch: 12431, MSE: 0.24302898432815292, Learning Rate: 0.037845\n",
      "Epoch: 12432, MSE: 0.24302626811427194, Learning Rate: 0.03784\n",
      "Epoch: 12433, MSE: 0.2430235518585182, Learning Rate: 0.037835\n",
      "Epoch: 12434, MSE: 0.24302083556089402, Learning Rate: 0.03783\n",
      "Epoch: 12435, MSE: 0.2430181192214037, Learning Rate: 0.037825\n",
      "Epoch: 12436, MSE: 0.2430154028400503, Learning Rate: 0.03782\n",
      "Epoch: 12437, MSE: 0.24301268641683638, Learning Rate: 0.037815\n",
      "Epoch: 12438, MSE: 0.24300996995176566, Learning Rate: 0.03781\n",
      "Epoch: 12439, MSE: 0.24300725344484117, Learning Rate: 0.037805000000000005\n",
      "Epoch: 12440, MSE: 0.24300453689606571, Learning Rate: 0.0378\n",
      "Epoch: 12441, MSE: 0.24300182030544276, Learning Rate: 0.037795\n",
      "Epoch: 12442, MSE: 0.24299910367297595, Learning Rate: 0.037790000000000004\n",
      "Epoch: 12443, MSE: 0.2429963869986678, Learning Rate: 0.037785000000000006\n",
      "Epoch: 12444, MSE: 0.2429936702825231, Learning Rate: 0.03778000000000001\n",
      "Epoch: 12445, MSE: 0.2429909535245425, Learning Rate: 0.037775\n",
      "Epoch: 12446, MSE: 0.2429882367247317, Learning Rate: 0.037770000000000005\n",
      "Epoch: 12447, MSE: 0.242985519883092, Learning Rate: 0.03776500000000001\n",
      "Epoch: 12448, MSE: 0.24298280299962785, Learning Rate: 0.03776000000000001\n",
      "Epoch: 12449, MSE: 0.2429800860743414, Learning Rate: 0.03775500000000001\n",
      "Epoch: 12450, MSE: 0.24297736910723686, Learning Rate: 0.03775\n",
      "Epoch: 12451, MSE: 0.24297465209831717, Learning Rate: 0.037745\n",
      "Epoch: 12452, MSE: 0.24297193504758594, Learning Rate: 0.037739999999999996\n",
      "Epoch: 12453, MSE: 0.24296921795504484, Learning Rate: 0.037735\n",
      "Epoch: 12454, MSE: 0.24296650082069865, Learning Rate: 0.03773\n",
      "Epoch: 12455, MSE: 0.24296378364455032, Learning Rate: 0.037725\n",
      "Epoch: 12456, MSE: 0.24296106642660228, Learning Rate: 0.037720000000000004\n",
      "Epoch: 12457, MSE: 0.24295834916685896, Learning Rate: 0.037715\n",
      "Epoch: 12458, MSE: 0.24295563186532226, Learning Rate: 0.03771\n",
      "Epoch: 12459, MSE: 0.2429529145219962, Learning Rate: 0.037705\n",
      "Epoch: 12460, MSE: 0.24295019713688346, Learning Rate: 0.037700000000000004\n",
      "Epoch: 12461, MSE: 0.24294747970998828, Learning Rate: 0.037695000000000006\n",
      "Epoch: 12462, MSE: 0.2429447622413133, Learning Rate: 0.03769\n",
      "Epoch: 12463, MSE: 0.24294204473086176, Learning Rate: 0.037685\n",
      "Epoch: 12464, MSE: 0.24293932717863606, Learning Rate: 0.037680000000000005\n",
      "Epoch: 12465, MSE: 0.24293660958464092, Learning Rate: 0.03767500000000001\n",
      "Epoch: 12466, MSE: 0.24293389194887857, Learning Rate: 0.03767000000000001\n",
      "Epoch: 12467, MSE: 0.2429311742713531, Learning Rate: 0.037665000000000004\n",
      "Epoch: 12468, MSE: 0.24292845655206632, Learning Rate: 0.037660000000000006\n",
      "Epoch: 12469, MSE: 0.24292573879102228, Learning Rate: 0.03765500000000001\n",
      "Epoch: 12470, MSE: 0.24292302098822424, Learning Rate: 0.037649999999999996\n",
      "Epoch: 12471, MSE: 0.24292030314367555, Learning Rate: 0.037645\n",
      "Epoch: 12472, MSE: 0.24291758525737975, Learning Rate: 0.03764\n",
      "Epoch: 12473, MSE: 0.2429148673293391, Learning Rate: 0.037635\n",
      "Epoch: 12474, MSE: 0.2429121493595573, Learning Rate: 0.03763\n",
      "Epoch: 12475, MSE: 0.24290943134803752, Learning Rate: 0.037625\n",
      "Epoch: 12476, MSE: 0.24290671329478375, Learning Rate: 0.03762\n",
      "Epoch: 12477, MSE: 0.2429039951997978, Learning Rate: 0.037615\n",
      "Epoch: 12478, MSE: 0.24290127706308443, Learning Rate: 0.037610000000000005\n",
      "Epoch: 12479, MSE: 0.24289855888464607, Learning Rate: 0.037605\n",
      "Epoch: 12480, MSE: 0.24289584066448502, Learning Rate: 0.0376\n",
      "Epoch: 12481, MSE: 0.24289312240260588, Learning Rate: 0.037595\n",
      "Epoch: 12482, MSE: 0.24289040409901194, Learning Rate: 0.037590000000000005\n",
      "Epoch: 12483, MSE: 0.24288768575370576, Learning Rate: 0.03758500000000001\n",
      "Epoch: 12484, MSE: 0.24288496736669143, Learning Rate: 0.03758\n",
      "Epoch: 12485, MSE: 0.24288224893797145, Learning Rate: 0.037575000000000004\n",
      "Epoch: 12486, MSE: 0.24287953046754873, Learning Rate: 0.037570000000000006\n",
      "Epoch: 12487, MSE: 0.24287681195542687, Learning Rate: 0.03756500000000001\n",
      "Epoch: 12488, MSE: 0.2428740934016088, Learning Rate: 0.03756000000000001\n",
      "Epoch: 12489, MSE: 0.2428713748060993, Learning Rate: 0.037555000000000005\n",
      "Epoch: 12490, MSE: 0.24286865616890002, Learning Rate: 0.03755\n",
      "Epoch: 12491, MSE: 0.2428659374900149, Learning Rate: 0.037544999999999995\n",
      "Epoch: 12492, MSE: 0.242863218769447, Learning Rate: 0.03754\n",
      "Epoch: 12493, MSE: 0.2428605000071989, Learning Rate: 0.037535\n",
      "Epoch: 12494, MSE: 0.24285778120327536, Learning Rate: 0.03753\n",
      "Epoch: 12495, MSE: 0.24285506235767848, Learning Rate: 0.037525\n",
      "Epoch: 12496, MSE: 0.24285234347041215, Learning Rate: 0.03752\n",
      "Epoch: 12497, MSE: 0.2428496245414785, Learning Rate: 0.037515\n",
      "Epoch: 12498, MSE: 0.2428469055708817, Learning Rate: 0.03751\n",
      "Epoch: 12499, MSE: 0.24284418655862502, Learning Rate: 0.037505000000000004\n",
      "Epoch: 12500, MSE: 0.2428414675047114, Learning Rate: 0.037500000000000006\n",
      "Epoch: 12501, MSE: 0.24283874840914427, Learning Rate: 0.037495\n",
      "Epoch: 12502, MSE: 0.24283602927192752, Learning Rate: 0.03749\n",
      "Epoch: 12503, MSE: 0.2428333100930624, Learning Rate: 0.037485000000000004\n",
      "Epoch: 12504, MSE: 0.24283059087255426, Learning Rate: 0.037480000000000006\n",
      "Epoch: 12505, MSE: 0.242827871610406, Learning Rate: 0.037475\n",
      "Epoch: 12506, MSE: 0.24282515230662027, Learning Rate: 0.03747\n",
      "Epoch: 12507, MSE: 0.24282243296120007, Learning Rate: 0.037465000000000005\n",
      "Epoch: 12508, MSE: 0.2428197135741494, Learning Rate: 0.03746000000000001\n",
      "Epoch: 12509, MSE: 0.24281699414547056, Learning Rate: 0.03745500000000001\n",
      "Epoch: 12510, MSE: 0.24281427467516883, Learning Rate: 0.037450000000000004\n",
      "Epoch: 12511, MSE: 0.2428115551632451, Learning Rate: 0.037445\n",
      "Epoch: 12512, MSE: 0.24280883560970457, Learning Rate: 0.037439999999999994\n",
      "Epoch: 12513, MSE: 0.24280611601454852, Learning Rate: 0.037434999999999996\n",
      "Epoch: 12514, MSE: 0.24280339637778184, Learning Rate: 0.03743\n",
      "Epoch: 12515, MSE: 0.24280067669940747, Learning Rate: 0.037425\n",
      "Epoch: 12516, MSE: 0.24279795697942758, Learning Rate: 0.03742\n",
      "Epoch: 12517, MSE: 0.24279523721784727, Learning Rate: 0.037415\n",
      "Epoch: 12518, MSE: 0.24279251741466784, Learning Rate: 0.03741\n",
      "Epoch: 12519, MSE: 0.24278979756989444, Learning Rate: 0.037405\n",
      "Epoch: 12520, MSE: 0.24278707768352917, Learning Rate: 0.0374\n",
      "Epoch: 12521, MSE: 0.24278435775557505, Learning Rate: 0.037395000000000005\n",
      "Epoch: 12522, MSE: 0.24278163778603695, Learning Rate: 0.03739\n",
      "Epoch: 12523, MSE: 0.24277891777491634, Learning Rate: 0.037385\n",
      "Epoch: 12524, MSE: 0.24277619772221734, Learning Rate: 0.037380000000000004\n",
      "Epoch: 12525, MSE: 0.24277347762794332, Learning Rate: 0.037375000000000005\n",
      "Epoch: 12526, MSE: 0.24277075749209684, Learning Rate: 0.03737000000000001\n",
      "Epoch: 12527, MSE: 0.24276803731468238, Learning Rate: 0.037365\n",
      "Epoch: 12528, MSE: 0.24276531709570165, Learning Rate: 0.037360000000000004\n",
      "Epoch: 12529, MSE: 0.2427625968351591, Learning Rate: 0.037355000000000006\n",
      "Epoch: 12530, MSE: 0.24275987653305836, Learning Rate: 0.03735000000000001\n",
      "Epoch: 12531, MSE: 0.24275715618940163, Learning Rate: 0.037344999999999996\n",
      "Epoch: 12532, MSE: 0.24275443580419268, Learning Rate: 0.03734\n",
      "Epoch: 12533, MSE: 0.24275171537743434, Learning Rate: 0.037335\n",
      "Epoch: 12534, MSE: 0.24274899490912974, Learning Rate: 0.037329999999999995\n",
      "Epoch: 12535, MSE: 0.24274627439928365, Learning Rate: 0.037325\n",
      "Epoch: 12536, MSE: 0.24274355384789753, Learning Rate: 0.03732\n",
      "Epoch: 12537, MSE: 0.24274083325497672, Learning Rate: 0.037315\n",
      "Epoch: 12538, MSE: 0.24273811262052242, Learning Rate: 0.03731\n",
      "Epoch: 12539, MSE: 0.24273539194453853, Learning Rate: 0.037305\n",
      "Epoch: 12540, MSE: 0.24273267122702905, Learning Rate: 0.0373\n",
      "Epoch: 12541, MSE: 0.24272995046799675, Learning Rate: 0.037295\n",
      "Epoch: 12542, MSE: 0.24272722966744512, Learning Rate: 0.037290000000000004\n",
      "Epoch: 12543, MSE: 0.2427245088253769, Learning Rate: 0.037285000000000006\n",
      "Epoch: 12544, MSE: 0.2427217879417962, Learning Rate: 0.03728\n",
      "Epoch: 12545, MSE: 0.24271906701670537, Learning Rate: 0.037275\n",
      "Epoch: 12546, MSE: 0.24271634605010817, Learning Rate: 0.037270000000000005\n",
      "Epoch: 12547, MSE: 0.24271362504200863, Learning Rate: 0.037265000000000006\n",
      "Epoch: 12548, MSE: 0.24271090399240908, Learning Rate: 0.03726000000000001\n",
      "Epoch: 12549, MSE: 0.24270818290131252, Learning Rate: 0.037255\n",
      "Epoch: 12550, MSE: 0.2427054617687231, Learning Rate: 0.037250000000000005\n",
      "Epoch: 12551, MSE: 0.24270274059464353, Learning Rate: 0.03724499999999999\n",
      "Epoch: 12552, MSE: 0.2427000193790777, Learning Rate: 0.037239999999999995\n",
      "Epoch: 12553, MSE: 0.24269729812202925, Learning Rate: 0.037235\n",
      "Epoch: 12554, MSE: 0.24269457682349976, Learning Rate: 0.03723\n",
      "Epoch: 12555, MSE: 0.24269185548349403, Learning Rate: 0.037225\n",
      "Epoch: 12556, MSE: 0.2426891341020142, Learning Rate: 0.037219999999999996\n",
      "Epoch: 12557, MSE: 0.24268641267906543, Learning Rate: 0.037215\n",
      "Epoch: 12558, MSE: 0.2426836912146496, Learning Rate: 0.03721\n",
      "Epoch: 12559, MSE: 0.24268096970876935, Learning Rate: 0.037205\n",
      "Epoch: 12560, MSE: 0.24267824816142944, Learning Rate: 0.037200000000000004\n",
      "Epoch: 12561, MSE: 0.24267552657263317, Learning Rate: 0.037195\n",
      "Epoch: 12562, MSE: 0.24267280494238214, Learning Rate: 0.03719\n",
      "Epoch: 12563, MSE: 0.24267008327068143, Learning Rate: 0.037185\n",
      "Epoch: 12564, MSE: 0.24266736155753363, Learning Rate: 0.037180000000000005\n",
      "Epoch: 12565, MSE: 0.24266463980294292, Learning Rate: 0.03717500000000001\n",
      "Epoch: 12566, MSE: 0.24266191800691103, Learning Rate: 0.03717\n",
      "Epoch: 12567, MSE: 0.24265919616944204, Learning Rate: 0.037165000000000004\n",
      "Epoch: 12568, MSE: 0.24265647429053916, Learning Rate: 0.037160000000000006\n",
      "Epoch: 12569, MSE: 0.24265375237020578, Learning Rate: 0.03715500000000001\n",
      "Epoch: 12570, MSE: 0.24265103040844535, Learning Rate: 0.03715000000000001\n",
      "Epoch: 12571, MSE: 0.24264830840526172, Learning Rate: 0.037145\n",
      "Epoch: 12572, MSE: 0.24264558636065672, Learning Rate: 0.03714\n",
      "Epoch: 12573, MSE: 0.2426428642746348, Learning Rate: 0.037134999999999994\n",
      "Epoch: 12574, MSE: 0.24264014214719937, Learning Rate: 0.037129999999999996\n",
      "Epoch: 12575, MSE: 0.24263741997835225, Learning Rate: 0.037125\n",
      "Epoch: 12576, MSE: 0.24263469776809884, Learning Rate: 0.03712\n",
      "Epoch: 12577, MSE: 0.2426319755164407, Learning Rate: 0.037115\n",
      "Epoch: 12578, MSE: 0.24262925322338277, Learning Rate: 0.03711\n",
      "Epoch: 12579, MSE: 0.24262653088892663, Learning Rate: 0.037105\n",
      "Epoch: 12580, MSE: 0.2426238085130763, Learning Rate: 0.0371\n",
      "Epoch: 12581, MSE: 0.24262108609583613, Learning Rate: 0.037095\n",
      "Epoch: 12582, MSE: 0.24261836363720826, Learning Rate: 0.037090000000000005\n",
      "Epoch: 12583, MSE: 0.24261564113719594, Learning Rate: 0.037085\n",
      "Epoch: 12584, MSE: 0.24261291859580333, Learning Rate: 0.03708\n",
      "Epoch: 12585, MSE: 0.2426101960130336, Learning Rate: 0.037075000000000004\n",
      "Epoch: 12586, MSE: 0.24260747338888874, Learning Rate: 0.037070000000000006\n",
      "Epoch: 12587, MSE: 0.2426047507233732, Learning Rate: 0.03706500000000001\n",
      "Epoch: 12588, MSE: 0.24260202801649136, Learning Rate: 0.03706\n",
      "Epoch: 12589, MSE: 0.2425993052682442, Learning Rate: 0.037055000000000005\n",
      "Epoch: 12590, MSE: 0.24259658247863627, Learning Rate: 0.03705000000000001\n",
      "Epoch: 12591, MSE: 0.2425938596476716, Learning Rate: 0.037044999999999995\n",
      "Epoch: 12592, MSE: 0.24259113677535166, Learning Rate: 0.03704\n",
      "Epoch: 12593, MSE: 0.24258841386168248, Learning Rate: 0.037035\n",
      "Epoch: 12594, MSE: 0.24258569090666424, Learning Rate: 0.03703\n",
      "Epoch: 12595, MSE: 0.24258296791030276, Learning Rate: 0.037024999999999995\n",
      "Epoch: 12596, MSE: 0.2425802448725995, Learning Rate: 0.03702\n",
      "Epoch: 12597, MSE: 0.24257752179355935, Learning Rate: 0.037015\n",
      "Epoch: 12598, MSE: 0.24257479867318518, Learning Rate: 0.03701\n",
      "Epoch: 12599, MSE: 0.2425720755114797, Learning Rate: 0.037005\n",
      "Epoch: 12600, MSE: 0.24256935230844692, Learning Rate: 0.037\n",
      "Epoch: 12601, MSE: 0.24256662906408966, Learning Rate: 0.036995\n",
      "Epoch: 12602, MSE: 0.24256390577841164, Learning Rate: 0.03699\n",
      "Epoch: 12603, MSE: 0.24256118245141667, Learning Rate: 0.036985000000000004\n",
      "Epoch: 12604, MSE: 0.24255845908310653, Learning Rate: 0.036980000000000006\n",
      "Epoch: 12605, MSE: 0.24255573567348626, Learning Rate: 0.036975\n",
      "Epoch: 12606, MSE: 0.2425530122225578, Learning Rate: 0.03697\n",
      "Epoch: 12607, MSE: 0.2425502887303262, Learning Rate: 0.036965000000000005\n",
      "Epoch: 12608, MSE: 0.24254756519679257, Learning Rate: 0.03696000000000001\n",
      "Epoch: 12609, MSE: 0.24254484162196244, Learning Rate: 0.03695500000000001\n",
      "Epoch: 12610, MSE: 0.2425421180058378, Learning Rate: 0.036950000000000004\n",
      "Epoch: 12611, MSE: 0.24253939434842176, Learning Rate: 0.036945\n",
      "Epoch: 12612, MSE: 0.24253667064971896, Learning Rate: 0.036939999999999994\n",
      "Epoch: 12613, MSE: 0.2425339469097314, Learning Rate: 0.036934999999999996\n",
      "Epoch: 12614, MSE: 0.24253122312846365, Learning Rate: 0.03693\n",
      "Epoch: 12615, MSE: 0.24252849930591866, Learning Rate: 0.036925\n",
      "Epoch: 12616, MSE: 0.2425257754420988, Learning Rate: 0.03692\n",
      "Epoch: 12617, MSE: 0.2425230515370085, Learning Rate: 0.036914999999999996\n",
      "Epoch: 12618, MSE: 0.24252032759065148, Learning Rate: 0.03691\n",
      "Epoch: 12619, MSE: 0.24251760360302932, Learning Rate: 0.036905\n",
      "Epoch: 12620, MSE: 0.2425148795741478, Learning Rate: 0.0369\n",
      "Epoch: 12621, MSE: 0.24251215550400776, Learning Rate: 0.036895000000000004\n",
      "Epoch: 12622, MSE: 0.24250943139261316, Learning Rate: 0.03689\n",
      "Epoch: 12623, MSE: 0.24250670723996942, Learning Rate: 0.036885\n",
      "Epoch: 12624, MSE: 0.24250398304607745, Learning Rate: 0.03688\n",
      "Epoch: 12625, MSE: 0.2425012588109417, Learning Rate: 0.036875000000000005\n",
      "Epoch: 12626, MSE: 0.24249853453456663, Learning Rate: 0.03687000000000001\n",
      "Epoch: 12627, MSE: 0.24249581021695268, Learning Rate: 0.036865\n",
      "Epoch: 12628, MSE: 0.24249308585810517, Learning Rate: 0.036860000000000004\n",
      "Epoch: 12629, MSE: 0.24249036145802758, Learning Rate: 0.036855000000000006\n",
      "Epoch: 12630, MSE: 0.24248763701672288, Learning Rate: 0.03685000000000001\n",
      "Epoch: 12631, MSE: 0.2424849125341937, Learning Rate: 0.03684500000000001\n",
      "Epoch: 12632, MSE: 0.24248218801044488, Learning Rate: 0.03684\n",
      "Epoch: 12633, MSE: 0.24247946344547816, Learning Rate: 0.036835\n",
      "Epoch: 12634, MSE: 0.24247673883929857, Learning Rate: 0.036829999999999995\n",
      "Epoch: 12635, MSE: 0.2424740141919081, Learning Rate: 0.036825\n",
      "Epoch: 12636, MSE: 0.24247128950331076, Learning Rate: 0.03682\n",
      "Epoch: 12637, MSE: 0.24246856477351028, Learning Rate: 0.036815\n",
      "Epoch: 12638, MSE: 0.24246584000250904, Learning Rate: 0.03681\n",
      "Epoch: 12639, MSE: 0.24246311519031052, Learning Rate: 0.036805\n",
      "Epoch: 12640, MSE: 0.24246039033691935, Learning Rate: 0.0368\n",
      "Epoch: 12641, MSE: 0.24245766544233752, Learning Rate: 0.036795\n",
      "Epoch: 12642, MSE: 0.24245494050656832, Learning Rate: 0.03679\n",
      "Epoch: 12643, MSE: 0.24245221552961663, Learning Rate: 0.036785000000000005\n",
      "Epoch: 12644, MSE: 0.24244949051148468, Learning Rate: 0.03678\n",
      "Epoch: 12645, MSE: 0.24244676545217553, Learning Rate: 0.036775\n",
      "Epoch: 12646, MSE: 0.24244404035169353, Learning Rate: 0.036770000000000004\n",
      "Epoch: 12647, MSE: 0.242441315210042, Learning Rate: 0.036765000000000006\n",
      "Epoch: 12648, MSE: 0.24243859002722354, Learning Rate: 0.03676000000000001\n",
      "Epoch: 12649, MSE: 0.2424358648032417, Learning Rate: 0.036755\n",
      "Epoch: 12650, MSE: 0.24243313953809975, Learning Rate: 0.036750000000000005\n",
      "Epoch: 12651, MSE: 0.2424304142318023, Learning Rate: 0.03674500000000001\n",
      "Epoch: 12652, MSE: 0.24242768888435084, Learning Rate: 0.036739999999999995\n",
      "Epoch: 12653, MSE: 0.2424249634957502, Learning Rate: 0.036735\n",
      "Epoch: 12654, MSE: 0.24242223806600335, Learning Rate: 0.03673\n",
      "Epoch: 12655, MSE: 0.24241951259511335, Learning Rate: 0.036725\n",
      "Epoch: 12656, MSE: 0.24241678708308398, Learning Rate: 0.036719999999999996\n",
      "Epoch: 12657, MSE: 0.24241406152991832, Learning Rate: 0.036715\n",
      "Epoch: 12658, MSE: 0.24241133593561984, Learning Rate: 0.03671\n",
      "Epoch: 12659, MSE: 0.2424086103001916, Learning Rate: 0.036705\n",
      "Epoch: 12660, MSE: 0.2424058846236376, Learning Rate: 0.0367\n",
      "Epoch: 12661, MSE: 0.24240315890596148, Learning Rate: 0.036695\n",
      "Epoch: 12662, MSE: 0.242400433147166, Learning Rate: 0.03669\n",
      "Epoch: 12663, MSE: 0.242397707347254, Learning Rate: 0.036685\n",
      "Epoch: 12664, MSE: 0.24239498150622943, Learning Rate: 0.036680000000000004\n",
      "Epoch: 12665, MSE: 0.24239225562409653, Learning Rate: 0.036675000000000006\n",
      "Epoch: 12666, MSE: 0.24238952970085798, Learning Rate: 0.03667\n",
      "Epoch: 12667, MSE: 0.24238680373651691, Learning Rate: 0.036665\n",
      "Epoch: 12668, MSE: 0.2423840777310773, Learning Rate: 0.036660000000000005\n",
      "Epoch: 12669, MSE: 0.2423813516845412, Learning Rate: 0.03665500000000001\n",
      "Epoch: 12670, MSE: 0.24237862559691345, Learning Rate: 0.03665000000000001\n",
      "Epoch: 12671, MSE: 0.24237589946819726, Learning Rate: 0.036645000000000004\n",
      "Epoch: 12672, MSE: 0.24237317329839497, Learning Rate: 0.03664\n",
      "Epoch: 12673, MSE: 0.2423704470875116, Learning Rate: 0.036634999999999994\n",
      "Epoch: 12674, MSE: 0.24236772083554922, Learning Rate: 0.036629999999999996\n",
      "Epoch: 12675, MSE: 0.24236499454251187, Learning Rate: 0.036625\n",
      "Epoch: 12676, MSE: 0.24236226820840295, Learning Rate: 0.03662\n",
      "Epoch: 12677, MSE: 0.24235954183322522, Learning Rate: 0.036615\n",
      "Epoch: 12678, MSE: 0.24235681541698256, Learning Rate: 0.03661\n",
      "Epoch: 12679, MSE: 0.24235408895967867, Learning Rate: 0.036605\n",
      "Epoch: 12680, MSE: 0.24235136246131633, Learning Rate: 0.0366\n",
      "Epoch: 12681, MSE: 0.24234863592189937, Learning Rate: 0.036595\n",
      "Epoch: 12682, MSE: 0.2423459093414307, Learning Rate: 0.036590000000000004\n",
      "Epoch: 12683, MSE: 0.2423431827199149, Learning Rate: 0.036585\n",
      "Epoch: 12684, MSE: 0.24234045605735396, Learning Rate: 0.03658\n",
      "Epoch: 12685, MSE: 0.24233772935375172, Learning Rate: 0.036575\n",
      "Epoch: 12686, MSE: 0.2423350026091125, Learning Rate: 0.036570000000000005\n",
      "Epoch: 12687, MSE: 0.24233227582343853, Learning Rate: 0.03656500000000001\n",
      "Epoch: 12688, MSE: 0.24232954899673326, Learning Rate: 0.03656\n",
      "Epoch: 12689, MSE: 0.24232682212900067, Learning Rate: 0.036555000000000004\n",
      "Epoch: 12690, MSE: 0.2423240952202442, Learning Rate: 0.036550000000000006\n",
      "Epoch: 12691, MSE: 0.242321368270467, Learning Rate: 0.03654500000000001\n",
      "Epoch: 12692, MSE: 0.24231864127967284, Learning Rate: 0.036539999999999996\n",
      "Epoch: 12693, MSE: 0.24231591424786406, Learning Rate: 0.036535\n",
      "Epoch: 12694, MSE: 0.24231318717504594, Learning Rate: 0.03653\n",
      "Epoch: 12695, MSE: 0.24231046006122048, Learning Rate: 0.036524999999999995\n",
      "Epoch: 12696, MSE: 0.24230773290639074, Learning Rate: 0.03652\n",
      "Epoch: 12697, MSE: 0.24230500571056113, Learning Rate: 0.036515\n",
      "Epoch: 12698, MSE: 0.24230227847373473, Learning Rate: 0.03651\n",
      "Epoch: 12699, MSE: 0.24229955119591493, Learning Rate: 0.036505\n",
      "Epoch: 12700, MSE: 0.24229682387710505, Learning Rate: 0.0365\n",
      "Epoch: 12701, MSE: 0.24229409651730893, Learning Rate: 0.036495\n",
      "Epoch: 12702, MSE: 0.24229136911652965, Learning Rate: 0.03649\n",
      "Epoch: 12703, MSE: 0.24228864167477077, Learning Rate: 0.036485000000000004\n",
      "Epoch: 12704, MSE: 0.24228591419203546, Learning Rate: 0.036480000000000005\n",
      "Epoch: 12705, MSE: 0.24228318666832718, Learning Rate: 0.036475\n",
      "Epoch: 12706, MSE: 0.24228045910364976, Learning Rate: 0.03647\n",
      "Epoch: 12707, MSE: 0.2422777314980067, Learning Rate: 0.036465000000000004\n",
      "Epoch: 12708, MSE: 0.24227500385140022, Learning Rate: 0.036460000000000006\n",
      "Epoch: 12709, MSE: 0.24227227616383523, Learning Rate: 0.03645500000000001\n",
      "Epoch: 12710, MSE: 0.24226954843531398, Learning Rate: 0.03645\n",
      "Epoch: 12711, MSE: 0.24226682066584096, Learning Rate: 0.036445000000000005\n",
      "Epoch: 12712, MSE: 0.24226409285541914, Learning Rate: 0.03643999999999999\n",
      "Epoch: 12713, MSE: 0.24226136500405213, Learning Rate: 0.036434999999999995\n",
      "Epoch: 12714, MSE: 0.24225863711174178, Learning Rate: 0.03643\n",
      "Epoch: 12715, MSE: 0.24225590917849418, Learning Rate: 0.036425\n",
      "Epoch: 12716, MSE: 0.24225318120431114, Learning Rate: 0.03642\n",
      "Epoch: 12717, MSE: 0.2422504531891961, Learning Rate: 0.036414999999999996\n",
      "Epoch: 12718, MSE: 0.24224772513315296, Learning Rate: 0.03641\n",
      "Epoch: 12719, MSE: 0.2422449970361852, Learning Rate: 0.036405\n",
      "Epoch: 12720, MSE: 0.24224226889829625, Learning Rate: 0.0364\n",
      "Epoch: 12721, MSE: 0.24223954071948897, Learning Rate: 0.036395000000000004\n",
      "Epoch: 12722, MSE: 0.24223681249976758, Learning Rate: 0.03639\n",
      "Epoch: 12723, MSE: 0.2422340842391344, Learning Rate: 0.036385\n",
      "Epoch: 12724, MSE: 0.24223135593759473, Learning Rate: 0.03638\n",
      "Epoch: 12725, MSE: 0.24222862759514985, Learning Rate: 0.036375000000000005\n",
      "Epoch: 12726, MSE: 0.24222589921180473, Learning Rate: 0.036370000000000006\n",
      "Epoch: 12727, MSE: 0.24222317078756192, Learning Rate: 0.036365\n",
      "Epoch: 12728, MSE: 0.2422204423224253, Learning Rate: 0.03636\n",
      "Epoch: 12729, MSE: 0.24221771381639878, Learning Rate: 0.036355000000000005\n",
      "Epoch: 12730, MSE: 0.24221498526948476, Learning Rate: 0.03635000000000001\n",
      "Epoch: 12731, MSE: 0.2422122566816878, Learning Rate: 0.03634500000000001\n",
      "Epoch: 12732, MSE: 0.24220952805301066, Learning Rate: 0.03634\n",
      "Epoch: 12733, MSE: 0.2422067993834559, Learning Rate: 0.036335\n",
      "Epoch: 12734, MSE: 0.24220407067302926, Learning Rate: 0.036329999999999994\n",
      "Epoch: 12735, MSE: 0.24220134192173237, Learning Rate: 0.036324999999999996\n",
      "Epoch: 12736, MSE: 0.24219861312956936, Learning Rate: 0.03632\n",
      "Epoch: 12737, MSE: 0.24219588429654323, Learning Rate: 0.036315\n",
      "Epoch: 12738, MSE: 0.24219315542265765, Learning Rate: 0.03631\n",
      "Epoch: 12739, MSE: 0.24219042650791645, Learning Rate: 0.036305\n",
      "Epoch: 12740, MSE: 0.24218769755232256, Learning Rate: 0.0363\n",
      "Epoch: 12741, MSE: 0.24218496855588026, Learning Rate: 0.036295\n",
      "Epoch: 12742, MSE: 0.24218223951859197, Learning Rate: 0.03629\n",
      "Epoch: 12743, MSE: 0.24217951044046182, Learning Rate: 0.036285000000000005\n",
      "Epoch: 12744, MSE: 0.24217678132149292, Learning Rate: 0.03628\n",
      "Epoch: 12745, MSE: 0.24217405216168852, Learning Rate: 0.036275\n",
      "Epoch: 12746, MSE: 0.2421713229610531, Learning Rate: 0.036270000000000004\n",
      "Epoch: 12747, MSE: 0.24216859371958882, Learning Rate: 0.036265000000000006\n",
      "Epoch: 12748, MSE: 0.24216586443730034, Learning Rate: 0.03626000000000001\n",
      "Epoch: 12749, MSE: 0.2421631351141901, Learning Rate: 0.036255\n",
      "Epoch: 12750, MSE: 0.2421604057502619, Learning Rate: 0.036250000000000004\n",
      "Epoch: 12751, MSE: 0.2421576763455195, Learning Rate: 0.036245000000000006\n",
      "Epoch: 12752, MSE: 0.24215494689996622, Learning Rate: 0.03624000000000001\n",
      "Epoch: 12753, MSE: 0.24215221741360574, Learning Rate: 0.036234999999999996\n",
      "Epoch: 12754, MSE: 0.24214948788644128, Learning Rate: 0.03623\n",
      "Epoch: 12755, MSE: 0.24214675831847593, Learning Rate: 0.036225\n",
      "Epoch: 12756, MSE: 0.24214402870971372, Learning Rate: 0.036219999999999995\n",
      "Epoch: 12757, MSE: 0.24214129906015797, Learning Rate: 0.036215\n",
      "Epoch: 12758, MSE: 0.24213856936981168, Learning Rate: 0.03621\n",
      "Epoch: 12759, MSE: 0.24213583963867918, Learning Rate: 0.036205\n",
      "Epoch: 12760, MSE: 0.24213310986676398, Learning Rate: 0.0362\n",
      "Epoch: 12761, MSE: 0.24213038005406834, Learning Rate: 0.036195\n",
      "Epoch: 12762, MSE: 0.24212765020059634, Learning Rate: 0.03619\n",
      "Epoch: 12763, MSE: 0.24212492030635197, Learning Rate: 0.036185\n",
      "Epoch: 12764, MSE: 0.24212219037133859, Learning Rate: 0.036180000000000004\n",
      "Epoch: 12765, MSE: 0.24211946039555918, Learning Rate: 0.036175000000000006\n",
      "Epoch: 12766, MSE: 0.24211673037901763, Learning Rate: 0.03617\n",
      "Epoch: 12767, MSE: 0.24211400032171684, Learning Rate: 0.036165\n",
      "Epoch: 12768, MSE: 0.24211127022366127, Learning Rate: 0.036160000000000005\n",
      "Epoch: 12769, MSE: 0.24210854008485302, Learning Rate: 0.03615500000000001\n",
      "Epoch: 12770, MSE: 0.24210580990529698, Learning Rate: 0.03615000000000001\n",
      "Epoch: 12771, MSE: 0.24210307968499636, Learning Rate: 0.036145000000000004\n",
      "Epoch: 12772, MSE: 0.24210034942395425, Learning Rate: 0.036140000000000005\n",
      "Epoch: 12773, MSE: 0.24209761912217373, Learning Rate: 0.036134999999999994\n",
      "Epoch: 12774, MSE: 0.2420948887796587, Learning Rate: 0.036129999999999995\n",
      "Epoch: 12775, MSE: 0.24209215839641346, Learning Rate: 0.036125\n",
      "Epoch: 12776, MSE: 0.24208942797243999, Learning Rate: 0.03612\n",
      "Epoch: 12777, MSE: 0.24208669750774311, Learning Rate: 0.036115\n",
      "Epoch: 12778, MSE: 0.24208396700232537, Learning Rate: 0.036109999999999996\n",
      "Epoch: 12779, MSE: 0.24208123645619106, Learning Rate: 0.036105\n",
      "Epoch: 12780, MSE: 0.24207850586934276, Learning Rate: 0.0361\n",
      "Epoch: 12781, MSE: 0.24207577524178478, Learning Rate: 0.036095\n",
      "Epoch: 12782, MSE: 0.24207304457352033, Learning Rate: 0.036090000000000004\n",
      "Epoch: 12783, MSE: 0.2420703138645525, Learning Rate: 0.036085\n",
      "Epoch: 12784, MSE: 0.24206758311488547, Learning Rate: 0.03608\n",
      "Epoch: 12785, MSE: 0.24206485232452246, Learning Rate: 0.036075\n",
      "Epoch: 12786, MSE: 0.24206212149346687, Learning Rate: 0.036070000000000005\n",
      "Epoch: 12787, MSE: 0.24205939062172221, Learning Rate: 0.03606500000000001\n",
      "Epoch: 12788, MSE: 0.2420566597092919, Learning Rate: 0.03606\n",
      "Epoch: 12789, MSE: 0.24205392875617937, Learning Rate: 0.036055000000000004\n",
      "Epoch: 12790, MSE: 0.24205119776238881, Learning Rate: 0.036050000000000006\n",
      "Epoch: 12791, MSE: 0.2420484667279232, Learning Rate: 0.03604500000000001\n",
      "Epoch: 12792, MSE: 0.24204573565278573, Learning Rate: 0.03604000000000001\n",
      "Epoch: 12793, MSE: 0.24204300453698052, Learning Rate: 0.036035\n",
      "Epoch: 12794, MSE: 0.242040273380511, Learning Rate: 0.03603\n",
      "Epoch: 12795, MSE: 0.24203754218337975, Learning Rate: 0.036024999999999995\n",
      "Epoch: 12796, MSE: 0.2420348109455913, Learning Rate: 0.036019999999999996\n",
      "Epoch: 12797, MSE: 0.2420320796671491, Learning Rate: 0.036015\n",
      "Epoch: 12798, MSE: 0.24202934834805645, Learning Rate: 0.03601\n",
      "Epoch: 12799, MSE: 0.24202661698831676, Learning Rate: 0.036005\n",
      "Epoch: 12800, MSE: 0.24202388558793364, Learning Rate: 0.036\n",
      "Epoch: 12801, MSE: 0.24202115414691044, Learning Rate: 0.035995\n",
      "Epoch: 12802, MSE: 0.24201842266525103, Learning Rate: 0.03599\n",
      "Epoch: 12803, MSE: 0.24201569114295823, Learning Rate: 0.035985\n",
      "Epoch: 12804, MSE: 0.24201295958003619, Learning Rate: 0.035980000000000005\n",
      "Epoch: 12805, MSE: 0.24201022797648866, Learning Rate: 0.035975\n",
      "Epoch: 12806, MSE: 0.24200749633231836, Learning Rate: 0.03597\n",
      "Epoch: 12807, MSE: 0.24200476464752974, Learning Rate: 0.035965000000000004\n",
      "Epoch: 12808, MSE: 0.24200203292212583, Learning Rate: 0.035960000000000006\n",
      "Epoch: 12809, MSE: 0.24199930115610943, Learning Rate: 0.03595500000000001\n",
      "Epoch: 12810, MSE: 0.24199656934948446, Learning Rate: 0.03595\n",
      "Epoch: 12811, MSE: 0.2419938375022552, Learning Rate: 0.035945000000000005\n",
      "Epoch: 12812, MSE: 0.24199110561442516, Learning Rate: 0.03594000000000001\n",
      "Epoch: 12813, MSE: 0.24198837368599704, Learning Rate: 0.035934999999999995\n",
      "Epoch: 12814, MSE: 0.24198564171697493, Learning Rate: 0.03593\n",
      "Epoch: 12815, MSE: 0.2419829097073619, Learning Rate: 0.035925\n",
      "Epoch: 12816, MSE: 0.24198017765716123, Learning Rate: 0.03592\n",
      "Epoch: 12817, MSE: 0.24197744556637735, Learning Rate: 0.035914999999999996\n",
      "Epoch: 12818, MSE: 0.2419747134350134, Learning Rate: 0.03591\n",
      "Epoch: 12819, MSE: 0.24197198126307373, Learning Rate: 0.035905\n",
      "Epoch: 12820, MSE: 0.24196924905055983, Learning Rate: 0.0359\n",
      "Epoch: 12821, MSE: 0.24196651679747705, Learning Rate: 0.035895\n",
      "Epoch: 12822, MSE: 0.2419637845038279, Learning Rate: 0.03589\n",
      "Epoch: 12823, MSE: 0.24196105216961633, Learning Rate: 0.035885\n",
      "Epoch: 12824, MSE: 0.2419583197948464, Learning Rate: 0.03588\n",
      "Epoch: 12825, MSE: 0.2419555873795199, Learning Rate: 0.035875000000000004\n",
      "Epoch: 12826, MSE: 0.24195285492364296, Learning Rate: 0.035870000000000006\n",
      "Epoch: 12827, MSE: 0.24195012242721733, Learning Rate: 0.035865\n",
      "Epoch: 12828, MSE: 0.24194738989024672, Learning Rate: 0.03586\n",
      "Epoch: 12829, MSE: 0.24194465731273487, Learning Rate: 0.035855000000000005\n",
      "Epoch: 12830, MSE: 0.24194192469468498, Learning Rate: 0.03585000000000001\n",
      "Epoch: 12831, MSE: 0.24193919203610156, Learning Rate: 0.03584500000000001\n",
      "Epoch: 12832, MSE: 0.2419364593369871, Learning Rate: 0.035840000000000004\n",
      "Epoch: 12833, MSE: 0.24193372659734574, Learning Rate: 0.035835\n",
      "Epoch: 12834, MSE: 0.24193099381718125, Learning Rate: 0.035829999999999994\n",
      "Epoch: 12835, MSE: 0.24192826099649645, Learning Rate: 0.035824999999999996\n",
      "Epoch: 12836, MSE: 0.24192552813529591, Learning Rate: 0.03582\n",
      "Epoch: 12837, MSE: 0.24192279523358168, Learning Rate: 0.035815\n",
      "Epoch: 12838, MSE: 0.24192006229135818, Learning Rate: 0.03581\n",
      "Epoch: 12839, MSE: 0.2419173293086293, Learning Rate: 0.035805\n",
      "Epoch: 12840, MSE: 0.24191459628539785, Learning Rate: 0.0358\n",
      "Epoch: 12841, MSE: 0.241911863221668, Learning Rate: 0.035795\n",
      "Epoch: 12842, MSE: 0.24190913011744292, Learning Rate: 0.03579\n",
      "Epoch: 12843, MSE: 0.241906396972726, Learning Rate: 0.035785000000000004\n",
      "Epoch: 12844, MSE: 0.24190366378752165, Learning Rate: 0.03578\n",
      "Epoch: 12845, MSE: 0.24190093056183193, Learning Rate: 0.035775\n",
      "Epoch: 12846, MSE: 0.2418981972956622, Learning Rate: 0.03577\n",
      "Epoch: 12847, MSE: 0.24189546398901432, Learning Rate: 0.035765000000000005\n",
      "Epoch: 12848, MSE: 0.24189273064189323, Learning Rate: 0.03576000000000001\n",
      "Epoch: 12849, MSE: 0.241889997254302, Learning Rate: 0.035755\n",
      "Epoch: 12850, MSE: 0.24188726382624415, Learning Rate: 0.035750000000000004\n",
      "Epoch: 12851, MSE: 0.24188453035772323, Learning Rate: 0.035745000000000006\n",
      "Epoch: 12852, MSE: 0.24188179684874214, Learning Rate: 0.03574000000000001\n",
      "Epoch: 12853, MSE: 0.24187906329930517, Learning Rate: 0.035734999999999996\n",
      "Epoch: 12854, MSE: 0.24187632970941567, Learning Rate: 0.03573\n",
      "Epoch: 12855, MSE: 0.24187359607907802, Learning Rate: 0.035725\n",
      "Epoch: 12856, MSE: 0.241870862408295, Learning Rate: 0.035719999999999995\n",
      "Epoch: 12857, MSE: 0.24186812869706945, Learning Rate: 0.035715\n",
      "Epoch: 12858, MSE: 0.2418653949454062, Learning Rate: 0.03571\n",
      "Epoch: 12859, MSE: 0.2418626611533086, Learning Rate: 0.035705\n",
      "Epoch: 12860, MSE: 0.2418599273207797, Learning Rate: 0.0357\n",
      "Epoch: 12861, MSE: 0.24185719344782347, Learning Rate: 0.035695\n",
      "Epoch: 12862, MSE: 0.2418544595344433, Learning Rate: 0.03569\n",
      "Epoch: 12863, MSE: 0.2418517255806431, Learning Rate: 0.035685\n",
      "Epoch: 12864, MSE: 0.2418489915864257, Learning Rate: 0.03568\n",
      "Epoch: 12865, MSE: 0.24184625755179573, Learning Rate: 0.035675000000000005\n",
      "Epoch: 12866, MSE: 0.2418435234767559, Learning Rate: 0.03567\n",
      "Epoch: 12867, MSE: 0.24184078936130943, Learning Rate: 0.035665\n",
      "Epoch: 12868, MSE: 0.24183805520546153, Learning Rate: 0.035660000000000004\n",
      "Epoch: 12869, MSE: 0.24183532100921346, Learning Rate: 0.035655000000000006\n",
      "Epoch: 12870, MSE: 0.24183258677257088, Learning Rate: 0.03565000000000001\n",
      "Epoch: 12871, MSE: 0.2418298524955368, Learning Rate: 0.035645\n",
      "Epoch: 12872, MSE: 0.24182711817811503, Learning Rate: 0.035640000000000005\n",
      "Epoch: 12873, MSE: 0.2418243838203082, Learning Rate: 0.03563499999999999\n",
      "Epoch: 12874, MSE: 0.24182164942211984, Learning Rate: 0.035629999999999995\n",
      "Epoch: 12875, MSE: 0.24181891498355554, Learning Rate: 0.035625\n",
      "Epoch: 12876, MSE: 0.24181618050461626, Learning Rate: 0.03562\n",
      "Epoch: 12877, MSE: 0.24181344598530688, Learning Rate: 0.035615\n",
      "Epoch: 12878, MSE: 0.24181071142563124, Learning Rate: 0.035609999999999996\n",
      "Epoch: 12879, MSE: 0.24180797682559296, Learning Rate: 0.035605\n",
      "Epoch: 12880, MSE: 0.24180524218519464, Learning Rate: 0.0356\n",
      "Epoch: 12881, MSE: 0.2418025075044402, Learning Rate: 0.035595\n",
      "Epoch: 12882, MSE: 0.24179977278333442, Learning Rate: 0.035590000000000004\n",
      "Epoch: 12883, MSE: 0.2417970380218795, Learning Rate: 0.035585\n",
      "Epoch: 12884, MSE: 0.24179430322007972, Learning Rate: 0.03558\n",
      "Epoch: 12885, MSE: 0.2417915683779384, Learning Rate: 0.035575\n",
      "Epoch: 12886, MSE: 0.24178883349545935, Learning Rate: 0.035570000000000004\n",
      "Epoch: 12887, MSE: 0.2417860985726457, Learning Rate: 0.035565000000000006\n",
      "Epoch: 12888, MSE: 0.24178336360950176, Learning Rate: 0.03556\n",
      "Epoch: 12889, MSE: 0.24178062860603075, Learning Rate: 0.035555\n",
      "Epoch: 12890, MSE: 0.24177789356223617, Learning Rate: 0.035550000000000005\n",
      "Epoch: 12891, MSE: 0.2417751584781215, Learning Rate: 0.03554500000000001\n",
      "Epoch: 12892, MSE: 0.24177242335369062, Learning Rate: 0.03554000000000001\n",
      "Epoch: 12893, MSE: 0.2417696881889477, Learning Rate: 0.035535000000000004\n",
      "Epoch: 12894, MSE: 0.24176695298389475, Learning Rate: 0.03553\n",
      "Epoch: 12895, MSE: 0.2417642177385368, Learning Rate: 0.035524999999999994\n",
      "Epoch: 12896, MSE: 0.241761482452877, Learning Rate: 0.035519999999999996\n",
      "Epoch: 12897, MSE: 0.24175874712691897, Learning Rate: 0.035515\n",
      "Epoch: 12898, MSE: 0.24175601176066627, Learning Rate: 0.03551\n",
      "Epoch: 12899, MSE: 0.24175327635412253, Learning Rate: 0.035505\n",
      "Epoch: 12900, MSE: 0.24175054090729206, Learning Rate: 0.0355\n",
      "Epoch: 12901, MSE: 0.24174780542017663, Learning Rate: 0.035495\n",
      "Epoch: 12902, MSE: 0.24174506989278147, Learning Rate: 0.03549\n",
      "Epoch: 12903, MSE: 0.2417423343251102, Learning Rate: 0.035485\n",
      "Epoch: 12904, MSE: 0.24173959871716502, Learning Rate: 0.035480000000000005\n",
      "Epoch: 12905, MSE: 0.24173686306895104, Learning Rate: 0.035475\n",
      "Epoch: 12906, MSE: 0.2417341273804722, Learning Rate: 0.03547\n",
      "Epoch: 12907, MSE: 0.24173139165173024, Learning Rate: 0.035465\n",
      "Epoch: 12908, MSE: 0.2417286558827299, Learning Rate: 0.035460000000000005\n",
      "Epoch: 12909, MSE: 0.24172592007347457, Learning Rate: 0.03545500000000001\n",
      "Epoch: 12910, MSE: 0.24172318422396774, Learning Rate: 0.03545\n",
      "Epoch: 12911, MSE: 0.24172044833421455, Learning Rate: 0.035445000000000004\n",
      "Epoch: 12912, MSE: 0.24171771240421625, Learning Rate: 0.035440000000000006\n",
      "Epoch: 12913, MSE: 0.24171497643397774, Learning Rate: 0.03543500000000001\n",
      "Epoch: 12914, MSE: 0.24171224042350223, Learning Rate: 0.035429999999999996\n",
      "Epoch: 12915, MSE: 0.24170950437279407, Learning Rate: 0.035425\n",
      "Epoch: 12916, MSE: 0.24170676828185622, Learning Rate: 0.03542\n",
      "Epoch: 12917, MSE: 0.24170403215069233, Learning Rate: 0.035414999999999995\n",
      "Epoch: 12918, MSE: 0.241701295979307, Learning Rate: 0.03541\n",
      "Epoch: 12919, MSE: 0.241698559767702, Learning Rate: 0.035405\n",
      "Epoch: 12920, MSE: 0.24169582351588273, Learning Rate: 0.0354\n",
      "Epoch: 12921, MSE: 0.2416930872238519, Learning Rate: 0.035395\n",
      "Epoch: 12922, MSE: 0.24169035089161295, Learning Rate: 0.03539\n",
      "Epoch: 12923, MSE: 0.2416876145191704, Learning Rate: 0.035385\n",
      "Epoch: 12924, MSE: 0.24168487810652622, Learning Rate: 0.03538\n",
      "Epoch: 12925, MSE: 0.24168214165368684, Learning Rate: 0.035375000000000004\n",
      "Epoch: 12926, MSE: 0.24167940516065387, Learning Rate: 0.035370000000000006\n",
      "Epoch: 12927, MSE: 0.24167666862743123, Learning Rate: 0.035365\n",
      "Epoch: 12928, MSE: 0.24167393205402246, Learning Rate: 0.03536\n",
      "Epoch: 12929, MSE: 0.2416711954404312, Learning Rate: 0.035355000000000004\n",
      "Epoch: 12930, MSE: 0.24166845878666215, Learning Rate: 0.035350000000000006\n",
      "Epoch: 12931, MSE: 0.24166572209271772, Learning Rate: 0.03534500000000001\n",
      "Epoch: 12932, MSE: 0.24166298535860115, Learning Rate: 0.03534\n",
      "Epoch: 12933, MSE: 0.24166024858431778, Learning Rate: 0.035335000000000005\n",
      "Epoch: 12934, MSE: 0.24165751176987021, Learning Rate: 0.03532999999999999\n",
      "Epoch: 12935, MSE: 0.24165477491526216, Learning Rate: 0.035324999999999995\n",
      "Epoch: 12936, MSE: 0.241652038020497, Learning Rate: 0.03532\n",
      "Epoch: 12937, MSE: 0.24164930108557967, Learning Rate: 0.035315\n",
      "Epoch: 12938, MSE: 0.2416465641105119, Learning Rate: 0.03531\n",
      "Epoch: 12939, MSE: 0.24164382709529886, Learning Rate: 0.035304999999999996\n",
      "Epoch: 12940, MSE: 0.24164109003994383, Learning Rate: 0.0353\n",
      "Epoch: 12941, MSE: 0.24163835294444974, Learning Rate: 0.035295\n",
      "Epoch: 12942, MSE: 0.24163561580882117, Learning Rate: 0.03529\n",
      "Epoch: 12943, MSE: 0.24163287863306138, Learning Rate: 0.035285000000000004\n",
      "Epoch: 12944, MSE: 0.2416301414171739, Learning Rate: 0.03528\n",
      "Epoch: 12945, MSE: 0.2416274041611628, Learning Rate: 0.035275\n",
      "Epoch: 12946, MSE: 0.24162466686503184, Learning Rate: 0.03527\n",
      "Epoch: 12947, MSE: 0.24162192952878322, Learning Rate: 0.035265000000000005\n",
      "Epoch: 12948, MSE: 0.24161919215242203, Learning Rate: 0.03526000000000001\n",
      "Epoch: 12949, MSE: 0.24161645473595197, Learning Rate: 0.035255\n",
      "Epoch: 12950, MSE: 0.24161371727937644, Learning Rate: 0.035250000000000004\n",
      "Epoch: 12951, MSE: 0.2416109797826988, Learning Rate: 0.035245000000000005\n",
      "Epoch: 12952, MSE: 0.2416082422459227, Learning Rate: 0.03524000000000001\n",
      "Epoch: 12953, MSE: 0.2416055046690519, Learning Rate: 0.03523500000000001\n",
      "Epoch: 12954, MSE: 0.24160276705209152, Learning Rate: 0.03523\n",
      "Epoch: 12955, MSE: 0.24160002939504205, Learning Rate: 0.035225\n",
      "Epoch: 12956, MSE: 0.24159729169790997, Learning Rate: 0.035219999999999994\n",
      "Epoch: 12957, MSE: 0.24159455396069798, Learning Rate: 0.035214999999999996\n",
      "Epoch: 12958, MSE: 0.2415918161834092, Learning Rate: 0.03521\n",
      "Epoch: 12959, MSE: 0.24158907836604868, Learning Rate: 0.035205\n",
      "Epoch: 12960, MSE: 0.24158634050861857, Learning Rate: 0.0352\n",
      "Epoch: 12961, MSE: 0.2415836026111239, Learning Rate: 0.035195\n",
      "Epoch: 12962, MSE: 0.24158086467356718, Learning Rate: 0.03519\n",
      "Epoch: 12963, MSE: 0.24157812669595286, Learning Rate: 0.035185\n",
      "Epoch: 12964, MSE: 0.241575388678284, Learning Rate: 0.03518\n",
      "Epoch: 12965, MSE: 0.2415726506205649, Learning Rate: 0.035175000000000005\n",
      "Epoch: 12966, MSE: 0.24156991252279894, Learning Rate: 0.03517\n",
      "Epoch: 12967, MSE: 0.24156717438498954, Learning Rate: 0.035165\n",
      "Epoch: 12968, MSE: 0.24156443620714163, Learning Rate: 0.035160000000000004\n",
      "Epoch: 12969, MSE: 0.24156169798925617, Learning Rate: 0.035155000000000006\n",
      "Epoch: 12970, MSE: 0.24155895973134037, Learning Rate: 0.03515000000000001\n",
      "Epoch: 12971, MSE: 0.24155622143339564, Learning Rate: 0.035145\n",
      "Epoch: 12972, MSE: 0.24155348309542682, Learning Rate: 0.035140000000000005\n",
      "Epoch: 12973, MSE: 0.24155074471743562, Learning Rate: 0.035135000000000007\n",
      "Epoch: 12974, MSE: 0.24154800629942755, Learning Rate: 0.035129999999999995\n",
      "Epoch: 12975, MSE: 0.24154526784140584, Learning Rate: 0.035124999999999997\n",
      "Epoch: 12976, MSE: 0.24154252934337367, Learning Rate: 0.03512\n",
      "Epoch: 12977, MSE: 0.24153979080533644, Learning Rate: 0.035115\n",
      "Epoch: 12978, MSE: 0.24153705222729618, Learning Rate: 0.035109999999999995\n",
      "Epoch: 12979, MSE: 0.24153431360925687, Learning Rate: 0.035105\n",
      "Epoch: 12980, MSE: 0.2415315749512221, Learning Rate: 0.0351\n",
      "Epoch: 12981, MSE: 0.24152883625319657, Learning Rate: 0.035095\n",
      "Epoch: 12982, MSE: 0.24152609751518225, Learning Rate: 0.03509\n",
      "Epoch: 12983, MSE: 0.24152335873718456, Learning Rate: 0.035085\n",
      "Epoch: 12984, MSE: 0.24152061991920645, Learning Rate: 0.03508\n",
      "Epoch: 12985, MSE: 0.2415178810612515, Learning Rate: 0.035075\n",
      "Epoch: 12986, MSE: 0.2415151421633233, Learning Rate: 0.035070000000000004\n",
      "Epoch: 12987, MSE: 0.24151240322542572, Learning Rate: 0.035065000000000006\n",
      "Epoch: 12988, MSE: 0.24150966424756254, Learning Rate: 0.03506\n",
      "Epoch: 12989, MSE: 0.24150692522973835, Learning Rate: 0.035055\n",
      "Epoch: 12990, MSE: 0.241504186171955, Learning Rate: 0.035050000000000005\n",
      "Epoch: 12991, MSE: 0.24150144707421745, Learning Rate: 0.03504500000000001\n",
      "Epoch: 12992, MSE: 0.24149870793652903, Learning Rate: 0.03504000000000001\n",
      "Epoch: 12993, MSE: 0.24149596875889412, Learning Rate: 0.035035000000000004\n",
      "Epoch: 12994, MSE: 0.24149322954131533, Learning Rate: 0.03503\n",
      "Epoch: 12995, MSE: 0.24149049028379663, Learning Rate: 0.035024999999999994\n",
      "Epoch: 12996, MSE: 0.24148775098634304, Learning Rate: 0.035019999999999996\n",
      "Epoch: 12997, MSE: 0.24148501164895614, Learning Rate: 0.035015\n",
      "Epoch: 12998, MSE: 0.2414822722716418, Learning Rate: 0.03501\n",
      "Epoch: 12999, MSE: 0.24147953285440174, Learning Rate: 0.035005\n",
      "Epoch: 13000, MSE: 0.24147679339724076, Learning Rate: 0.034999999999999996\n",
      "Epoch: 13001, MSE: 0.24147405390016308, Learning Rate: 0.034995\n",
      "Epoch: 13002, MSE: 0.24147131436317093, Learning Rate: 0.03499\n",
      "Epoch: 13003, MSE: 0.24146857478626946, Learning Rate: 0.034985\n",
      "Epoch: 13004, MSE: 0.2414658351694616, Learning Rate: 0.034980000000000004\n",
      "Epoch: 13005, MSE: 0.24146309551275158, Learning Rate: 0.034975\n",
      "Epoch: 13006, MSE: 0.24146035581614259, Learning Rate: 0.03497\n",
      "Epoch: 13007, MSE: 0.24145761607963875, Learning Rate: 0.034965\n",
      "Epoch: 13008, MSE: 0.24145487630324297, Learning Rate: 0.034960000000000005\n",
      "Epoch: 13009, MSE: 0.2414521364869608, Learning Rate: 0.03495500000000001\n",
      "Epoch: 13010, MSE: 0.24144939663079348, Learning Rate: 0.03495\n",
      "Epoch: 13011, MSE: 0.24144665673474705, Learning Rate: 0.034945000000000004\n",
      "Epoch: 13012, MSE: 0.24144391679882418, Learning Rate: 0.034940000000000006\n",
      "Epoch: 13013, MSE: 0.24144117682302776, Learning Rate: 0.03493500000000001\n",
      "Epoch: 13014, MSE: 0.24143843680736388, Learning Rate: 0.03493000000000001\n",
      "Epoch: 13015, MSE: 0.2414356967518338, Learning Rate: 0.034925\n",
      "Epoch: 13016, MSE: 0.24143295665644246, Learning Rate: 0.03492\n",
      "Epoch: 13017, MSE: 0.2414302165211939, Learning Rate: 0.034914999999999995\n",
      "Epoch: 13018, MSE: 0.24142747634609046, Learning Rate: 0.03491\n",
      "Epoch: 13019, MSE: 0.2414247361311374, Learning Rate: 0.034905\n",
      "Epoch: 13020, MSE: 0.2414219958763383, Learning Rate: 0.0349\n",
      "Epoch: 13021, MSE: 0.24141925558169547, Learning Rate: 0.034895\n",
      "Epoch: 13022, MSE: 0.24141651524721391, Learning Rate: 0.03489\n",
      "Epoch: 13023, MSE: 0.24141377487289753, Learning Rate: 0.034885\n",
      "Epoch: 13024, MSE: 0.24141103445874926, Learning Rate: 0.03488\n",
      "Epoch: 13025, MSE: 0.2414082940047738, Learning Rate: 0.034875\n",
      "Epoch: 13026, MSE: 0.24140555351097345, Learning Rate: 0.034870000000000005\n",
      "Epoch: 13027, MSE: 0.24140281297735303, Learning Rate: 0.034865\n",
      "Epoch: 13028, MSE: 0.2414000724039163, Learning Rate: 0.03486\n",
      "Epoch: 13029, MSE: 0.2413973317906674, Learning Rate: 0.034855000000000004\n",
      "Epoch: 13030, MSE: 0.2413945911376089, Learning Rate: 0.034850000000000006\n",
      "Epoch: 13031, MSE: 0.24139185044474534, Learning Rate: 0.03484500000000001\n",
      "Epoch: 13032, MSE: 0.24138910971208, Learning Rate: 0.03484\n",
      "Epoch: 13033, MSE: 0.24138636893961687, Learning Rate: 0.034835000000000005\n",
      "Epoch: 13034, MSE: 0.24138362812735983, Learning Rate: 0.03483000000000001\n",
      "Epoch: 13035, MSE: 0.24138088727531276, Learning Rate: 0.034824999999999995\n",
      "Epoch: 13036, MSE: 0.2413781463834789, Learning Rate: 0.03482\n",
      "Epoch: 13037, MSE: 0.24137540545186176, Learning Rate: 0.034815\n",
      "Epoch: 13038, MSE: 0.24137266448046704, Learning Rate: 0.03481\n",
      "Epoch: 13039, MSE: 0.24136992346929606, Learning Rate: 0.034804999999999996\n",
      "Epoch: 13040, MSE: 0.24136718241835406, Learning Rate: 0.0348\n",
      "Epoch: 13041, MSE: 0.24136444132764392, Learning Rate: 0.034795\n",
      "Epoch: 13042, MSE: 0.2413617001971705, Learning Rate: 0.03479\n",
      "Epoch: 13043, MSE: 0.2413589590269367, Learning Rate: 0.034785\n",
      "Epoch: 13044, MSE: 0.24135621781694633, Learning Rate: 0.03478\n",
      "Epoch: 13045, MSE: 0.24135347656720382, Learning Rate: 0.034775\n",
      "Epoch: 13046, MSE: 0.2413507352777122, Learning Rate: 0.03477\n",
      "Epoch: 13047, MSE: 0.24134799394847478, Learning Rate: 0.034765000000000004\n",
      "Epoch: 13048, MSE: 0.2413452525794969, Learning Rate: 0.034760000000000006\n",
      "Epoch: 13049, MSE: 0.24134251117078145, Learning Rate: 0.034755\n",
      "Epoch: 13050, MSE: 0.24133976972233248, Learning Rate: 0.03475\n",
      "Epoch: 13051, MSE: 0.24133702823415282, Learning Rate: 0.034745000000000005\n",
      "Epoch: 13052, MSE: 0.24133428670624726, Learning Rate: 0.03474000000000001\n",
      "Epoch: 13053, MSE: 0.24133154513861863, Learning Rate: 0.03473500000000001\n",
      "Epoch: 13054, MSE: 0.24132880353127265, Learning Rate: 0.034730000000000004\n",
      "Epoch: 13055, MSE: 0.2413260618842112, Learning Rate: 0.034725\n",
      "Epoch: 13056, MSE: 0.24132332019743816, Learning Rate: 0.034719999999999994\n",
      "Epoch: 13057, MSE: 0.24132057847095845, Learning Rate: 0.034714999999999996\n",
      "Epoch: 13058, MSE: 0.241317836704775, Learning Rate: 0.03471\n",
      "Epoch: 13059, MSE: 0.24131509489889155, Learning Rate: 0.034705\n",
      "Epoch: 13060, MSE: 0.24131235305331256, Learning Rate: 0.0347\n",
      "Epoch: 13061, MSE: 0.24130961116804123, Learning Rate: 0.034695\n",
      "Epoch: 13062, MSE: 0.24130686924308173, Learning Rate: 0.03469\n",
      "Epoch: 13063, MSE: 0.24130412727843728, Learning Rate: 0.034685\n",
      "Epoch: 13064, MSE: 0.24130138527411207, Learning Rate: 0.03468\n",
      "Epoch: 13065, MSE: 0.24129864323011024, Learning Rate: 0.034675000000000004\n",
      "Epoch: 13066, MSE: 0.2412959011464348, Learning Rate: 0.03467\n",
      "Epoch: 13067, MSE: 0.24129315902308981, Learning Rate: 0.034665\n",
      "Epoch: 13068, MSE: 0.24129041686008032, Learning Rate: 0.03466\n",
      "Epoch: 13069, MSE: 0.24128767465740814, Learning Rate: 0.034655000000000005\n",
      "Epoch: 13070, MSE: 0.24128493241507798, Learning Rate: 0.03465000000000001\n",
      "Epoch: 13071, MSE: 0.24128219013309316, Learning Rate: 0.034645\n",
      "Epoch: 13072, MSE: 0.2412794478114582, Learning Rate: 0.034640000000000004\n",
      "Epoch: 13073, MSE: 0.24127670545017688, Learning Rate: 0.034635000000000006\n",
      "Epoch: 13074, MSE: 0.2412739630492528, Learning Rate: 0.03463000000000001\n",
      "Epoch: 13075, MSE: 0.2412712206086895, Learning Rate: 0.034624999999999996\n",
      "Epoch: 13076, MSE: 0.24126847812849048, Learning Rate: 0.03462\n",
      "Epoch: 13077, MSE: 0.24126573560866071, Learning Rate: 0.034615\n",
      "Epoch: 13078, MSE: 0.24126299304920376, Learning Rate: 0.034609999999999995\n",
      "Epoch: 13079, MSE: 0.2412602504501227, Learning Rate: 0.034605\n",
      "Epoch: 13080, MSE: 0.24125750781142138, Learning Rate: 0.0346\n",
      "Epoch: 13081, MSE: 0.24125476513310334, Learning Rate: 0.034595\n",
      "Epoch: 13082, MSE: 0.24125202241517346, Learning Rate: 0.03459\n",
      "Epoch: 13083, MSE: 0.24124927965763537, Learning Rate: 0.034585\n",
      "Epoch: 13084, MSE: 0.241246536860492, Learning Rate: 0.03458\n",
      "Epoch: 13085, MSE: 0.241243794023747, Learning Rate: 0.034575\n",
      "Epoch: 13086, MSE: 0.24124105114740685, Learning Rate: 0.034570000000000004\n",
      "Epoch: 13087, MSE: 0.24123830823147205, Learning Rate: 0.034565000000000005\n",
      "Epoch: 13088, MSE: 0.24123556527594883, Learning Rate: 0.03456\n",
      "Epoch: 13089, MSE: 0.24123282228083903, Learning Rate: 0.034555\n",
      "Epoch: 13090, MSE: 0.24123007924614756, Learning Rate: 0.034550000000000004\n",
      "Epoch: 13091, MSE: 0.24122733617187797, Learning Rate: 0.034545000000000006\n",
      "Epoch: 13092, MSE: 0.24122459305803412, Learning Rate: 0.03454000000000001\n",
      "Epoch: 13093, MSE: 0.24122184990462006, Learning Rate: 0.034535\n",
      "Epoch: 13094, MSE: 0.24121910671164, Learning Rate: 0.034530000000000005\n",
      "Epoch: 13095, MSE: 0.24121636347909658, Learning Rate: 0.03452499999999999\n",
      "Epoch: 13096, MSE: 0.24121362020699488, Learning Rate: 0.034519999999999995\n",
      "Epoch: 13097, MSE: 0.24121087689533768, Learning Rate: 0.034515\n",
      "Epoch: 13098, MSE: 0.24120813354412973, Learning Rate: 0.03451\n",
      "Epoch: 13099, MSE: 0.24120539015337367, Learning Rate: 0.034505\n",
      "Epoch: 13100, MSE: 0.24120264672307423, Learning Rate: 0.034499999999999996\n",
      "Epoch: 13101, MSE: 0.24119990325323565, Learning Rate: 0.034495\n",
      "Epoch: 13102, MSE: 0.24119715974386108, Learning Rate: 0.03449\n",
      "Epoch: 13103, MSE: 0.24119441619495383, Learning Rate: 0.034485\n",
      "Epoch: 13104, MSE: 0.24119167260651872, Learning Rate: 0.034480000000000004\n",
      "Epoch: 13105, MSE: 0.24118892897855895, Learning Rate: 0.034475\n",
      "Epoch: 13106, MSE: 0.24118618531107958, Learning Rate: 0.03447\n",
      "Epoch: 13107, MSE: 0.24118344160408262, Learning Rate: 0.034465\n",
      "Epoch: 13108, MSE: 0.2411806978575736, Learning Rate: 0.034460000000000005\n",
      "Epoch: 13109, MSE: 0.24117795407155487, Learning Rate: 0.034455000000000006\n",
      "Epoch: 13110, MSE: 0.2411752102460312, Learning Rate: 0.03445\n",
      "Epoch: 13111, MSE: 0.24117246638100634, Learning Rate: 0.034445\n",
      "Epoch: 13112, MSE: 0.24116972247648394, Learning Rate: 0.034440000000000005\n",
      "Epoch: 13113, MSE: 0.24116697853246796, Learning Rate: 0.03443500000000001\n",
      "Epoch: 13114, MSE: 0.241164234548962, Learning Rate: 0.03443000000000001\n",
      "Epoch: 13115, MSE: 0.2411614905259703, Learning Rate: 0.034425\n",
      "Epoch: 13116, MSE: 0.24115874646349697, Learning Rate: 0.03442\n",
      "Epoch: 13117, MSE: 0.24115600236154558, Learning Rate: 0.034414999999999994\n",
      "Epoch: 13118, MSE: 0.24115325822011865, Learning Rate: 0.034409999999999996\n",
      "Epoch: 13119, MSE: 0.24115051403922272, Learning Rate: 0.034405\n",
      "Epoch: 13120, MSE: 0.24114776981885877, Learning Rate: 0.0344\n",
      "Epoch: 13121, MSE: 0.241145025559033, Learning Rate: 0.034395\n",
      "Epoch: 13122, MSE: 0.24114228125974796, Learning Rate: 0.03439\n",
      "Epoch: 13123, MSE: 0.24113953692100842, Learning Rate: 0.034385\n",
      "Epoch: 13124, MSE: 0.2411367925428169, Learning Rate: 0.03438\n",
      "Epoch: 13125, MSE: 0.2411340481251789, Learning Rate: 0.034375\n",
      "Epoch: 13126, MSE: 0.24113130366809624, Learning Rate: 0.034370000000000005\n",
      "Epoch: 13127, MSE: 0.24112855917157477, Learning Rate: 0.034365\n",
      "Epoch: 13128, MSE: 0.24112581463561775, Learning Rate: 0.03436\n",
      "Epoch: 13129, MSE: 0.24112307006022882, Learning Rate: 0.034355000000000004\n",
      "Epoch: 13130, MSE: 0.2411203254454117, Learning Rate: 0.034350000000000006\n",
      "Epoch: 13131, MSE: 0.24111758079117074, Learning Rate: 0.03434500000000001\n",
      "Epoch: 13132, MSE: 0.24111483609750936, Learning Rate: 0.03434\n",
      "Epoch: 13133, MSE: 0.24111209136443185, Learning Rate: 0.034335000000000004\n",
      "Epoch: 13134, MSE: 0.24110934659194128, Learning Rate: 0.034330000000000006\n",
      "Epoch: 13135, MSE: 0.2411066017800429, Learning Rate: 0.03432500000000001\n",
      "Epoch: 13136, MSE: 0.24110385692873915, Learning Rate: 0.034319999999999996\n",
      "Epoch: 13137, MSE: 0.24110111203803464, Learning Rate: 0.034315\n",
      "Epoch: 13138, MSE: 0.24109836710793361, Learning Rate: 0.03431\n",
      "Epoch: 13139, MSE: 0.24109562213843905, Learning Rate: 0.034304999999999995\n",
      "Epoch: 13140, MSE: 0.2410928771295553, Learning Rate: 0.0343\n",
      "Epoch: 13141, MSE: 0.24109013208128652, Learning Rate: 0.034295\n",
      "Epoch: 13142, MSE: 0.241087386993636, Learning Rate: 0.03429\n",
      "Epoch: 13143, MSE: 0.24108464186660852, Learning Rate: 0.034285\n",
      "Epoch: 13144, MSE: 0.24108189670020647, Learning Rate: 0.03428\n",
      "Epoch: 13145, MSE: 0.2410791514944357, Learning Rate: 0.034275\n",
      "Epoch: 13146, MSE: 0.24107640624929821, Learning Rate: 0.03427\n",
      "Epoch: 13147, MSE: 0.2410736609647986, Learning Rate: 0.034265000000000004\n",
      "Epoch: 13148, MSE: 0.24107091564094146, Learning Rate: 0.034260000000000006\n",
      "Epoch: 13149, MSE: 0.2410681702777306, Learning Rate: 0.034255\n",
      "Epoch: 13150, MSE: 0.2410654248751685, Learning Rate: 0.03425\n",
      "Epoch: 13151, MSE: 0.24106267943326012, Learning Rate: 0.034245000000000005\n",
      "Epoch: 13152, MSE: 0.24105993395200925, Learning Rate: 0.03424000000000001\n",
      "Epoch: 13153, MSE: 0.24105718843142032, Learning Rate: 0.03423500000000001\n",
      "Epoch: 13154, MSE: 0.24105444287149616, Learning Rate: 0.034230000000000003\n",
      "Epoch: 13155, MSE: 0.2410516972722409, Learning Rate: 0.034225000000000005\n",
      "Epoch: 13156, MSE: 0.2410489516336597, Learning Rate: 0.034219999999999993\n",
      "Epoch: 13157, MSE: 0.24104620595575493, Learning Rate: 0.034214999999999995\n",
      "Epoch: 13158, MSE: 0.24104346023853068, Learning Rate: 0.03421\n",
      "Epoch: 13159, MSE: 0.24104071448199196, Learning Rate: 0.034205\n",
      "Epoch: 13160, MSE: 0.24103796868614077, Learning Rate: 0.0342\n",
      "Epoch: 13161, MSE: 0.24103522285098336, Learning Rate: 0.034194999999999996\n",
      "Epoch: 13162, MSE: 0.24103247697652214, Learning Rate: 0.03419\n",
      "Epoch: 13163, MSE: 0.24102973106276154, Learning Rate: 0.034185\n",
      "Epoch: 13164, MSE: 0.2410269851097054, Learning Rate: 0.03418\n",
      "Epoch: 13165, MSE: 0.24102423911735768, Learning Rate: 0.034175000000000004\n",
      "Epoch: 13166, MSE: 0.2410214930857214, Learning Rate: 0.03417\n",
      "Epoch: 13167, MSE: 0.24101874701480214, Learning Rate: 0.034165\n",
      "Epoch: 13168, MSE: 0.24101600090460182, Learning Rate: 0.03416\n",
      "Epoch: 13169, MSE: 0.24101325475512644, Learning Rate: 0.034155000000000005\n",
      "Epoch: 13170, MSE: 0.2410105085663785, Learning Rate: 0.03415000000000001\n",
      "Epoch: 13171, MSE: 0.241007762338362, Learning Rate: 0.034145\n",
      "Epoch: 13172, MSE: 0.2410050160710816, Learning Rate: 0.034140000000000004\n",
      "Epoch: 13173, MSE: 0.24100226976454117, Learning Rate: 0.034135000000000006\n",
      "Epoch: 13174, MSE: 0.2409995234187434, Learning Rate: 0.03413000000000001\n",
      "Epoch: 13175, MSE: 0.24099677703369402, Learning Rate: 0.03412500000000001\n",
      "Epoch: 13176, MSE: 0.24099403060939578, Learning Rate: 0.03412\n",
      "Epoch: 13177, MSE: 0.24099128414585266, Learning Rate: 0.034115\n",
      "Epoch: 13178, MSE: 0.24098853764306952, Learning Rate: 0.034109999999999994\n",
      "Epoch: 13179, MSE: 0.24098579110104879, Learning Rate: 0.034104999999999996\n",
      "Epoch: 13180, MSE: 0.24098304451979505, Learning Rate: 0.0341\n",
      "Epoch: 13181, MSE: 0.24098029789931402, Learning Rate: 0.034095\n",
      "Epoch: 13182, MSE: 0.2409775512396063, Learning Rate: 0.03409\n",
      "Epoch: 13183, MSE: 0.24097480454067802, Learning Rate: 0.034085\n",
      "Epoch: 13184, MSE: 0.24097205780253314, Learning Rate: 0.03408\n",
      "Epoch: 13185, MSE: 0.2409693110251747, Learning Rate: 0.034075\n",
      "Epoch: 13186, MSE: 0.24096656420860615, Learning Rate: 0.03407\n",
      "Epoch: 13187, MSE: 0.24096381735283398, Learning Rate: 0.034065000000000005\n",
      "Epoch: 13188, MSE: 0.24096107045785958, Learning Rate: 0.03406\n",
      "Epoch: 13189, MSE: 0.24095832352368812, Learning Rate: 0.034055\n",
      "Epoch: 13190, MSE: 0.24095557655032243, Learning Rate: 0.034050000000000004\n",
      "Epoch: 13191, MSE: 0.24095282953776792, Learning Rate: 0.034045000000000006\n",
      "Epoch: 13192, MSE: 0.24095008248602823, Learning Rate: 0.03404000000000001\n",
      "Epoch: 13193, MSE: 0.24094733539510665, Learning Rate: 0.034035\n",
      "Epoch: 13194, MSE: 0.240944588265007, Learning Rate: 0.034030000000000005\n",
      "Epoch: 13195, MSE: 0.24094184109573438, Learning Rate: 0.03402500000000001\n",
      "Epoch: 13196, MSE: 0.2409390938872912, Learning Rate: 0.034019999999999995\n",
      "Epoch: 13197, MSE: 0.24093634663968283, Learning Rate: 0.034015\n",
      "Epoch: 13198, MSE: 0.24093359935291234, Learning Rate: 0.03401\n",
      "Epoch: 13199, MSE: 0.24093085202698475, Learning Rate: 0.034005\n",
      "Epoch: 13200, MSE: 0.2409281046619019, Learning Rate: 0.033999999999999996\n",
      "Epoch: 13201, MSE: 0.24092535725767023, Learning Rate: 0.033995\n",
      "Epoch: 13202, MSE: 0.24092260981429217, Learning Rate: 0.03399\n",
      "Epoch: 13203, MSE: 0.24091986233177246, Learning Rate: 0.033985\n",
      "Epoch: 13204, MSE: 0.24091711481011419, Learning Rate: 0.03398\n",
      "Epoch: 13205, MSE: 0.24091436724932214, Learning Rate: 0.033975\n",
      "Epoch: 13206, MSE: 0.2409116196493997, Learning Rate: 0.03397\n",
      "Epoch: 13207, MSE: 0.24090887201035135, Learning Rate: 0.033965\n",
      "Epoch: 13208, MSE: 0.24090612433218098, Learning Rate: 0.033960000000000004\n",
      "Epoch: 13209, MSE: 0.24090337661489183, Learning Rate: 0.033955000000000006\n",
      "Epoch: 13210, MSE: 0.24090062885848929, Learning Rate: 0.03395\n",
      "Epoch: 13211, MSE: 0.24089788106297572, Learning Rate: 0.033945\n",
      "Epoch: 13212, MSE: 0.240895133228357, Learning Rate: 0.033940000000000005\n",
      "Epoch: 13213, MSE: 0.24089238535463414, Learning Rate: 0.03393500000000001\n",
      "Epoch: 13214, MSE: 0.24088963744181444, Learning Rate: 0.03393000000000001\n",
      "Epoch: 13215, MSE: 0.24088688948990067, Learning Rate: 0.033925000000000004\n",
      "Epoch: 13216, MSE: 0.24088414149889578, Learning Rate: 0.03392\n",
      "Epoch: 13217, MSE: 0.2408813934688042, Learning Rate: 0.033914999999999994\n",
      "Epoch: 13218, MSE: 0.2408786453996304, Learning Rate: 0.033909999999999996\n",
      "Epoch: 13219, MSE: 0.24087589729137845, Learning Rate: 0.033905\n",
      "Epoch: 13220, MSE: 0.24087314914405245, Learning Rate: 0.0339\n",
      "Epoch: 13221, MSE: 0.2408704009576557, Learning Rate: 0.033895\n",
      "Epoch: 13222, MSE: 0.24086765273219232, Learning Rate: 0.033889999999999997\n",
      "Epoch: 13223, MSE: 0.24086490446766712, Learning Rate: 0.033885\n",
      "Epoch: 13224, MSE: 0.2408621561640824, Learning Rate: 0.03388\n",
      "Epoch: 13225, MSE: 0.2408594078214434, Learning Rate: 0.033875\n",
      "Epoch: 13226, MSE: 0.240856659439755, Learning Rate: 0.033870000000000004\n",
      "Epoch: 13227, MSE: 0.24085391101901943, Learning Rate: 0.033865\n",
      "Epoch: 13228, MSE: 0.24085116255924094, Learning Rate: 0.03386\n",
      "Epoch: 13229, MSE: 0.2408484140604251, Learning Rate: 0.033855\n",
      "Epoch: 13230, MSE: 0.24084566552257414, Learning Rate: 0.033850000000000005\n",
      "Epoch: 13231, MSE: 0.24084291694569265, Learning Rate: 0.03384500000000001\n",
      "Epoch: 13232, MSE: 0.2408401683297847, Learning Rate: 0.03384\n",
      "Epoch: 13233, MSE: 0.2408374196748546, Learning Rate: 0.033835000000000004\n",
      "Epoch: 13234, MSE: 0.2408346709809061, Learning Rate: 0.033830000000000006\n",
      "Epoch: 13235, MSE: 0.2408319222479421, Learning Rate: 0.03382500000000001\n",
      "Epoch: 13236, MSE: 0.2408291734759686, Learning Rate: 0.033819999999999996\n",
      "Epoch: 13237, MSE: 0.2408264246649888, Learning Rate: 0.033815\n",
      "Epoch: 13238, MSE: 0.240823675815006, Learning Rate: 0.03381\n",
      "Epoch: 13239, MSE: 0.24082092692602514, Learning Rate: 0.033804999999999995\n",
      "Epoch: 13240, MSE: 0.24081817799804978, Learning Rate: 0.0338\n",
      "Epoch: 13241, MSE: 0.24081542903108455, Learning Rate: 0.033795\n",
      "Epoch: 13242, MSE: 0.24081268002513226, Learning Rate: 0.03379\n",
      "Epoch: 13243, MSE: 0.24080993098019757, Learning Rate: 0.033785\n",
      "Epoch: 13244, MSE: 0.24080718189628525, Learning Rate: 0.03378\n",
      "Epoch: 13245, MSE: 0.24080443277339766, Learning Rate: 0.033775\n",
      "Epoch: 13246, MSE: 0.2408016836115407, Learning Rate: 0.03377\n",
      "Epoch: 13247, MSE: 0.24079893441071706, Learning Rate: 0.033765\n",
      "Epoch: 13248, MSE: 0.24079618517093088, Learning Rate: 0.033760000000000005\n",
      "Epoch: 13249, MSE: 0.24079343589218774, Learning Rate: 0.033755\n",
      "Epoch: 13250, MSE: 0.24079068657448882, Learning Rate: 0.03375\n",
      "Epoch: 13251, MSE: 0.24078793721784045, Learning Rate: 0.033745000000000004\n",
      "Epoch: 13252, MSE: 0.24078518782224595, Learning Rate: 0.033740000000000006\n",
      "Epoch: 13253, MSE: 0.24078243838770902, Learning Rate: 0.03373500000000001\n",
      "Epoch: 13254, MSE: 0.24077968891423476, Learning Rate: 0.03373\n",
      "Epoch: 13255, MSE: 0.24077693940182607, Learning Rate: 0.033725000000000005\n",
      "Epoch: 13256, MSE: 0.2407741898504879, Learning Rate: 0.03372000000000001\n",
      "Epoch: 13257, MSE: 0.2407714402602224, Learning Rate: 0.033714999999999995\n",
      "Epoch: 13258, MSE: 0.24076869063103717, Learning Rate: 0.03371\n",
      "Epoch: 13259, MSE: 0.24076594096293202, Learning Rate: 0.033705\n",
      "Epoch: 13260, MSE: 0.24076319125591386, Learning Rate: 0.0337\n",
      "Epoch: 13261, MSE: 0.2407604415099856, Learning Rate: 0.033694999999999996\n",
      "Epoch: 13262, MSE: 0.24075769172515246, Learning Rate: 0.03369\n",
      "Epoch: 13263, MSE: 0.24075494190141736, Learning Rate: 0.033685\n",
      "Epoch: 13264, MSE: 0.24075219203878365, Learning Rate: 0.03368\n",
      "Epoch: 13265, MSE: 0.24074944213725746, Learning Rate: 0.033675000000000004\n",
      "Epoch: 13266, MSE: 0.2407466921968415, Learning Rate: 0.03367\n",
      "Epoch: 13267, MSE: 0.24074394221753986, Learning Rate: 0.033665\n",
      "Epoch: 13268, MSE: 0.24074119219935647, Learning Rate: 0.03366\n",
      "Epoch: 13269, MSE: 0.24073844214229556, Learning Rate: 0.033655000000000004\n",
      "Epoch: 13270, MSE: 0.2407356920463618, Learning Rate: 0.033650000000000006\n",
      "Epoch: 13271, MSE: 0.24073294191155906, Learning Rate: 0.033645\n",
      "Epoch: 13272, MSE: 0.24073019173789142, Learning Rate: 0.03364\n",
      "Epoch: 13273, MSE: 0.24072744152536096, Learning Rate: 0.033635000000000005\n",
      "Epoch: 13274, MSE: 0.24072469127397506, Learning Rate: 0.03363000000000001\n",
      "Epoch: 13275, MSE: 0.24072194098373526, Learning Rate: 0.03362500000000001\n",
      "Epoch: 13276, MSE: 0.24071919065464684, Learning Rate: 0.033620000000000004\n",
      "Epoch: 13277, MSE: 0.2407164402867129, Learning Rate: 0.033615\n",
      "Epoch: 13278, MSE: 0.24071368987993894, Learning Rate: 0.033609999999999994\n",
      "Epoch: 13279, MSE: 0.2407109394343275, Learning Rate: 0.033604999999999996\n",
      "Epoch: 13280, MSE: 0.24070818894988383, Learning Rate: 0.0336\n",
      "Epoch: 13281, MSE: 0.24070543842661138, Learning Rate: 0.033595\n",
      "Epoch: 13282, MSE: 0.24070268786451482, Learning Rate: 0.03359\n",
      "Epoch: 13283, MSE: 0.24069993726359745, Learning Rate: 0.033585\n",
      "Epoch: 13284, MSE: 0.24069718662386375, Learning Rate: 0.03358\n",
      "Epoch: 13285, MSE: 0.2406944359453171, Learning Rate: 0.033575\n",
      "Epoch: 13286, MSE: 0.2406916852279626, Learning Rate: 0.03357\n",
      "Epoch: 13287, MSE: 0.24068893447180392, Learning Rate: 0.033565000000000005\n",
      "Epoch: 13288, MSE: 0.24068618367684508, Learning Rate: 0.03356\n",
      "Epoch: 13289, MSE: 0.240683432843091, Learning Rate: 0.033555\n",
      "Epoch: 13290, MSE: 0.24068068197054435, Learning Rate: 0.03355\n",
      "Epoch: 13291, MSE: 0.2406779310592104, Learning Rate: 0.033545000000000005\n",
      "Epoch: 13292, MSE: 0.2406751801090921, Learning Rate: 0.03354000000000001\n",
      "Epoch: 13293, MSE: 0.24067242912019374, Learning Rate: 0.033535\n",
      "Epoch: 13294, MSE: 0.24066967809252057, Learning Rate: 0.033530000000000004\n",
      "Epoch: 13295, MSE: 0.2406669270260757, Learning Rate: 0.033525000000000006\n",
      "Epoch: 13296, MSE: 0.24066417592086373, Learning Rate: 0.03352000000000001\n",
      "Epoch: 13297, MSE: 0.24066142477688812, Learning Rate: 0.033514999999999996\n",
      "Epoch: 13298, MSE: 0.24065867359415305, Learning Rate: 0.03351\n",
      "Epoch: 13299, MSE: 0.24065592237266303, Learning Rate: 0.033505\n",
      "Epoch: 13300, MSE: 0.24065317111242243, Learning Rate: 0.033499999999999995\n",
      "Epoch: 13301, MSE: 0.24065041981343488, Learning Rate: 0.033495\n",
      "Epoch: 13302, MSE: 0.24064766847570415, Learning Rate: 0.03349\n",
      "Epoch: 13303, MSE: 0.24064491709923477, Learning Rate: 0.033485\n",
      "Epoch: 13304, MSE: 0.24064216568403052, Learning Rate: 0.03348\n",
      "Epoch: 13305, MSE: 0.24063941423009658, Learning Rate: 0.033475\n",
      "Epoch: 13306, MSE: 0.24063666273743634, Learning Rate: 0.03347\n",
      "Epoch: 13307, MSE: 0.24063391120605285, Learning Rate: 0.033465\n",
      "Epoch: 13308, MSE: 0.24063115963595139, Learning Rate: 0.033460000000000004\n",
      "Epoch: 13309, MSE: 0.2406284080271367, Learning Rate: 0.033455000000000006\n",
      "Epoch: 13310, MSE: 0.24062565637961172, Learning Rate: 0.03345\n",
      "Epoch: 13311, MSE: 0.24062290469338043, Learning Rate: 0.033445\n",
      "Epoch: 13312, MSE: 0.24062015296844774, Learning Rate: 0.033440000000000004\n",
      "Epoch: 13313, MSE: 0.24061740120481753, Learning Rate: 0.033435000000000006\n",
      "Epoch: 13314, MSE: 0.2406146494024937, Learning Rate: 0.03343000000000001\n",
      "Epoch: 13315, MSE: 0.24061189756148102, Learning Rate: 0.033425\n",
      "Epoch: 13316, MSE: 0.24060914568178274, Learning Rate: 0.033420000000000005\n",
      "Epoch: 13317, MSE: 0.24060639376340331, Learning Rate: 0.03341499999999999\n",
      "Epoch: 13318, MSE: 0.2406036418063462, Learning Rate: 0.033409999999999995\n",
      "Epoch: 13319, MSE: 0.24060088981061764, Learning Rate: 0.033405\n",
      "Epoch: 13320, MSE: 0.24059813777622008, Learning Rate: 0.0334\n",
      "Epoch: 13321, MSE: 0.24059538570315697, Learning Rate: 0.033395\n",
      "Epoch: 13322, MSE: 0.24059263359143396, Learning Rate: 0.033389999999999996\n",
      "Epoch: 13323, MSE: 0.24058988144105428, Learning Rate: 0.033385\n",
      "Epoch: 13324, MSE: 0.24058712925202339, Learning Rate: 0.03338\n",
      "Epoch: 13325, MSE: 0.2405843770243432, Learning Rate: 0.033375\n",
      "Epoch: 13326, MSE: 0.24058162475802003, Learning Rate: 0.033370000000000004\n",
      "Epoch: 13327, MSE: 0.24057887245305645, Learning Rate: 0.033365\n",
      "Epoch: 13328, MSE: 0.24057612010945703, Learning Rate: 0.03336\n",
      "Epoch: 13329, MSE: 0.24057336772722707, Learning Rate: 0.033355\n",
      "Epoch: 13330, MSE: 0.24057061530636956, Learning Rate: 0.033350000000000005\n",
      "Epoch: 13331, MSE: 0.2405678628468888, Learning Rate: 0.03334500000000001\n",
      "Epoch: 13332, MSE: 0.240565110348788, Learning Rate: 0.03334\n",
      "Epoch: 13333, MSE: 0.24056235781207363, Learning Rate: 0.033335000000000004\n",
      "Epoch: 13334, MSE: 0.24055960523674735, Learning Rate: 0.033330000000000005\n",
      "Epoch: 13335, MSE: 0.24055685262281498, Learning Rate: 0.03332500000000001\n",
      "Epoch: 13336, MSE: 0.24055409997028002, Learning Rate: 0.03332000000000001\n",
      "Epoch: 13337, MSE: 0.2405513472791466, Learning Rate: 0.033315\n",
      "Epoch: 13338, MSE: 0.24054859454941901, Learning Rate: 0.03331\n",
      "Epoch: 13339, MSE: 0.24054584178110144, Learning Rate: 0.033304999999999994\n",
      "Epoch: 13340, MSE: 0.24054308897419802, Learning Rate: 0.033299999999999996\n",
      "Epoch: 13341, MSE: 0.2405403361287134, Learning Rate: 0.033295\n",
      "Epoch: 13342, MSE: 0.24053758324465066, Learning Rate: 0.03329\n",
      "Epoch: 13343, MSE: 0.24053483032201423, Learning Rate: 0.033285\n",
      "Epoch: 13344, MSE: 0.2405320773608094, Learning Rate: 0.03328\n",
      "Epoch: 13345, MSE: 0.24052932436103894, Learning Rate: 0.033275\n",
      "Epoch: 13346, MSE: 0.24052657132270833, Learning Rate: 0.03327\n",
      "Epoch: 13347, MSE: 0.2405238182458199, Learning Rate: 0.033265\n",
      "Epoch: 13348, MSE: 0.24052106513037969, Learning Rate: 0.033260000000000005\n",
      "Epoch: 13349, MSE: 0.24051831197639112, Learning Rate: 0.033255\n",
      "Epoch: 13350, MSE: 0.2405155587838585, Learning Rate: 0.03325\n",
      "Epoch: 13351, MSE: 0.24051280555278481, Learning Rate: 0.033245000000000004\n",
      "Epoch: 13352, MSE: 0.24051005228317654, Learning Rate: 0.033240000000000006\n",
      "Epoch: 13353, MSE: 0.2405072989750358, Learning Rate: 0.03323500000000001\n",
      "Epoch: 13354, MSE: 0.24050454562836837, Learning Rate: 0.03323\n",
      "Epoch: 13355, MSE: 0.24050179224317664, Learning Rate: 0.033225000000000005\n",
      "Epoch: 13356, MSE: 0.2404990388194661, Learning Rate: 0.033220000000000006\n",
      "Epoch: 13357, MSE: 0.2404962853572403, Learning Rate: 0.033214999999999995\n",
      "Epoch: 13358, MSE: 0.24049353185650404, Learning Rate: 0.033209999999999996\n",
      "Epoch: 13359, MSE: 0.24049077831726184, Learning Rate: 0.033205\n",
      "Epoch: 13360, MSE: 0.24048802473951655, Learning Rate: 0.0332\n",
      "Epoch: 13361, MSE: 0.24048527112327342, Learning Rate: 0.033194999999999995\n",
      "Epoch: 13362, MSE: 0.24048251746853622, Learning Rate: 0.03319\n",
      "Epoch: 13363, MSE: 0.2404797637753085, Learning Rate: 0.033185\n",
      "Epoch: 13364, MSE: 0.24047701004359603, Learning Rate: 0.03318\n",
      "Epoch: 13365, MSE: 0.2404742562734024, Learning Rate: 0.033175\n",
      "Epoch: 13366, MSE: 0.24047150246473023, Learning Rate: 0.03317\n",
      "Epoch: 13367, MSE: 0.24046874861758624, Learning Rate: 0.033165\n",
      "Epoch: 13368, MSE: 0.2404659947319732, Learning Rate: 0.03316\n",
      "Epoch: 13369, MSE: 0.24046324080789472, Learning Rate: 0.033155000000000004\n",
      "Epoch: 13370, MSE: 0.2404604868453566, Learning Rate: 0.033150000000000006\n",
      "Epoch: 13371, MSE: 0.24045773284436153, Learning Rate: 0.033145\n",
      "Epoch: 13372, MSE: 0.24045497880491537, Learning Rate: 0.03314\n",
      "Epoch: 13373, MSE: 0.24045222472702127, Learning Rate: 0.033135000000000005\n",
      "Epoch: 13374, MSE: 0.2404494706106834, Learning Rate: 0.03313000000000001\n",
      "Epoch: 13375, MSE: 0.24044671645590537, Learning Rate: 0.03312500000000001\n",
      "Epoch: 13376, MSE: 0.24044396226269302, Learning Rate: 0.033120000000000004\n",
      "Epoch: 13377, MSE: 0.24044120803104976, Learning Rate: 0.033115000000000006\n",
      "Epoch: 13378, MSE: 0.24043845376097947, Learning Rate: 0.033109999999999994\n",
      "Epoch: 13379, MSE: 0.24043569945248588, Learning Rate: 0.033104999999999996\n",
      "Epoch: 13380, MSE: 0.24043294510557534, Learning Rate: 0.0331\n",
      "Epoch: 13381, MSE: 0.24043019072024974, Learning Rate: 0.033095\n",
      "Epoch: 13382, MSE: 0.24042743629651495, Learning Rate: 0.03309\n",
      "Epoch: 13383, MSE: 0.24042468183437435, Learning Rate: 0.033084999999999996\n",
      "Epoch: 13384, MSE: 0.24042192733383216, Learning Rate: 0.03308\n",
      "Epoch: 13385, MSE: 0.24041917279489278, Learning Rate: 0.033075\n",
      "Epoch: 13386, MSE: 0.24041641821756013, Learning Rate: 0.03307\n",
      "Epoch: 13387, MSE: 0.24041366360183894, Learning Rate: 0.033065000000000004\n",
      "Epoch: 13388, MSE: 0.24041090894773365, Learning Rate: 0.03306\n",
      "Epoch: 13389, MSE: 0.24040815425524786, Learning Rate: 0.033055\n",
      "Epoch: 13390, MSE: 0.24040539952438642, Learning Rate: 0.03305\n",
      "Epoch: 13391, MSE: 0.2404026447551527, Learning Rate: 0.033045000000000005\n",
      "Epoch: 13392, MSE: 0.24039988994755124, Learning Rate: 0.03304000000000001\n",
      "Epoch: 13393, MSE: 0.24039713510158628, Learning Rate: 0.033035\n",
      "Epoch: 13394, MSE: 0.24039438021726334, Learning Rate: 0.033030000000000004\n",
      "Epoch: 13395, MSE: 0.24039162529458424, Learning Rate: 0.033025000000000006\n",
      "Epoch: 13396, MSE: 0.24038887033355527, Learning Rate: 0.03302000000000001\n",
      "Epoch: 13397, MSE: 0.24038611533417995, Learning Rate: 0.03301500000000001\n",
      "Epoch: 13398, MSE: 0.24038336029646265, Learning Rate: 0.03301\n",
      "Epoch: 13399, MSE: 0.2403806052204067, Learning Rate: 0.033005\n",
      "Epoch: 13400, MSE: 0.24037785010601778, Learning Rate: 0.032999999999999995\n",
      "Epoch: 13401, MSE: 0.24037509495329992, Learning Rate: 0.032995\n",
      "Epoch: 13402, MSE: 0.24037233976225642, Learning Rate: 0.03299\n",
      "Epoch: 13403, MSE: 0.2403695845328921, Learning Rate: 0.032985\n",
      "Epoch: 13404, MSE: 0.24036682926521147, Learning Rate: 0.03298\n",
      "Epoch: 13405, MSE: 0.24036407395921788, Learning Rate: 0.032975\n",
      "Epoch: 13406, MSE: 0.24036131861491636, Learning Rate: 0.03297\n",
      "Epoch: 13407, MSE: 0.24035856323231128, Learning Rate: 0.032965\n",
      "Epoch: 13408, MSE: 0.24035580781140675, Learning Rate: 0.03296\n",
      "Epoch: 13409, MSE: 0.24035305235220694, Learning Rate: 0.032955000000000005\n",
      "Epoch: 13410, MSE: 0.24035029685471546, Learning Rate: 0.03295\n",
      "Epoch: 13411, MSE: 0.2403475413189383, Learning Rate: 0.032945\n",
      "Epoch: 13412, MSE: 0.24034478574487822, Learning Rate: 0.032940000000000004\n",
      "Epoch: 13413, MSE: 0.24034203013254019, Learning Rate: 0.032935000000000006\n",
      "Epoch: 13414, MSE: 0.24033927448192768, Learning Rate: 0.03293000000000001\n",
      "Epoch: 13415, MSE: 0.2403365187930456, Learning Rate: 0.032925\n",
      "Epoch: 13416, MSE: 0.24033376306589824, Learning Rate: 0.032920000000000005\n",
      "Epoch: 13417, MSE: 0.2403310073004898, Learning Rate: 0.03291500000000001\n",
      "Epoch: 13418, MSE: 0.2403282514968246, Learning Rate: 0.032909999999999995\n",
      "Epoch: 13419, MSE: 0.24032549565490693, Learning Rate: 0.032905\n",
      "Epoch: 13420, MSE: 0.240322739774741, Learning Rate: 0.0329\n",
      "Epoch: 13421, MSE: 0.24031998385633016, Learning Rate: 0.032895\n",
      "Epoch: 13422, MSE: 0.24031722789968107, Learning Rate: 0.032889999999999996\n",
      "Epoch: 13423, MSE: 0.24031447190479563, Learning Rate: 0.032885\n",
      "Epoch: 13424, MSE: 0.24031171587167943, Learning Rate: 0.03288\n",
      "Epoch: 13425, MSE: 0.240308959800336, Learning Rate: 0.032875\n",
      "Epoch: 13426, MSE: 0.24030620369077, Learning Rate: 0.03287\n",
      "Epoch: 13427, MSE: 0.2403034475429866, Learning Rate: 0.032865\n",
      "Epoch: 13428, MSE: 0.2403006913569887, Learning Rate: 0.03286\n",
      "Epoch: 13429, MSE: 0.2402979351327819, Learning Rate: 0.032855\n",
      "Epoch: 13430, MSE: 0.24029517887036778, Learning Rate: 0.032850000000000004\n",
      "Epoch: 13431, MSE: 0.24029242256975453, Learning Rate: 0.032845000000000006\n",
      "Epoch: 13432, MSE: 0.24028966623094383, Learning Rate: 0.03284\n",
      "Epoch: 13433, MSE: 0.2402869098539398, Learning Rate: 0.032835\n",
      "Epoch: 13434, MSE: 0.24028415343874918, Learning Rate: 0.032830000000000005\n",
      "Epoch: 13435, MSE: 0.24028139698537393, Learning Rate: 0.03282500000000001\n",
      "Epoch: 13436, MSE: 0.2402786404938196, Learning Rate: 0.03282000000000001\n",
      "Epoch: 13437, MSE: 0.24027588396408964, Learning Rate: 0.032815000000000004\n",
      "Epoch: 13438, MSE: 0.24027312739618883, Learning Rate: 0.03281\n",
      "Epoch: 13439, MSE: 0.2402703707901215, Learning Rate: 0.032804999999999994\n",
      "Epoch: 13440, MSE: 0.24026761414589204, Learning Rate: 0.032799999999999996\n",
      "Epoch: 13441, MSE: 0.24026485746350457, Learning Rate: 0.032795\n",
      "Epoch: 13442, MSE: 0.24026210074296303, Learning Rate: 0.03279\n",
      "Epoch: 13443, MSE: 0.24025934398427282, Learning Rate: 0.032785\n",
      "Epoch: 13444, MSE: 0.240256587187437, Learning Rate: 0.03278\n",
      "Epoch: 13445, MSE: 0.24025383035246062, Learning Rate: 0.032775\n",
      "Epoch: 13446, MSE: 0.24025107347934838, Learning Rate: 0.03277\n",
      "Epoch: 13447, MSE: 0.24024831656810372, Learning Rate: 0.032765\n",
      "Epoch: 13448, MSE: 0.24024555961873179, Learning Rate: 0.032760000000000004\n",
      "Epoch: 13449, MSE: 0.24024280263123596, Learning Rate: 0.032755\n",
      "Epoch: 13450, MSE: 0.240240045605621, Learning Rate: 0.03275\n",
      "Epoch: 13451, MSE: 0.2402372885418917, Learning Rate: 0.032745\n",
      "Epoch: 13452, MSE: 0.24023453144005202, Learning Rate: 0.032740000000000005\n",
      "Epoch: 13453, MSE: 0.24023177430010637, Learning Rate: 0.03273500000000001\n",
      "Epoch: 13454, MSE: 0.24022901712205874, Learning Rate: 0.03273\n",
      "Epoch: 13455, MSE: 0.24022625990591404, Learning Rate: 0.032725000000000004\n",
      "Epoch: 13456, MSE: 0.24022350265167636, Learning Rate: 0.032720000000000006\n",
      "Epoch: 13457, MSE: 0.2402207453593497, Learning Rate: 0.03271500000000001\n",
      "Epoch: 13458, MSE: 0.2402179880289389, Learning Rate: 0.032709999999999996\n",
      "Epoch: 13459, MSE: 0.24021523066044873, Learning Rate: 0.032705\n",
      "Epoch: 13460, MSE: 0.2402124732538822, Learning Rate: 0.0327\n",
      "Epoch: 13461, MSE: 0.2402097158092438, Learning Rate: 0.032694999999999995\n",
      "Epoch: 13462, MSE: 0.24020695832653952, Learning Rate: 0.03269\n",
      "Epoch: 13463, MSE: 0.2402042008057728, Learning Rate: 0.032685\n",
      "Epoch: 13464, MSE: 0.24020144324694684, Learning Rate: 0.03268\n",
      "Epoch: 13465, MSE: 0.2401986856500681, Learning Rate: 0.032675\n",
      "Epoch: 13466, MSE: 0.2401959280151389, Learning Rate: 0.03267\n",
      "Epoch: 13467, MSE: 0.24019317034216472, Learning Rate: 0.032665\n",
      "Epoch: 13468, MSE: 0.24019041263115032, Learning Rate: 0.03266\n",
      "Epoch: 13469, MSE: 0.24018765488209934, Learning Rate: 0.032655\n",
      "Epoch: 13470, MSE: 0.24018489709501625, Learning Rate: 0.032650000000000005\n",
      "Epoch: 13471, MSE: 0.24018213926990525, Learning Rate: 0.032645\n",
      "Epoch: 13472, MSE: 0.24017938140677123, Learning Rate: 0.03264\n",
      "Epoch: 13473, MSE: 0.2401766235056182, Learning Rate: 0.032635000000000004\n",
      "Epoch: 13474, MSE: 0.24017386556645057, Learning Rate: 0.032630000000000006\n",
      "Epoch: 13475, MSE: 0.24017110758927315, Learning Rate: 0.03262500000000001\n",
      "Epoch: 13476, MSE: 0.2401683495740893, Learning Rate: 0.03262\n",
      "Epoch: 13477, MSE: 0.24016559152090383, Learning Rate: 0.032615000000000005\n",
      "Epoch: 13478, MSE: 0.24016283342972194, Learning Rate: 0.03260999999999999\n",
      "Epoch: 13479, MSE: 0.24016007530054762, Learning Rate: 0.032604999999999995\n",
      "Epoch: 13480, MSE: 0.24015731713338404, Learning Rate: 0.0326\n",
      "Epoch: 13481, MSE: 0.24015455892823656, Learning Rate: 0.032595\n",
      "Epoch: 13482, MSE: 0.24015180068511047, Learning Rate: 0.03259\n",
      "Epoch: 13483, MSE: 0.2401490424040084, Learning Rate: 0.032584999999999996\n",
      "Epoch: 13484, MSE: 0.2401462840849363, Learning Rate: 0.03258\n",
      "Epoch: 13485, MSE: 0.24014352572789702, Learning Rate: 0.032575\n",
      "Epoch: 13486, MSE: 0.2401407673328965, Learning Rate: 0.03257\n",
      "Epoch: 13487, MSE: 0.24013800889993786, Learning Rate: 0.032565000000000004\n",
      "Epoch: 13488, MSE: 0.24013525042902642, Learning Rate: 0.03256\n",
      "Epoch: 13489, MSE: 0.24013249192016642, Learning Rate: 0.032555\n",
      "Epoch: 13490, MSE: 0.24012973337336205, Learning Rate: 0.03255\n",
      "Epoch: 13491, MSE: 0.24012697478861686, Learning Rate: 0.032545000000000004\n",
      "Epoch: 13492, MSE: 0.24012421616593638, Learning Rate: 0.032540000000000006\n",
      "Epoch: 13493, MSE: 0.24012145750532476, Learning Rate: 0.032535\n",
      "Epoch: 13494, MSE: 0.24011869880678632, Learning Rate: 0.03253\n",
      "Epoch: 13495, MSE: 0.2401159400703261, Learning Rate: 0.032525000000000005\n",
      "Epoch: 13496, MSE: 0.2401131812959476, Learning Rate: 0.03252000000000001\n",
      "Epoch: 13497, MSE: 0.2401104224836555, Learning Rate: 0.03251500000000001\n",
      "Epoch: 13498, MSE: 0.2401076636334545, Learning Rate: 0.03251\n",
      "Epoch: 13499, MSE: 0.24010490474534799, Learning Rate: 0.032505\n",
      "Epoch: 13500, MSE: 0.24010214581934197, Learning Rate: 0.032499999999999994\n",
      "Epoch: 13501, MSE: 0.24009938685544016, Learning Rate: 0.032494999999999996\n",
      "Epoch: 13502, MSE: 0.24009662785364647, Learning Rate: 0.03249\n",
      "Epoch: 13503, MSE: 0.24009386881396613, Learning Rate: 0.032485\n",
      "Epoch: 13504, MSE: 0.24009110973640282, Learning Rate: 0.03248\n",
      "Epoch: 13505, MSE: 0.2400883506209619, Learning Rate: 0.032475\n",
      "Epoch: 13506, MSE: 0.24008559146764644, Learning Rate: 0.03247\n",
      "Epoch: 13507, MSE: 0.24008283227646163, Learning Rate: 0.032465\n",
      "Epoch: 13508, MSE: 0.24008007304741283, Learning Rate: 0.03246\n",
      "Epoch: 13509, MSE: 0.24007731378050293, Learning Rate: 0.032455000000000005\n",
      "Epoch: 13510, MSE: 0.2400745544757371, Learning Rate: 0.03245\n",
      "Epoch: 13511, MSE: 0.2400717951331197, Learning Rate: 0.032445\n",
      "Epoch: 13512, MSE: 0.2400690357526554, Learning Rate: 0.032440000000000004\n",
      "Epoch: 13513, MSE: 0.24006627633434796, Learning Rate: 0.032435000000000005\n",
      "Epoch: 13514, MSE: 0.2400635168782024, Learning Rate: 0.03243000000000001\n",
      "Epoch: 13515, MSE: 0.24006075738422294, Learning Rate: 0.032425\n",
      "Epoch: 13516, MSE: 0.24005799785241438, Learning Rate: 0.032420000000000004\n",
      "Epoch: 13517, MSE: 0.24005523828278097, Learning Rate: 0.032415000000000006\n",
      "Epoch: 13518, MSE: 0.24005247867532684, Learning Rate: 0.03241000000000001\n",
      "Epoch: 13519, MSE: 0.24004971903005648, Learning Rate: 0.032404999999999996\n",
      "Epoch: 13520, MSE: 0.24004695934697518, Learning Rate: 0.0324\n",
      "Epoch: 13521, MSE: 0.24004419962608672, Learning Rate: 0.032395\n",
      "Epoch: 13522, MSE: 0.24004143986739476, Learning Rate: 0.032389999999999995\n",
      "Epoch: 13523, MSE: 0.24003868007090526, Learning Rate: 0.032385\n",
      "Epoch: 13524, MSE: 0.24003592023662182, Learning Rate: 0.03238\n",
      "Epoch: 13525, MSE: 0.24003316036454878, Learning Rate: 0.032375\n",
      "Epoch: 13526, MSE: 0.2400304004546916, Learning Rate: 0.03237\n",
      "Epoch: 13527, MSE: 0.24002764050705275, Learning Rate: 0.032365\n",
      "Epoch: 13528, MSE: 0.24002488052163895, Learning Rate: 0.03236\n",
      "Epoch: 13529, MSE: 0.24002212049845456, Learning Rate: 0.032355\n",
      "Epoch: 13530, MSE: 0.24001936043750208, Learning Rate: 0.032350000000000004\n",
      "Epoch: 13531, MSE: 0.24001660033878752, Learning Rate: 0.032345000000000006\n",
      "Epoch: 13532, MSE: 0.2400138402023148, Learning Rate: 0.03234\n",
      "Epoch: 13533, MSE: 0.24001108002808863, Learning Rate: 0.032335\n",
      "Epoch: 13534, MSE: 0.2400083198161132, Learning Rate: 0.032330000000000005\n",
      "Epoch: 13535, MSE: 0.240005559566393, Learning Rate: 0.032325000000000007\n",
      "Epoch: 13536, MSE: 0.24000279927893292, Learning Rate: 0.03232000000000001\n",
      "Epoch: 13537, MSE: 0.24000003895373762, Learning Rate: 0.032315\n",
      "Epoch: 13538, MSE: 0.23999727859081113, Learning Rate: 0.032310000000000005\n",
      "Epoch: 13539, MSE: 0.23999451819015746, Learning Rate: 0.03230499999999999\n",
      "Epoch: 13540, MSE: 0.23999175775178233, Learning Rate: 0.032299999999999995\n",
      "Epoch: 13541, MSE: 0.23998899727568893, Learning Rate: 0.032295\n",
      "Epoch: 13542, MSE: 0.23998623676188272, Learning Rate: 0.03229\n",
      "Epoch: 13543, MSE: 0.23998347621036786, Learning Rate: 0.032285\n",
      "Epoch: 13544, MSE: 0.2399807156211484, Learning Rate: 0.032279999999999996\n",
      "Epoch: 13545, MSE: 0.23997795499422997, Learning Rate: 0.032275\n",
      "Epoch: 13546, MSE: 0.23997519432961614, Learning Rate: 0.03227\n",
      "Epoch: 13547, MSE: 0.23997243362731055, Learning Rate: 0.032265\n",
      "Epoch: 13548, MSE: 0.23996967288732002, Learning Rate: 0.032260000000000004\n",
      "Epoch: 13549, MSE: 0.23996691210964727, Learning Rate: 0.032255\n",
      "Epoch: 13550, MSE: 0.23996415129429757, Learning Rate: 0.03225\n",
      "Epoch: 13551, MSE: 0.2399613904412756, Learning Rate: 0.032245\n",
      "Epoch: 13552, MSE: 0.2399586295505845, Learning Rate: 0.032240000000000005\n",
      "Epoch: 13553, MSE: 0.2399558686222308, Learning Rate: 0.03223500000000001\n",
      "Epoch: 13554, MSE: 0.23995310765621722, Learning Rate: 0.03223\n",
      "Epoch: 13555, MSE: 0.23995034665254897, Learning Rate: 0.032225000000000004\n",
      "Epoch: 13556, MSE: 0.2399475856112311, Learning Rate: 0.032220000000000006\n",
      "Epoch: 13557, MSE: 0.23994482453226787, Learning Rate: 0.03221500000000001\n",
      "Epoch: 13558, MSE: 0.23994206341566288, Learning Rate: 0.03221000000000001\n",
      "Epoch: 13559, MSE: 0.23993930226142235, Learning Rate: 0.032205\n",
      "Epoch: 13560, MSE: 0.23993654106954912, Learning Rate: 0.0322\n",
      "Epoch: 13561, MSE: 0.23993377984004818, Learning Rate: 0.032194999999999994\n",
      "Epoch: 13562, MSE: 0.23993101857292481, Learning Rate: 0.032189999999999996\n",
      "Epoch: 13563, MSE: 0.23992825726818295, Learning Rate: 0.032185\n",
      "Epoch: 13564, MSE: 0.23992549592582635, Learning Rate: 0.03218\n",
      "Epoch: 13565, MSE: 0.23992273454586174, Learning Rate: 0.032175\n",
      "Epoch: 13566, MSE: 0.2399199731282918, Learning Rate: 0.03217\n",
      "Epoch: 13567, MSE: 0.2399172116731218, Learning Rate: 0.032165\n",
      "Epoch: 13568, MSE: 0.2399144501803557, Learning Rate: 0.03216\n",
      "Epoch: 13569, MSE: 0.23991168864999804, Learning Rate: 0.032155\n",
      "Epoch: 13570, MSE: 0.23990892708205444, Learning Rate: 0.032150000000000005\n",
      "Epoch: 13571, MSE: 0.2399061654765283, Learning Rate: 0.032145\n",
      "Epoch: 13572, MSE: 0.23990340383342515, Learning Rate: 0.03214\n",
      "Epoch: 13573, MSE: 0.23990064215274928, Learning Rate: 0.032135000000000004\n",
      "Epoch: 13574, MSE: 0.2398978804345037, Learning Rate: 0.032130000000000006\n",
      "Epoch: 13575, MSE: 0.23989511867869537, Learning Rate: 0.03212500000000001\n",
      "Epoch: 13576, MSE: 0.23989235688532698, Learning Rate: 0.03212\n",
      "Epoch: 13577, MSE: 0.2398895950544038, Learning Rate: 0.032115000000000005\n",
      "Epoch: 13578, MSE: 0.23988683318593101, Learning Rate: 0.03211000000000001\n",
      "Epoch: 13579, MSE: 0.23988407127991232, Learning Rate: 0.032104999999999995\n",
      "Epoch: 13580, MSE: 0.23988130933635202, Learning Rate: 0.0321\n",
      "Epoch: 13581, MSE: 0.2398785473552556, Learning Rate: 0.032095\n",
      "Epoch: 13582, MSE: 0.23987578533662712, Learning Rate: 0.03209\n",
      "Epoch: 13583, MSE: 0.23987302328047114, Learning Rate: 0.032084999999999995\n",
      "Epoch: 13584, MSE: 0.23987026118679267, Learning Rate: 0.03208\n",
      "Epoch: 13585, MSE: 0.2398674990555957, Learning Rate: 0.032075\n",
      "Epoch: 13586, MSE: 0.23986473688688553, Learning Rate: 0.03207\n",
      "Epoch: 13587, MSE: 0.23986197468066534, Learning Rate: 0.032065\n",
      "Epoch: 13588, MSE: 0.23985921243694183, Learning Rate: 0.03206\n",
      "Epoch: 13589, MSE: 0.23985645015571683, Learning Rate: 0.032055\n",
      "Epoch: 13590, MSE: 0.2398536878369976, Learning Rate: 0.03205\n",
      "Epoch: 13591, MSE: 0.23985092548078774, Learning Rate: 0.032045000000000004\n",
      "Epoch: 13592, MSE: 0.23984816308709087, Learning Rate: 0.032040000000000006\n",
      "Epoch: 13593, MSE: 0.23984540065591312, Learning Rate: 0.032035\n",
      "Epoch: 13594, MSE: 0.239842638187257, Learning Rate: 0.03203\n",
      "Epoch: 13595, MSE: 0.2398398756811297, Learning Rate: 0.032025000000000005\n",
      "Epoch: 13596, MSE: 0.23983711313753467, Learning Rate: 0.03202000000000001\n",
      "Epoch: 13597, MSE: 0.23983435055647565, Learning Rate: 0.03201500000000001\n",
      "Epoch: 13598, MSE: 0.23983158793795856, Learning Rate: 0.032010000000000004\n",
      "Epoch: 13599, MSE: 0.23982882528198707, Learning Rate: 0.032005\n",
      "Epoch: 13600, MSE: 0.2398260625885663, Learning Rate: 0.031999999999999994\n",
      "Epoch: 13601, MSE: 0.23982329985770096, Learning Rate: 0.031994999999999996\n",
      "Epoch: 13602, MSE: 0.23982053708939496, Learning Rate: 0.03199\n",
      "Epoch: 13603, MSE: 0.23981777428365342, Learning Rate: 0.031985\n",
      "Epoch: 13604, MSE: 0.2398150114404808, Learning Rate: 0.03198\n",
      "Epoch: 13605, MSE: 0.23981224855988179, Learning Rate: 0.031974999999999996\n",
      "Epoch: 13606, MSE: 0.23980948564186114, Learning Rate: 0.03197\n",
      "Epoch: 13607, MSE: 0.23980672268642347, Learning Rate: 0.031965\n",
      "Epoch: 13608, MSE: 0.23980395969357302, Learning Rate: 0.03196\n",
      "Epoch: 13609, MSE: 0.23980119666331445, Learning Rate: 0.031955000000000004\n",
      "Epoch: 13610, MSE: 0.23979843359565245, Learning Rate: 0.03195\n",
      "Epoch: 13611, MSE: 0.23979567049059236, Learning Rate: 0.031945\n",
      "Epoch: 13612, MSE: 0.23979290734813813, Learning Rate: 0.03194\n",
      "Epoch: 13613, MSE: 0.23979014416829345, Learning Rate: 0.031935000000000005\n",
      "Epoch: 13614, MSE: 0.239787380951065, Learning Rate: 0.03193000000000001\n",
      "Epoch: 13615, MSE: 0.2397846176964559, Learning Rate: 0.031925\n",
      "Epoch: 13616, MSE: 0.2397818544044711, Learning Rate: 0.031920000000000004\n",
      "Epoch: 13617, MSE: 0.23977909107511516, Learning Rate: 0.031915000000000006\n",
      "Epoch: 13618, MSE: 0.23977632770839374, Learning Rate: 0.03191000000000001\n",
      "Epoch: 13619, MSE: 0.23977356430430977, Learning Rate: 0.031904999999999996\n",
      "Epoch: 13620, MSE: 0.23977080086286964, Learning Rate: 0.0319\n",
      "Epoch: 13621, MSE: 0.23976803738407682, Learning Rate: 0.031895\n",
      "Epoch: 13622, MSE: 0.2397652738679363, Learning Rate: 0.031889999999999995\n",
      "Epoch: 13623, MSE: 0.23976251031445278, Learning Rate: 0.031885\n",
      "Epoch: 13624, MSE: 0.23975974672363054, Learning Rate: 0.03188\n",
      "Epoch: 13625, MSE: 0.23975698309547455, Learning Rate: 0.031875\n",
      "Epoch: 13626, MSE: 0.23975421942998928, Learning Rate: 0.03187\n",
      "Epoch: 13627, MSE: 0.2397514557271801, Learning Rate: 0.031865\n",
      "Epoch: 13628, MSE: 0.23974869198705043, Learning Rate: 0.03186\n",
      "Epoch: 13629, MSE: 0.2397459282096061, Learning Rate: 0.031855\n",
      "Epoch: 13630, MSE: 0.2397431643948512, Learning Rate: 0.03185\n",
      "Epoch: 13631, MSE: 0.23974040054279003, Learning Rate: 0.031845000000000005\n",
      "Epoch: 13632, MSE: 0.23973763665342798, Learning Rate: 0.03184\n",
      "Epoch: 13633, MSE: 0.23973487272676977, Learning Rate: 0.031835\n",
      "Epoch: 13634, MSE: 0.23973210876281908, Learning Rate: 0.031830000000000004\n",
      "Epoch: 13635, MSE: 0.23972934476158195, Learning Rate: 0.031825000000000006\n",
      "Epoch: 13636, MSE: 0.2397265807230618, Learning Rate: 0.03182000000000001\n",
      "Epoch: 13637, MSE: 0.23972381664726397, Learning Rate: 0.031815\n",
      "Epoch: 13638, MSE: 0.2397210525341929, Learning Rate: 0.031810000000000005\n",
      "Epoch: 13639, MSE: 0.23971828838385298, Learning Rate: 0.03180500000000001\n",
      "Epoch: 13640, MSE: 0.2397155241962495, Learning Rate: 0.031799999999999995\n",
      "Epoch: 13641, MSE: 0.23971275997138722, Learning Rate: 0.031795\n",
      "Epoch: 13642, MSE: 0.2397099957092704, Learning Rate: 0.03179\n",
      "Epoch: 13643, MSE: 0.23970723140990374, Learning Rate: 0.031785\n",
      "Epoch: 13644, MSE: 0.23970446707329146, Learning Rate: 0.031779999999999996\n",
      "Epoch: 13645, MSE: 0.23970170269943997, Learning Rate: 0.031775\n",
      "Epoch: 13646, MSE: 0.23969893828835204, Learning Rate: 0.03177\n",
      "Epoch: 13647, MSE: 0.23969617384003314, Learning Rate: 0.031765\n",
      "Epoch: 13648, MSE: 0.23969340935448816, Learning Rate: 0.031760000000000004\n",
      "Epoch: 13649, MSE: 0.2396906448317215, Learning Rate: 0.031755\n",
      "Epoch: 13650, MSE: 0.239687880271738, Learning Rate: 0.03175\n",
      "Epoch: 13651, MSE: 0.23968511567454212, Learning Rate: 0.031745\n",
      "Epoch: 13652, MSE: 0.2396823510401391, Learning Rate: 0.031740000000000004\n",
      "Epoch: 13653, MSE: 0.23967958636853331, Learning Rate: 0.031735000000000006\n",
      "Epoch: 13654, MSE: 0.23967682165972867, Learning Rate: 0.03173\n",
      "Epoch: 13655, MSE: 0.23967405691373173, Learning Rate: 0.031725\n",
      "Epoch: 13656, MSE: 0.23967129213054575, Learning Rate: 0.031720000000000005\n",
      "Epoch: 13657, MSE: 0.23966852731017574, Learning Rate: 0.03171500000000001\n",
      "Epoch: 13658, MSE: 0.2396657624526263, Learning Rate: 0.03171000000000001\n",
      "Epoch: 13659, MSE: 0.2396629975579029, Learning Rate: 0.031705000000000004\n",
      "Epoch: 13660, MSE: 0.2396602326260094, Learning Rate: 0.0317\n",
      "Epoch: 13661, MSE: 0.23965746765695106, Learning Rate: 0.031694999999999994\n",
      "Epoch: 13662, MSE: 0.23965470265073194, Learning Rate: 0.031689999999999996\n",
      "Epoch: 13663, MSE: 0.23965193760735728, Learning Rate: 0.031685\n",
      "Epoch: 13664, MSE: 0.23964917252683218, Learning Rate: 0.03168\n",
      "Epoch: 13665, MSE: 0.23964640740916032, Learning Rate: 0.031675\n",
      "Epoch: 13666, MSE: 0.2396436422543477, Learning Rate: 0.03167\n",
      "Epoch: 13667, MSE: 0.23964087706239817, Learning Rate: 0.031665\n",
      "Epoch: 13668, MSE: 0.23963811183331651, Learning Rate: 0.03166\n",
      "Epoch: 13669, MSE: 0.23963534656710792, Learning Rate: 0.031655\n",
      "Epoch: 13670, MSE: 0.23963258126377676, Learning Rate: 0.031650000000000005\n",
      "Epoch: 13671, MSE: 0.23962981592332794, Learning Rate: 0.031645\n",
      "Epoch: 13672, MSE: 0.23962705054576663, Learning Rate: 0.03164\n",
      "Epoch: 13673, MSE: 0.23962428513109646, Learning Rate: 0.031635\n",
      "Epoch: 13674, MSE: 0.23962151967932221, Learning Rate: 0.031630000000000005\n",
      "Epoch: 13675, MSE: 0.23961875419045042, Learning Rate: 0.03162500000000001\n",
      "Epoch: 13676, MSE: 0.2396159886644841, Learning Rate: 0.03162\n",
      "Epoch: 13677, MSE: 0.23961322310142827, Learning Rate: 0.031615000000000004\n",
      "Epoch: 13678, MSE: 0.23961045750128823, Learning Rate: 0.031610000000000006\n",
      "Epoch: 13679, MSE: 0.23960769186406902, Learning Rate: 0.03160500000000001\n",
      "Epoch: 13680, MSE: 0.2396049261897744, Learning Rate: 0.031599999999999996\n",
      "Epoch: 13681, MSE: 0.23960216047840976, Learning Rate: 0.031595\n",
      "Epoch: 13682, MSE: 0.23959939472997988, Learning Rate: 0.03159\n",
      "Epoch: 13683, MSE: 0.23959662894448855, Learning Rate: 0.031584999999999995\n",
      "Epoch: 13684, MSE: 0.23959386312194172, Learning Rate: 0.03158\n",
      "Epoch: 13685, MSE: 0.23959109726234393, Learning Rate: 0.031575\n",
      "Epoch: 13686, MSE: 0.2395883313657003, Learning Rate: 0.03157\n",
      "Epoch: 13687, MSE: 0.23958556543201473, Learning Rate: 0.031565\n",
      "Epoch: 13688, MSE: 0.23958279946129243, Learning Rate: 0.03156\n",
      "Epoch: 13689, MSE: 0.23958003345353784, Learning Rate: 0.031555\n",
      "Epoch: 13690, MSE: 0.23957726740875682, Learning Rate: 0.03155\n",
      "Epoch: 13691, MSE: 0.23957450132695238, Learning Rate: 0.031545000000000004\n",
      "Epoch: 13692, MSE: 0.23957173520813085, Learning Rate: 0.031540000000000006\n",
      "Epoch: 13693, MSE: 0.23956896905229663, Learning Rate: 0.031535\n",
      "Epoch: 13694, MSE: 0.2395662028594542, Learning Rate: 0.03153\n",
      "Epoch: 13695, MSE: 0.2395634366296081, Learning Rate: 0.031525000000000004\n",
      "Epoch: 13696, MSE: 0.2395606703627642, Learning Rate: 0.031520000000000006\n",
      "Epoch: 13697, MSE: 0.239557904058926, Learning Rate: 0.03151500000000001\n",
      "Epoch: 13698, MSE: 0.23955513771809947, Learning Rate: 0.03151\n",
      "Epoch: 13699, MSE: 0.2395523713402887, Learning Rate: 0.031505000000000005\n",
      "Epoch: 13700, MSE: 0.23954960492549893, Learning Rate: 0.03149999999999999\n",
      "Epoch: 13701, MSE: 0.2395468384737349, Learning Rate: 0.031494999999999995\n",
      "Epoch: 13702, MSE: 0.2395440719849999, Learning Rate: 0.03149\n",
      "Epoch: 13703, MSE: 0.23954130545930125, Learning Rate: 0.031485\n",
      "Epoch: 13704, MSE: 0.23953853889664273, Learning Rate: 0.03148\n",
      "Epoch: 13705, MSE: 0.2395357722970284, Learning Rate: 0.031474999999999996\n",
      "Epoch: 13706, MSE: 0.2395330056604644, Learning Rate: 0.03147\n",
      "Epoch: 13707, MSE: 0.2395302389869537, Learning Rate: 0.031465\n",
      "Epoch: 13708, MSE: 0.23952747227650323, Learning Rate: 0.03146\n",
      "Epoch: 13709, MSE: 0.2395247055291169, Learning Rate: 0.031455000000000004\n",
      "Epoch: 13710, MSE: 0.2395219387447983, Learning Rate: 0.03145\n",
      "Epoch: 13711, MSE: 0.23951917192355437, Learning Rate: 0.031445\n",
      "Epoch: 13712, MSE: 0.23951640506538835, Learning Rate: 0.03144\n",
      "Epoch: 13713, MSE: 0.23951363817030583, Learning Rate: 0.031435000000000005\n",
      "Epoch: 13714, MSE: 0.2395108712383127, Learning Rate: 0.03143000000000001\n",
      "Epoch: 13715, MSE: 0.23950810426941152, Learning Rate: 0.031425\n",
      "Epoch: 13716, MSE: 0.23950533726360884, Learning Rate: 0.031420000000000003\n",
      "Epoch: 13717, MSE: 0.23950257022090846, Learning Rate: 0.031415000000000005\n",
      "Epoch: 13718, MSE: 0.23949980314131658, Learning Rate: 0.03141000000000001\n",
      "Epoch: 13719, MSE: 0.2394970360248363, Learning Rate: 0.03140500000000001\n",
      "Epoch: 13720, MSE: 0.23949426887147254, Learning Rate: 0.0314\n",
      "Epoch: 13721, MSE: 0.23949150168123207, Learning Rate: 0.031395\n",
      "Epoch: 13722, MSE: 0.23948873445411778, Learning Rate: 0.031389999999999994\n",
      "Epoch: 13723, MSE: 0.23948596719013646, Learning Rate: 0.031384999999999996\n",
      "Epoch: 13724, MSE: 0.23948319988929115, Learning Rate: 0.03138\n",
      "Epoch: 13725, MSE: 0.23948043255158752, Learning Rate: 0.031375\n",
      "Epoch: 13726, MSE: 0.23947766517703004, Learning Rate: 0.03137\n",
      "Epoch: 13727, MSE: 0.23947489776562444, Learning Rate: 0.031365\n",
      "Epoch: 13728, MSE: 0.23947213031737424, Learning Rate: 0.03136\n",
      "Epoch: 13729, MSE: 0.23946936283228554, Learning Rate: 0.031355\n",
      "Epoch: 13730, MSE: 0.23946659531036232, Learning Rate: 0.03135\n",
      "Epoch: 13731, MSE: 0.2394638277516101, Learning Rate: 0.031345000000000005\n",
      "Epoch: 13732, MSE: 0.23946106015603333, Learning Rate: 0.03134\n",
      "Epoch: 13733, MSE: 0.23945829252363712, Learning Rate: 0.031335\n",
      "Epoch: 13734, MSE: 0.23945552485442656, Learning Rate: 0.031330000000000004\n",
      "Epoch: 13735, MSE: 0.23945275714840633, Learning Rate: 0.031325000000000006\n",
      "Epoch: 13736, MSE: 0.2394499894055808, Learning Rate: 0.03132000000000001\n",
      "Epoch: 13737, MSE: 0.239447221625955, Learning Rate: 0.031315\n",
      "Epoch: 13738, MSE: 0.23944445380953458, Learning Rate: 0.031310000000000004\n",
      "Epoch: 13739, MSE: 0.23944168595632367, Learning Rate: 0.031305000000000006\n",
      "Epoch: 13740, MSE: 0.23943891806632842, Learning Rate: 0.031299999999999994\n",
      "Epoch: 13741, MSE: 0.2394361501395519, Learning Rate: 0.031294999999999996\n",
      "Epoch: 13742, MSE: 0.23943338217600027, Learning Rate: 0.03129\n",
      "Epoch: 13743, MSE: 0.23943061417567726, Learning Rate: 0.031285\n",
      "Epoch: 13744, MSE: 0.23942784613858942, Learning Rate: 0.031279999999999995\n",
      "Epoch: 13745, MSE: 0.23942507806474, Learning Rate: 0.031275\n",
      "Epoch: 13746, MSE: 0.23942230995413522, Learning Rate: 0.03127\n",
      "Epoch: 13747, MSE: 0.23941954180677916, Learning Rate: 0.031265\n",
      "Epoch: 13748, MSE: 0.2394167736226774, Learning Rate: 0.03126\n",
      "Epoch: 13749, MSE: 0.23941400540183333, Learning Rate: 0.031255\n",
      "Epoch: 13750, MSE: 0.23941123714425366, Learning Rate: 0.03125\n",
      "Epoch: 13751, MSE: 0.23940846884994327, Learning Rate: 0.031245000000000002\n",
      "Epoch: 13752, MSE: 0.23940570051890642, Learning Rate: 0.031240000000000004\n",
      "Epoch: 13753, MSE: 0.23940293215114744, Learning Rate: 0.031235000000000002\n",
      "Epoch: 13754, MSE: 0.23940016374667214, Learning Rate: 0.031230000000000004\n",
      "Epoch: 13755, MSE: 0.23939739530548426, Learning Rate: 0.031225000000000003\n",
      "Epoch: 13756, MSE: 0.23939462682759094, Learning Rate: 0.031220000000000005\n",
      "Epoch: 13757, MSE: 0.23939185831299484, Learning Rate: 0.031215000000000007\n",
      "Epoch: 13758, MSE: 0.23938908976170267, Learning Rate: 0.031210000000000005\n",
      "Epoch: 13759, MSE: 0.23938632117371833, Learning Rate: 0.031205000000000007\n",
      "Epoch: 13760, MSE: 0.2393835525490469, Learning Rate: 0.031200000000000006\n",
      "Epoch: 13761, MSE: 0.23938078388769274, Learning Rate: 0.031194999999999997\n",
      "Epoch: 13762, MSE: 0.23937801518966212, Learning Rate: 0.031189999999999996\n",
      "Epoch: 13763, MSE: 0.23937524645495925, Learning Rate: 0.031184999999999997\n",
      "Epoch: 13764, MSE: 0.2393724776835888, Learning Rate: 0.03118\n",
      "Epoch: 13765, MSE: 0.23936970887555603, Learning Rate: 0.031174999999999998\n",
      "Epoch: 13766, MSE: 0.23936694003086678, Learning Rate: 0.03117\n",
      "Epoch: 13767, MSE: 0.23936417114952427, Learning Rate: 0.031164999999999998\n",
      "Epoch: 13768, MSE: 0.23936140223153474, Learning Rate: 0.03116\n",
      "Epoch: 13769, MSE: 0.2393586332769029, Learning Rate: 0.031155000000000002\n",
      "Epoch: 13770, MSE: 0.23935586428563324, Learning Rate: 0.03115\n",
      "Epoch: 13771, MSE: 0.23935309525773152, Learning Rate: 0.031145000000000003\n",
      "Epoch: 13772, MSE: 0.23935032619320096, Learning Rate: 0.03114\n",
      "Epoch: 13773, MSE: 0.23934755709204858, Learning Rate: 0.031135000000000003\n",
      "Epoch: 13774, MSE: 0.23934478795427824, Learning Rate: 0.031130000000000005\n",
      "Epoch: 13775, MSE: 0.23934201877989564, Learning Rate: 0.031125000000000003\n",
      "Epoch: 13776, MSE: 0.23933924956890512, Learning Rate: 0.031120000000000005\n",
      "Epoch: 13777, MSE: 0.2393364803213123, Learning Rate: 0.031115000000000004\n",
      "Epoch: 13778, MSE: 0.23933371103712078, Learning Rate: 0.031110000000000006\n",
      "Epoch: 13779, MSE: 0.23933094171633718, Learning Rate: 0.031105000000000008\n",
      "Epoch: 13780, MSE: 0.23932817235896578, Learning Rate: 0.031100000000000006\n",
      "Epoch: 13781, MSE: 0.23932540296501123, Learning Rate: 0.031094999999999998\n",
      "Epoch: 13782, MSE: 0.2393226335344788, Learning Rate: 0.031089999999999996\n",
      "Epoch: 13783, MSE: 0.23931986406737368, Learning Rate: 0.031084999999999998\n",
      "Epoch: 13784, MSE: 0.23931709456370007, Learning Rate: 0.031079999999999997\n",
      "Epoch: 13785, MSE: 0.23931432502346486, Learning Rate: 0.031075\n",
      "Epoch: 13786, MSE: 0.2393115554466716, Learning Rate: 0.03107\n",
      "Epoch: 13787, MSE: 0.23930878583332438, Learning Rate: 0.031065\n",
      "Epoch: 13788, MSE: 0.23930601618343034, Learning Rate: 0.03106\n",
      "Epoch: 13789, MSE: 0.23930324649699325, Learning Rate: 0.031055\n",
      "Epoch: 13790, MSE: 0.23930047677401775, Learning Rate: 0.03105\n",
      "Epoch: 13791, MSE: 0.23929770701451025, Learning Rate: 0.031045000000000003\n",
      "Epoch: 13792, MSE: 0.23929493721847406, Learning Rate: 0.03104\n",
      "Epoch: 13793, MSE: 0.23929216738591533, Learning Rate: 0.031035000000000004\n",
      "Epoch: 13794, MSE: 0.23928939751683936, Learning Rate: 0.031030000000000002\n",
      "Epoch: 13795, MSE: 0.23928662761124994, Learning Rate: 0.031025000000000004\n",
      "Epoch: 13796, MSE: 0.23928385766915258, Learning Rate: 0.031020000000000006\n",
      "Epoch: 13797, MSE: 0.23928108769055317, Learning Rate: 0.031015000000000004\n",
      "Epoch: 13798, MSE: 0.23927831767545557, Learning Rate: 0.031010000000000006\n",
      "Epoch: 13799, MSE: 0.23927554762386524, Learning Rate: 0.031005000000000005\n",
      "Epoch: 13800, MSE: 0.23927277753578763, Learning Rate: 0.031000000000000007\n",
      "Epoch: 13801, MSE: 0.23927000741122728, Learning Rate: 0.030994999999999995\n",
      "Epoch: 13802, MSE: 0.23926723725018906, Learning Rate: 0.030989999999999997\n",
      "Epoch: 13803, MSE: 0.2392644670526784, Learning Rate: 0.030985\n",
      "Epoch: 13804, MSE: 0.23926169681870013, Learning Rate: 0.030979999999999997\n",
      "Epoch: 13805, MSE: 0.23925892654825937, Learning Rate: 0.030975\n",
      "Epoch: 13806, MSE: 0.23925615624136093, Learning Rate: 0.030969999999999998\n",
      "Epoch: 13807, MSE: 0.23925338589801085, Learning Rate: 0.030965\n",
      "Epoch: 13808, MSE: 0.23925061551821306, Learning Rate: 0.03096\n",
      "Epoch: 13809, MSE: 0.23924784510197325, Learning Rate: 0.030955\n",
      "Epoch: 13810, MSE: 0.2392450746492952, Learning Rate: 0.030950000000000002\n",
      "Epoch: 13811, MSE: 0.23924230416018621, Learning Rate: 0.030945\n",
      "Epoch: 13812, MSE: 0.239239533634649, Learning Rate: 0.030940000000000002\n",
      "Epoch: 13813, MSE: 0.23923676307269054, Learning Rate: 0.030935000000000004\n",
      "Epoch: 13814, MSE: 0.23923399247431476, Learning Rate: 0.030930000000000003\n",
      "Epoch: 13815, MSE: 0.23923122183952675, Learning Rate: 0.030925000000000005\n",
      "Epoch: 13816, MSE: 0.23922845116833158, Learning Rate: 0.030920000000000003\n",
      "Epoch: 13817, MSE: 0.23922568046073617, Learning Rate: 0.030915000000000005\n",
      "Epoch: 13818, MSE: 0.23922290971674237, Learning Rate: 0.030910000000000007\n",
      "Epoch: 13819, MSE: 0.23922013893635768, Learning Rate: 0.030905000000000005\n",
      "Epoch: 13820, MSE: 0.23921736811958613, Learning Rate: 0.030900000000000007\n",
      "Epoch: 13821, MSE: 0.23921459726643343, Learning Rate: 0.030894999999999995\n",
      "Epoch: 13822, MSE: 0.2392118263769039, Learning Rate: 0.030889999999999997\n",
      "Epoch: 13823, MSE: 0.23920905545100307, Learning Rate: 0.030884999999999996\n",
      "Epoch: 13824, MSE: 0.23920628448873618, Learning Rate: 0.030879999999999998\n",
      "Epoch: 13825, MSE: 0.23920351349010782, Learning Rate: 0.030875\n",
      "Epoch: 13826, MSE: 0.23920074245512318, Learning Rate: 0.030869999999999998\n",
      "Epoch: 13827, MSE: 0.2391979713837888, Learning Rate: 0.030865\n",
      "Epoch: 13828, MSE: 0.23919520027610752, Learning Rate: 0.03086\n",
      "Epoch: 13829, MSE: 0.23919242913208574, Learning Rate: 0.030855\n",
      "Epoch: 13830, MSE: 0.23918965795172842, Learning Rate: 0.030850000000000002\n",
      "Epoch: 13831, MSE: 0.23918688673504004, Learning Rate: 0.030845\n",
      "Epoch: 13832, MSE: 0.23918411548202684, Learning Rate: 0.030840000000000003\n",
      "Epoch: 13833, MSE: 0.23918134419269305, Learning Rate: 0.030835\n",
      "Epoch: 13834, MSE: 0.23917857286704358, Learning Rate: 0.030830000000000003\n",
      "Epoch: 13835, MSE: 0.2391758015050841, Learning Rate: 0.030825000000000005\n",
      "Epoch: 13836, MSE: 0.23917303010681956, Learning Rate: 0.030820000000000004\n",
      "Epoch: 13837, MSE: 0.239170258672255, Learning Rate: 0.030815000000000006\n",
      "Epoch: 13838, MSE: 0.23916748720139627, Learning Rate: 0.030810000000000004\n",
      "Epoch: 13839, MSE: 0.23916471569424694, Learning Rate: 0.030805000000000006\n",
      "Epoch: 13840, MSE: 0.23916194415081463, Learning Rate: 0.030800000000000008\n",
      "Epoch: 13841, MSE: 0.23915917257110195, Learning Rate: 0.030794999999999996\n",
      "Epoch: 13842, MSE: 0.23915640095511487, Learning Rate: 0.030789999999999998\n",
      "Epoch: 13843, MSE: 0.23915362930285847, Learning Rate: 0.030784999999999996\n",
      "Epoch: 13844, MSE: 0.23915085761433894, Learning Rate: 0.03078\n",
      "Epoch: 13845, MSE: 0.2391480858895597, Learning Rate: 0.030774999999999997\n",
      "Epoch: 13846, MSE: 0.2391453141285265, Learning Rate: 0.03077\n",
      "Epoch: 13847, MSE: 0.23914254233124538, Learning Rate: 0.030765\n",
      "Epoch: 13848, MSE: 0.23913977049772098, Learning Rate: 0.03076\n",
      "Epoch: 13849, MSE: 0.23913699862795776, Learning Rate: 0.030755\n",
      "Epoch: 13850, MSE: 0.23913422672196133, Learning Rate: 0.03075\n",
      "Epoch: 13851, MSE: 0.23913145477973755, Learning Rate: 0.030745\n",
      "Epoch: 13852, MSE: 0.2391286828012908, Learning Rate: 0.030740000000000003\n",
      "Epoch: 13853, MSE: 0.23912591078662596, Learning Rate: 0.030735000000000002\n",
      "Epoch: 13854, MSE: 0.23912313873574836, Learning Rate: 0.030730000000000004\n",
      "Epoch: 13855, MSE: 0.23912036664866437, Learning Rate: 0.030725000000000002\n",
      "Epoch: 13856, MSE: 0.23911759452537762, Learning Rate: 0.030720000000000004\n",
      "Epoch: 13857, MSE: 0.23911482236589376, Learning Rate: 0.030715000000000006\n",
      "Epoch: 13858, MSE: 0.23911205017021872, Learning Rate: 0.030710000000000005\n",
      "Epoch: 13859, MSE: 0.2391092779383557, Learning Rate: 0.030705000000000007\n",
      "Epoch: 13860, MSE: 0.23910650567031247, Learning Rate: 0.030700000000000005\n",
      "Epoch: 13861, MSE: 0.23910373336609242, Learning Rate: 0.030694999999999997\n",
      "Epoch: 13862, MSE: 0.23910096102570144, Learning Rate: 0.030689999999999995\n",
      "Epoch: 13863, MSE: 0.2390981886491437, Learning Rate: 0.030684999999999997\n",
      "Epoch: 13864, MSE: 0.23909541623642608, Learning Rate: 0.03068\n",
      "Epoch: 13865, MSE: 0.23909264378755274, Learning Rate: 0.030674999999999997\n",
      "Epoch: 13866, MSE: 0.23908987130252826, Learning Rate: 0.03067\n",
      "Epoch: 13867, MSE: 0.23908709878135956, Learning Rate: 0.030664999999999998\n",
      "Epoch: 13868, MSE: 0.2390843262240506, Learning Rate: 0.03066\n",
      "Epoch: 13869, MSE: 0.23908155363060635, Learning Rate: 0.030655\n",
      "Epoch: 13870, MSE: 0.23907878100103255, Learning Rate: 0.03065\n",
      "Epoch: 13871, MSE: 0.23907600833533493, Learning Rate: 0.030645000000000002\n",
      "Epoch: 13872, MSE: 0.23907323563351773, Learning Rate: 0.03064\n",
      "Epoch: 13873, MSE: 0.2390704628955869, Learning Rate: 0.030635000000000003\n",
      "Epoch: 13874, MSE: 0.2390676901215473, Learning Rate: 0.030630000000000004\n",
      "Epoch: 13875, MSE: 0.23906491731140336, Learning Rate: 0.030625000000000003\n",
      "Epoch: 13876, MSE: 0.2390621444651623, Learning Rate: 0.030620000000000005\n",
      "Epoch: 13877, MSE: 0.23905937158282647, Learning Rate: 0.030615000000000003\n",
      "Epoch: 13878, MSE: 0.23905659866440454, Learning Rate: 0.030610000000000005\n",
      "Epoch: 13879, MSE: 0.23905382570989875, Learning Rate: 0.030605000000000007\n",
      "Epoch: 13880, MSE: 0.2390510527193158, Learning Rate: 0.030600000000000006\n",
      "Epoch: 13881, MSE: 0.23904827969266054, Learning Rate: 0.030595000000000008\n",
      "Epoch: 13882, MSE: 0.23904550662993862, Learning Rate: 0.030589999999999996\n",
      "Epoch: 13883, MSE: 0.23904273353115446, Learning Rate: 0.030584999999999998\n",
      "Epoch: 13884, MSE: 0.23903996039631387, Learning Rate: 0.030579999999999996\n",
      "Epoch: 13885, MSE: 0.23903718722542283, Learning Rate: 0.030574999999999998\n",
      "Epoch: 13886, MSE: 0.2390344140184848, Learning Rate: 0.03057\n",
      "Epoch: 13887, MSE: 0.239031640775506, Learning Rate: 0.030565\n",
      "Epoch: 13888, MSE: 0.23902886749649205, Learning Rate: 0.03056\n",
      "Epoch: 13889, MSE: 0.2390260941814472, Learning Rate: 0.030555\n",
      "Epoch: 13890, MSE: 0.23902332083037822, Learning Rate: 0.03055\n",
      "Epoch: 13891, MSE: 0.23902054744328896, Learning Rate: 0.030545000000000003\n",
      "Epoch: 13892, MSE: 0.2390177740201852, Learning Rate: 0.03054\n",
      "Epoch: 13893, MSE: 0.23901500056107206, Learning Rate: 0.030535000000000003\n",
      "Epoch: 13894, MSE: 0.23901222706595548, Learning Rate: 0.03053\n",
      "Epoch: 13895, MSE: 0.23900945353483957, Learning Rate: 0.030525000000000004\n",
      "Epoch: 13896, MSE: 0.23900667996773006, Learning Rate: 0.030520000000000005\n",
      "Epoch: 13897, MSE: 0.23900390636463228, Learning Rate: 0.030515000000000004\n",
      "Epoch: 13898, MSE: 0.23900113272555248, Learning Rate: 0.030510000000000006\n",
      "Epoch: 13899, MSE: 0.23899835905049446, Learning Rate: 0.030505000000000004\n",
      "Epoch: 13900, MSE: 0.23899558533946366, Learning Rate: 0.030500000000000006\n",
      "Epoch: 13901, MSE: 0.2389928115924663, Learning Rate: 0.030495000000000008\n",
      "Epoch: 13902, MSE: 0.23899003780950703, Learning Rate: 0.030489999999999996\n",
      "Epoch: 13903, MSE: 0.23898726399059053, Learning Rate: 0.030484999999999998\n",
      "Epoch: 13904, MSE: 0.23898449013572343, Learning Rate: 0.030479999999999997\n",
      "Epoch: 13905, MSE: 0.23898171624491096, Learning Rate: 0.030475\n",
      "Epoch: 13906, MSE: 0.2389789423181571, Learning Rate: 0.030469999999999997\n",
      "Epoch: 13907, MSE: 0.2389761683554677, Learning Rate: 0.030465\n",
      "Epoch: 13908, MSE: 0.23897339435684903, Learning Rate: 0.03046\n",
      "Epoch: 13909, MSE: 0.23897062032230537, Learning Rate: 0.030455\n",
      "Epoch: 13910, MSE: 0.23896784625184175, Learning Rate: 0.03045\n",
      "Epoch: 13911, MSE: 0.23896507214546428, Learning Rate: 0.030445\n",
      "Epoch: 13912, MSE: 0.23896229800317795, Learning Rate: 0.030440000000000002\n",
      "Epoch: 13913, MSE: 0.23895952382498806, Learning Rate: 0.030435000000000004\n",
      "Epoch: 13914, MSE: 0.23895674961090063, Learning Rate: 0.030430000000000002\n",
      "Epoch: 13915, MSE: 0.23895397536091945, Learning Rate: 0.030425000000000004\n",
      "Epoch: 13916, MSE: 0.23895120107505105, Learning Rate: 0.030420000000000003\n",
      "Epoch: 13917, MSE: 0.23894842675330027, Learning Rate: 0.030415000000000005\n",
      "Epoch: 13918, MSE: 0.23894565239567325, Learning Rate: 0.030410000000000006\n",
      "Epoch: 13919, MSE: 0.23894287800217345, Learning Rate: 0.030405000000000005\n",
      "Epoch: 13920, MSE: 0.23894010357280812, Learning Rate: 0.030400000000000007\n",
      "Epoch: 13921, MSE: 0.23893732910758167, Learning Rate: 0.030395000000000005\n",
      "Epoch: 13922, MSE: 0.23893455460649995, Learning Rate: 0.030389999999999997\n",
      "Epoch: 13923, MSE: 0.23893178006956825, Learning Rate: 0.030384999999999995\n",
      "Epoch: 13924, MSE: 0.23892900549679025, Learning Rate: 0.030379999999999997\n",
      "Epoch: 13925, MSE: 0.23892623088817427, Learning Rate: 0.030375\n",
      "Epoch: 13926, MSE: 0.2389234562437235, Learning Rate: 0.030369999999999998\n",
      "Epoch: 13927, MSE: 0.23892068156344393, Learning Rate: 0.030365\n",
      "Epoch: 13928, MSE: 0.2389179068473404, Learning Rate: 0.030359999999999998\n",
      "Epoch: 13929, MSE: 0.23891513209541915, Learning Rate: 0.030355\n",
      "Epoch: 13930, MSE: 0.23891235730768468, Learning Rate: 0.030350000000000002\n",
      "Epoch: 13931, MSE: 0.23890958248414318, Learning Rate: 0.030345\n",
      "Epoch: 13932, MSE: 0.23890680762479993, Learning Rate: 0.030340000000000002\n",
      "Epoch: 13933, MSE: 0.2389040327296593, Learning Rate: 0.030335\n",
      "Epoch: 13934, MSE: 0.23890125779872817, Learning Rate: 0.030330000000000003\n",
      "Epoch: 13935, MSE: 0.2388984828320099, Learning Rate: 0.030325000000000005\n",
      "Epoch: 13936, MSE: 0.23889570782951208, Learning Rate: 0.030320000000000003\n",
      "Epoch: 13937, MSE: 0.23889293279123877, Learning Rate: 0.030315000000000005\n",
      "Epoch: 13938, MSE: 0.23889015771719543, Learning Rate: 0.030310000000000004\n",
      "Epoch: 13939, MSE: 0.2388873826073879, Learning Rate: 0.030305000000000006\n",
      "Epoch: 13940, MSE: 0.23888460746182144, Learning Rate: 0.030300000000000007\n",
      "Epoch: 13941, MSE: 0.2388818322805012, Learning Rate: 0.030295000000000006\n",
      "Epoch: 13942, MSE: 0.238879057063433, Learning Rate: 0.030289999999999997\n",
      "Epoch: 13943, MSE: 0.23887628181062107, Learning Rate: 0.030284999999999996\n",
      "Epoch: 13944, MSE: 0.23887350652207204, Learning Rate: 0.030279999999999998\n",
      "Epoch: 13945, MSE: 0.2388707311977912, Learning Rate: 0.030274999999999996\n",
      "Epoch: 13946, MSE: 0.23886795583778353, Learning Rate: 0.03027\n",
      "Epoch: 13947, MSE: 0.23886518044205426, Learning Rate: 0.030265\n",
      "Epoch: 13948, MSE: 0.23886240501060935, Learning Rate: 0.03026\n",
      "Epoch: 13949, MSE: 0.23885962954345402, Learning Rate: 0.030255\n",
      "Epoch: 13950, MSE: 0.2388568540405938, Learning Rate: 0.03025\n",
      "Epoch: 13951, MSE: 0.2388540785020337, Learning Rate: 0.030245\n",
      "Epoch: 13952, MSE: 0.2388513029277794, Learning Rate: 0.030240000000000003\n",
      "Epoch: 13953, MSE: 0.2388485273178368, Learning Rate: 0.030235\n",
      "Epoch: 13954, MSE: 0.2388457516722107, Learning Rate: 0.030230000000000003\n",
      "Epoch: 13955, MSE: 0.2388429759909059, Learning Rate: 0.030225000000000002\n",
      "Epoch: 13956, MSE: 0.23884020027392952, Learning Rate: 0.030220000000000004\n",
      "Epoch: 13957, MSE: 0.2388374245212861, Learning Rate: 0.030215000000000006\n",
      "Epoch: 13958, MSE: 0.23883464873297972, Learning Rate: 0.030210000000000004\n",
      "Epoch: 13959, MSE: 0.23883187290901822, Learning Rate: 0.030205000000000006\n",
      "Epoch: 13960, MSE: 0.23882909704940608, Learning Rate: 0.030200000000000005\n",
      "Epoch: 13961, MSE: 0.23882632115414837, Learning Rate: 0.030195000000000007\n",
      "Epoch: 13962, MSE: 0.2388235452232505, Learning Rate: 0.030189999999999995\n",
      "Epoch: 13963, MSE: 0.2388207692567188, Learning Rate: 0.030184999999999997\n",
      "Epoch: 13964, MSE: 0.23881799325455752, Learning Rate: 0.03018\n",
      "Epoch: 13965, MSE: 0.2388152172167734, Learning Rate: 0.030174999999999997\n",
      "Epoch: 13966, MSE: 0.23881244114337127, Learning Rate: 0.03017\n",
      "Epoch: 13967, MSE: 0.23880966503435544, Learning Rate: 0.030164999999999997\n",
      "Epoch: 13968, MSE: 0.23880688888973328, Learning Rate: 0.03016\n",
      "Epoch: 13969, MSE: 0.23880411270950977, Learning Rate: 0.030155\n",
      "Epoch: 13970, MSE: 0.23880133649368898, Learning Rate: 0.03015\n",
      "Epoch: 13971, MSE: 0.2387985602422788, Learning Rate: 0.030145\n",
      "Epoch: 13972, MSE: 0.23879578395528242, Learning Rate: 0.03014\n",
      "Epoch: 13973, MSE: 0.23879300763270664, Learning Rate: 0.030135000000000002\n",
      "Epoch: 13974, MSE: 0.2387902312745563, Learning Rate: 0.030130000000000004\n",
      "Epoch: 13975, MSE: 0.2387874548808381, Learning Rate: 0.030125000000000002\n",
      "Epoch: 13976, MSE: 0.23878467845155554, Learning Rate: 0.030120000000000004\n",
      "Epoch: 13977, MSE: 0.23878190198671573, Learning Rate: 0.030115000000000003\n",
      "Epoch: 13978, MSE: 0.23877912548632294, Learning Rate: 0.030110000000000005\n",
      "Epoch: 13979, MSE: 0.23877634895038413, Learning Rate: 0.030105000000000007\n",
      "Epoch: 13980, MSE: 0.23877357237890348, Learning Rate: 0.030100000000000005\n",
      "Epoch: 13981, MSE: 0.23877079577188692, Learning Rate: 0.030095000000000007\n",
      "Epoch: 13982, MSE: 0.23876801912934054, Learning Rate: 0.030089999999999995\n",
      "Epoch: 13983, MSE: 0.23876524245126912, Learning Rate: 0.030084999999999997\n",
      "Epoch: 13984, MSE: 0.23876246573767776, Learning Rate: 0.030079999999999996\n",
      "Epoch: 13985, MSE: 0.23875968898857317, Learning Rate: 0.030074999999999998\n",
      "Epoch: 13986, MSE: 0.2387569122039601, Learning Rate: 0.03007\n",
      "Epoch: 13987, MSE: 0.2387541353838444, Learning Rate: 0.030064999999999998\n",
      "Epoch: 13988, MSE: 0.23875135852823182, Learning Rate: 0.03006\n",
      "Epoch: 13989, MSE: 0.23874858163712664, Learning Rate: 0.030055\n",
      "Epoch: 13990, MSE: 0.23874580471053608, Learning Rate: 0.03005\n",
      "Epoch: 13991, MSE: 0.23874302774846468, Learning Rate: 0.030045000000000002\n",
      "Epoch: 13992, MSE: 0.23874025075091804, Learning Rate: 0.03004\n",
      "Epoch: 13993, MSE: 0.23873747371790144, Learning Rate: 0.030035000000000003\n",
      "Epoch: 13994, MSE: 0.23873469664942104, Learning Rate: 0.03003\n",
      "Epoch: 13995, MSE: 0.238731919545482, Learning Rate: 0.030025000000000003\n",
      "Epoch: 13996, MSE: 0.23872914240608972, Learning Rate: 0.030020000000000005\n",
      "Epoch: 13997, MSE: 0.2387263652312509, Learning Rate: 0.030015000000000003\n",
      "Epoch: 13998, MSE: 0.23872358802096963, Learning Rate: 0.030010000000000005\n",
      "Epoch: 13999, MSE: 0.23872081077525203, Learning Rate: 0.030005000000000004\n",
      "Epoch: 14000, MSE: 0.23871803349410337, Learning Rate: 0.030000000000000006\n",
      "Epoch: 14001, MSE: 0.2387152561775308, Learning Rate: 0.029995000000000008\n",
      "Epoch: 14002, MSE: 0.2387124788255375, Learning Rate: 0.029990000000000006\n",
      "Epoch: 14003, MSE: 0.23870970143812917, Learning Rate: 0.029984999999999998\n",
      "Epoch: 14004, MSE: 0.23870692401531374, Learning Rate: 0.029979999999999996\n",
      "Epoch: 14005, MSE: 0.2387041465570947, Learning Rate: 0.029974999999999998\n",
      "Epoch: 14006, MSE: 0.23870136906347908, Learning Rate: 0.029969999999999997\n",
      "Epoch: 14007, MSE: 0.23869859153447143, Learning Rate: 0.029965\n",
      "Epoch: 14008, MSE: 0.23869581397007622, Learning Rate: 0.02996\n",
      "Epoch: 14009, MSE: 0.2386930363703022, Learning Rate: 0.029955\n",
      "Epoch: 14010, MSE: 0.23869025873515207, Learning Rate: 0.02995\n",
      "Epoch: 14011, MSE: 0.23868748106463245, Learning Rate: 0.029945\n",
      "Epoch: 14012, MSE: 0.23868470335874958, Learning Rate: 0.02994\n",
      "Epoch: 14013, MSE: 0.2386819256175083, Learning Rate: 0.029935000000000003\n",
      "Epoch: 14014, MSE: 0.2386791478409134, Learning Rate: 0.029930000000000002\n",
      "Epoch: 14015, MSE: 0.23867637002897193, Learning Rate: 0.029925000000000004\n",
      "Epoch: 14016, MSE: 0.2386735921816893, Learning Rate: 0.029920000000000002\n",
      "Epoch: 14017, MSE: 0.23867081429907017, Learning Rate: 0.029915000000000004\n",
      "Epoch: 14018, MSE: 0.23866803638112125, Learning Rate: 0.029910000000000006\n",
      "Epoch: 14019, MSE: 0.23866525842784814, Learning Rate: 0.029905000000000004\n",
      "Epoch: 14020, MSE: 0.23866248043925517, Learning Rate: 0.029900000000000006\n",
      "Epoch: 14021, MSE: 0.23865970241534823, Learning Rate: 0.029895000000000005\n",
      "Epoch: 14022, MSE: 0.23865692435613445, Learning Rate: 0.029890000000000007\n",
      "Epoch: 14023, MSE: 0.23865414626161827, Learning Rate: 0.029884999999999995\n",
      "Epoch: 14024, MSE: 0.23865136813180632, Learning Rate: 0.029879999999999997\n",
      "Epoch: 14025, MSE: 0.23864858996670202, Learning Rate: 0.029875\n",
      "Epoch: 14026, MSE: 0.2386458117663133, Learning Rate: 0.029869999999999997\n",
      "Epoch: 14027, MSE: 0.23864303353064506, Learning Rate: 0.029865\n",
      "Epoch: 14028, MSE: 0.23864025525970214, Learning Rate: 0.029859999999999998\n",
      "Epoch: 14029, MSE: 0.238637476953491, Learning Rate: 0.029855\n",
      "Epoch: 14030, MSE: 0.23863469861201755, Learning Rate: 0.02985\n",
      "Epoch: 14031, MSE: 0.23863192023528712, Learning Rate: 0.029845\n",
      "Epoch: 14032, MSE: 0.23862914182330439, Learning Rate: 0.029840000000000002\n",
      "Epoch: 14033, MSE: 0.23862636337607637, Learning Rate: 0.029835\n",
      "Epoch: 14034, MSE: 0.23862358489360805, Learning Rate: 0.029830000000000002\n",
      "Epoch: 14035, MSE: 0.23862080637590558, Learning Rate: 0.029825000000000004\n",
      "Epoch: 14036, MSE: 0.2386180278229737, Learning Rate: 0.029820000000000003\n",
      "Epoch: 14037, MSE: 0.2386152492348198, Learning Rate: 0.029815000000000005\n",
      "Epoch: 14038, MSE: 0.23861247061144752, Learning Rate: 0.029810000000000003\n",
      "Epoch: 14039, MSE: 0.2386096919528635, Learning Rate: 0.029805000000000005\n",
      "Epoch: 14040, MSE: 0.2386069132590733, Learning Rate: 0.029800000000000007\n",
      "Epoch: 14041, MSE: 0.2386041345300828, Learning Rate: 0.029795000000000006\n",
      "Epoch: 14042, MSE: 0.2386013557658979, Learning Rate: 0.029790000000000007\n",
      "Epoch: 14043, MSE: 0.2385985769665225, Learning Rate: 0.029784999999999996\n",
      "Epoch: 14044, MSE: 0.23859579813196563, Learning Rate: 0.029779999999999997\n",
      "Epoch: 14045, MSE: 0.2385930192622302, Learning Rate: 0.029774999999999996\n",
      "Epoch: 14046, MSE: 0.23859024035732215, Learning Rate: 0.029769999999999998\n",
      "Epoch: 14047, MSE: 0.23858746141724893, Learning Rate: 0.029765\n",
      "Epoch: 14048, MSE: 0.23858468244201428, Learning Rate: 0.029759999999999998\n",
      "Epoch: 14049, MSE: 0.2385819034316252, Learning Rate: 0.029755\n",
      "Epoch: 14050, MSE: 0.23857912438608642, Learning Rate: 0.02975\n",
      "Epoch: 14051, MSE: 0.23857634530540478, Learning Rate: 0.029745\n",
      "Epoch: 14052, MSE: 0.2385735661895847, Learning Rate: 0.029740000000000003\n",
      "Epoch: 14053, MSE: 0.2385707870386329, Learning Rate: 0.029735\n",
      "Epoch: 14054, MSE: 0.2385680078525545, Learning Rate: 0.029730000000000003\n",
      "Epoch: 14055, MSE: 0.2385652286313557, Learning Rate: 0.029725\n",
      "Epoch: 14056, MSE: 0.23856244937504167, Learning Rate: 0.029720000000000003\n",
      "Epoch: 14057, MSE: 0.2385596700836191, Learning Rate: 0.029715000000000005\n",
      "Epoch: 14058, MSE: 0.2385568907570921, Learning Rate: 0.029710000000000004\n",
      "Epoch: 14059, MSE: 0.23855411139546853, Learning Rate: 0.029705000000000006\n",
      "Epoch: 14060, MSE: 0.23855133199875256, Learning Rate: 0.029700000000000004\n",
      "Epoch: 14061, MSE: 0.23854855256694998, Learning Rate: 0.029695000000000006\n",
      "Epoch: 14062, MSE: 0.23854577310006694, Learning Rate: 0.029690000000000008\n",
      "Epoch: 14063, MSE: 0.23854299359810904, Learning Rate: 0.029684999999999996\n",
      "Epoch: 14064, MSE: 0.23854021406108233, Learning Rate: 0.029679999999999998\n",
      "Epoch: 14065, MSE: 0.23853743448899248, Learning Rate: 0.029674999999999997\n",
      "Epoch: 14066, MSE: 0.23853465488184517, Learning Rate: 0.02967\n",
      "Epoch: 14067, MSE: 0.2385318752396457, Learning Rate: 0.029664999999999997\n",
      "Epoch: 14068, MSE: 0.23852909556240093, Learning Rate: 0.02966\n",
      "Epoch: 14069, MSE: 0.23852631585011572, Learning Rate: 0.029655\n",
      "Epoch: 14070, MSE: 0.2385235361027953, Learning Rate: 0.02965\n",
      "Epoch: 14071, MSE: 0.23852075632044728, Learning Rate: 0.029645\n",
      "Epoch: 14072, MSE: 0.2385179765030755, Learning Rate: 0.02964\n",
      "Epoch: 14073, MSE: 0.23851519665068746, Learning Rate: 0.029635\n",
      "Epoch: 14074, MSE: 0.23851241676328727, Learning Rate: 0.029630000000000004\n",
      "Epoch: 14075, MSE: 0.23850963684088233, Learning Rate: 0.029625000000000002\n",
      "Epoch: 14076, MSE: 0.2385068568834774, Learning Rate: 0.029620000000000004\n",
      "Epoch: 14077, MSE: 0.23850407689107708, Learning Rate: 0.029615000000000002\n",
      "Epoch: 14078, MSE: 0.23850129686369015, Learning Rate: 0.029610000000000004\n",
      "Epoch: 14079, MSE: 0.2384985168013201, Learning Rate: 0.029605000000000006\n",
      "Epoch: 14080, MSE: 0.23849573670397364, Learning Rate: 0.029600000000000005\n",
      "Epoch: 14081, MSE: 0.2384929565716567, Learning Rate: 0.029595000000000007\n",
      "Epoch: 14082, MSE: 0.23849017640437445, Learning Rate: 0.029590000000000005\n",
      "Epoch: 14083, MSE: 0.23848739620213263, Learning Rate: 0.029584999999999997\n",
      "Epoch: 14084, MSE: 0.2384846159649383, Learning Rate: 0.029579999999999995\n",
      "Epoch: 14085, MSE: 0.23848183569279582, Learning Rate: 0.029574999999999997\n",
      "Epoch: 14086, MSE: 0.23847905538571199, Learning Rate: 0.02957\n",
      "Epoch: 14087, MSE: 0.23847627504369237, Learning Rate: 0.029564999999999998\n",
      "Epoch: 14088, MSE: 0.2384734946667416, Learning Rate: 0.02956\n",
      "Epoch: 14089, MSE: 0.23847071425486785, Learning Rate: 0.029554999999999998\n",
      "Epoch: 14090, MSE: 0.23846793380807504, Learning Rate: 0.02955\n",
      "Epoch: 14091, MSE: 0.2384651533263695, Learning Rate: 0.029545000000000002\n",
      "Epoch: 14092, MSE: 0.23846237280975716, Learning Rate: 0.02954\n",
      "Epoch: 14093, MSE: 0.23845959225824442, Learning Rate: 0.029535000000000002\n",
      "Epoch: 14094, MSE: 0.23845681167183624, Learning Rate: 0.02953\n",
      "Epoch: 14095, MSE: 0.23845403105053897, Learning Rate: 0.029525000000000003\n",
      "Epoch: 14096, MSE: 0.2384512503943581, Learning Rate: 0.029520000000000005\n",
      "Epoch: 14097, MSE: 0.2384484697033004, Learning Rate: 0.029515000000000003\n",
      "Epoch: 14098, MSE: 0.23844568897737053, Learning Rate: 0.029510000000000005\n",
      "Epoch: 14099, MSE: 0.2384429082165746, Learning Rate: 0.029505000000000003\n",
      "Epoch: 14100, MSE: 0.23844012742091897, Learning Rate: 0.029500000000000005\n",
      "Epoch: 14101, MSE: 0.2384373465904091, Learning Rate: 0.029495000000000007\n",
      "Epoch: 14102, MSE: 0.23843456572505148, Learning Rate: 0.029490000000000006\n",
      "Epoch: 14103, MSE: 0.23843178482485117, Learning Rate: 0.029484999999999997\n",
      "Epoch: 14104, MSE: 0.2384290038898145, Learning Rate: 0.029479999999999996\n",
      "Epoch: 14105, MSE: 0.23842622291994753, Learning Rate: 0.029474999999999998\n",
      "Epoch: 14106, MSE: 0.23842344191525505, Learning Rate: 0.029469999999999996\n",
      "Epoch: 14107, MSE: 0.23842066087574446, Learning Rate: 0.029464999999999998\n",
      "Epoch: 14108, MSE: 0.238417879801421, Learning Rate: 0.02946\n",
      "Epoch: 14109, MSE: 0.23841509869229022, Learning Rate: 0.029455\n",
      "Epoch: 14110, MSE: 0.23841231754835882, Learning Rate: 0.02945\n",
      "Epoch: 14111, MSE: 0.23840953636963147, Learning Rate: 0.029445\n",
      "Epoch: 14112, MSE: 0.2384067551561153, Learning Rate: 0.02944\n",
      "Epoch: 14113, MSE: 0.23840397390781531, Learning Rate: 0.029435000000000003\n",
      "Epoch: 14114, MSE: 0.23840119262473808, Learning Rate: 0.02943\n",
      "Epoch: 14115, MSE: 0.2383984113068888, Learning Rate: 0.029425000000000003\n",
      "Epoch: 14116, MSE: 0.23839562995427477, Learning Rate: 0.02942\n",
      "Epoch: 14117, MSE: 0.23839284856690032, Learning Rate: 0.029415000000000004\n",
      "Epoch: 14118, MSE: 0.2383900671447725, Learning Rate: 0.029410000000000006\n",
      "Epoch: 14119, MSE: 0.23838728568789658, Learning Rate: 0.029405000000000004\n",
      "Epoch: 14120, MSE: 0.23838450419627805, Learning Rate: 0.029400000000000006\n",
      "Epoch: 14121, MSE: 0.2383817226699243, Learning Rate: 0.029395000000000004\n",
      "Epoch: 14122, MSE: 0.23837894110883986, Learning Rate: 0.029390000000000006\n",
      "Epoch: 14123, MSE: 0.23837615951303193, Learning Rate: 0.029384999999999994\n",
      "Epoch: 14124, MSE: 0.23837337788250482, Learning Rate: 0.029379999999999996\n",
      "Epoch: 14125, MSE: 0.23837059621726647, Learning Rate: 0.029375\n",
      "Epoch: 14126, MSE: 0.23836781451732125, Learning Rate: 0.029369999999999997\n",
      "Epoch: 14127, MSE: 0.2383650327826754, Learning Rate: 0.029365\n",
      "Epoch: 14128, MSE: 0.2383622510133354, Learning Rate: 0.029359999999999997\n",
      "Epoch: 14129, MSE: 0.23835946920930765, Learning Rate: 0.029355\n",
      "Epoch: 14130, MSE: 0.2383566873705956, Learning Rate: 0.02935\n",
      "Epoch: 14131, MSE: 0.23835390549720886, Learning Rate: 0.029345\n",
      "Epoch: 14132, MSE: 0.2383511235891502, Learning Rate: 0.02934\n",
      "Epoch: 14133, MSE: 0.2383483416464278, Learning Rate: 0.029335\n",
      "Epoch: 14134, MSE: 0.2383455596690462, Learning Rate: 0.029330000000000002\n",
      "Epoch: 14135, MSE: 0.23834277765701245, Learning Rate: 0.029325000000000004\n",
      "Epoch: 14136, MSE: 0.23833999561033195, Learning Rate: 0.029320000000000002\n",
      "Epoch: 14137, MSE: 0.23833721352901052, Learning Rate: 0.029315000000000004\n",
      "Epoch: 14138, MSE: 0.2383344314130546, Learning Rate: 0.029310000000000003\n",
      "Epoch: 14139, MSE: 0.23833164926246986, Learning Rate: 0.029305000000000005\n",
      "Epoch: 14140, MSE: 0.2383288670772634, Learning Rate: 0.029300000000000007\n",
      "Epoch: 14141, MSE: 0.23832608485743856, Learning Rate: 0.029295000000000005\n",
      "Epoch: 14142, MSE: 0.23832330260300372, Learning Rate: 0.029290000000000007\n",
      "Epoch: 14143, MSE: 0.23832052031396442, Learning Rate: 0.029285000000000005\n",
      "Epoch: 14144, MSE: 0.2383177379903259, Learning Rate: 0.029279999999999997\n",
      "Epoch: 14145, MSE: 0.23831495563209562, Learning Rate: 0.029274999999999995\n",
      "Epoch: 14146, MSE: 0.238312173239279, Learning Rate: 0.029269999999999997\n",
      "Epoch: 14147, MSE: 0.23830939081188068, Learning Rate: 0.029265\n",
      "Epoch: 14148, MSE: 0.2383066083499074, Learning Rate: 0.029259999999999998\n",
      "Epoch: 14149, MSE: 0.23830382585336615, Learning Rate: 0.029255\n",
      "Epoch: 14150, MSE: 0.23830104332226248, Learning Rate: 0.029249999999999998\n",
      "Epoch: 14151, MSE: 0.2382982607566023, Learning Rate: 0.029245\n",
      "Epoch: 14152, MSE: 0.23829547815639224, Learning Rate: 0.029240000000000002\n",
      "Epoch: 14153, MSE: 0.23829269552163673, Learning Rate: 0.029235\n",
      "Epoch: 14154, MSE: 0.23828991285234358, Learning Rate: 0.029230000000000003\n",
      "Epoch: 14155, MSE: 0.2382871301485179, Learning Rate: 0.029225\n",
      "Epoch: 14156, MSE: 0.23828434741016497, Learning Rate: 0.029220000000000003\n",
      "Epoch: 14157, MSE: 0.23828156463729286, Learning Rate: 0.029215000000000005\n",
      "Epoch: 14158, MSE: 0.2382787818299068, Learning Rate: 0.029210000000000003\n",
      "Epoch: 14159, MSE: 0.2382759989880121, Learning Rate: 0.029205000000000005\n",
      "Epoch: 14160, MSE: 0.23827321611161514, Learning Rate: 0.029200000000000004\n",
      "Epoch: 14161, MSE: 0.23827043320072244, Learning Rate: 0.029195000000000006\n",
      "Epoch: 14162, MSE: 0.23826765025534027, Learning Rate: 0.029190000000000008\n",
      "Epoch: 14163, MSE: 0.23826486727547289, Learning Rate: 0.029185000000000006\n",
      "Epoch: 14164, MSE: 0.23826208426112946, Learning Rate: 0.029179999999999998\n",
      "Epoch: 14165, MSE: 0.2382593012123132, Learning Rate: 0.029174999999999996\n",
      "Epoch: 14166, MSE: 0.2382565181290321, Learning Rate: 0.029169999999999998\n",
      "Epoch: 14167, MSE: 0.238253735011291, Learning Rate: 0.029164999999999996\n",
      "Epoch: 14168, MSE: 0.23825095185909628, Learning Rate: 0.02916\n",
      "Epoch: 14169, MSE: 0.23824816867245527, Learning Rate: 0.029155\n",
      "Epoch: 14170, MSE: 0.23824538545137283, Learning Rate: 0.02915\n",
      "Epoch: 14171, MSE: 0.2382426021958541, Learning Rate: 0.029145\n",
      "Epoch: 14172, MSE: 0.23823981890590767, Learning Rate: 0.02914\n",
      "Epoch: 14173, MSE: 0.23823703558153805, Learning Rate: 0.029135\n",
      "Epoch: 14174, MSE: 0.23823425222275102, Learning Rate: 0.029130000000000003\n",
      "Epoch: 14175, MSE: 0.23823146882955412, Learning Rate: 0.029125\n",
      "Epoch: 14176, MSE: 0.23822868540195144, Learning Rate: 0.029120000000000004\n",
      "Epoch: 14177, MSE: 0.23822590193995188, Learning Rate: 0.029115000000000002\n",
      "Epoch: 14178, MSE: 0.2382231184435594, Learning Rate: 0.029110000000000004\n",
      "Epoch: 14179, MSE: 0.23822033491278125, Learning Rate: 0.029105000000000006\n",
      "Epoch: 14180, MSE: 0.2382175513476221, Learning Rate: 0.029100000000000004\n",
      "Epoch: 14181, MSE: 0.23821476774808975, Learning Rate: 0.029095000000000006\n",
      "Epoch: 14182, MSE: 0.23821198411418937, Learning Rate: 0.029090000000000005\n",
      "Epoch: 14183, MSE: 0.23820920044592764, Learning Rate: 0.029085000000000007\n",
      "Epoch: 14184, MSE: 0.2382064167433101, Learning Rate: 0.029079999999999995\n",
      "Epoch: 14185, MSE: 0.23820363300634348, Learning Rate: 0.029074999999999997\n",
      "Epoch: 14186, MSE: 0.23820084923503435, Learning Rate: 0.02907\n",
      "Epoch: 14187, MSE: 0.23819806542938732, Learning Rate: 0.029064999999999997\n",
      "Epoch: 14188, MSE: 0.23819528158940986, Learning Rate: 0.02906\n",
      "Epoch: 14189, MSE: 0.23819249771510786, Learning Rate: 0.029054999999999997\n",
      "Epoch: 14190, MSE: 0.23818971380648732, Learning Rate: 0.02905\n",
      "Epoch: 14191, MSE: 0.2381869298635547, Learning Rate: 0.029045\n",
      "Epoch: 14192, MSE: 0.23818414588631548, Learning Rate: 0.02904\n",
      "Epoch: 14193, MSE: 0.2381813618747767, Learning Rate: 0.029035000000000002\n",
      "Epoch: 14194, MSE: 0.2381785778289431, Learning Rate: 0.02903\n",
      "Epoch: 14195, MSE: 0.23817579374882286, Learning Rate: 0.029025000000000002\n",
      "Epoch: 14196, MSE: 0.23817300963442167, Learning Rate: 0.029020000000000004\n",
      "Epoch: 14197, MSE: 0.2381702254857444, Learning Rate: 0.029015000000000003\n",
      "Epoch: 14198, MSE: 0.238167441302799, Learning Rate: 0.029010000000000005\n",
      "Epoch: 14199, MSE: 0.23816465708559037, Learning Rate: 0.029005000000000003\n",
      "Epoch: 14200, MSE: 0.23816187283412513, Learning Rate: 0.029000000000000005\n",
      "Epoch: 14201, MSE: 0.23815908854841017, Learning Rate: 0.028995000000000007\n",
      "Epoch: 14202, MSE: 0.23815630422845022, Learning Rate: 0.028990000000000005\n",
      "Epoch: 14203, MSE: 0.23815351987425293, Learning Rate: 0.028985000000000007\n",
      "Epoch: 14204, MSE: 0.23815073548582363, Learning Rate: 0.028979999999999995\n",
      "Epoch: 14205, MSE: 0.23814795106316894, Learning Rate: 0.028974999999999997\n",
      "Epoch: 14206, MSE: 0.2381451666062947, Learning Rate: 0.028969999999999996\n",
      "Epoch: 14207, MSE: 0.23814238211520794, Learning Rate: 0.028964999999999998\n",
      "Epoch: 14208, MSE: 0.2381395975899141, Learning Rate: 0.02896\n",
      "Epoch: 14209, MSE: 0.23813681303041995, Learning Rate: 0.028954999999999998\n",
      "Epoch: 14210, MSE: 0.23813402843673062, Learning Rate: 0.02895\n",
      "Epoch: 14211, MSE: 0.23813124380885473, Learning Rate: 0.028945\n",
      "Epoch: 14212, MSE: 0.23812845914679556, Learning Rate: 0.02894\n",
      "Epoch: 14213, MSE: 0.23812567445056212, Learning Rate: 0.028935000000000002\n",
      "Epoch: 14214, MSE: 0.23812288972015858, Learning Rate: 0.02893\n",
      "Epoch: 14215, MSE: 0.23812010495559285, Learning Rate: 0.028925000000000003\n",
      "Epoch: 14216, MSE: 0.23811732015686918, Learning Rate: 0.02892\n",
      "Epoch: 14217, MSE: 0.23811453532399557, Learning Rate: 0.028915000000000003\n",
      "Epoch: 14218, MSE: 0.2381117504569782, Learning Rate: 0.028910000000000005\n",
      "Epoch: 14219, MSE: 0.23810896555582223, Learning Rate: 0.028905000000000004\n",
      "Epoch: 14220, MSE: 0.2381061806205347, Learning Rate: 0.028900000000000006\n",
      "Epoch: 14221, MSE: 0.23810339565112212, Learning Rate: 0.028895000000000004\n",
      "Epoch: 14222, MSE: 0.23810061064758978, Learning Rate: 0.028890000000000006\n",
      "Epoch: 14223, MSE: 0.2380978256099449, Learning Rate: 0.028885000000000008\n",
      "Epoch: 14224, MSE: 0.2380950405381936, Learning Rate: 0.028879999999999996\n",
      "Epoch: 14225, MSE: 0.23809225543234241, Learning Rate: 0.028874999999999998\n",
      "Epoch: 14226, MSE: 0.23808947029239713, Learning Rate: 0.028869999999999996\n",
      "Epoch: 14227, MSE: 0.23808668511836426, Learning Rate: 0.028865\n",
      "Epoch: 14228, MSE: 0.23808389991024997, Learning Rate: 0.028859999999999997\n",
      "Epoch: 14229, MSE: 0.23808111466806042, Learning Rate: 0.028855\n",
      "Epoch: 14230, MSE: 0.2380783293918026, Learning Rate: 0.02885\n",
      "Epoch: 14231, MSE: 0.23807554408148204, Learning Rate: 0.028845\n",
      "Epoch: 14232, MSE: 0.23807275873710584, Learning Rate: 0.02884\n",
      "Epoch: 14233, MSE: 0.23806997335867933, Learning Rate: 0.028835\n",
      "Epoch: 14234, MSE: 0.23806718794621065, Learning Rate: 0.02883\n",
      "Epoch: 14235, MSE: 0.23806440249970398, Learning Rate: 0.028825000000000003\n",
      "Epoch: 14236, MSE: 0.23806161701916723, Learning Rate: 0.028820000000000002\n",
      "Epoch: 14237, MSE: 0.23805883150460552, Learning Rate: 0.028815000000000004\n",
      "Epoch: 14238, MSE: 0.23805604595602622, Learning Rate: 0.028810000000000002\n",
      "Epoch: 14239, MSE: 0.2380532603734348, Learning Rate: 0.028805000000000004\n",
      "Epoch: 14240, MSE: 0.2380504747568386, Learning Rate: 0.028800000000000006\n",
      "Epoch: 14241, MSE: 0.23804768910624322, Learning Rate: 0.028795000000000005\n",
      "Epoch: 14242, MSE: 0.2380449034216547, Learning Rate: 0.028790000000000007\n",
      "Epoch: 14243, MSE: 0.2380421177030811, Learning Rate: 0.028785000000000005\n",
      "Epoch: 14244, MSE: 0.23803933195052737, Learning Rate: 0.028779999999999997\n",
      "Epoch: 14245, MSE: 0.2380365461639999, Learning Rate: 0.028774999999999995\n",
      "Epoch: 14246, MSE: 0.23803376034350554, Learning Rate: 0.028769999999999997\n",
      "Epoch: 14247, MSE: 0.23803097448904986, Learning Rate: 0.028765\n",
      "Epoch: 14248, MSE: 0.23802818860064126, Learning Rate: 0.028759999999999997\n",
      "Epoch: 14249, MSE: 0.2380254026782834, Learning Rate: 0.028755\n",
      "Epoch: 14250, MSE: 0.23802261672198483, Learning Rate: 0.028749999999999998\n",
      "Epoch: 14251, MSE: 0.23801983073175048, Learning Rate: 0.028745\n",
      "Epoch: 14252, MSE: 0.23801704470758736, Learning Rate: 0.02874\n",
      "Epoch: 14253, MSE: 0.23801425864950254, Learning Rate: 0.028735\n",
      "Epoch: 14254, MSE: 0.23801147255750124, Learning Rate: 0.028730000000000002\n",
      "Epoch: 14255, MSE: 0.238008686431591, Learning Rate: 0.028725\n",
      "Epoch: 14256, MSE: 0.23800590027177732, Learning Rate: 0.028720000000000002\n",
      "Epoch: 14257, MSE: 0.23800311407806654, Learning Rate: 0.028715000000000004\n",
      "Epoch: 14258, MSE: 0.23800032785046607, Learning Rate: 0.028710000000000003\n",
      "Epoch: 14259, MSE: 0.23799754158898148, Learning Rate: 0.028705000000000005\n",
      "Epoch: 14260, MSE: 0.2379947552936199, Learning Rate: 0.028700000000000003\n",
      "Epoch: 14261, MSE: 0.23799196896438665, Learning Rate: 0.028695000000000005\n",
      "Epoch: 14262, MSE: 0.2379891826012895, Learning Rate: 0.028690000000000007\n",
      "Epoch: 14263, MSE: 0.23798639620433373, Learning Rate: 0.028685000000000006\n",
      "Epoch: 14264, MSE: 0.23798360977352692, Learning Rate: 0.028680000000000008\n",
      "Epoch: 14265, MSE: 0.23798082330887466, Learning Rate: 0.028674999999999996\n",
      "Epoch: 14266, MSE: 0.23797803681038354, Learning Rate: 0.028669999999999998\n",
      "Epoch: 14267, MSE: 0.23797525027806016, Learning Rate: 0.028664999999999996\n",
      "Epoch: 14268, MSE: 0.23797246371191103, Learning Rate: 0.028659999999999998\n",
      "Epoch: 14269, MSE: 0.23796967711194258, Learning Rate: 0.028655\n",
      "Epoch: 14270, MSE: 0.2379668904781615, Learning Rate: 0.02865\n",
      "Epoch: 14271, MSE: 0.23796410381057365, Learning Rate: 0.028645\n",
      "Epoch: 14272, MSE: 0.23796131710918644, Learning Rate: 0.02864\n",
      "Epoch: 14273, MSE: 0.23795853037400488, Learning Rate: 0.028635\n",
      "Epoch: 14274, MSE: 0.23795574360503685, Learning Rate: 0.028630000000000003\n",
      "Epoch: 14275, MSE: 0.23795295680228848, Learning Rate: 0.028625\n",
      "Epoch: 14276, MSE: 0.23795016996576573, Learning Rate: 0.028620000000000003\n",
      "Epoch: 14277, MSE: 0.23794738309547533, Learning Rate: 0.028615\n",
      "Epoch: 14278, MSE: 0.23794459619142486, Learning Rate: 0.028610000000000003\n",
      "Epoch: 14279, MSE: 0.23794180925361855, Learning Rate: 0.028605000000000005\n",
      "Epoch: 14280, MSE: 0.2379390222820657, Learning Rate: 0.028600000000000004\n",
      "Epoch: 14281, MSE: 0.23793623527677069, Learning Rate: 0.028595000000000006\n",
      "Epoch: 14282, MSE: 0.23793344823774115, Learning Rate: 0.028590000000000004\n",
      "Epoch: 14283, MSE: 0.2379306611649827, Learning Rate: 0.028585000000000006\n",
      "Epoch: 14284, MSE: 0.23792787405850185, Learning Rate: 0.028580000000000008\n",
      "Epoch: 14285, MSE: 0.2379250869183067, Learning Rate: 0.028574999999999996\n",
      "Epoch: 14286, MSE: 0.2379222997444023, Learning Rate: 0.028569999999999998\n",
      "Epoch: 14287, MSE: 0.23791951253679594, Learning Rate: 0.028564999999999997\n",
      "Epoch: 14288, MSE: 0.23791672529549354, Learning Rate: 0.02856\n",
      "Epoch: 14289, MSE: 0.2379139380205019, Learning Rate: 0.028554999999999997\n",
      "Epoch: 14290, MSE: 0.23791115071182742, Learning Rate: 0.02855\n",
      "Epoch: 14291, MSE: 0.23790836336947735, Learning Rate: 0.028545\n",
      "Epoch: 14292, MSE: 0.23790557599345755, Learning Rate: 0.02854\n",
      "Epoch: 14293, MSE: 0.2379027885837737, Learning Rate: 0.028535\n",
      "Epoch: 14294, MSE: 0.23790000114043483, Learning Rate: 0.02853\n",
      "Epoch: 14295, MSE: 0.23789721366344557, Learning Rate: 0.028525000000000002\n",
      "Epoch: 14296, MSE: 0.23789442615281356, Learning Rate: 0.028520000000000004\n",
      "Epoch: 14297, MSE: 0.23789163860854426, Learning Rate: 0.028515000000000002\n",
      "Epoch: 14298, MSE: 0.23788885103064472, Learning Rate: 0.028510000000000004\n",
      "Epoch: 14299, MSE: 0.23788606341912213, Learning Rate: 0.028505000000000003\n",
      "Epoch: 14300, MSE: 0.23788327577398213, Learning Rate: 0.028500000000000004\n",
      "Epoch: 14301, MSE: 0.2378804880952319, Learning Rate: 0.028495000000000006\n",
      "Epoch: 14302, MSE: 0.23787770038287825, Learning Rate: 0.028490000000000005\n",
      "Epoch: 14303, MSE: 0.23787491263692695, Learning Rate: 0.028485000000000007\n",
      "Epoch: 14304, MSE: 0.23787212485738524, Learning Rate: 0.028480000000000005\n",
      "Epoch: 14305, MSE: 0.2378693370442597, Learning Rate: 0.028474999999999997\n",
      "Epoch: 14306, MSE: 0.23786654919755695, Learning Rate: 0.028469999999999995\n",
      "Epoch: 14307, MSE: 0.2378637613172836, Learning Rate: 0.028464999999999997\n",
      "Epoch: 14308, MSE: 0.23786097340344564, Learning Rate: 0.02846\n",
      "Epoch: 14309, MSE: 0.23785818545605003, Learning Rate: 0.028454999999999998\n",
      "Epoch: 14310, MSE: 0.23785539747510434, Learning Rate: 0.02845\n",
      "Epoch: 14311, MSE: 0.23785260946061407, Learning Rate: 0.028444999999999998\n",
      "Epoch: 14312, MSE: 0.23784982141258623, Learning Rate: 0.02844\n",
      "Epoch: 14313, MSE: 0.23784703333102766, Learning Rate: 0.028435000000000002\n",
      "Epoch: 14314, MSE: 0.23784424521594444, Learning Rate: 0.02843\n",
      "Epoch: 14315, MSE: 0.23784145706734403, Learning Rate: 0.028425000000000002\n",
      "Epoch: 14316, MSE: 0.2378386688852329, Learning Rate: 0.02842\n",
      "Epoch: 14317, MSE: 0.23783588066961608, Learning Rate: 0.028415000000000003\n",
      "Epoch: 14318, MSE: 0.23783309242050268, Learning Rate: 0.028410000000000005\n",
      "Epoch: 14319, MSE: 0.2378303041378979, Learning Rate: 0.028405000000000003\n",
      "Epoch: 14320, MSE: 0.23782751582180908, Learning Rate: 0.028400000000000005\n",
      "Epoch: 14321, MSE: 0.23782472747224256, Learning Rate: 0.028395000000000004\n",
      "Epoch: 14322, MSE: 0.23782193908920488, Learning Rate: 0.028390000000000006\n",
      "Epoch: 14323, MSE: 0.23781915067270323, Learning Rate: 0.028385000000000007\n",
      "Epoch: 14324, MSE: 0.23781636222274347, Learning Rate: 0.028380000000000006\n",
      "Epoch: 14325, MSE: 0.23781357373933318, Learning Rate: 0.028374999999999997\n",
      "Epoch: 14326, MSE: 0.2378107852224788, Learning Rate: 0.028369999999999996\n",
      "Epoch: 14327, MSE: 0.2378079966721871, Learning Rate: 0.028364999999999998\n",
      "Epoch: 14328, MSE: 0.23780520808846414, Learning Rate: 0.028359999999999996\n",
      "Epoch: 14329, MSE: 0.23780241947131747, Learning Rate: 0.028354999999999998\n",
      "Epoch: 14330, MSE: 0.23779963082075237, Learning Rate: 0.02835\n",
      "Epoch: 14331, MSE: 0.237796842136778, Learning Rate: 0.028345\n",
      "Epoch: 14332, MSE: 0.23779405341939866, Learning Rate: 0.02834\n",
      "Epoch: 14333, MSE: 0.23779126466862263, Learning Rate: 0.028335\n",
      "Epoch: 14334, MSE: 0.23778847588445534, Learning Rate: 0.02833\n",
      "Epoch: 14335, MSE: 0.23778568706690587, Learning Rate: 0.028325000000000003\n",
      "Epoch: 14336, MSE: 0.2377828982159776, Learning Rate: 0.02832\n",
      "Epoch: 14337, MSE: 0.23778010933167992, Learning Rate: 0.028315000000000003\n",
      "Epoch: 14338, MSE: 0.23777732041401817, Learning Rate: 0.028310000000000002\n",
      "Epoch: 14339, MSE: 0.23777453146300084, Learning Rate: 0.028305000000000004\n",
      "Epoch: 14340, MSE: 0.23777174247863225, Learning Rate: 0.028300000000000006\n",
      "Epoch: 14341, MSE: 0.23776895346092095, Learning Rate: 0.028295000000000004\n",
      "Epoch: 14342, MSE: 0.23776616440987244, Learning Rate: 0.028290000000000006\n",
      "Epoch: 14343, MSE: 0.23776337532549455, Learning Rate: 0.028285000000000005\n",
      "Epoch: 14344, MSE: 0.23776058620779428, Learning Rate: 0.028280000000000007\n",
      "Epoch: 14345, MSE: 0.23775779705677738, Learning Rate: 0.028274999999999995\n",
      "Epoch: 14346, MSE: 0.23775500787245107, Learning Rate: 0.028269999999999997\n",
      "Epoch: 14347, MSE: 0.23775221865482193, Learning Rate: 0.028265\n",
      "Epoch: 14348, MSE: 0.23774942940389743, Learning Rate: 0.028259999999999997\n",
      "Epoch: 14349, MSE: 0.23774664011968286, Learning Rate: 0.028255\n",
      "Epoch: 14350, MSE: 0.2377438508021866, Learning Rate: 0.028249999999999997\n",
      "Epoch: 14351, MSE: 0.2377410614514154, Learning Rate: 0.028245\n",
      "Epoch: 14352, MSE: 0.23773827206737425, Learning Rate: 0.02824\n",
      "Epoch: 14353, MSE: 0.23773548265007252, Learning Rate: 0.028235\n",
      "Epoch: 14354, MSE: 0.23773269319951532, Learning Rate: 0.02823\n",
      "Epoch: 14355, MSE: 0.23772990371570973, Learning Rate: 0.028225\n",
      "Epoch: 14356, MSE: 0.2377271141986632, Learning Rate: 0.028220000000000002\n",
      "Epoch: 14357, MSE: 0.23772432464838186, Learning Rate: 0.028215000000000004\n",
      "Epoch: 14358, MSE: 0.2377215350648719, Learning Rate: 0.028210000000000002\n",
      "Epoch: 14359, MSE: 0.23771874544814203, Learning Rate: 0.028205000000000004\n",
      "Epoch: 14360, MSE: 0.2377159557981975, Learning Rate: 0.028200000000000003\n",
      "Epoch: 14361, MSE: 0.23771316611504634, Learning Rate: 0.028195000000000005\n",
      "Epoch: 14362, MSE: 0.23771037639869486, Learning Rate: 0.028190000000000007\n",
      "Epoch: 14363, MSE: 0.2377075866491499, Learning Rate: 0.028185000000000005\n",
      "Epoch: 14364, MSE: 0.23770479686641705, Learning Rate: 0.028180000000000007\n",
      "Epoch: 14365, MSE: 0.23770200705050595, Learning Rate: 0.028174999999999995\n",
      "Epoch: 14366, MSE: 0.2376992172014205, Learning Rate: 0.028169999999999997\n",
      "Epoch: 14367, MSE: 0.2376964273191699, Learning Rate: 0.028164999999999996\n",
      "Epoch: 14368, MSE: 0.2376936374037597, Learning Rate: 0.028159999999999998\n",
      "Epoch: 14369, MSE: 0.23769084745519697, Learning Rate: 0.028155\n",
      "Epoch: 14370, MSE: 0.23768805747348956, Learning Rate: 0.028149999999999998\n",
      "Epoch: 14371, MSE: 0.2376852674586429, Learning Rate: 0.028145\n",
      "Epoch: 14372, MSE: 0.2376824774106651, Learning Rate: 0.02814\n",
      "Epoch: 14373, MSE: 0.2376796873295622, Learning Rate: 0.028135\n",
      "Epoch: 14374, MSE: 0.2376768972153415, Learning Rate: 0.028130000000000002\n",
      "Epoch: 14375, MSE: 0.23767410706800937, Learning Rate: 0.028125\n",
      "Epoch: 14376, MSE: 0.23767131688757456, Learning Rate: 0.028120000000000003\n",
      "Epoch: 14377, MSE: 0.2376685266740414, Learning Rate: 0.028115\n",
      "Epoch: 14378, MSE: 0.23766573642741778, Learning Rate: 0.028110000000000003\n",
      "Epoch: 14379, MSE: 0.23766294614771163, Learning Rate: 0.028105000000000005\n",
      "Epoch: 14380, MSE: 0.23766015583492872, Learning Rate: 0.028100000000000003\n",
      "Epoch: 14381, MSE: 0.23765736548907634, Learning Rate: 0.028095000000000005\n",
      "Epoch: 14382, MSE: 0.23765457511016133, Learning Rate: 0.028090000000000004\n",
      "Epoch: 14383, MSE: 0.23765178469819073, Learning Rate: 0.028085000000000006\n",
      "Epoch: 14384, MSE: 0.23764899425317212, Learning Rate: 0.028080000000000008\n",
      "Epoch: 14385, MSE: 0.23764620377511123, Learning Rate: 0.028075000000000006\n",
      "Epoch: 14386, MSE: 0.23764341326401553, Learning Rate: 0.028069999999999998\n",
      "Epoch: 14387, MSE: 0.23764062271989234, Learning Rate: 0.028064999999999996\n",
      "Epoch: 14388, MSE: 0.23763783214274883, Learning Rate: 0.028059999999999998\n",
      "Epoch: 14389, MSE: 0.23763504153259035, Learning Rate: 0.028054999999999997\n",
      "Epoch: 14390, MSE: 0.23763225088942616, Learning Rate: 0.02805\n",
      "Epoch: 14391, MSE: 0.2376294602132614, Learning Rate: 0.028045\n",
      "Epoch: 14392, MSE: 0.2376266695041037, Learning Rate: 0.02804\n",
      "Epoch: 14393, MSE: 0.23762387876195992, Learning Rate: 0.028035\n",
      "Epoch: 14394, MSE: 0.23762108798683756, Learning Rate: 0.02803\n",
      "Epoch: 14395, MSE: 0.23761829717874297, Learning Rate: 0.028025\n",
      "Epoch: 14396, MSE: 0.2376155063376833, Learning Rate: 0.028020000000000003\n",
      "Epoch: 14397, MSE: 0.23761271546366614, Learning Rate: 0.028015\n",
      "Epoch: 14398, MSE: 0.23760992455669736, Learning Rate: 0.028010000000000004\n",
      "Epoch: 14399, MSE: 0.23760713361678562, Learning Rate: 0.028005000000000002\n",
      "Epoch: 14400, MSE: 0.23760434264393712, Learning Rate: 0.028000000000000004\n",
      "Epoch: 14401, MSE: 0.23760155163815744, Learning Rate: 0.027995000000000006\n",
      "Epoch: 14402, MSE: 0.23759876059945542, Learning Rate: 0.027990000000000004\n",
      "Epoch: 14403, MSE: 0.23759596952783743, Learning Rate: 0.027985000000000006\n",
      "Epoch: 14404, MSE: 0.23759317842331015, Learning Rate: 0.027980000000000005\n",
      "Epoch: 14405, MSE: 0.2375903872858822, Learning Rate: 0.027975000000000007\n",
      "Epoch: 14406, MSE: 0.23758759611555896, Learning Rate: 0.027969999999999995\n",
      "Epoch: 14407, MSE: 0.23758480491234835, Learning Rate: 0.027964999999999997\n",
      "Epoch: 14408, MSE: 0.23758201367625664, Learning Rate: 0.02796\n",
      "Epoch: 14409, MSE: 0.23757922240729162, Learning Rate: 0.027954999999999997\n",
      "Epoch: 14410, MSE: 0.23757643110545973, Learning Rate: 0.02795\n",
      "Epoch: 14411, MSE: 0.23757363977076876, Learning Rate: 0.027944999999999998\n",
      "Epoch: 14412, MSE: 0.23757084840322526, Learning Rate: 0.02794\n",
      "Epoch: 14413, MSE: 0.23756805700283626, Learning Rate: 0.027935\n",
      "Epoch: 14414, MSE: 0.23756526556960902, Learning Rate: 0.02793\n",
      "Epoch: 14415, MSE: 0.2375624741035508, Learning Rate: 0.027925000000000002\n",
      "Epoch: 14416, MSE: 0.23755968260466792, Learning Rate: 0.02792\n",
      "Epoch: 14417, MSE: 0.23755689107296876, Learning Rate: 0.027915000000000002\n",
      "Epoch: 14418, MSE: 0.23755409950845938, Learning Rate: 0.027910000000000004\n",
      "Epoch: 14419, MSE: 0.23755130791114762, Learning Rate: 0.027905000000000003\n",
      "Epoch: 14420, MSE: 0.23754851628103932, Learning Rate: 0.027900000000000005\n",
      "Epoch: 14421, MSE: 0.2375457246181439, Learning Rate: 0.027895000000000003\n",
      "Epoch: 14422, MSE: 0.23754293292246606, Learning Rate: 0.027890000000000005\n",
      "Epoch: 14423, MSE: 0.2375401411940136, Learning Rate: 0.027885000000000007\n",
      "Epoch: 14424, MSE: 0.23753734943279467, Learning Rate: 0.027880000000000005\n",
      "Epoch: 14425, MSE: 0.23753455763881542, Learning Rate: 0.027875000000000007\n",
      "Epoch: 14426, MSE: 0.23753176581208296, Learning Rate: 0.027869999999999995\n",
      "Epoch: 14427, MSE: 0.23752897395260547, Learning Rate: 0.027864999999999997\n",
      "Epoch: 14428, MSE: 0.2375261820603884, Learning Rate: 0.027859999999999996\n",
      "Epoch: 14429, MSE: 0.2375233901354402, Learning Rate: 0.027854999999999998\n",
      "Epoch: 14430, MSE: 0.23752059817776766, Learning Rate: 0.02785\n",
      "Epoch: 14431, MSE: 0.2375178061873778, Learning Rate: 0.027844999999999998\n",
      "Epoch: 14432, MSE: 0.23751501416427792, Learning Rate: 0.02784\n",
      "Epoch: 14433, MSE: 0.23751222210847497, Learning Rate: 0.027835\n",
      "Epoch: 14434, MSE: 0.23750943001997651, Learning Rate: 0.02783\n",
      "Epoch: 14435, MSE: 0.23750663789878987, Learning Rate: 0.027825000000000003\n",
      "Epoch: 14436, MSE: 0.2375038457449215, Learning Rate: 0.02782\n",
      "Epoch: 14437, MSE: 0.23750105355837964, Learning Rate: 0.027815000000000003\n",
      "Epoch: 14438, MSE: 0.23749826133917085, Learning Rate: 0.02781\n",
      "Epoch: 14439, MSE: 0.23749546908730038, Learning Rate: 0.027805000000000003\n",
      "Epoch: 14440, MSE: 0.2374926768027784, Learning Rate: 0.027800000000000005\n",
      "Epoch: 14441, MSE: 0.2374898844856116, Learning Rate: 0.027795000000000004\n",
      "Epoch: 14442, MSE: 0.2374870921358064, Learning Rate: 0.027790000000000006\n",
      "Epoch: 14443, MSE: 0.23748429975336963, Learning Rate: 0.027785000000000004\n",
      "Epoch: 14444, MSE: 0.23748150733831003, Learning Rate: 0.027780000000000006\n",
      "Epoch: 14445, MSE: 0.2374787148906334, Learning Rate: 0.027775000000000008\n",
      "Epoch: 14446, MSE: 0.23747592241034776, Learning Rate: 0.027769999999999996\n",
      "Epoch: 14447, MSE: 0.23747312989745994, Learning Rate: 0.027764999999999998\n",
      "Epoch: 14448, MSE: 0.23747033735197737, Learning Rate: 0.027759999999999996\n",
      "Epoch: 14449, MSE: 0.23746754477390697, Learning Rate: 0.027755\n",
      "Epoch: 14450, MSE: 0.23746475216325627, Learning Rate: 0.027749999999999997\n",
      "Epoch: 14451, MSE: 0.2374619595200325, Learning Rate: 0.027745\n",
      "Epoch: 14452, MSE: 0.2374591668442434, Learning Rate: 0.02774\n",
      "Epoch: 14453, MSE: 0.23745637413589524, Learning Rate: 0.027735\n",
      "Epoch: 14454, MSE: 0.23745358139499634, Learning Rate: 0.02773\n",
      "Epoch: 14455, MSE: 0.23745078862155272, Learning Rate: 0.027725\n",
      "Epoch: 14456, MSE: 0.23744799581557255, Learning Rate: 0.02772\n",
      "Epoch: 14457, MSE: 0.23744520297706284, Learning Rate: 0.027715000000000004\n",
      "Epoch: 14458, MSE: 0.23744241010603154, Learning Rate: 0.027710000000000002\n",
      "Epoch: 14459, MSE: 0.23743961720248422, Learning Rate: 0.027705000000000004\n",
      "Epoch: 14460, MSE: 0.23743682426643045, Learning Rate: 0.027700000000000002\n",
      "Epoch: 14461, MSE: 0.2374340312978754, Learning Rate: 0.027695000000000004\n",
      "Epoch: 14462, MSE: 0.23743123829682838, Learning Rate: 0.027690000000000006\n",
      "Epoch: 14463, MSE: 0.2374284452632951, Learning Rate: 0.027685000000000005\n",
      "Epoch: 14464, MSE: 0.23742565219728348, Learning Rate: 0.027680000000000007\n",
      "Epoch: 14465, MSE: 0.23742285909880115, Learning Rate: 0.027675000000000005\n",
      "Epoch: 14466, MSE: 0.2374200659678547, Learning Rate: 0.027669999999999997\n",
      "Epoch: 14467, MSE: 0.237417272804452, Learning Rate: 0.027664999999999995\n",
      "Epoch: 14468, MSE: 0.23741447960860024, Learning Rate: 0.027659999999999997\n",
      "Epoch: 14469, MSE: 0.2374116863803061, Learning Rate: 0.027655\n",
      "Epoch: 14470, MSE: 0.2374088931195782, Learning Rate: 0.027649999999999997\n",
      "Epoch: 14471, MSE: 0.23740609982642316, Learning Rate: 0.027645\n",
      "Epoch: 14472, MSE: 0.2374033065008487, Learning Rate: 0.027639999999999998\n",
      "Epoch: 14473, MSE: 0.2374005131428613, Learning Rate: 0.027635\n",
      "Epoch: 14474, MSE: 0.2373977197524696, Learning Rate: 0.027630000000000002\n",
      "Epoch: 14475, MSE: 0.2373949263296797, Learning Rate: 0.027625\n",
      "Epoch: 14476, MSE: 0.2373921328744999, Learning Rate: 0.027620000000000002\n",
      "Epoch: 14477, MSE: 0.23738933938693713, Learning Rate: 0.027615\n",
      "Epoch: 14478, MSE: 0.23738654586699923, Learning Rate: 0.027610000000000003\n",
      "Epoch: 14479, MSE: 0.23738375231469278, Learning Rate: 0.027605000000000005\n",
      "Epoch: 14480, MSE: 0.23738095873002585, Learning Rate: 0.027600000000000003\n",
      "Epoch: 14481, MSE: 0.2373781651130065, Learning Rate: 0.027595000000000005\n",
      "Epoch: 14482, MSE: 0.23737537146363918, Learning Rate: 0.027590000000000003\n",
      "Epoch: 14483, MSE: 0.23737257778193502, Learning Rate: 0.027585000000000005\n",
      "Epoch: 14484, MSE: 0.23736978406789921, Learning Rate: 0.027580000000000007\n",
      "Epoch: 14485, MSE: 0.23736699032153974, Learning Rate: 0.027575000000000006\n",
      "Epoch: 14486, MSE: 0.2373641965428637, Learning Rate: 0.027569999999999997\n",
      "Epoch: 14487, MSE: 0.2373614027318797, Learning Rate: 0.027564999999999996\n",
      "Epoch: 14488, MSE: 0.23735860888859356, Learning Rate: 0.027559999999999998\n",
      "Epoch: 14489, MSE: 0.23735581501301348, Learning Rate: 0.027554999999999996\n",
      "Epoch: 14490, MSE: 0.23735302110514764, Learning Rate: 0.027549999999999998\n",
      "Epoch: 14491, MSE: 0.23735022716500215, Learning Rate: 0.027545\n",
      "Epoch: 14492, MSE: 0.2373474331925847, Learning Rate: 0.02754\n",
      "Epoch: 14493, MSE: 0.23734463918790405, Learning Rate: 0.027535\n",
      "Epoch: 14494, MSE: 0.23734184515096668, Learning Rate: 0.02753\n",
      "Epoch: 14495, MSE: 0.23733905108177922, Learning Rate: 0.027525\n",
      "Epoch: 14496, MSE: 0.2373362569803504, Learning Rate: 0.027520000000000003\n",
      "Epoch: 14497, MSE: 0.23733346284668763, Learning Rate: 0.027515\n",
      "Epoch: 14498, MSE: 0.23733066868079747, Learning Rate: 0.027510000000000003\n",
      "Epoch: 14499, MSE: 0.23732787448268894, Learning Rate: 0.027505\n",
      "Epoch: 14500, MSE: 0.23732508025236682, Learning Rate: 0.027500000000000004\n",
      "Epoch: 14501, MSE: 0.2373222859898415, Learning Rate: 0.027495000000000006\n",
      "Epoch: 14502, MSE: 0.23731949169511965, Learning Rate: 0.027490000000000004\n",
      "Epoch: 14503, MSE: 0.2373166973682084, Learning Rate: 0.027485000000000006\n",
      "Epoch: 14504, MSE: 0.23731390300911448, Learning Rate: 0.027480000000000004\n",
      "Epoch: 14505, MSE: 0.23731110861784666, Learning Rate: 0.027475000000000006\n",
      "Epoch: 14506, MSE: 0.23730831419441215, Learning Rate: 0.02747000000000001\n",
      "Epoch: 14507, MSE: 0.23730551973881928, Learning Rate: 0.027464999999999996\n",
      "Epoch: 14508, MSE: 0.2373027252510739, Learning Rate: 0.02746\n",
      "Epoch: 14509, MSE: 0.23729993073118397, Learning Rate: 0.027454999999999997\n",
      "Epoch: 14510, MSE: 0.23729713617915763, Learning Rate: 0.02745\n",
      "Epoch: 14511, MSE: 0.2372943415950026, Learning Rate: 0.027444999999999997\n",
      "Epoch: 14512, MSE: 0.23729154697872587, Learning Rate: 0.02744\n",
      "Epoch: 14513, MSE: 0.2372887523303351, Learning Rate: 0.027435\n",
      "Epoch: 14514, MSE: 0.23728595764983781, Learning Rate: 0.02743\n",
      "Epoch: 14515, MSE: 0.23728316293724133, Learning Rate: 0.027425\n",
      "Epoch: 14516, MSE: 0.23728036819255457, Learning Rate: 0.02742\n",
      "Epoch: 14517, MSE: 0.23727757341578365, Learning Rate: 0.027415000000000002\n",
      "Epoch: 14518, MSE: 0.2372747786069364, Learning Rate: 0.027410000000000004\n",
      "Epoch: 14519, MSE: 0.23727198376602068, Learning Rate: 0.027405000000000002\n",
      "Epoch: 14520, MSE: 0.23726918889304385, Learning Rate: 0.027400000000000004\n",
      "Epoch: 14521, MSE: 0.2372663939880139, Learning Rate: 0.027395000000000003\n",
      "Epoch: 14522, MSE: 0.2372635990509383, Learning Rate: 0.027390000000000005\n",
      "Epoch: 14523, MSE: 0.2372608040818242, Learning Rate: 0.027385000000000007\n",
      "Epoch: 14524, MSE: 0.23725800908067984, Learning Rate: 0.027380000000000005\n",
      "Epoch: 14525, MSE: 0.23725521404751249, Learning Rate: 0.027375000000000007\n",
      "Epoch: 14526, MSE: 0.23725241898233063, Learning Rate: 0.027370000000000005\n",
      "Epoch: 14527, MSE: 0.2372496238851394, Learning Rate: 0.027364999999999997\n",
      "Epoch: 14528, MSE: 0.2372468287559495, Learning Rate: 0.027359999999999995\n",
      "Epoch: 14529, MSE: 0.23724403359476703, Learning Rate: 0.027354999999999997\n",
      "Epoch: 14530, MSE: 0.2372412384015998, Learning Rate: 0.02735\n",
      "Epoch: 14531, MSE: 0.23723844317645523, Learning Rate: 0.027344999999999998\n",
      "Epoch: 14532, MSE: 0.23723564791934154, Learning Rate: 0.02734\n",
      "Epoch: 14533, MSE: 0.23723285263026578, Learning Rate: 0.027334999999999998\n",
      "Epoch: 14534, MSE: 0.23723005730923602, Learning Rate: 0.02733\n",
      "Epoch: 14535, MSE: 0.23722726195625984, Learning Rate: 0.027325000000000002\n",
      "Epoch: 14536, MSE: 0.23722446657134516, Learning Rate: 0.02732\n",
      "Epoch: 14537, MSE: 0.23722167115449924, Learning Rate: 0.027315000000000002\n",
      "Epoch: 14538, MSE: 0.23721887570572986, Learning Rate: 0.02731\n",
      "Epoch: 14539, MSE: 0.23721608022504456, Learning Rate: 0.027305000000000003\n",
      "Epoch: 14540, MSE: 0.2372132847124513, Learning Rate: 0.027300000000000005\n",
      "Epoch: 14541, MSE: 0.23721048916795823, Learning Rate: 0.027295000000000003\n",
      "Epoch: 14542, MSE: 0.2372076935915723, Learning Rate: 0.027290000000000005\n",
      "Epoch: 14543, MSE: 0.23720489798330124, Learning Rate: 0.027285000000000004\n",
      "Epoch: 14544, MSE: 0.2372021023431531, Learning Rate: 0.027280000000000006\n",
      "Epoch: 14545, MSE: 0.237199306671136, Learning Rate: 0.027275000000000008\n",
      "Epoch: 14546, MSE: 0.23719651096725616, Learning Rate: 0.027270000000000006\n",
      "Epoch: 14547, MSE: 0.23719371523152408, Learning Rate: 0.027264999999999998\n",
      "Epoch: 14548, MSE: 0.23719091946394436, Learning Rate: 0.027259999999999996\n",
      "Epoch: 14549, MSE: 0.2371881236645262, Learning Rate: 0.027254999999999998\n",
      "Epoch: 14550, MSE: 0.23718532783327745, Learning Rate: 0.027249999999999996\n",
      "Epoch: 14551, MSE: 0.237182531970206, Learning Rate: 0.027245\n",
      "Epoch: 14552, MSE: 0.2371797360753191, Learning Rate: 0.02724\n",
      "Epoch: 14553, MSE: 0.23717694014862437, Learning Rate: 0.027235\n",
      "Epoch: 14554, MSE: 0.23717414419013144, Learning Rate: 0.02723\n",
      "Epoch: 14555, MSE: 0.23717134819984498, Learning Rate: 0.027225\n",
      "Epoch: 14556, MSE: 0.23716855217777508, Learning Rate: 0.02722\n",
      "Epoch: 14557, MSE: 0.23716575612392796, Learning Rate: 0.027215000000000003\n",
      "Epoch: 14558, MSE: 0.2371629600383136, Learning Rate: 0.02721\n",
      "Epoch: 14559, MSE: 0.23716016392093753, Learning Rate: 0.027205000000000003\n",
      "Epoch: 14560, MSE: 0.23715736777180849, Learning Rate: 0.027200000000000002\n",
      "Epoch: 14561, MSE: 0.23715457159093523, Learning Rate: 0.027195000000000004\n",
      "Epoch: 14562, MSE: 0.23715177537832385, Learning Rate: 0.027190000000000006\n",
      "Epoch: 14563, MSE: 0.23714897913398283, Learning Rate: 0.027185000000000004\n",
      "Epoch: 14564, MSE: 0.23714618285792058, Learning Rate: 0.027180000000000006\n",
      "Epoch: 14565, MSE: 0.23714338655014422, Learning Rate: 0.027175000000000005\n",
      "Epoch: 14566, MSE: 0.23714059021066172, Learning Rate: 0.027170000000000007\n",
      "Epoch: 14567, MSE: 0.23713779383948164, Learning Rate: 0.027164999999999995\n",
      "Epoch: 14568, MSE: 0.23713499743661035, Learning Rate: 0.027159999999999997\n",
      "Epoch: 14569, MSE: 0.237132201002057, Learning Rate: 0.027155\n",
      "Epoch: 14570, MSE: 0.23712940453582942, Learning Rate: 0.027149999999999997\n",
      "Epoch: 14571, MSE: 0.23712660803793464, Learning Rate: 0.027145\n",
      "Epoch: 14572, MSE: 0.23712381150838135, Learning Rate: 0.027139999999999997\n",
      "Epoch: 14573, MSE: 0.2371210149471763, Learning Rate: 0.027135\n",
      "Epoch: 14574, MSE: 0.23711821835432834, Learning Rate: 0.02713\n",
      "Epoch: 14575, MSE: 0.2371154217298454, Learning Rate: 0.027125\n",
      "Epoch: 14576, MSE: 0.23711262507373496, Learning Rate: 0.027120000000000002\n",
      "Epoch: 14577, MSE: 0.237109828386005, Learning Rate: 0.027115\n",
      "Epoch: 14578, MSE: 0.23710703166666353, Learning Rate: 0.027110000000000002\n",
      "Epoch: 14579, MSE: 0.23710423491571797, Learning Rate: 0.027105000000000004\n",
      "Epoch: 14580, MSE: 0.2371014381331767, Learning Rate: 0.027100000000000003\n",
      "Epoch: 14581, MSE: 0.23709864131904757, Learning Rate: 0.027095000000000004\n",
      "Epoch: 14582, MSE: 0.23709584447333906, Learning Rate: 0.027090000000000003\n",
      "Epoch: 14583, MSE: 0.2370930475960586, Learning Rate: 0.027085000000000005\n",
      "Epoch: 14584, MSE: 0.23709025068721346, Learning Rate: 0.027080000000000007\n",
      "Epoch: 14585, MSE: 0.2370874537468124, Learning Rate: 0.027075000000000005\n",
      "Epoch: 14586, MSE: 0.2370846567748631, Learning Rate: 0.027070000000000007\n",
      "Epoch: 14587, MSE: 0.237081859771374, Learning Rate: 0.027064999999999995\n",
      "Epoch: 14588, MSE: 0.23707906273635213, Learning Rate: 0.027059999999999997\n",
      "Epoch: 14589, MSE: 0.23707626566980605, Learning Rate: 0.027054999999999996\n",
      "Epoch: 14590, MSE: 0.23707346857174388, Learning Rate: 0.027049999999999998\n",
      "Epoch: 14591, MSE: 0.23707067144217273, Learning Rate: 0.027045\n",
      "Epoch: 14592, MSE: 0.23706787428110207, Learning Rate: 0.027039999999999998\n",
      "Epoch: 14593, MSE: 0.23706507708853838, Learning Rate: 0.027035\n",
      "Epoch: 14594, MSE: 0.23706227986449074, Learning Rate: 0.02703\n",
      "Epoch: 14595, MSE: 0.23705948260896628, Learning Rate: 0.027025\n",
      "Epoch: 14596, MSE: 0.237056685321973, Learning Rate: 0.027020000000000002\n",
      "Epoch: 14597, MSE: 0.2370538880035197, Learning Rate: 0.027015\n",
      "Epoch: 14598, MSE: 0.23705109065361377, Learning Rate: 0.027010000000000003\n",
      "Epoch: 14599, MSE: 0.23704829327226343, Learning Rate: 0.027005\n",
      "Epoch: 14600, MSE: 0.23704549585947743, Learning Rate: 0.027000000000000003\n",
      "Epoch: 14601, MSE: 0.23704269841526274, Learning Rate: 0.026995000000000005\n",
      "Epoch: 14602, MSE: 0.23703990093962723, Learning Rate: 0.026990000000000004\n",
      "Epoch: 14603, MSE: 0.23703710343257958, Learning Rate: 0.026985000000000006\n",
      "Epoch: 14604, MSE: 0.23703430589412783, Learning Rate: 0.026980000000000004\n",
      "Epoch: 14605, MSE: 0.23703150832427988, Learning Rate: 0.026975000000000006\n",
      "Epoch: 14606, MSE: 0.23702871072304416, Learning Rate: 0.026970000000000008\n",
      "Epoch: 14607, MSE: 0.23702591309042778, Learning Rate: 0.026964999999999996\n",
      "Epoch: 14608, MSE: 0.23702311542644036, Learning Rate: 0.026959999999999998\n",
      "Epoch: 14609, MSE: 0.23702031773108806, Learning Rate: 0.026954999999999996\n",
      "Epoch: 14610, MSE: 0.23701752000438003, Learning Rate: 0.026949999999999998\n",
      "Epoch: 14611, MSE: 0.23701472224632422, Learning Rate: 0.026944999999999997\n",
      "Epoch: 14612, MSE: 0.23701192445692917, Learning Rate: 0.02694\n",
      "Epoch: 14613, MSE: 0.23700912663620288, Learning Rate: 0.026935\n",
      "Epoch: 14614, MSE: 0.23700632878415231, Learning Rate: 0.02693\n",
      "Epoch: 14615, MSE: 0.23700353090078644, Learning Rate: 0.026925\n",
      "Epoch: 14616, MSE: 0.23700073298611377, Learning Rate: 0.02692\n",
      "Epoch: 14617, MSE: 0.23699793504014155, Learning Rate: 0.026915\n",
      "Epoch: 14618, MSE: 0.23699513706287823, Learning Rate: 0.026910000000000003\n",
      "Epoch: 14619, MSE: 0.23699233905433273, Learning Rate: 0.026905000000000002\n",
      "Epoch: 14620, MSE: 0.236989541014512, Learning Rate: 0.026900000000000004\n",
      "Epoch: 14621, MSE: 0.2369867429434248, Learning Rate: 0.026895000000000002\n",
      "Epoch: 14622, MSE: 0.2369839448410791, Learning Rate: 0.026890000000000004\n",
      "Epoch: 14623, MSE: 0.2369811467074823, Learning Rate: 0.026885000000000006\n",
      "Epoch: 14624, MSE: 0.23697834854264435, Learning Rate: 0.026880000000000005\n",
      "Epoch: 14625, MSE: 0.23697555034657242, Learning Rate: 0.026875000000000007\n",
      "Epoch: 14626, MSE: 0.23697275211927457, Learning Rate: 0.026870000000000005\n",
      "Epoch: 14627, MSE: 0.23696995386075903, Learning Rate: 0.026865000000000007\n",
      "Epoch: 14628, MSE: 0.23696715557103393, Learning Rate: 0.026859999999999995\n",
      "Epoch: 14629, MSE: 0.2369643572501074, Learning Rate: 0.026854999999999997\n",
      "Epoch: 14630, MSE: 0.23696155889798834, Learning Rate: 0.02685\n",
      "Epoch: 14631, MSE: 0.23695876051468417, Learning Rate: 0.026844999999999997\n",
      "Epoch: 14632, MSE: 0.2369559621002031, Learning Rate: 0.02684\n",
      "Epoch: 14633, MSE: 0.23695316365455354, Learning Rate: 0.026834999999999998\n",
      "Epoch: 14634, MSE: 0.2369503651777436, Learning Rate: 0.02683\n",
      "Epoch: 14635, MSE: 0.23694756666978264, Learning Rate: 0.026825\n",
      "Epoch: 14636, MSE: 0.23694476813067689, Learning Rate: 0.02682\n",
      "Epoch: 14637, MSE: 0.23694196956043576, Learning Rate: 0.026815000000000002\n",
      "Epoch: 14638, MSE: 0.23693917095906777, Learning Rate: 0.02681\n",
      "Epoch: 14639, MSE: 0.2369363723265809, Learning Rate: 0.026805000000000002\n",
      "Epoch: 14640, MSE: 0.2369335736629829, Learning Rate: 0.026800000000000004\n",
      "Epoch: 14641, MSE: 0.23693077496828216, Learning Rate: 0.026795000000000003\n",
      "Epoch: 14642, MSE: 0.23692797624248704, Learning Rate: 0.026790000000000005\n",
      "Epoch: 14643, MSE: 0.23692517748560643, Learning Rate: 0.026785000000000003\n",
      "Epoch: 14644, MSE: 0.23692237869764735, Learning Rate: 0.026780000000000005\n",
      "Epoch: 14645, MSE: 0.23691957987861945, Learning Rate: 0.026775000000000007\n",
      "Epoch: 14646, MSE: 0.23691678102852962, Learning Rate: 0.026770000000000006\n",
      "Epoch: 14647, MSE: 0.23691398214738743, Learning Rate: 0.026765000000000008\n",
      "Epoch: 14648, MSE: 0.23691118323520047, Learning Rate: 0.026759999999999996\n",
      "Epoch: 14649, MSE: 0.2369083842919776, Learning Rate: 0.026754999999999998\n",
      "Epoch: 14650, MSE: 0.23690558531772635, Learning Rate: 0.026749999999999996\n",
      "Epoch: 14651, MSE: 0.23690278631245615, Learning Rate: 0.026744999999999998\n",
      "Epoch: 14652, MSE: 0.2368999872761741, Learning Rate: 0.02674\n",
      "Epoch: 14653, MSE: 0.23689718820888891, Learning Rate: 0.026735\n",
      "Epoch: 14654, MSE: 0.23689438911060925, Learning Rate: 0.02673\n",
      "Epoch: 14655, MSE: 0.236891589981344, Learning Rate: 0.026725\n",
      "Epoch: 14656, MSE: 0.23688879082109957, Learning Rate: 0.02672\n",
      "Epoch: 14657, MSE: 0.23688599162988558, Learning Rate: 0.026715000000000003\n",
      "Epoch: 14658, MSE: 0.23688319240771175, Learning Rate: 0.02671\n",
      "Epoch: 14659, MSE: 0.23688039315458329, Learning Rate: 0.026705000000000003\n",
      "Epoch: 14660, MSE: 0.2368775938705112, Learning Rate: 0.0267\n",
      "Epoch: 14661, MSE: 0.23687479455550275, Learning Rate: 0.026695000000000003\n",
      "Epoch: 14662, MSE: 0.23687199520956695, Learning Rate: 0.026690000000000005\n",
      "Epoch: 14663, MSE: 0.2368691958327106, Learning Rate: 0.026685000000000004\n",
      "Epoch: 14664, MSE: 0.2368663964249453, Learning Rate: 0.026680000000000006\n",
      "Epoch: 14665, MSE: 0.23686359698627568, Learning Rate: 0.026675000000000004\n",
      "Epoch: 14666, MSE: 0.23686079751671227, Learning Rate: 0.026670000000000006\n",
      "Epoch: 14667, MSE: 0.23685799801626362, Learning Rate: 0.026665000000000008\n",
      "Epoch: 14668, MSE: 0.2368551984849369, Learning Rate: 0.026659999999999996\n",
      "Epoch: 14669, MSE: 0.2368523989227419, Learning Rate: 0.026654999999999998\n",
      "Epoch: 14670, MSE: 0.23684959932968583, Learning Rate: 0.026649999999999997\n",
      "Epoch: 14671, MSE: 0.2368467997057784, Learning Rate: 0.026645\n",
      "Epoch: 14672, MSE: 0.23684400005102677, Learning Rate: 0.026639999999999997\n",
      "Epoch: 14673, MSE: 0.23684120036543993, Learning Rate: 0.026635\n",
      "Epoch: 14674, MSE: 0.23683840064902695, Learning Rate: 0.02663\n",
      "Epoch: 14675, MSE: 0.23683560090179534, Learning Rate: 0.026625\n",
      "Epoch: 14676, MSE: 0.23683280112375404, Learning Rate: 0.02662\n",
      "Epoch: 14677, MSE: 0.23683000131491175, Learning Rate: 0.026615\n",
      "Epoch: 14678, MSE: 0.23682720147527603, Learning Rate: 0.02661\n",
      "Epoch: 14679, MSE: 0.23682440160485638, Learning Rate: 0.026605000000000004\n",
      "Epoch: 14680, MSE: 0.23682160170366096, Learning Rate: 0.026600000000000002\n",
      "Epoch: 14681, MSE: 0.236818801771698, Learning Rate: 0.026595000000000004\n",
      "Epoch: 14682, MSE: 0.23681600180897613, Learning Rate: 0.026590000000000003\n",
      "Epoch: 14683, MSE: 0.23681320181550417, Learning Rate: 0.026585000000000004\n",
      "Epoch: 14684, MSE: 0.23681040179129048, Learning Rate: 0.026580000000000006\n",
      "Epoch: 14685, MSE: 0.23680760173634355, Learning Rate: 0.026575000000000005\n",
      "Epoch: 14686, MSE: 0.23680480165067144, Learning Rate: 0.026570000000000007\n",
      "Epoch: 14687, MSE: 0.23680200153428305, Learning Rate: 0.026565000000000005\n",
      "Epoch: 14688, MSE: 0.23679920138718766, Learning Rate: 0.026559999999999997\n",
      "Epoch: 14689, MSE: 0.23679640120939258, Learning Rate: 0.026554999999999995\n",
      "Epoch: 14690, MSE: 0.23679360100090724, Learning Rate: 0.026549999999999997\n",
      "Epoch: 14691, MSE: 0.23679080076173967, Learning Rate: 0.026545\n",
      "Epoch: 14692, MSE: 0.23678800049189852, Learning Rate: 0.026539999999999998\n",
      "Epoch: 14693, MSE: 0.23678520019139246, Learning Rate: 0.026535\n",
      "Epoch: 14694, MSE: 0.2367823998602305, Learning Rate: 0.026529999999999998\n",
      "Epoch: 14695, MSE: 0.2367795994984209, Learning Rate: 0.026525\n",
      "Epoch: 14696, MSE: 0.23677679910597155, Learning Rate: 0.026520000000000002\n",
      "Epoch: 14697, MSE: 0.23677399868289187, Learning Rate: 0.026515\n",
      "Epoch: 14698, MSE: 0.23677119822919107, Learning Rate: 0.026510000000000002\n",
      "Epoch: 14699, MSE: 0.23676839774487599, Learning Rate: 0.026505\n",
      "Epoch: 14700, MSE: 0.2367655972299565, Learning Rate: 0.026500000000000003\n",
      "Epoch: 14701, MSE: 0.23676279668444086, Learning Rate: 0.026495000000000005\n",
      "Epoch: 14702, MSE: 0.23675999610833762, Learning Rate: 0.026490000000000003\n",
      "Epoch: 14703, MSE: 0.2367571955016566, Learning Rate: 0.026485000000000005\n",
      "Epoch: 14704, MSE: 0.23675439486440503, Learning Rate: 0.026480000000000004\n",
      "Epoch: 14705, MSE: 0.23675159419659128, Learning Rate: 0.026475000000000005\n",
      "Epoch: 14706, MSE: 0.23674879349822492, Learning Rate: 0.026470000000000007\n",
      "Epoch: 14707, MSE: 0.23674599276931393, Learning Rate: 0.026465000000000006\n",
      "Epoch: 14708, MSE: 0.23674319200986826, Learning Rate: 0.026459999999999997\n",
      "Epoch: 14709, MSE: 0.23674039121989512, Learning Rate: 0.026454999999999996\n",
      "Epoch: 14710, MSE: 0.23673759039940404, Learning Rate: 0.026449999999999998\n",
      "Epoch: 14711, MSE: 0.23673478954840338, Learning Rate: 0.026444999999999996\n",
      "Epoch: 14712, MSE: 0.23673198866690226, Learning Rate: 0.026439999999999998\n",
      "Epoch: 14713, MSE: 0.2367291877549085, Learning Rate: 0.026435\n",
      "Epoch: 14714, MSE: 0.23672638681243158, Learning Rate: 0.02643\n",
      "Epoch: 14715, MSE: 0.23672358583948025, Learning Rate: 0.026425\n",
      "Epoch: 14716, MSE: 0.2367207848360626, Learning Rate: 0.02642\n",
      "Epoch: 14717, MSE: 0.23671798380218734, Learning Rate: 0.026415\n",
      "Epoch: 14718, MSE: 0.2367151827378644, Learning Rate: 0.026410000000000003\n",
      "Epoch: 14719, MSE: 0.2367123816431012, Learning Rate: 0.026405\n",
      "Epoch: 14720, MSE: 0.23670958051790697, Learning Rate: 0.026400000000000003\n",
      "Epoch: 14721, MSE: 0.23670677936228993, Learning Rate: 0.026395000000000002\n",
      "Epoch: 14722, MSE: 0.23670397817625996, Learning Rate: 0.026390000000000004\n",
      "Epoch: 14723, MSE: 0.23670117695982545, Learning Rate: 0.026385000000000006\n",
      "Epoch: 14724, MSE: 0.23669837571299482, Learning Rate: 0.026380000000000004\n",
      "Epoch: 14725, MSE: 0.236695574435777, Learning Rate: 0.026375000000000006\n",
      "Epoch: 14726, MSE: 0.23669277312818035, Learning Rate: 0.026370000000000005\n",
      "Epoch: 14727, MSE: 0.23668997179021445, Learning Rate: 0.026365000000000006\n",
      "Epoch: 14728, MSE: 0.2366871704218873, Learning Rate: 0.026359999999999995\n",
      "Epoch: 14729, MSE: 0.23668436902320847, Learning Rate: 0.026354999999999996\n",
      "Epoch: 14730, MSE: 0.23668156759418602, Learning Rate: 0.02635\n",
      "Epoch: 14731, MSE: 0.23667876613482894, Learning Rate: 0.026344999999999997\n",
      "Epoch: 14732, MSE: 0.236675964645147, Learning Rate: 0.02634\n",
      "Epoch: 14733, MSE: 0.236673163125148, Learning Rate: 0.026334999999999997\n",
      "Epoch: 14734, MSE: 0.23667036157484067, Learning Rate: 0.02633\n",
      "Epoch: 14735, MSE: 0.2366675599942345, Learning Rate: 0.026325\n",
      "Epoch: 14736, MSE: 0.2366647583833379, Learning Rate: 0.02632\n",
      "Epoch: 14737, MSE: 0.23666195674215992, Learning Rate: 0.026315\n",
      "Epoch: 14738, MSE: 0.23665915507070975, Learning Rate: 0.02631\n",
      "Epoch: 14739, MSE: 0.23665635336899524, Learning Rate: 0.026305000000000002\n",
      "Epoch: 14740, MSE: 0.23665355163702653, Learning Rate: 0.026300000000000004\n",
      "Epoch: 14741, MSE: 0.23665074987481183, Learning Rate: 0.026295000000000002\n",
      "Epoch: 14742, MSE: 0.23664794808235967, Learning Rate: 0.026290000000000004\n",
      "Epoch: 14743, MSE: 0.23664514625967967, Learning Rate: 0.026285000000000003\n",
      "Epoch: 14744, MSE: 0.23664234440678028, Learning Rate: 0.026280000000000005\n",
      "Epoch: 14745, MSE: 0.2366395425236705, Learning Rate: 0.026275000000000007\n",
      "Epoch: 14746, MSE: 0.23663674061035947, Learning Rate: 0.026270000000000005\n",
      "Epoch: 14747, MSE: 0.2366339386668559, Learning Rate: 0.026265000000000007\n",
      "Epoch: 14748, MSE: 0.2366311366931685, Learning Rate: 0.026259999999999995\n",
      "Epoch: 14749, MSE: 0.2366283346893066, Learning Rate: 0.026254999999999997\n",
      "Epoch: 14750, MSE: 0.23662553265527886, Learning Rate: 0.026249999999999996\n",
      "Epoch: 14751, MSE: 0.23662273059109415, Learning Rate: 0.026244999999999997\n",
      "Epoch: 14752, MSE: 0.23661992849676214, Learning Rate: 0.02624\n",
      "Epoch: 14753, MSE: 0.23661712637229132, Learning Rate: 0.026234999999999998\n",
      "Epoch: 14754, MSE: 0.23661432421768977, Learning Rate: 0.02623\n",
      "Epoch: 14755, MSE: 0.23661152203296815, Learning Rate: 0.026225\n",
      "Epoch: 14756, MSE: 0.2366087198181339, Learning Rate: 0.02622\n",
      "Epoch: 14757, MSE: 0.23660591757319693, Learning Rate: 0.026215000000000002\n",
      "Epoch: 14758, MSE: 0.23660311529816644, Learning Rate: 0.02621\n",
      "Epoch: 14759, MSE: 0.23660031299305062, Learning Rate: 0.026205000000000003\n",
      "Epoch: 14760, MSE: 0.23659751065785897, Learning Rate: 0.0262\n",
      "Epoch: 14761, MSE: 0.23659470829260001, Learning Rate: 0.026195000000000003\n",
      "Epoch: 14762, MSE: 0.23659190589728343, Learning Rate: 0.026190000000000005\n",
      "Epoch: 14763, MSE: 0.2365891034719178, Learning Rate: 0.026185000000000003\n",
      "Epoch: 14764, MSE: 0.23658630101651207, Learning Rate: 0.026180000000000005\n",
      "Epoch: 14765, MSE: 0.23658349853107602, Learning Rate: 0.026175000000000004\n",
      "Epoch: 14766, MSE: 0.23658069601561854, Learning Rate: 0.026170000000000006\n",
      "Epoch: 14767, MSE: 0.23657789347014732, Learning Rate: 0.026165000000000008\n",
      "Epoch: 14768, MSE: 0.2365750908946728, Learning Rate: 0.026160000000000006\n",
      "Epoch: 14769, MSE: 0.236572288289204, Learning Rate: 0.026154999999999998\n",
      "Epoch: 14770, MSE: 0.23656948565374883, Learning Rate: 0.026149999999999996\n",
      "Epoch: 14771, MSE: 0.2365666829883181, Learning Rate: 0.026144999999999998\n",
      "Epoch: 14772, MSE: 0.2365638802929199, Learning Rate: 0.026139999999999997\n",
      "Epoch: 14773, MSE: 0.2365610775675628, Learning Rate: 0.026135\n",
      "Epoch: 14774, MSE: 0.236558274812257, Learning Rate: 0.02613\n",
      "Epoch: 14775, MSE: 0.23655547202701072, Learning Rate: 0.026125\n",
      "Epoch: 14776, MSE: 0.23655266921183368, Learning Rate: 0.02612\n",
      "Epoch: 14777, MSE: 0.2365498663667355, Learning Rate: 0.026115\n",
      "Epoch: 14778, MSE: 0.23654706349172414, Learning Rate: 0.02611\n",
      "Epoch: 14779, MSE: 0.2365442605868085, Learning Rate: 0.026105000000000003\n",
      "Epoch: 14780, MSE: 0.23654145765199935, Learning Rate: 0.0261\n",
      "Epoch: 14781, MSE: 0.23653865468730464, Learning Rate: 0.026095000000000004\n",
      "Epoch: 14782, MSE: 0.23653585169273314, Learning Rate: 0.026090000000000002\n",
      "Epoch: 14783, MSE: 0.23653304866829583, Learning Rate: 0.026085000000000004\n",
      "Epoch: 14784, MSE: 0.2365302456139996, Learning Rate: 0.026080000000000006\n",
      "Epoch: 14785, MSE: 0.23652744252985589, Learning Rate: 0.026075000000000004\n",
      "Epoch: 14786, MSE: 0.23652463941587173, Learning Rate: 0.026070000000000006\n",
      "Epoch: 14787, MSE: 0.23652183627205783, Learning Rate: 0.026065000000000005\n",
      "Epoch: 14788, MSE: 0.2365190330984229, Learning Rate: 0.026060000000000007\n",
      "Epoch: 14789, MSE: 0.23651622989497606, Learning Rate: 0.026054999999999995\n",
      "Epoch: 14790, MSE: 0.23651342666172634, Learning Rate: 0.026049999999999997\n",
      "Epoch: 14791, MSE: 0.23651062339868323, Learning Rate: 0.026045\n",
      "Epoch: 14792, MSE: 0.23650782010585614, Learning Rate: 0.026039999999999997\n",
      "Epoch: 14793, MSE: 0.23650501678325478, Learning Rate: 0.026035\n",
      "Epoch: 14794, MSE: 0.2365022134308864, Learning Rate: 0.026029999999999998\n",
      "Epoch: 14795, MSE: 0.23649941004876246, Learning Rate: 0.026025\n",
      "Epoch: 14796, MSE: 0.2364966066368911, Learning Rate: 0.02602\n",
      "Epoch: 14797, MSE: 0.2364938031952814, Learning Rate: 0.026015\n",
      "Epoch: 14798, MSE: 0.23649099972394325, Learning Rate: 0.026010000000000002\n",
      "Epoch: 14799, MSE: 0.23648819622288564, Learning Rate: 0.026005\n",
      "Epoch: 14800, MSE: 0.23648539269211813, Learning Rate: 0.026000000000000002\n",
      "Epoch: 14801, MSE: 0.2364825891316494, Learning Rate: 0.025995000000000004\n",
      "Epoch: 14802, MSE: 0.23647978554148874, Learning Rate: 0.025990000000000003\n",
      "Epoch: 14803, MSE: 0.23647698192164693, Learning Rate: 0.025985000000000005\n",
      "Epoch: 14804, MSE: 0.23647417827213163, Learning Rate: 0.025980000000000003\n",
      "Epoch: 14805, MSE: 0.2364713745929529, Learning Rate: 0.025975000000000005\n",
      "Epoch: 14806, MSE: 0.23646857088411913, Learning Rate: 0.025970000000000007\n",
      "Epoch: 14807, MSE: 0.23646576714564102, Learning Rate: 0.025965000000000005\n",
      "Epoch: 14808, MSE: 0.23646296337752676, Learning Rate: 0.025960000000000007\n",
      "Epoch: 14809, MSE: 0.2364601595797868, Learning Rate: 0.025954999999999995\n",
      "Epoch: 14810, MSE: 0.2364573557524291, Learning Rate: 0.025949999999999997\n",
      "Epoch: 14811, MSE: 0.23645455189546513, Learning Rate: 0.025944999999999996\n",
      "Epoch: 14812, MSE: 0.23645174800890167, Learning Rate: 0.025939999999999998\n",
      "Epoch: 14813, MSE: 0.23644894409274947, Learning Rate: 0.025935\n",
      "Epoch: 14814, MSE: 0.2364461401470183, Learning Rate: 0.025929999999999998\n",
      "Epoch: 14815, MSE: 0.2364433361717165, Learning Rate: 0.025925\n",
      "Epoch: 14816, MSE: 0.23644053216685454, Learning Rate: 0.02592\n",
      "Epoch: 14817, MSE: 0.2364377281324415, Learning Rate: 0.025915\n",
      "Epoch: 14818, MSE: 0.23643492406848593, Learning Rate: 0.025910000000000002\n",
      "Epoch: 14819, MSE: 0.23643211997499752, Learning Rate: 0.025905\n",
      "Epoch: 14820, MSE: 0.23642931585198718, Learning Rate: 0.025900000000000003\n",
      "Epoch: 14821, MSE: 0.236426511699462, Learning Rate: 0.025895\n",
      "Epoch: 14822, MSE: 0.23642370751743352, Learning Rate: 0.025890000000000003\n",
      "Epoch: 14823, MSE: 0.2364209033059102, Learning Rate: 0.025885000000000005\n",
      "Epoch: 14824, MSE: 0.23641809906490158, Learning Rate: 0.025880000000000004\n",
      "Epoch: 14825, MSE: 0.2364152947944169, Learning Rate: 0.025875000000000006\n",
      "Epoch: 14826, MSE: 0.23641249049446603, Learning Rate: 0.025870000000000004\n",
      "Epoch: 14827, MSE: 0.23640968616505745, Learning Rate: 0.025865000000000006\n",
      "Epoch: 14828, MSE: 0.23640688180620303, Learning Rate: 0.025860000000000008\n",
      "Epoch: 14829, MSE: 0.23640407741790959, Learning Rate: 0.025854999999999996\n",
      "Epoch: 14830, MSE: 0.23640127300018798, Learning Rate: 0.025849999999999998\n",
      "Epoch: 14831, MSE: 0.23639846855304775, Learning Rate: 0.025844999999999996\n",
      "Epoch: 14832, MSE: 0.23639566407649815, Learning Rate: 0.02584\n",
      "Epoch: 14833, MSE: 0.23639285957054745, Learning Rate: 0.025834999999999997\n",
      "Epoch: 14834, MSE: 0.23639005503520752, Learning Rate: 0.02583\n",
      "Epoch: 14835, MSE: 0.23638725047048675, Learning Rate: 0.025825\n",
      "Epoch: 14836, MSE: 0.2363844458763938, Learning Rate: 0.02582\n",
      "Epoch: 14837, MSE: 0.23638164125293967, Learning Rate: 0.025815\n",
      "Epoch: 14838, MSE: 0.2363788366001331, Learning Rate: 0.02581\n",
      "Epoch: 14839, MSE: 0.23637603191798406, Learning Rate: 0.025805\n",
      "Epoch: 14840, MSE: 0.23637322720650217, Learning Rate: 0.025800000000000003\n",
      "Epoch: 14841, MSE: 0.2363704224656961, Learning Rate: 0.025795000000000002\n",
      "Epoch: 14842, MSE: 0.23636761769557596, Learning Rate: 0.025790000000000004\n",
      "Epoch: 14843, MSE: 0.23636481289615235, Learning Rate: 0.025785000000000002\n",
      "Epoch: 14844, MSE: 0.2363620080674337, Learning Rate: 0.025780000000000004\n",
      "Epoch: 14845, MSE: 0.23635920320942994, Learning Rate: 0.025775000000000006\n",
      "Epoch: 14846, MSE: 0.2363563983221509, Learning Rate: 0.025770000000000005\n",
      "Epoch: 14847, MSE: 0.23635359340560538, Learning Rate: 0.025765000000000007\n",
      "Epoch: 14848, MSE: 0.23635078845980328, Learning Rate: 0.025760000000000005\n",
      "Epoch: 14849, MSE: 0.23634798348475536, Learning Rate: 0.025754999999999997\n",
      "Epoch: 14850, MSE: 0.23634517848047046, Learning Rate: 0.025749999999999995\n",
      "Epoch: 14851, MSE: 0.23634237344695833, Learning Rate: 0.025744999999999997\n",
      "Epoch: 14852, MSE: 0.23633956838422743, Learning Rate: 0.02574\n",
      "Epoch: 14853, MSE: 0.236336763292289, Learning Rate: 0.025734999999999997\n",
      "Epoch: 14854, MSE: 0.23633395817115263, Learning Rate: 0.02573\n",
      "Epoch: 14855, MSE: 0.23633115302082705, Learning Rate: 0.025724999999999998\n",
      "Epoch: 14856, MSE: 0.23632834784132242, Learning Rate: 0.02572\n",
      "Epoch: 14857, MSE: 0.23632554263264896, Learning Rate: 0.025715000000000002\n",
      "Epoch: 14858, MSE: 0.23632273739481613, Learning Rate: 0.02571\n",
      "Epoch: 14859, MSE: 0.2363199321278321, Learning Rate: 0.025705000000000002\n",
      "Epoch: 14860, MSE: 0.23631712683170925, Learning Rate: 0.0257\n",
      "Epoch: 14861, MSE: 0.23631432150645587, Learning Rate: 0.025695000000000003\n",
      "Epoch: 14862, MSE: 0.2363115161520808, Learning Rate: 0.025690000000000004\n",
      "Epoch: 14863, MSE: 0.236308710768595, Learning Rate: 0.025685000000000003\n",
      "Epoch: 14864, MSE: 0.23630590535600857, Learning Rate: 0.025680000000000005\n",
      "Epoch: 14865, MSE: 0.23630309991433013, Learning Rate: 0.025675000000000003\n",
      "Epoch: 14866, MSE: 0.2363002944435701, Learning Rate: 0.025670000000000005\n",
      "Epoch: 14867, MSE: 0.23629748894373837, Learning Rate: 0.025665000000000007\n",
      "Epoch: 14868, MSE: 0.23629468341484436, Learning Rate: 0.025660000000000006\n",
      "Epoch: 14869, MSE: 0.23629187785689737, Learning Rate: 0.025654999999999997\n",
      "Epoch: 14870, MSE: 0.23628907226990817, Learning Rate: 0.025649999999999996\n",
      "Epoch: 14871, MSE: 0.23628626665388647, Learning Rate: 0.025644999999999998\n",
      "Epoch: 14872, MSE: 0.23628346100884126, Learning Rate: 0.025639999999999996\n",
      "Epoch: 14873, MSE: 0.23628065533478293, Learning Rate: 0.025634999999999998\n",
      "Epoch: 14874, MSE: 0.23627784963172144, Learning Rate: 0.02563\n",
      "Epoch: 14875, MSE: 0.2362750438996666, Learning Rate: 0.025625\n",
      "Epoch: 14876, MSE: 0.2362722381386281, Learning Rate: 0.02562\n",
      "Epoch: 14877, MSE: 0.23626943234861536, Learning Rate: 0.025615\n",
      "Epoch: 14878, MSE: 0.23626662652963806, Learning Rate: 0.02561\n",
      "Epoch: 14879, MSE: 0.23626382068170762, Learning Rate: 0.025605000000000003\n",
      "Epoch: 14880, MSE: 0.23626101480483253, Learning Rate: 0.0256\n",
      "Epoch: 14881, MSE: 0.23625820889902355, Learning Rate: 0.025595000000000003\n",
      "Epoch: 14882, MSE: 0.23625540296428907, Learning Rate: 0.02559\n",
      "Epoch: 14883, MSE: 0.23625259700064036, Learning Rate: 0.025585000000000004\n",
      "Epoch: 14884, MSE: 0.23624979100808735, Learning Rate: 0.025580000000000006\n",
      "Epoch: 14885, MSE: 0.2362469849866388, Learning Rate: 0.025575000000000004\n",
      "Epoch: 14886, MSE: 0.23624417893630592, Learning Rate: 0.025570000000000006\n",
      "Epoch: 14887, MSE: 0.23624137285709815, Learning Rate: 0.025565000000000004\n",
      "Epoch: 14888, MSE: 0.23623856674902496, Learning Rate: 0.025560000000000006\n",
      "Epoch: 14889, MSE: 0.23623576061209675, Learning Rate: 0.025555000000000008\n",
      "Epoch: 14890, MSE: 0.23623295444632314, Learning Rate: 0.025549999999999996\n",
      "Epoch: 14891, MSE: 0.23623014825171496, Learning Rate: 0.025544999999999998\n",
      "Epoch: 14892, MSE: 0.2362273420282808, Learning Rate: 0.025539999999999997\n",
      "Epoch: 14893, MSE: 0.2362245357760316, Learning Rate: 0.025535\n",
      "Epoch: 14894, MSE: 0.23622172949497702, Learning Rate: 0.025529999999999997\n",
      "Epoch: 14895, MSE: 0.23621892318512716, Learning Rate: 0.025525\n",
      "Epoch: 14896, MSE: 0.23621611684649224, Learning Rate: 0.02552\n",
      "Epoch: 14897, MSE: 0.2362133104790815, Learning Rate: 0.025515\n",
      "Epoch: 14898, MSE: 0.23621050408290584, Learning Rate: 0.02551\n",
      "Epoch: 14899, MSE: 0.23620769765797472, Learning Rate: 0.025505\n",
      "Epoch: 14900, MSE: 0.23620489120429783, Learning Rate: 0.025500000000000002\n",
      "Epoch: 14901, MSE: 0.23620208472188653, Learning Rate: 0.025495000000000004\n",
      "Epoch: 14902, MSE: 0.23619927821074968, Learning Rate: 0.025490000000000002\n",
      "Epoch: 14903, MSE: 0.23619647167089788, Learning Rate: 0.025485000000000004\n",
      "Epoch: 14904, MSE: 0.23619366510233997, Learning Rate: 0.025480000000000003\n",
      "Epoch: 14905, MSE: 0.23619085850508853, Learning Rate: 0.025475000000000005\n",
      "Epoch: 14906, MSE: 0.23618805187915118, Learning Rate: 0.025470000000000007\n",
      "Epoch: 14907, MSE: 0.23618524522453876, Learning Rate: 0.025465000000000005\n",
      "Epoch: 14908, MSE: 0.23618243854126134, Learning Rate: 0.025460000000000007\n",
      "Epoch: 14909, MSE: 0.2361796318293301, Learning Rate: 0.025455000000000005\n",
      "Epoch: 14910, MSE: 0.2361768250887534, Learning Rate: 0.025449999999999997\n",
      "Epoch: 14911, MSE: 0.2361740183195422, Learning Rate: 0.025444999999999995\n",
      "Epoch: 14912, MSE: 0.23617121152170753, Learning Rate: 0.025439999999999997\n",
      "Epoch: 14913, MSE: 0.23616840469525718, Learning Rate: 0.025435\n",
      "Epoch: 14914, MSE: 0.2361655978402041, Learning Rate: 0.025429999999999998\n",
      "Epoch: 14915, MSE: 0.23616279095655698, Learning Rate: 0.025425\n",
      "Epoch: 14916, MSE: 0.23615998404432476, Learning Rate: 0.025419999999999998\n",
      "Epoch: 14917, MSE: 0.23615717710351983, Learning Rate: 0.025415\n",
      "Epoch: 14918, MSE: 0.23615437013415083, Learning Rate: 0.025410000000000002\n",
      "Epoch: 14919, MSE: 0.236151563136229, Learning Rate: 0.025405\n",
      "Epoch: 14920, MSE: 0.23614875610976407, Learning Rate: 0.025400000000000002\n",
      "Epoch: 14921, MSE: 0.23614594905476588, Learning Rate: 0.025395\n",
      "Epoch: 14922, MSE: 0.23614314197124459, Learning Rate: 0.025390000000000003\n",
      "Epoch: 14923, MSE: 0.2361403348592109, Learning Rate: 0.025385000000000005\n",
      "Epoch: 14924, MSE: 0.2361375277186747, Learning Rate: 0.025380000000000003\n",
      "Epoch: 14925, MSE: 0.23613472054964715, Learning Rate: 0.025375000000000005\n",
      "Epoch: 14926, MSE: 0.23613191335213707, Learning Rate: 0.025370000000000004\n",
      "Epoch: 14927, MSE: 0.23612910612615481, Learning Rate: 0.025365000000000006\n",
      "Epoch: 14928, MSE: 0.23612629887171174, Learning Rate: 0.025360000000000008\n",
      "Epoch: 14929, MSE: 0.23612349158881787, Learning Rate: 0.025355000000000006\n",
      "Epoch: 14930, MSE: 0.23612068427748223, Learning Rate: 0.025349999999999998\n",
      "Epoch: 14931, MSE: 0.2361178769377164, Learning Rate: 0.025344999999999996\n",
      "Epoch: 14932, MSE: 0.2361150695695303, Learning Rate: 0.025339999999999998\n",
      "Epoch: 14933, MSE: 0.2361122621729347, Learning Rate: 0.025334999999999996\n",
      "Epoch: 14934, MSE: 0.2361094547479389, Learning Rate: 0.02533\n",
      "Epoch: 14935, MSE: 0.23610664729455277, Learning Rate: 0.025325\n",
      "Epoch: 14936, MSE: 0.23610383981278876, Learning Rate: 0.02532\n",
      "Epoch: 14937, MSE: 0.23610103230265486, Learning Rate: 0.025315\n",
      "Epoch: 14938, MSE: 0.2360982247641634, Learning Rate: 0.02531\n",
      "Epoch: 14939, MSE: 0.23609541719732322, Learning Rate: 0.025305\n",
      "Epoch: 14940, MSE: 0.23609260960214457, Learning Rate: 0.025300000000000003\n",
      "Epoch: 14941, MSE: 0.23608980197863907, Learning Rate: 0.025295\n",
      "Epoch: 14942, MSE: 0.23608699432681685, Learning Rate: 0.025290000000000003\n",
      "Epoch: 14943, MSE: 0.23608418664668765, Learning Rate: 0.025285000000000002\n",
      "Epoch: 14944, MSE: 0.2360813789382617, Learning Rate: 0.025280000000000004\n",
      "Epoch: 14945, MSE: 0.2360785712015504, Learning Rate: 0.025275000000000006\n",
      "Epoch: 14946, MSE: 0.23607576343656297, Learning Rate: 0.025270000000000004\n",
      "Epoch: 14947, MSE: 0.23607295564331024, Learning Rate: 0.025265000000000006\n",
      "Epoch: 14948, MSE: 0.23607014782180336, Learning Rate: 0.025260000000000005\n",
      "Epoch: 14949, MSE: 0.23606733997205157, Learning Rate: 0.025255000000000007\n",
      "Epoch: 14950, MSE: 0.23606453209406641, Learning Rate: 0.025249999999999995\n",
      "Epoch: 14951, MSE: 0.23606172418785673, Learning Rate: 0.025244999999999997\n",
      "Epoch: 14952, MSE: 0.23605891625343553, Learning Rate: 0.02524\n",
      "Epoch: 14953, MSE: 0.23605610829081058, Learning Rate: 0.025234999999999997\n",
      "Epoch: 14954, MSE: 0.2360533002999939, Learning Rate: 0.02523\n",
      "Epoch: 14955, MSE: 0.2360504922809952, Learning Rate: 0.025224999999999997\n",
      "Epoch: 14956, MSE: 0.2360476842338255, Learning Rate: 0.02522\n",
      "Epoch: 14957, MSE: 0.23604487615849534, Learning Rate: 0.025215\n",
      "Epoch: 14958, MSE: 0.23604206805501504, Learning Rate: 0.02521\n",
      "Epoch: 14959, MSE: 0.2360392599233943, Learning Rate: 0.025205\n",
      "Epoch: 14960, MSE: 0.23603645176364496, Learning Rate: 0.0252\n",
      "Epoch: 14961, MSE: 0.23603364357577675, Learning Rate: 0.025195000000000002\n",
      "Epoch: 14962, MSE: 0.23603083535980093, Learning Rate: 0.025190000000000004\n",
      "Epoch: 14963, MSE: 0.2360280271157265, Learning Rate: 0.025185000000000003\n",
      "Epoch: 14964, MSE: 0.23602521884356562, Learning Rate: 0.025180000000000004\n",
      "Epoch: 14965, MSE: 0.23602241054332795, Learning Rate: 0.025175000000000003\n",
      "Epoch: 14966, MSE: 0.23601960221502494, Learning Rate: 0.025170000000000005\n",
      "Epoch: 14967, MSE: 0.23601679385866586, Learning Rate: 0.025165000000000007\n",
      "Epoch: 14968, MSE: 0.23601398547426217, Learning Rate: 0.025160000000000005\n",
      "Epoch: 14969, MSE: 0.23601117706182406, Learning Rate: 0.025155000000000007\n",
      "Epoch: 14970, MSE: 0.23600836862136285, Learning Rate: 0.025149999999999995\n",
      "Epoch: 14971, MSE: 0.2360055601528882, Learning Rate: 0.025144999999999997\n",
      "Epoch: 14972, MSE: 0.2360027516564111, Learning Rate: 0.025139999999999996\n",
      "Epoch: 14973, MSE: 0.23599994313194292, Learning Rate: 0.025134999999999998\n",
      "Epoch: 14974, MSE: 0.2359971345794926, Learning Rate: 0.02513\n",
      "Epoch: 14975, MSE: 0.23599432599907208, Learning Rate: 0.025124999999999998\n",
      "Epoch: 14976, MSE: 0.23599151739069135, Learning Rate: 0.02512\n",
      "Epoch: 14977, MSE: 0.2359887087543623, Learning Rate: 0.025115\n",
      "Epoch: 14978, MSE: 0.23598590009009418, Learning Rate: 0.02511\n",
      "Epoch: 14979, MSE: 0.23598309139789816, Learning Rate: 0.025105000000000002\n",
      "Epoch: 14980, MSE: 0.23598028267778526, Learning Rate: 0.0251\n",
      "Epoch: 14981, MSE: 0.23597747392976562, Learning Rate: 0.025095000000000003\n",
      "Epoch: 14982, MSE: 0.23597466515384993, Learning Rate: 0.02509\n",
      "Epoch: 14983, MSE: 0.2359718563500489, Learning Rate: 0.025085000000000003\n",
      "Epoch: 14984, MSE: 0.23596904751837383, Learning Rate: 0.025080000000000005\n",
      "Epoch: 14985, MSE: 0.23596623865883537, Learning Rate: 0.025075000000000004\n",
      "Epoch: 14986, MSE: 0.23596342977144366, Learning Rate: 0.025070000000000005\n",
      "Epoch: 14987, MSE: 0.23596062085620956, Learning Rate: 0.025065000000000004\n",
      "Epoch: 14988, MSE: 0.23595781191314416, Learning Rate: 0.025060000000000006\n",
      "Epoch: 14989, MSE: 0.2359550029422583, Learning Rate: 0.025055000000000008\n",
      "Epoch: 14990, MSE: 0.23595219394356226, Learning Rate: 0.025049999999999996\n",
      "Epoch: 14991, MSE: 0.23594938491706746, Learning Rate: 0.025044999999999998\n",
      "Epoch: 14992, MSE: 0.23594657586278364, Learning Rate: 0.025039999999999996\n",
      "Epoch: 14993, MSE: 0.23594376678072218, Learning Rate: 0.025034999999999998\n",
      "Epoch: 14994, MSE: 0.23594095767089454, Learning Rate: 0.025029999999999997\n",
      "Epoch: 14995, MSE: 0.23593814853331124, Learning Rate: 0.025025\n",
      "Epoch: 14996, MSE: 0.2359353393679817, Learning Rate: 0.02502\n",
      "Epoch: 14997, MSE: 0.2359325301749185, Learning Rate: 0.025015\n",
      "Epoch: 14998, MSE: 0.23592972095413212, Learning Rate: 0.02501\n",
      "Epoch: 14999, MSE: 0.23592691170563265, Learning Rate: 0.025005\n",
      "Epoch: 15000, MSE: 0.23592410242943113, Learning Rate: 0.025\n",
      "Epoch: 15001, MSE: 0.23592129312553872, Learning Rate: 0.024995000000000003\n",
      "Epoch: 15002, MSE: 0.23591848379396702, Learning Rate: 0.024990000000000002\n",
      "Epoch: 15003, MSE: 0.23591567443472594, Learning Rate: 0.024985000000000004\n",
      "Epoch: 15004, MSE: 0.23591286504782627, Learning Rate: 0.024980000000000002\n",
      "Epoch: 15005, MSE: 0.23591005563327921, Learning Rate: 0.024975000000000004\n",
      "Epoch: 15006, MSE: 0.23590724619109565, Learning Rate: 0.024970000000000006\n",
      "Epoch: 15007, MSE: 0.235904436721287, Learning Rate: 0.024965000000000005\n",
      "Epoch: 15008, MSE: 0.23590162722386332, Learning Rate: 0.024960000000000006\n",
      "Epoch: 15009, MSE: 0.23589881769883603, Learning Rate: 0.024955000000000005\n",
      "Epoch: 15010, MSE: 0.23589600814621614, Learning Rate: 0.024950000000000007\n",
      "Epoch: 15011, MSE: 0.23589319856601465, Learning Rate: 0.024944999999999995\n",
      "Epoch: 15012, MSE: 0.2358903889582416, Learning Rate: 0.024939999999999997\n",
      "Epoch: 15013, MSE: 0.23588757932290927, Learning Rate: 0.024935\n",
      "Epoch: 15014, MSE: 0.23588476966002778, Learning Rate: 0.024929999999999997\n",
      "Epoch: 15015, MSE: 0.23588195996960865, Learning Rate: 0.024925\n",
      "Epoch: 15016, MSE: 0.23587915025166237, Learning Rate: 0.024919999999999998\n",
      "Epoch: 15017, MSE: 0.23587634050620007, Learning Rate: 0.024915\n",
      "Epoch: 15018, MSE: 0.23587353073323314, Learning Rate: 0.02491\n",
      "Epoch: 15019, MSE: 0.23587072093277206, Learning Rate: 0.024905\n",
      "Epoch: 15020, MSE: 0.23586791110482874, Learning Rate: 0.024900000000000002\n",
      "Epoch: 15021, MSE: 0.23586510124941315, Learning Rate: 0.024895\n",
      "Epoch: 15022, MSE: 0.23586229136653666, Learning Rate: 0.024890000000000002\n",
      "Epoch: 15023, MSE: 0.2358594814562113, Learning Rate: 0.024885000000000004\n",
      "Epoch: 15024, MSE: 0.23585667151844658, Learning Rate: 0.024880000000000003\n",
      "Epoch: 15025, MSE: 0.23585386155325497, Learning Rate: 0.024875000000000005\n",
      "Epoch: 15026, MSE: 0.23585105156064606, Learning Rate: 0.024870000000000003\n",
      "Epoch: 15027, MSE: 0.23584824154063297, Learning Rate: 0.024865000000000005\n",
      "Epoch: 15028, MSE: 0.23584543149322432, Learning Rate: 0.024860000000000007\n",
      "Epoch: 15029, MSE: 0.2358426214184332, Learning Rate: 0.024855000000000006\n",
      "Epoch: 15030, MSE: 0.23583981131627013, Learning Rate: 0.024850000000000007\n",
      "Epoch: 15031, MSE: 0.23583700118674605, Learning Rate: 0.024844999999999996\n",
      "Epoch: 15032, MSE: 0.23583419102987213, Learning Rate: 0.024839999999999997\n",
      "Epoch: 15033, MSE: 0.23583138084565958, Learning Rate: 0.024834999999999996\n",
      "Epoch: 15034, MSE: 0.2358285706341199, Learning Rate: 0.024829999999999998\n",
      "Epoch: 15035, MSE: 0.23582576039526387, Learning Rate: 0.024825\n",
      "Epoch: 15036, MSE: 0.23582295012910276, Learning Rate: 0.02482\n",
      "Epoch: 15037, MSE: 0.23582013983564776, Learning Rate: 0.024815\n",
      "Epoch: 15038, MSE: 0.23581732951490952, Learning Rate: 0.02481\n",
      "Epoch: 15039, MSE: 0.23581451916690074, Learning Rate: 0.024805\n",
      "Epoch: 15040, MSE: 0.23581170879163119, Learning Rate: 0.024800000000000003\n",
      "Epoch: 15041, MSE: 0.23580889838911243, Learning Rate: 0.024795\n",
      "Epoch: 15042, MSE: 0.23580608795935595, Learning Rate: 0.024790000000000003\n",
      "Epoch: 15043, MSE: 0.23580327750237287, Learning Rate: 0.024785\n",
      "Epoch: 15044, MSE: 0.23580046701817517, Learning Rate: 0.024780000000000003\n",
      "Epoch: 15045, MSE: 0.23579765650677256, Learning Rate: 0.024775000000000005\n",
      "Epoch: 15046, MSE: 0.235794845968177, Learning Rate: 0.024770000000000004\n",
      "Epoch: 15047, MSE: 0.23579203540240037, Learning Rate: 0.024765000000000006\n",
      "Epoch: 15048, MSE: 0.23578922480945277, Learning Rate: 0.024760000000000004\n",
      "Epoch: 15049, MSE: 0.23578641418934768, Learning Rate: 0.024755000000000006\n",
      "Epoch: 15050, MSE: 0.2357836035420942, Learning Rate: 0.024750000000000008\n",
      "Epoch: 15051, MSE: 0.2357807928677041, Learning Rate: 0.024744999999999996\n",
      "Epoch: 15052, MSE: 0.2357779821661889, Learning Rate: 0.024739999999999998\n",
      "Epoch: 15053, MSE: 0.23577517143756102, Learning Rate: 0.024734999999999997\n",
      "Epoch: 15054, MSE: 0.23577236068183008, Learning Rate: 0.02473\n",
      "Epoch: 15055, MSE: 0.23576954989900817, Learning Rate: 0.024724999999999997\n",
      "Epoch: 15056, MSE: 0.23576673908910672, Learning Rate: 0.02472\n",
      "Epoch: 15057, MSE: 0.23576392825213766, Learning Rate: 0.024715\n",
      "Epoch: 15058, MSE: 0.2357611173881106, Learning Rate: 0.02471\n",
      "Epoch: 15059, MSE: 0.2357583064970389, Learning Rate: 0.024705\n",
      "Epoch: 15060, MSE: 0.23575549557893274, Learning Rate: 0.0247\n",
      "Epoch: 15061, MSE: 0.23575268463380383, Learning Rate: 0.024695\n",
      "Epoch: 15062, MSE: 0.23574987366166447, Learning Rate: 0.024690000000000004\n",
      "Epoch: 15063, MSE: 0.23574706266252513, Learning Rate: 0.024685000000000002\n",
      "Epoch: 15064, MSE: 0.23574425163639706, Learning Rate: 0.024680000000000004\n",
      "Epoch: 15065, MSE: 0.23574144058329227, Learning Rate: 0.024675000000000002\n",
      "Epoch: 15066, MSE: 0.2357386295032219, Learning Rate: 0.024670000000000004\n",
      "Epoch: 15067, MSE: 0.2357358183961979, Learning Rate: 0.024665000000000006\n",
      "Epoch: 15068, MSE: 0.235733007262231, Learning Rate: 0.024660000000000005\n",
      "Epoch: 15069, MSE: 0.2357301961013333, Learning Rate: 0.024655000000000007\n",
      "Epoch: 15070, MSE: 0.23572738491351533, Learning Rate: 0.024650000000000005\n",
      "Epoch: 15071, MSE: 0.23572457369879063, Learning Rate: 0.024644999999999997\n",
      "Epoch: 15072, MSE: 0.23572176245716822, Learning Rate: 0.024639999999999995\n",
      "Epoch: 15073, MSE: 0.23571895118866154, Learning Rate: 0.024634999999999997\n",
      "Epoch: 15074, MSE: 0.23571613989328133, Learning Rate: 0.02463\n",
      "Epoch: 15075, MSE: 0.23571332857103902, Learning Rate: 0.024624999999999998\n",
      "Epoch: 15076, MSE: 0.23571051722194647, Learning Rate: 0.02462\n",
      "Epoch: 15077, MSE: 0.23570770584601478, Learning Rate: 0.024614999999999998\n",
      "Epoch: 15078, MSE: 0.23570489444325612, Learning Rate: 0.02461\n",
      "Epoch: 15079, MSE: 0.23570208301368215, Learning Rate: 0.024605000000000002\n",
      "Epoch: 15080, MSE: 0.2356992715573042, Learning Rate: 0.0246\n",
      "Epoch: 15081, MSE: 0.23569646007413358, Learning Rate: 0.024595000000000002\n",
      "Epoch: 15082, MSE: 0.23569364856418162, Learning Rate: 0.02459\n",
      "Epoch: 15083, MSE: 0.23569083702746071, Learning Rate: 0.024585000000000003\n",
      "Epoch: 15084, MSE: 0.23568802546398232, Learning Rate: 0.024580000000000005\n",
      "Epoch: 15085, MSE: 0.23568521387375774, Learning Rate: 0.024575000000000003\n",
      "Epoch: 15086, MSE: 0.23568240225679965, Learning Rate: 0.024570000000000005\n",
      "Epoch: 15087, MSE: 0.2356795906131184, Learning Rate: 0.024565000000000003\n",
      "Epoch: 15088, MSE: 0.2356767789427256, Learning Rate: 0.024560000000000005\n",
      "Epoch: 15089, MSE: 0.2356739672456342, Learning Rate: 0.024555000000000007\n",
      "Epoch: 15090, MSE: 0.23567115552185444, Learning Rate: 0.024550000000000006\n",
      "Epoch: 15091, MSE: 0.23566834377139942, Learning Rate: 0.024544999999999997\n",
      "Epoch: 15092, MSE: 0.23566553199428045, Learning Rate: 0.024539999999999996\n",
      "Epoch: 15093, MSE: 0.2356627201905078, Learning Rate: 0.024534999999999998\n",
      "Epoch: 15094, MSE: 0.23565990836009537, Learning Rate: 0.024529999999999996\n",
      "Epoch: 15095, MSE: 0.23565709650305364, Learning Rate: 0.024524999999999998\n",
      "Epoch: 15096, MSE: 0.235654284619395, Learning Rate: 0.02452\n",
      "Epoch: 15097, MSE: 0.23565147270913045, Learning Rate: 0.024515\n",
      "Epoch: 15098, MSE: 0.23564866077227184, Learning Rate: 0.02451\n",
      "Epoch: 15099, MSE: 0.2356458488088314, Learning Rate: 0.024505\n",
      "Epoch: 15100, MSE: 0.23564303681882093, Learning Rate: 0.0245\n",
      "Epoch: 15101, MSE: 0.23564022480225189, Learning Rate: 0.024495000000000003\n",
      "Epoch: 15102, MSE: 0.23563741275913677, Learning Rate: 0.02449\n",
      "Epoch: 15103, MSE: 0.23563460068948638, Learning Rate: 0.024485000000000003\n",
      "Epoch: 15104, MSE: 0.23563178859331385, Learning Rate: 0.024480000000000002\n",
      "Epoch: 15105, MSE: 0.2356289764706291, Learning Rate: 0.024475000000000004\n",
      "Epoch: 15106, MSE: 0.23562616432144534, Learning Rate: 0.024470000000000006\n",
      "Epoch: 15107, MSE: 0.23562335214577396, Learning Rate: 0.024465000000000004\n",
      "Epoch: 15108, MSE: 0.23562053994362717, Learning Rate: 0.024460000000000006\n",
      "Epoch: 15109, MSE: 0.2356177277150167, Learning Rate: 0.024455000000000005\n",
      "Epoch: 15110, MSE: 0.2356149154599546, Learning Rate: 0.024450000000000006\n",
      "Epoch: 15111, MSE: 0.23561210317845252, Learning Rate: 0.024444999999999995\n",
      "Epoch: 15112, MSE: 0.23560929087052226, Learning Rate: 0.024439999999999996\n",
      "Epoch: 15113, MSE: 0.23560647853617633, Learning Rate: 0.024435\n",
      "Epoch: 15114, MSE: 0.23560366617542577, Learning Rate: 0.024429999999999997\n",
      "Epoch: 15115, MSE: 0.235600853788283, Learning Rate: 0.024425\n",
      "Epoch: 15116, MSE: 0.2355980413747603, Learning Rate: 0.024419999999999997\n",
      "Epoch: 15117, MSE: 0.23559522893486826, Learning Rate: 0.024415\n",
      "Epoch: 15118, MSE: 0.23559241646862097, Learning Rate: 0.02441\n",
      "Epoch: 15119, MSE: 0.23558960397602963, Learning Rate: 0.024405\n",
      "Epoch: 15120, MSE: 0.2355867914571042, Learning Rate: 0.0244\n",
      "Epoch: 15121, MSE: 0.23558397891185984, Learning Rate: 0.024395\n",
      "Epoch: 15122, MSE: 0.2355811663403063, Learning Rate: 0.024390000000000002\n",
      "Epoch: 15123, MSE: 0.23557835374245678, Learning Rate: 0.024385000000000004\n",
      "Epoch: 15124, MSE: 0.23557554111832243, Learning Rate: 0.024380000000000002\n",
      "Epoch: 15125, MSE: 0.23557272846791574, Learning Rate: 0.024375000000000004\n",
      "Epoch: 15126, MSE: 0.23556991579124975, Learning Rate: 0.024370000000000003\n",
      "Epoch: 15127, MSE: 0.23556710308833467, Learning Rate: 0.024365000000000005\n",
      "Epoch: 15128, MSE: 0.23556429035918308, Learning Rate: 0.024360000000000007\n",
      "Epoch: 15129, MSE: 0.23556147760380797, Learning Rate: 0.024355000000000005\n",
      "Epoch: 15130, MSE: 0.23555866482222, Learning Rate: 0.024350000000000007\n",
      "Epoch: 15131, MSE: 0.23555585201443344, Learning Rate: 0.024345000000000006\n",
      "Epoch: 15132, MSE: 0.23555303918045817, Learning Rate: 0.024339999999999997\n",
      "Epoch: 15133, MSE: 0.2355502263203072, Learning Rate: 0.024334999999999996\n",
      "Epoch: 15134, MSE: 0.2355474134339933, Learning Rate: 0.024329999999999997\n",
      "Epoch: 15135, MSE: 0.2355446005215271, Learning Rate: 0.024325\n",
      "Epoch: 15136, MSE: 0.23554178758292246, Learning Rate: 0.024319999999999998\n",
      "Epoch: 15137, MSE: 0.23553897461818996, Learning Rate: 0.024315\n",
      "Epoch: 15138, MSE: 0.23553616162734287, Learning Rate: 0.02431\n",
      "Epoch: 15139, MSE: 0.23553334861039332, Learning Rate: 0.024305\n",
      "Epoch: 15140, MSE: 0.23553053556735237, Learning Rate: 0.024300000000000002\n",
      "Epoch: 15141, MSE: 0.2355277224982337, Learning Rate: 0.024295\n",
      "Epoch: 15142, MSE: 0.23552490940304824, Learning Rate: 0.024290000000000003\n",
      "Epoch: 15143, MSE: 0.23552209628180892, Learning Rate: 0.024285\n",
      "Epoch: 15144, MSE: 0.2355192831345288, Learning Rate: 0.024280000000000003\n",
      "Epoch: 15145, MSE: 0.23551646996121767, Learning Rate: 0.024275000000000005\n",
      "Epoch: 15146, MSE: 0.23551365676189043, Learning Rate: 0.024270000000000003\n",
      "Epoch: 15147, MSE: 0.23551084353655805, Learning Rate: 0.024265000000000005\n",
      "Epoch: 15148, MSE: 0.2355080302852323, Learning Rate: 0.024260000000000004\n",
      "Epoch: 15149, MSE: 0.23550521700792698, Learning Rate: 0.024255000000000006\n",
      "Epoch: 15150, MSE: 0.2355024037046524, Learning Rate: 0.024250000000000008\n",
      "Epoch: 15151, MSE: 0.23549959037542306, Learning Rate: 0.024245000000000006\n",
      "Epoch: 15152, MSE: 0.23549677702024976, Learning Rate: 0.024239999999999998\n",
      "Epoch: 15153, MSE: 0.2354939636391451, Learning Rate: 0.024234999999999996\n",
      "Epoch: 15154, MSE: 0.2354911502321216, Learning Rate: 0.024229999999999998\n",
      "Epoch: 15155, MSE: 0.23548833679919184, Learning Rate: 0.024224999999999997\n",
      "Epoch: 15156, MSE: 0.23548552334036796, Learning Rate: 0.02422\n",
      "Epoch: 15157, MSE: 0.23548270985566147, Learning Rate: 0.024215\n",
      "Epoch: 15158, MSE: 0.2354798963450865, Learning Rate: 0.02421\n",
      "Epoch: 15159, MSE: 0.2354770828086543, Learning Rate: 0.024205\n",
      "Epoch: 15160, MSE: 0.23547426924637724, Learning Rate: 0.0242\n",
      "Epoch: 15161, MSE: 0.2354714556582674, Learning Rate: 0.024195\n",
      "Epoch: 15162, MSE: 0.2354686420443382, Learning Rate: 0.024190000000000003\n",
      "Epoch: 15163, MSE: 0.2354658284046014, Learning Rate: 0.024185\n",
      "Epoch: 15164, MSE: 0.23546301473907033, Learning Rate: 0.024180000000000004\n",
      "Epoch: 15165, MSE: 0.235460201047756, Learning Rate: 0.024175000000000002\n",
      "Epoch: 15166, MSE: 0.23545738733067262, Learning Rate: 0.024170000000000004\n",
      "Epoch: 15167, MSE: 0.23545457358783073, Learning Rate: 0.024165000000000006\n",
      "Epoch: 15168, MSE: 0.23545175981924396, Learning Rate: 0.024160000000000004\n",
      "Epoch: 15169, MSE: 0.23544894602492455, Learning Rate: 0.024155000000000006\n",
      "Epoch: 15170, MSE: 0.2354461322048852, Learning Rate: 0.024150000000000005\n",
      "Epoch: 15171, MSE: 0.23544331835913773, Learning Rate: 0.024145000000000007\n",
      "Epoch: 15172, MSE: 0.23544050448769607, Learning Rate: 0.024139999999999995\n",
      "Epoch: 15173, MSE: 0.23543769059057085, Learning Rate: 0.024134999999999997\n",
      "Epoch: 15174, MSE: 0.23543487666777624, Learning Rate: 0.02413\n",
      "Epoch: 15175, MSE: 0.235432062719324, Learning Rate: 0.024124999999999997\n",
      "Epoch: 15176, MSE: 0.235429248745227, Learning Rate: 0.02412\n",
      "Epoch: 15177, MSE: 0.23542643474549815, Learning Rate: 0.024114999999999998\n",
      "Epoch: 15178, MSE: 0.23542362072014877, Learning Rate: 0.02411\n",
      "Epoch: 15179, MSE: 0.23542080666919343, Learning Rate: 0.024105\n",
      "Epoch: 15180, MSE: 0.23541799259264193, Learning Rate: 0.0241\n",
      "Epoch: 15181, MSE: 0.23541517849050964, Learning Rate: 0.024095000000000002\n",
      "Epoch: 15182, MSE: 0.2354123643628078, Learning Rate: 0.02409\n",
      "Epoch: 15183, MSE: 0.23540955020954993, Learning Rate: 0.024085000000000002\n",
      "Epoch: 15184, MSE: 0.23540673603074685, Learning Rate: 0.024080000000000004\n",
      "Epoch: 15185, MSE: 0.23540392182641387, Learning Rate: 0.024075000000000003\n",
      "Epoch: 15186, MSE: 0.23540110759656177, Learning Rate: 0.024070000000000005\n",
      "Epoch: 15187, MSE: 0.23539829334120377, Learning Rate: 0.024065000000000003\n",
      "Epoch: 15188, MSE: 0.23539547906035216, Learning Rate: 0.024060000000000005\n",
      "Epoch: 15189, MSE: 0.2353926647540205, Learning Rate: 0.024055000000000007\n",
      "Epoch: 15190, MSE: 0.23538985042222083, Learning Rate: 0.024050000000000005\n",
      "Epoch: 15191, MSE: 0.2353870360649661, Learning Rate: 0.024045000000000007\n",
      "Epoch: 15192, MSE: 0.23538422168226972, Learning Rate: 0.024039999999999995\n",
      "Epoch: 15193, MSE: 0.235381407274143, Learning Rate: 0.024034999999999997\n",
      "Epoch: 15194, MSE: 0.2353785928405996, Learning Rate: 0.024029999999999996\n",
      "Epoch: 15195, MSE: 0.23537577838165225, Learning Rate: 0.024024999999999998\n",
      "Epoch: 15196, MSE: 0.2353729638973131, Learning Rate: 0.02402\n",
      "Epoch: 15197, MSE: 0.23537014938759615, Learning Rate: 0.024014999999999998\n",
      "Epoch: 15198, MSE: 0.23536733485251288, Learning Rate: 0.02401\n",
      "Epoch: 15199, MSE: 0.23536452029207738, Learning Rate: 0.024005\n",
      "Epoch: 15200, MSE: 0.23536170570630152, Learning Rate: 0.024\n",
      "Epoch: 15201, MSE: 0.23535889109519847, Learning Rate: 0.023995000000000002\n",
      "Epoch: 15202, MSE: 0.23535607645878148, Learning Rate: 0.02399\n",
      "Epoch: 15203, MSE: 0.23535326179706242, Learning Rate: 0.023985000000000003\n",
      "Epoch: 15204, MSE: 0.2353504471100559, Learning Rate: 0.02398\n",
      "Epoch: 15205, MSE: 0.2353476323977728, Learning Rate: 0.023975000000000003\n",
      "Epoch: 15206, MSE: 0.23534481766022713, Learning Rate: 0.023970000000000005\n",
      "Epoch: 15207, MSE: 0.23534200289743137, Learning Rate: 0.023965000000000004\n",
      "Epoch: 15208, MSE: 0.23533918810939883, Learning Rate: 0.023960000000000006\n",
      "Epoch: 15209, MSE: 0.2353363732961418, Learning Rate: 0.023955000000000004\n",
      "Epoch: 15210, MSE: 0.23533355845767395, Learning Rate: 0.023950000000000006\n",
      "Epoch: 15211, MSE: 0.2353307435940078, Learning Rate: 0.023945000000000008\n",
      "Epoch: 15212, MSE: 0.23532792870515687, Learning Rate: 0.023939999999999996\n",
      "Epoch: 15213, MSE: 0.23532511379113283, Learning Rate: 0.023934999999999998\n",
      "Epoch: 15214, MSE: 0.23532229885194955, Learning Rate: 0.023929999999999996\n",
      "Epoch: 15215, MSE: 0.23531948388762106, Learning Rate: 0.023925\n",
      "Epoch: 15216, MSE: 0.23531666889815903, Learning Rate: 0.023919999999999997\n",
      "Epoch: 15217, MSE: 0.2353138538835758, Learning Rate: 0.023915\n",
      "Epoch: 15218, MSE: 0.23531103884388668, Learning Rate: 0.02391\n",
      "Epoch: 15219, MSE: 0.23530822377910227, Learning Rate: 0.023905\n",
      "Epoch: 15220, MSE: 0.23530540868923785, Learning Rate: 0.0239\n",
      "Epoch: 15221, MSE: 0.2353025935743048, Learning Rate: 0.023895\n",
      "Epoch: 15222, MSE: 0.2352997784343163, Learning Rate: 0.02389\n",
      "Epoch: 15223, MSE: 0.23529696326928606, Learning Rate: 0.023885000000000003\n",
      "Epoch: 15224, MSE: 0.23529414807922786, Learning Rate: 0.023880000000000002\n",
      "Epoch: 15225, MSE: 0.235291332864153, Learning Rate: 0.023875000000000004\n",
      "Epoch: 15226, MSE: 0.23528851762407607, Learning Rate: 0.023870000000000002\n",
      "Epoch: 15227, MSE: 0.23528570235900903, Learning Rate: 0.023865000000000004\n",
      "Epoch: 15228, MSE: 0.23528288706896686, Learning Rate: 0.023860000000000006\n",
      "Epoch: 15229, MSE: 0.23528007175396048, Learning Rate: 0.023855000000000005\n",
      "Epoch: 15230, MSE: 0.2352772564140046, Learning Rate: 0.023850000000000007\n",
      "Epoch: 15231, MSE: 0.23527444104911263, Learning Rate: 0.023845000000000005\n",
      "Epoch: 15232, MSE: 0.23527162565929557, Learning Rate: 0.023839999999999997\n",
      "Epoch: 15233, MSE: 0.23526881024456847, Learning Rate: 0.023834999999999995\n",
      "Epoch: 15234, MSE: 0.23526599480494456, Learning Rate: 0.023829999999999997\n",
      "Epoch: 15235, MSE: 0.23526317934043708, Learning Rate: 0.023825\n",
      "Epoch: 15236, MSE: 0.23526036385105809, Learning Rate: 0.023819999999999997\n",
      "Epoch: 15237, MSE: 0.23525754833682178, Learning Rate: 0.023815\n",
      "Epoch: 15238, MSE: 0.23525473279774095, Learning Rate: 0.023809999999999998\n",
      "Epoch: 15239, MSE: 0.2352519172338294, Learning Rate: 0.023805\n",
      "Epoch: 15240, MSE: 0.23524910164510013, Learning Rate: 0.0238\n",
      "Epoch: 15241, MSE: 0.23524628603156603, Learning Rate: 0.023795\n",
      "Epoch: 15242, MSE: 0.23524347039324114, Learning Rate: 0.023790000000000002\n",
      "Epoch: 15243, MSE: 0.23524065473013908, Learning Rate: 0.023785\n",
      "Epoch: 15244, MSE: 0.23523783904227172, Learning Rate: 0.023780000000000003\n",
      "Epoch: 15245, MSE: 0.23523502332965346, Learning Rate: 0.023775000000000004\n",
      "Epoch: 15246, MSE: 0.23523220759229813, Learning Rate: 0.023770000000000003\n",
      "Epoch: 15247, MSE: 0.2352293918302176, Learning Rate: 0.023765000000000005\n",
      "Epoch: 15248, MSE: 0.23522657604342587, Learning Rate: 0.023760000000000003\n",
      "Epoch: 15249, MSE: 0.23522376023193722, Learning Rate: 0.023755000000000005\n",
      "Epoch: 15250, MSE: 0.23522094439576344, Learning Rate: 0.023750000000000007\n",
      "Epoch: 15251, MSE: 0.23521812853491905, Learning Rate: 0.023745000000000006\n",
      "Epoch: 15252, MSE: 0.23521531264941775, Learning Rate: 0.023740000000000008\n",
      "Epoch: 15253, MSE: 0.23521249673927203, Learning Rate: 0.023734999999999996\n",
      "Epoch: 15254, MSE: 0.23520968080449525, Learning Rate: 0.023729999999999998\n",
      "Epoch: 15255, MSE: 0.23520686484510206, Learning Rate: 0.023724999999999996\n",
      "Epoch: 15256, MSE: 0.23520404886110458, Learning Rate: 0.023719999999999998\n",
      "Epoch: 15257, MSE: 0.2352012328525175, Learning Rate: 0.023715\n",
      "Epoch: 15258, MSE: 0.23519841681935366, Learning Rate: 0.02371\n",
      "Epoch: 15259, MSE: 0.23519560076162616, Learning Rate: 0.023705\n",
      "Epoch: 15260, MSE: 0.23519278467934976, Learning Rate: 0.0237\n",
      "Epoch: 15261, MSE: 0.2351899685725368, Learning Rate: 0.023695\n",
      "Epoch: 15262, MSE: 0.2351871524412008, Learning Rate: 0.023690000000000003\n",
      "Epoch: 15263, MSE: 0.235184336285356, Learning Rate: 0.023685\n",
      "Epoch: 15264, MSE: 0.2351815201050162, Learning Rate: 0.023680000000000003\n",
      "Epoch: 15265, MSE: 0.23517870390019388, Learning Rate: 0.023675\n",
      "Epoch: 15266, MSE: 0.23517588767090333, Learning Rate: 0.023670000000000004\n",
      "Epoch: 15267, MSE: 0.2351730714171579, Learning Rate: 0.023665000000000005\n",
      "Epoch: 15268, MSE: 0.23517025513897205, Learning Rate: 0.023660000000000004\n",
      "Epoch: 15269, MSE: 0.2351674388363581, Learning Rate: 0.023655000000000006\n",
      "Epoch: 15270, MSE: 0.23516462250932993, Learning Rate: 0.023650000000000004\n",
      "Epoch: 15271, MSE: 0.23516180615790214, Learning Rate: 0.023645000000000006\n",
      "Epoch: 15272, MSE: 0.23515898978208777, Learning Rate: 0.023640000000000008\n",
      "Epoch: 15273, MSE: 0.23515617338189979, Learning Rate: 0.023634999999999996\n",
      "Epoch: 15274, MSE: 0.2351533569573533, Learning Rate: 0.023629999999999998\n",
      "Epoch: 15275, MSE: 0.2351505405084608, Learning Rate: 0.023624999999999997\n",
      "Epoch: 15276, MSE: 0.235147724035237, Learning Rate: 0.02362\n",
      "Epoch: 15277, MSE: 0.23514490753769443, Learning Rate: 0.023614999999999997\n",
      "Epoch: 15278, MSE: 0.23514209101584757, Learning Rate: 0.02361\n",
      "Epoch: 15279, MSE: 0.23513927446971045, Learning Rate: 0.023605\n",
      "Epoch: 15280, MSE: 0.2351364578992961, Learning Rate: 0.0236\n",
      "Epoch: 15281, MSE: 0.2351336413046182, Learning Rate: 0.023595\n",
      "Epoch: 15282, MSE: 0.2351308246856925, Learning Rate: 0.02359\n",
      "Epoch: 15283, MSE: 0.2351280080425293, Learning Rate: 0.023585000000000002\n",
      "Epoch: 15284, MSE: 0.2351251913751454, Learning Rate: 0.023580000000000004\n",
      "Epoch: 15285, MSE: 0.23512237468355338, Learning Rate: 0.023575000000000002\n",
      "Epoch: 15286, MSE: 0.23511955796776757, Learning Rate: 0.023570000000000004\n",
      "Epoch: 15287, MSE: 0.23511674122780027, Learning Rate: 0.023565000000000003\n",
      "Epoch: 15288, MSE: 0.23511392446366722, Learning Rate: 0.023560000000000005\n",
      "Epoch: 15289, MSE: 0.23511110767538151, Learning Rate: 0.023555000000000006\n",
      "Epoch: 15290, MSE: 0.23510829086295723, Learning Rate: 0.023550000000000005\n",
      "Epoch: 15291, MSE: 0.23510547402640827, Learning Rate: 0.023545000000000007\n",
      "Epoch: 15292, MSE: 0.23510265716574819, Learning Rate: 0.023540000000000005\n",
      "Epoch: 15293, MSE: 0.23509984028099098, Learning Rate: 0.023534999999999997\n",
      "Epoch: 15294, MSE: 0.23509702337215052, Learning Rate: 0.023529999999999995\n",
      "Epoch: 15295, MSE: 0.23509420643924114, Learning Rate: 0.023524999999999997\n",
      "Epoch: 15296, MSE: 0.23509138948227648, Learning Rate: 0.02352\n",
      "Epoch: 15297, MSE: 0.23508857250127066, Learning Rate: 0.023514999999999998\n",
      "Epoch: 15298, MSE: 0.23508575549623706, Learning Rate: 0.02351\n",
      "Epoch: 15299, MSE: 0.23508293846719133, Learning Rate: 0.023504999999999998\n",
      "Epoch: 15300, MSE: 0.23508012141414508, Learning Rate: 0.0235\n",
      "Epoch: 15301, MSE: 0.23507730433711468, Learning Rate: 0.023495000000000002\n",
      "Epoch: 15302, MSE: 0.23507448723611188, Learning Rate: 0.02349\n",
      "Epoch: 15303, MSE: 0.23507167011115204, Learning Rate: 0.023485000000000002\n",
      "Epoch: 15304, MSE: 0.23506885296224914, Learning Rate: 0.02348\n",
      "Epoch: 15305, MSE: 0.23506603578941762, Learning Rate: 0.023475000000000003\n",
      "Epoch: 15306, MSE: 0.2350632185926701, Learning Rate: 0.023470000000000005\n",
      "Epoch: 15307, MSE: 0.23506040137202208, Learning Rate: 0.023465000000000003\n",
      "Epoch: 15308, MSE: 0.23505758412748706, Learning Rate: 0.023460000000000005\n",
      "Epoch: 15309, MSE: 0.23505476685907953, Learning Rate: 0.023455000000000004\n",
      "Epoch: 15310, MSE: 0.2350519495668132, Learning Rate: 0.023450000000000006\n",
      "Epoch: 15311, MSE: 0.23504913225070273, Learning Rate: 0.023445000000000008\n",
      "Epoch: 15312, MSE: 0.23504631491076156, Learning Rate: 0.023440000000000006\n",
      "Epoch: 15313, MSE: 0.23504349754700404, Learning Rate: 0.023434999999999997\n",
      "Epoch: 15314, MSE: 0.2350406801594443, Learning Rate: 0.023429999999999996\n",
      "Epoch: 15315, MSE: 0.23503786274809743, Learning Rate: 0.023424999999999998\n",
      "Epoch: 15316, MSE: 0.23503504531297634, Learning Rate: 0.023419999999999996\n",
      "Epoch: 15317, MSE: 0.2350322278540959, Learning Rate: 0.023415\n",
      "Epoch: 15318, MSE: 0.23502941037146977, Learning Rate: 0.02341\n",
      "Epoch: 15319, MSE: 0.23502659286511293, Learning Rate: 0.023405\n",
      "Epoch: 15320, MSE: 0.2350237753350397, Learning Rate: 0.0234\n",
      "Epoch: 15321, MSE: 0.23502095778126364, Learning Rate: 0.023395\n",
      "Epoch: 15322, MSE: 0.2350181402037997, Learning Rate: 0.02339\n",
      "Epoch: 15323, MSE: 0.23501532260266117, Learning Rate: 0.023385000000000003\n",
      "Epoch: 15324, MSE: 0.235012504977864, Learning Rate: 0.02338\n",
      "Epoch: 15325, MSE: 0.2350096873294209, Learning Rate: 0.023375000000000003\n",
      "Epoch: 15326, MSE: 0.23500686965734613, Learning Rate: 0.023370000000000002\n",
      "Epoch: 15327, MSE: 0.23500405196165564, Learning Rate: 0.023365000000000004\n",
      "Epoch: 15328, MSE: 0.23500123424236205, Learning Rate: 0.023360000000000006\n",
      "Epoch: 15329, MSE: 0.23499841649948192, Learning Rate: 0.023355000000000004\n",
      "Epoch: 15330, MSE: 0.23499559873302725, Learning Rate: 0.023350000000000006\n",
      "Epoch: 15331, MSE: 0.23499278094301362, Learning Rate: 0.023345000000000005\n",
      "Epoch: 15332, MSE: 0.23498996312945497, Learning Rate: 0.023340000000000007\n",
      "Epoch: 15333, MSE: 0.23498714529236578, Learning Rate: 0.023334999999999995\n",
      "Epoch: 15334, MSE: 0.23498432743176034, Learning Rate: 0.023329999999999997\n",
      "Epoch: 15335, MSE: 0.2349815095476539, Learning Rate: 0.023325\n",
      "Epoch: 15336, MSE: 0.23497869164006055, Learning Rate: 0.023319999999999997\n",
      "Epoch: 15337, MSE: 0.23497587370899486, Learning Rate: 0.023315\n",
      "Epoch: 15338, MSE: 0.23497305575447006, Learning Rate: 0.023309999999999997\n",
      "Epoch: 15339, MSE: 0.23497023777650217, Learning Rate: 0.023305\n",
      "Epoch: 15340, MSE: 0.2349674197751053, Learning Rate: 0.0233\n",
      "Epoch: 15341, MSE: 0.23496460175029352, Learning Rate: 0.023295\n",
      "Epoch: 15342, MSE: 0.23496178370208187, Learning Rate: 0.02329\n",
      "Epoch: 15343, MSE: 0.2349589656304851, Learning Rate: 0.023285\n",
      "Epoch: 15344, MSE: 0.23495614753551633, Learning Rate: 0.023280000000000002\n",
      "Epoch: 15345, MSE: 0.23495332941719138, Learning Rate: 0.023275000000000004\n",
      "Epoch: 15346, MSE: 0.23495051127552463, Learning Rate: 0.023270000000000002\n",
      "Epoch: 15347, MSE: 0.23494769311053149, Learning Rate: 0.023265000000000004\n",
      "Epoch: 15348, MSE: 0.23494487492222477, Learning Rate: 0.023260000000000003\n",
      "Epoch: 15349, MSE: 0.2349420567106206, Learning Rate: 0.023255000000000005\n",
      "Epoch: 15350, MSE: 0.2349392384757329, Learning Rate: 0.023250000000000007\n",
      "Epoch: 15351, MSE: 0.2349364202175758, Learning Rate: 0.023245000000000005\n",
      "Epoch: 15352, MSE: 0.23493360193616528, Learning Rate: 0.023240000000000007\n",
      "Epoch: 15353, MSE: 0.23493078363151523, Learning Rate: 0.023234999999999995\n",
      "Epoch: 15354, MSE: 0.2349279653036411, Learning Rate: 0.023229999999999997\n",
      "Epoch: 15355, MSE: 0.23492514695255595, Learning Rate: 0.023224999999999996\n",
      "Epoch: 15356, MSE: 0.23492232857827636, Learning Rate: 0.023219999999999998\n",
      "Epoch: 15357, MSE: 0.23491951018081492, Learning Rate: 0.023215\n",
      "Epoch: 15358, MSE: 0.23491669176018853, Learning Rate: 0.023209999999999998\n",
      "Epoch: 15359, MSE: 0.23491387331641053, Learning Rate: 0.023205\n",
      "Epoch: 15360, MSE: 0.23491105484949673, Learning Rate: 0.0232\n",
      "Epoch: 15361, MSE: 0.2349082363594617, Learning Rate: 0.023195\n",
      "Epoch: 15362, MSE: 0.23490541784631921, Learning Rate: 0.023190000000000002\n",
      "Epoch: 15363, MSE: 0.23490259931008484, Learning Rate: 0.023185\n",
      "Epoch: 15364, MSE: 0.23489978075077395, Learning Rate: 0.023180000000000003\n",
      "Epoch: 15365, MSE: 0.23489696216840014, Learning Rate: 0.023175\n",
      "Epoch: 15366, MSE: 0.23489414356297902, Learning Rate: 0.023170000000000003\n",
      "Epoch: 15367, MSE: 0.2348913249345252, Learning Rate: 0.023165000000000005\n",
      "Epoch: 15368, MSE: 0.23488850628305388, Learning Rate: 0.023160000000000004\n",
      "Epoch: 15369, MSE: 0.23488568760857975, Learning Rate: 0.023155000000000005\n",
      "Epoch: 15370, MSE: 0.23488286891111743, Learning Rate: 0.023150000000000004\n",
      "Epoch: 15371, MSE: 0.23488005019068228, Learning Rate: 0.023145000000000006\n",
      "Epoch: 15372, MSE: 0.23487723144728895, Learning Rate: 0.023140000000000008\n",
      "Epoch: 15373, MSE: 0.23487441268095255, Learning Rate: 0.023134999999999996\n",
      "Epoch: 15374, MSE: 0.23487159389168805, Learning Rate: 0.023129999999999998\n",
      "Epoch: 15375, MSE: 0.23486877507950935, Learning Rate: 0.023124999999999996\n",
      "Epoch: 15376, MSE: 0.23486595624443346, Learning Rate: 0.023119999999999998\n",
      "Epoch: 15377, MSE: 0.23486313738647369, Learning Rate: 0.023114999999999997\n",
      "Epoch: 15378, MSE: 0.23486031850564648, Learning Rate: 0.02311\n",
      "Epoch: 15379, MSE: 0.23485749960196473, Learning Rate: 0.023105\n",
      "Epoch: 15380, MSE: 0.23485468067544568, Learning Rate: 0.0231\n",
      "Epoch: 15381, MSE: 0.23485186172610314, Learning Rate: 0.023095\n",
      "Epoch: 15382, MSE: 0.2348490427539529, Learning Rate: 0.02309\n",
      "Epoch: 15383, MSE: 0.2348462237590093, Learning Rate: 0.023085\n",
      "Epoch: 15384, MSE: 0.23484340474128781, Learning Rate: 0.023080000000000003\n",
      "Epoch: 15385, MSE: 0.23484058570080332, Learning Rate: 0.023075000000000002\n",
      "Epoch: 15386, MSE: 0.23483776663757147, Learning Rate: 0.023070000000000004\n",
      "Epoch: 15387, MSE: 0.23483494755160667, Learning Rate: 0.023065000000000002\n",
      "Epoch: 15388, MSE: 0.23483212844292445, Learning Rate: 0.023060000000000004\n",
      "Epoch: 15389, MSE: 0.23482930931154034, Learning Rate: 0.023055000000000006\n",
      "Epoch: 15390, MSE: 0.23482649015746823, Learning Rate: 0.023050000000000005\n",
      "Epoch: 15391, MSE: 0.23482367098072454, Learning Rate: 0.023045000000000006\n",
      "Epoch: 15392, MSE: 0.23482085178132436, Learning Rate: 0.023040000000000005\n",
      "Epoch: 15393, MSE: 0.2348180325592832, Learning Rate: 0.023035000000000007\n",
      "Epoch: 15394, MSE: 0.2348152133146149, Learning Rate: 0.023029999999999995\n",
      "Epoch: 15395, MSE: 0.23481239404733503, Learning Rate: 0.023024999999999997\n",
      "Epoch: 15396, MSE: 0.2348095747574614, Learning Rate: 0.02302\n",
      "Epoch: 15397, MSE: 0.23480675544500496, Learning Rate: 0.023014999999999997\n",
      "Epoch: 15398, MSE: 0.23480393610998423, Learning Rate: 0.02301\n",
      "Epoch: 15399, MSE: 0.23480111675241308, Learning Rate: 0.023004999999999998\n",
      "Epoch: 15400, MSE: 0.2347982973723076, Learning Rate: 0.023\n",
      "Epoch: 15401, MSE: 0.2347954779696831, Learning Rate: 0.022995\n",
      "Epoch: 15402, MSE: 0.23479265854455386, Learning Rate: 0.02299\n",
      "Epoch: 15403, MSE: 0.2347898390969362, Learning Rate: 0.022985000000000002\n",
      "Epoch: 15404, MSE: 0.23478701962684573, Learning Rate: 0.02298\n",
      "Epoch: 15405, MSE: 0.23478420013429668, Learning Rate: 0.022975000000000002\n",
      "Epoch: 15406, MSE: 0.2347813806193055, Learning Rate: 0.022970000000000004\n",
      "Epoch: 15407, MSE: 0.23477856108188686, Learning Rate: 0.022965000000000003\n",
      "Epoch: 15408, MSE: 0.23477574152205666, Learning Rate: 0.022960000000000005\n",
      "Epoch: 15409, MSE: 0.23477292193983007, Learning Rate: 0.022955000000000003\n",
      "Epoch: 15410, MSE: 0.2347701023352229, Learning Rate: 0.022950000000000005\n",
      "Epoch: 15411, MSE: 0.23476728270825054, Learning Rate: 0.022945000000000007\n",
      "Epoch: 15412, MSE: 0.2347644630589277, Learning Rate: 0.022940000000000006\n",
      "Epoch: 15413, MSE: 0.23476164338727076, Learning Rate: 0.022935000000000007\n",
      "Epoch: 15414, MSE: 0.23475882369329523, Learning Rate: 0.022929999999999996\n",
      "Epoch: 15415, MSE: 0.23475600397701524, Learning Rate: 0.022924999999999997\n",
      "Epoch: 15416, MSE: 0.23475318423844874, Learning Rate: 0.022919999999999996\n",
      "Epoch: 15417, MSE: 0.2347503644776093, Learning Rate: 0.022914999999999998\n",
      "Epoch: 15418, MSE: 0.23474754469451348, Learning Rate: 0.02291\n",
      "Epoch: 15419, MSE: 0.2347447248891755, Learning Rate: 0.022905\n",
      "Epoch: 15420, MSE: 0.23474190506161285, Learning Rate: 0.0229\n",
      "Epoch: 15421, MSE: 0.23473908521184003, Learning Rate: 0.022895\n",
      "Epoch: 15422, MSE: 0.23473626533987293, Learning Rate: 0.02289\n",
      "Epoch: 15423, MSE: 0.23473344544572655, Learning Rate: 0.022885000000000003\n",
      "Epoch: 15424, MSE: 0.23473062552941792, Learning Rate: 0.02288\n",
      "Epoch: 15425, MSE: 0.23472780559096154, Learning Rate: 0.022875000000000003\n",
      "Epoch: 15426, MSE: 0.23472498563037267, Learning Rate: 0.02287\n",
      "Epoch: 15427, MSE: 0.2347221656476689, Learning Rate: 0.022865000000000003\n",
      "Epoch: 15428, MSE: 0.23471934564286465, Learning Rate: 0.022860000000000005\n",
      "Epoch: 15429, MSE: 0.23471652561597556, Learning Rate: 0.022855000000000004\n",
      "Epoch: 15430, MSE: 0.2347137055670172, Learning Rate: 0.022850000000000006\n",
      "Epoch: 15431, MSE: 0.23471088549600594, Learning Rate: 0.022845000000000004\n",
      "Epoch: 15432, MSE: 0.23470806540295658, Learning Rate: 0.022840000000000006\n",
      "Epoch: 15433, MSE: 0.23470524528788667, Learning Rate: 0.022835000000000008\n",
      "Epoch: 15434, MSE: 0.23470242515081088, Learning Rate: 0.022829999999999996\n",
      "Epoch: 15435, MSE: 0.23469960499174436, Learning Rate: 0.022824999999999998\n",
      "Epoch: 15436, MSE: 0.23469678481070386, Learning Rate: 0.022819999999999997\n",
      "Epoch: 15437, MSE: 0.23469396460770478, Learning Rate: 0.022815\n",
      "Epoch: 15438, MSE: 0.23469114438276342, Learning Rate: 0.022809999999999997\n",
      "Epoch: 15439, MSE: 0.23468832413589594, Learning Rate: 0.022805\n",
      "Epoch: 15440, MSE: 0.23468550386711667, Learning Rate: 0.0228\n",
      "Epoch: 15441, MSE: 0.2346826835764433, Learning Rate: 0.022795\n",
      "Epoch: 15442, MSE: 0.23467986326389056, Learning Rate: 0.02279\n",
      "Epoch: 15443, MSE: 0.23467704292947478, Learning Rate: 0.022785\n",
      "Epoch: 15444, MSE: 0.2346742225732116, Learning Rate: 0.02278\n",
      "Epoch: 15445, MSE: 0.23467140219511745, Learning Rate: 0.022775000000000004\n",
      "Epoch: 15446, MSE: 0.23466858179520833, Learning Rate: 0.022770000000000002\n",
      "Epoch: 15447, MSE: 0.23466576137349898, Learning Rate: 0.022765000000000004\n",
      "Epoch: 15448, MSE: 0.23466294093000806, Learning Rate: 0.022760000000000002\n",
      "Epoch: 15449, MSE: 0.2346601204647489, Learning Rate: 0.022755000000000004\n",
      "Epoch: 15450, MSE: 0.23465729997773827, Learning Rate: 0.022750000000000006\n",
      "Epoch: 15451, MSE: 0.23465447946899315, Learning Rate: 0.022745000000000005\n",
      "Epoch: 15452, MSE: 0.2346516589385277, Learning Rate: 0.022740000000000007\n",
      "Epoch: 15453, MSE: 0.2346488383863603, Learning Rate: 0.022735000000000005\n",
      "Epoch: 15454, MSE: 0.23464601781250535, Learning Rate: 0.022729999999999997\n",
      "Epoch: 15455, MSE: 0.2346431972169798, Learning Rate: 0.022724999999999995\n",
      "Epoch: 15456, MSE: 0.2346403765997991, Learning Rate: 0.022719999999999997\n",
      "Epoch: 15457, MSE: 0.23463755596098013, Learning Rate: 0.022715\n",
      "Epoch: 15458, MSE: 0.2346347353005387, Learning Rate: 0.022709999999999998\n",
      "Epoch: 15459, MSE: 0.23463191461849062, Learning Rate: 0.022705\n",
      "Epoch: 15460, MSE: 0.23462909391485293, Learning Rate: 0.022699999999999998\n",
      "Epoch: 15461, MSE: 0.2346262731896403, Learning Rate: 0.022695\n",
      "Epoch: 15462, MSE: 0.2346234524428697, Learning Rate: 0.022690000000000002\n",
      "Epoch: 15463, MSE: 0.2346206316745584, Learning Rate: 0.022685\n",
      "Epoch: 15464, MSE: 0.23461781088472136, Learning Rate: 0.022680000000000002\n",
      "Epoch: 15465, MSE: 0.2346149900733749, Learning Rate: 0.022675\n",
      "Epoch: 15466, MSE: 0.23461216924053643, Learning Rate: 0.022670000000000003\n",
      "Epoch: 15467, MSE: 0.23460934838622124, Learning Rate: 0.022665000000000005\n",
      "Epoch: 15468, MSE: 0.23460652751044517, Learning Rate: 0.022660000000000003\n",
      "Epoch: 15469, MSE: 0.23460370661322533, Learning Rate: 0.022655000000000005\n",
      "Epoch: 15470, MSE: 0.234600885694578, Learning Rate: 0.022650000000000003\n",
      "Epoch: 15471, MSE: 0.23459806475451933, Learning Rate: 0.022645000000000005\n",
      "Epoch: 15472, MSE: 0.23459524379306465, Learning Rate: 0.022640000000000007\n",
      "Epoch: 15473, MSE: 0.23459242281023257, Learning Rate: 0.022635000000000006\n",
      "Epoch: 15474, MSE: 0.23458960180603752, Learning Rate: 0.022629999999999997\n",
      "Epoch: 15475, MSE: 0.23458678078049786, Learning Rate: 0.022624999999999996\n",
      "Epoch: 15476, MSE: 0.2345839597336279, Learning Rate: 0.022619999999999998\n",
      "Epoch: 15477, MSE: 0.23458113866544503, Learning Rate: 0.022614999999999996\n",
      "Epoch: 15478, MSE: 0.23457831757596553, Learning Rate: 0.022609999999999998\n",
      "Epoch: 15479, MSE: 0.23457549646520567, Learning Rate: 0.022605\n",
      "Epoch: 15480, MSE: 0.23457267533318202, Learning Rate: 0.0226\n",
      "Epoch: 15481, MSE: 0.23456985417991233, Learning Rate: 0.022595\n",
      "Epoch: 15482, MSE: 0.23456703300541062, Learning Rate: 0.02259\n",
      "Epoch: 15483, MSE: 0.23456421180969544, Learning Rate: 0.022585\n",
      "Epoch: 15484, MSE: 0.234561390592783, Learning Rate: 0.022580000000000003\n",
      "Epoch: 15485, MSE: 0.23455856935468944, Learning Rate: 0.022575\n",
      "Epoch: 15486, MSE: 0.23455574809543062, Learning Rate: 0.022570000000000003\n",
      "Epoch: 15487, MSE: 0.23455292681502443, Learning Rate: 0.022565\n",
      "Epoch: 15488, MSE: 0.234550105513487, Learning Rate: 0.022560000000000004\n",
      "Epoch: 15489, MSE: 0.23454728419083468, Learning Rate: 0.022555000000000006\n",
      "Epoch: 15490, MSE: 0.23454446284708452, Learning Rate: 0.022550000000000004\n",
      "Epoch: 15491, MSE: 0.2345416414822527, Learning Rate: 0.022545000000000006\n",
      "Epoch: 15492, MSE: 0.2345388200963564, Learning Rate: 0.022540000000000004\n",
      "Epoch: 15493, MSE: 0.23453599868941186, Learning Rate: 0.022535000000000006\n",
      "Epoch: 15494, MSE: 0.23453317726143563, Learning Rate: 0.022529999999999994\n",
      "Epoch: 15495, MSE: 0.23453035581244477, Learning Rate: 0.022524999999999996\n",
      "Epoch: 15496, MSE: 0.23452753434245588, Learning Rate: 0.02252\n",
      "Epoch: 15497, MSE: 0.2345247128514867, Learning Rate: 0.022514999999999997\n",
      "Epoch: 15498, MSE: 0.23452189133955126, Learning Rate: 0.02251\n",
      "Epoch: 15499, MSE: 0.23451906980666953, Learning Rate: 0.022504999999999997\n",
      "Epoch: 15500, MSE: 0.2345162482528558, Learning Rate: 0.0225\n",
      "Epoch: 15501, MSE: 0.23451342667812822, Learning Rate: 0.022495\n",
      "Epoch: 15502, MSE: 0.23451060508250374, Learning Rate: 0.02249\n",
      "Epoch: 15503, MSE: 0.2345077834659979, Learning Rate: 0.022485\n",
      "Epoch: 15504, MSE: 0.23450496182862854, Learning Rate: 0.02248\n",
      "Epoch: 15505, MSE: 0.23450214017041265, Learning Rate: 0.022475000000000002\n",
      "Epoch: 15506, MSE: 0.23449931849136704, Learning Rate: 0.022470000000000004\n",
      "Epoch: 15507, MSE: 0.23449649679150725, Learning Rate: 0.022465000000000002\n",
      "Epoch: 15508, MSE: 0.2344936750708525, Learning Rate: 0.022460000000000004\n",
      "Epoch: 15509, MSE: 0.23449085332941835, Learning Rate: 0.022455000000000003\n",
      "Epoch: 15510, MSE: 0.2344880315672218, Learning Rate: 0.022450000000000005\n",
      "Epoch: 15511, MSE: 0.23448520978427875, Learning Rate: 0.022445000000000007\n",
      "Epoch: 15512, MSE: 0.23448238798060844, Learning Rate: 0.022440000000000005\n",
      "Epoch: 15513, MSE: 0.2344795661562262, Learning Rate: 0.022435000000000007\n",
      "Epoch: 15514, MSE: 0.2344767443111495, Learning Rate: 0.022430000000000005\n",
      "Epoch: 15515, MSE: 0.23447392244539594, Learning Rate: 0.022424999999999997\n",
      "Epoch: 15516, MSE: 0.23447110055898168, Learning Rate: 0.022419999999999995\n",
      "Epoch: 15517, MSE: 0.2344682786519243, Learning Rate: 0.022414999999999997\n",
      "Epoch: 15518, MSE: 0.23446545672424038, Learning Rate: 0.02241\n",
      "Epoch: 15519, MSE: 0.23446263477594828, Learning Rate: 0.022404999999999998\n",
      "Epoch: 15520, MSE: 0.23445981280706216, Learning Rate: 0.0224\n",
      "Epoch: 15521, MSE: 0.2344569908176025, Learning Rate: 0.022394999999999998\n",
      "Epoch: 15522, MSE: 0.23445416880758452, Learning Rate: 0.02239\n",
      "Epoch: 15523, MSE: 0.23445134677702617, Learning Rate: 0.022385000000000002\n",
      "Epoch: 15524, MSE: 0.23444852472594424, Learning Rate: 0.02238\n",
      "Epoch: 15525, MSE: 0.234445702654356, Learning Rate: 0.022375000000000003\n",
      "Epoch: 15526, MSE: 0.2344428805622781, Learning Rate: 0.02237\n",
      "Epoch: 15527, MSE: 0.23444005844972832, Learning Rate: 0.022365000000000003\n",
      "Epoch: 15528, MSE: 0.23443723631672347, Learning Rate: 0.022360000000000005\n",
      "Epoch: 15529, MSE: 0.23443441416328198, Learning Rate: 0.022355000000000003\n",
      "Epoch: 15530, MSE: 0.23443159198941996, Learning Rate: 0.022350000000000005\n",
      "Epoch: 15531, MSE: 0.23442876979515548, Learning Rate: 0.022345000000000004\n",
      "Epoch: 15532, MSE: 0.23442594758050406, Learning Rate: 0.022340000000000006\n",
      "Epoch: 15533, MSE: 0.23442312534548482, Learning Rate: 0.022335000000000008\n",
      "Epoch: 15534, MSE: 0.2344203030901146, Learning Rate: 0.022330000000000006\n",
      "Epoch: 15535, MSE: 0.2344174808144108, Learning Rate: 0.022324999999999998\n",
      "Epoch: 15536, MSE: 0.23441465851838983, Learning Rate: 0.022319999999999996\n",
      "Epoch: 15537, MSE: 0.23441183620207118, Learning Rate: 0.022314999999999998\n",
      "Epoch: 15538, MSE: 0.23440901386546997, Learning Rate: 0.022309999999999997\n",
      "Epoch: 15539, MSE: 0.2344061915086048, Learning Rate: 0.022305\n",
      "Epoch: 15540, MSE: 0.23440336913149276, Learning Rate: 0.0223\n",
      "Epoch: 15541, MSE: 0.23440054673415128, Learning Rate: 0.022295\n",
      "Epoch: 15542, MSE: 0.23439772431659803, Learning Rate: 0.02229\n",
      "Epoch: 15543, MSE: 0.23439490187884948, Learning Rate: 0.022285\n",
      "Epoch: 15544, MSE: 0.23439207942092544, Learning Rate: 0.02228\n",
      "Epoch: 15545, MSE: 0.2343892569428412, Learning Rate: 0.022275000000000003\n",
      "Epoch: 15546, MSE: 0.23438643444461482, Learning Rate: 0.02227\n",
      "Epoch: 15547, MSE: 0.23438361192626472, Learning Rate: 0.022265000000000004\n",
      "Epoch: 15548, MSE: 0.23438078938780746, Learning Rate: 0.022260000000000002\n",
      "Epoch: 15549, MSE: 0.23437796682926035, Learning Rate: 0.022255000000000004\n",
      "Epoch: 15550, MSE: 0.2343751442506421, Learning Rate: 0.022250000000000006\n",
      "Epoch: 15551, MSE: 0.23437232165196922, Learning Rate: 0.022245000000000004\n",
      "Epoch: 15552, MSE: 0.23436949903326043, Learning Rate: 0.022240000000000006\n",
      "Epoch: 15553, MSE: 0.23436667639453246, Learning Rate: 0.022235000000000005\n",
      "Epoch: 15554, MSE: 0.2343638537358034, Learning Rate: 0.022230000000000007\n",
      "Epoch: 15555, MSE: 0.23436103105709083, Learning Rate: 0.022224999999999995\n",
      "Epoch: 15556, MSE: 0.2343582083584117, Learning Rate: 0.022219999999999997\n",
      "Epoch: 15557, MSE: 0.23435538563978525, Learning Rate: 0.022215\n",
      "Epoch: 15558, MSE: 0.23435256290122788, Learning Rate: 0.022209999999999997\n",
      "Epoch: 15559, MSE: 0.23434974014275883, Learning Rate: 0.022205\n",
      "Epoch: 15560, MSE: 0.23434691736439342, Learning Rate: 0.022199999999999998\n",
      "Epoch: 15561, MSE: 0.23434409456615113, Learning Rate: 0.022195\n",
      "Epoch: 15562, MSE: 0.2343412717480499, Learning Rate: 0.02219\n",
      "Epoch: 15563, MSE: 0.2343384489101065, Learning Rate: 0.022185\n",
      "Epoch: 15564, MSE: 0.2343356260523398, Learning Rate: 0.022180000000000002\n",
      "Epoch: 15565, MSE: 0.23433280317476599, Learning Rate: 0.022175\n",
      "Epoch: 15566, MSE: 0.23432998027740534, Learning Rate: 0.022170000000000002\n",
      "Epoch: 15567, MSE: 0.2343271573602738, Learning Rate: 0.022165000000000004\n",
      "Epoch: 15568, MSE: 0.2343243344233897, Learning Rate: 0.022160000000000003\n",
      "Epoch: 15569, MSE: 0.23432151146677146, Learning Rate: 0.022155000000000005\n",
      "Epoch: 15570, MSE: 0.23431868849043677, Learning Rate: 0.022150000000000003\n",
      "Epoch: 15571, MSE: 0.23431586549440325, Learning Rate: 0.022145000000000005\n",
      "Epoch: 15572, MSE: 0.23431304247868873, Learning Rate: 0.022140000000000007\n",
      "Epoch: 15573, MSE: 0.23431021944331223, Learning Rate: 0.022135000000000005\n",
      "Epoch: 15574, MSE: 0.23430739638829054, Learning Rate: 0.022130000000000007\n",
      "Epoch: 15575, MSE: 0.23430457331364254, Learning Rate: 0.022124999999999995\n",
      "Epoch: 15576, MSE: 0.234301750219385, Learning Rate: 0.022119999999999997\n",
      "Epoch: 15577, MSE: 0.23429892710553735, Learning Rate: 0.022114999999999996\n",
      "Epoch: 15578, MSE: 0.23429610397211692, Learning Rate: 0.022109999999999998\n",
      "Epoch: 15579, MSE: 0.23429328081914158, Learning Rate: 0.022105\n",
      "Epoch: 15580, MSE: 0.23429045764663078, Learning Rate: 0.022099999999999998\n",
      "Epoch: 15581, MSE: 0.2342876344546008, Learning Rate: 0.022095\n",
      "Epoch: 15582, MSE: 0.23428481124307063, Learning Rate: 0.02209\n",
      "Epoch: 15583, MSE: 0.23428198801205857, Learning Rate: 0.022085\n",
      "Epoch: 15584, MSE: 0.23427916476158245, Learning Rate: 0.022080000000000002\n",
      "Epoch: 15585, MSE: 0.2342763414916611, Learning Rate: 0.022075\n",
      "Epoch: 15586, MSE: 0.23427351820231135, Learning Rate: 0.022070000000000003\n",
      "Epoch: 15587, MSE: 0.23427069489355237, Learning Rate: 0.022065\n",
      "Epoch: 15588, MSE: 0.23426787156540307, Learning Rate: 0.022060000000000003\n",
      "Epoch: 15589, MSE: 0.23426504821787986, Learning Rate: 0.022055000000000005\n",
      "Epoch: 15590, MSE: 0.2342622248510025, Learning Rate: 0.022050000000000004\n",
      "Epoch: 15591, MSE: 0.23425940146478907, Learning Rate: 0.022045000000000006\n",
      "Epoch: 15592, MSE: 0.2342565780592568, Learning Rate: 0.022040000000000004\n",
      "Epoch: 15593, MSE: 0.2342537546344253, Learning Rate: 0.022035000000000006\n",
      "Epoch: 15594, MSE: 0.23425093119031187, Learning Rate: 0.022030000000000008\n",
      "Epoch: 15595, MSE: 0.234248107726936, Learning Rate: 0.022024999999999996\n",
      "Epoch: 15596, MSE: 0.23424528424431446, Learning Rate: 0.022019999999999998\n",
      "Epoch: 15597, MSE: 0.2342424607424677, Learning Rate: 0.022014999999999996\n",
      "Epoch: 15598, MSE: 0.23423963722141264, Learning Rate: 0.02201\n",
      "Epoch: 15599, MSE: 0.23423681368116805, Learning Rate: 0.022004999999999997\n",
      "Epoch: 15600, MSE: 0.23423399012175192, Learning Rate: 0.022\n",
      "Epoch: 15601, MSE: 0.23423116654318304, Learning Rate: 0.021995\n",
      "Epoch: 15602, MSE: 0.23422834294548014, Learning Rate: 0.02199\n",
      "Epoch: 15603, MSE: 0.2342255193286623, Learning Rate: 0.021985\n",
      "Epoch: 15604, MSE: 0.23422269569274642, Learning Rate: 0.02198\n",
      "Epoch: 15605, MSE: 0.23421987203775263, Learning Rate: 0.021975\n",
      "Epoch: 15606, MSE: 0.23421704836369822, Learning Rate: 0.021970000000000003\n",
      "Epoch: 15607, MSE: 0.2342142246706025, Learning Rate: 0.021965000000000002\n",
      "Epoch: 15608, MSE: 0.23421140095848303, Learning Rate: 0.021960000000000004\n",
      "Epoch: 15609, MSE: 0.23420857722735922, Learning Rate: 0.021955000000000002\n",
      "Epoch: 15610, MSE: 0.2342057534772506, Learning Rate: 0.021950000000000004\n",
      "Epoch: 15611, MSE: 0.23420292970817427, Learning Rate: 0.021945000000000006\n",
      "Epoch: 15612, MSE: 0.23420010592014964, Learning Rate: 0.021940000000000005\n",
      "Epoch: 15613, MSE: 0.23419728211319518, Learning Rate: 0.021935000000000007\n",
      "Epoch: 15614, MSE: 0.23419445828732902, Learning Rate: 0.021930000000000005\n",
      "Epoch: 15615, MSE: 0.23419163444257088, Learning Rate: 0.021924999999999997\n",
      "Epoch: 15616, MSE: 0.23418881057893864, Learning Rate: 0.021919999999999995\n",
      "Epoch: 15617, MSE: 0.23418598669645135, Learning Rate: 0.021914999999999997\n",
      "Epoch: 15618, MSE: 0.2341831627951284, Learning Rate: 0.02191\n",
      "Epoch: 15619, MSE: 0.23418033887498746, Learning Rate: 0.021904999999999997\n",
      "Epoch: 15620, MSE: 0.23417751493604763, Learning Rate: 0.0219\n",
      "Epoch: 15621, MSE: 0.23417469097832816, Learning Rate: 0.021894999999999998\n",
      "Epoch: 15622, MSE: 0.23417186700184792, Learning Rate: 0.02189\n",
      "Epoch: 15623, MSE: 0.23416904300662472, Learning Rate: 0.021885\n",
      "Epoch: 15624, MSE: 0.23416621899267878, Learning Rate: 0.02188\n",
      "Epoch: 15625, MSE: 0.23416339496002775, Learning Rate: 0.021875000000000002\n",
      "Epoch: 15626, MSE: 0.23416057090869177, Learning Rate: 0.02187\n",
      "Epoch: 15627, MSE: 0.23415774683868842, Learning Rate: 0.021865000000000002\n",
      "Epoch: 15628, MSE: 0.2341549227500376, Learning Rate: 0.021860000000000004\n",
      "Epoch: 15629, MSE: 0.23415209864275832, Learning Rate: 0.021855000000000003\n",
      "Epoch: 15630, MSE: 0.23414927451686893, Learning Rate: 0.021850000000000005\n",
      "Epoch: 15631, MSE: 0.23414645037238874, Learning Rate: 0.021845000000000003\n",
      "Epoch: 15632, MSE: 0.23414362620933662, Learning Rate: 0.021840000000000005\n",
      "Epoch: 15633, MSE: 0.23414080202773183, Learning Rate: 0.021835000000000007\n",
      "Epoch: 15634, MSE: 0.2341379778275925, Learning Rate: 0.021830000000000006\n",
      "Epoch: 15635, MSE: 0.23413515360893933, Learning Rate: 0.021825000000000008\n",
      "Epoch: 15636, MSE: 0.23413232937179024, Learning Rate: 0.021819999999999996\n",
      "Epoch: 15637, MSE: 0.23412950511616426, Learning Rate: 0.021814999999999998\n",
      "Epoch: 15638, MSE: 0.23412668084208155, Learning Rate: 0.021809999999999996\n",
      "Epoch: 15639, MSE: 0.23412385654956017, Learning Rate: 0.021804999999999998\n",
      "Epoch: 15640, MSE: 0.23412103223861966, Learning Rate: 0.0218\n",
      "Epoch: 15641, MSE: 0.23411820790927937, Learning Rate: 0.021795\n",
      "Epoch: 15642, MSE: 0.23411538356155775, Learning Rate: 0.02179\n",
      "Epoch: 15643, MSE: 0.23411255919547522, Learning Rate: 0.021785\n",
      "Epoch: 15644, MSE: 0.2341097348110498, Learning Rate: 0.02178\n",
      "Epoch: 15645, MSE: 0.23410691040830156, Learning Rate: 0.021775000000000003\n",
      "Epoch: 15646, MSE: 0.23410408598724902, Learning Rate: 0.02177\n",
      "Epoch: 15647, MSE: 0.23410126154791255, Learning Rate: 0.021765000000000003\n",
      "Epoch: 15648, MSE: 0.23409843709031036, Learning Rate: 0.02176\n",
      "Epoch: 15649, MSE: 0.23409561261446266, Learning Rate: 0.021755000000000004\n",
      "Epoch: 15650, MSE: 0.2340927881203879, Learning Rate: 0.021750000000000005\n",
      "Epoch: 15651, MSE: 0.23408996360810605, Learning Rate: 0.021745000000000004\n",
      "Epoch: 15652, MSE: 0.23408713907763595, Learning Rate: 0.021740000000000006\n",
      "Epoch: 15653, MSE: 0.2340843145289978, Learning Rate: 0.021735000000000004\n",
      "Epoch: 15654, MSE: 0.23408148996221087, Learning Rate: 0.021730000000000006\n",
      "Epoch: 15655, MSE: 0.23407866537729358, Learning Rate: 0.021725000000000008\n",
      "Epoch: 15656, MSE: 0.2340758407742665, Learning Rate: 0.021719999999999996\n",
      "Epoch: 15657, MSE: 0.23407301615314868, Learning Rate: 0.021714999999999998\n",
      "Epoch: 15658, MSE: 0.23407019151395891, Learning Rate: 0.021709999999999997\n",
      "Epoch: 15659, MSE: 0.23406736685671817, Learning Rate: 0.021705\n",
      "Epoch: 15660, MSE: 0.2340645421814451, Learning Rate: 0.021699999999999997\n",
      "Epoch: 15661, MSE: 0.23406171748815938, Learning Rate: 0.021695\n",
      "Epoch: 15662, MSE: 0.23405889277688025, Learning Rate: 0.02169\n",
      "Epoch: 15663, MSE: 0.2340560680476274, Learning Rate: 0.021685\n",
      "Epoch: 15664, MSE: 0.23405324330042135, Learning Rate: 0.02168\n",
      "Epoch: 15665, MSE: 0.2340504185352802, Learning Rate: 0.021675\n",
      "Epoch: 15666, MSE: 0.23404759375222461, Learning Rate: 0.021670000000000002\n",
      "Epoch: 15667, MSE: 0.2340447689512739, Learning Rate: 0.021665000000000004\n",
      "Epoch: 15668, MSE: 0.23404194413244853, Learning Rate: 0.021660000000000002\n",
      "Epoch: 15669, MSE: 0.2340391192957666, Learning Rate: 0.021655000000000004\n",
      "Epoch: 15670, MSE: 0.23403629444124968, Learning Rate: 0.021650000000000003\n",
      "Epoch: 15671, MSE: 0.23403346956891566, Learning Rate: 0.021645000000000005\n",
      "Epoch: 15672, MSE: 0.2340306446787855, Learning Rate: 0.021640000000000006\n",
      "Epoch: 15673, MSE: 0.23402781977087891, Learning Rate: 0.021635000000000005\n",
      "Epoch: 15674, MSE: 0.23402499484521472, Learning Rate: 0.021630000000000007\n",
      "Epoch: 15675, MSE: 0.23402216990181365, Learning Rate: 0.021625000000000005\n",
      "Epoch: 15676, MSE: 0.23401934494069548, Learning Rate: 0.021619999999999997\n",
      "Epoch: 15677, MSE: 0.23401651996188025, Learning Rate: 0.021614999999999995\n",
      "Epoch: 15678, MSE: 0.23401369496538676, Learning Rate: 0.021609999999999997\n",
      "Epoch: 15679, MSE: 0.23401086995123596, Learning Rate: 0.021605\n",
      "Epoch: 15680, MSE: 0.2340080449194474, Learning Rate: 0.021599999999999998\n",
      "Epoch: 15681, MSE: 0.23400521987004091, Learning Rate: 0.021595\n",
      "Epoch: 15682, MSE: 0.23400239480303678, Learning Rate: 0.021589999999999998\n",
      "Epoch: 15683, MSE: 0.23399956971845431, Learning Rate: 0.021585\n",
      "Epoch: 15684, MSE: 0.2339967446163144, Learning Rate: 0.021580000000000002\n",
      "Epoch: 15685, MSE: 0.23399391949663542, Learning Rate: 0.021575\n",
      "Epoch: 15686, MSE: 0.23399109435943938, Learning Rate: 0.021570000000000002\n",
      "Epoch: 15687, MSE: 0.2339882692047449, Learning Rate: 0.021565\n",
      "Epoch: 15688, MSE: 0.23398544403257354, Learning Rate: 0.021560000000000003\n",
      "Epoch: 15689, MSE: 0.23398261884294327, Learning Rate: 0.021555000000000005\n",
      "Epoch: 15690, MSE: 0.23397979363587615, Learning Rate: 0.021550000000000003\n",
      "Epoch: 15691, MSE: 0.23397696841139118, Learning Rate: 0.021545000000000005\n",
      "Epoch: 15692, MSE: 0.23397414316950862, Learning Rate: 0.021540000000000004\n",
      "Epoch: 15693, MSE: 0.233971317910249, Learning Rate: 0.021535000000000006\n",
      "Epoch: 15694, MSE: 0.2339684926336322, Learning Rate: 0.021530000000000007\n",
      "Epoch: 15695, MSE: 0.23396566733967866, Learning Rate: 0.021525000000000006\n",
      "Epoch: 15696, MSE: 0.23396284202840825, Learning Rate: 0.021519999999999997\n",
      "Epoch: 15697, MSE: 0.23396001669984184, Learning Rate: 0.021514999999999996\n",
      "Epoch: 15698, MSE: 0.23395719135399945, Learning Rate: 0.021509999999999998\n",
      "Epoch: 15699, MSE: 0.23395436599090022, Learning Rate: 0.021504999999999996\n",
      "Epoch: 15700, MSE: 0.23395154061056592, Learning Rate: 0.0215\n",
      "Epoch: 15701, MSE: 0.23394871521301625, Learning Rate: 0.021495\n",
      "Epoch: 15702, MSE: 0.23394588979827136, Learning Rate: 0.02149\n",
      "Epoch: 15703, MSE: 0.23394306436635187, Learning Rate: 0.021485\n",
      "Epoch: 15704, MSE: 0.2339402389172786, Learning Rate: 0.02148\n",
      "Epoch: 15705, MSE: 0.23393741345107114, Learning Rate: 0.021475\n",
      "Epoch: 15706, MSE: 0.23393458796775027, Learning Rate: 0.021470000000000003\n",
      "Epoch: 15707, MSE: 0.23393176246733643, Learning Rate: 0.021465\n",
      "Epoch: 15708, MSE: 0.23392893694985006, Learning Rate: 0.021460000000000003\n",
      "Epoch: 15709, MSE: 0.23392611141531158, Learning Rate: 0.021455000000000002\n",
      "Epoch: 15710, MSE: 0.2339232858637425, Learning Rate: 0.021450000000000004\n",
      "Epoch: 15711, MSE: 0.23392046029516, Learning Rate: 0.021445000000000006\n",
      "Epoch: 15712, MSE: 0.23391763470958926, Learning Rate: 0.021440000000000004\n",
      "Epoch: 15713, MSE: 0.23391480910704768, Learning Rate: 0.021435000000000006\n",
      "Epoch: 15714, MSE: 0.2339119834875564, Learning Rate: 0.021430000000000005\n",
      "Epoch: 15715, MSE: 0.23390915785113703, Learning Rate: 0.021425000000000007\n",
      "Epoch: 15716, MSE: 0.23390633219780826, Learning Rate: 0.021419999999999995\n",
      "Epoch: 15717, MSE: 0.23390350652759326, Learning Rate: 0.021414999999999997\n",
      "Epoch: 15718, MSE: 0.23390068084051024, Learning Rate: 0.02141\n",
      "Epoch: 15719, MSE: 0.23389785513658234, Learning Rate: 0.021404999999999997\n",
      "Epoch: 15720, MSE: 0.23389502941582774, Learning Rate: 0.0214\n",
      "Epoch: 15721, MSE: 0.23389220367826832, Learning Rate: 0.021394999999999997\n",
      "Epoch: 15722, MSE: 0.23388937792392495, Learning Rate: 0.02139\n",
      "Epoch: 15723, MSE: 0.2338865521528184, Learning Rate: 0.021385\n",
      "Epoch: 15724, MSE: 0.23388372636496899, Learning Rate: 0.02138\n",
      "Epoch: 15725, MSE: 0.23388090056039845, Learning Rate: 0.021375\n",
      "Epoch: 15726, MSE: 0.2338780747391257, Learning Rate: 0.02137\n",
      "Epoch: 15727, MSE: 0.23387524890117406, Learning Rate: 0.021365000000000002\n",
      "Epoch: 15728, MSE: 0.23387242304656308, Learning Rate: 0.021360000000000004\n",
      "Epoch: 15729, MSE: 0.23386959717531333, Learning Rate: 0.021355000000000002\n",
      "Epoch: 15730, MSE: 0.23386677128744604, Learning Rate: 0.021350000000000004\n",
      "Epoch: 15731, MSE: 0.23386394538298202, Learning Rate: 0.021345000000000003\n",
      "Epoch: 15732, MSE: 0.23386111946194246, Learning Rate: 0.021340000000000005\n",
      "Epoch: 15733, MSE: 0.23385829352434875, Learning Rate: 0.021335000000000007\n",
      "Epoch: 15734, MSE: 0.23385546757022094, Learning Rate: 0.021330000000000005\n",
      "Epoch: 15735, MSE: 0.2338526415995805, Learning Rate: 0.021325000000000007\n",
      "Epoch: 15736, MSE: 0.23384981561244805, Learning Rate: 0.021319999999999995\n",
      "Epoch: 15737, MSE: 0.2338469896088447, Learning Rate: 0.021314999999999997\n",
      "Epoch: 15738, MSE: 0.23384416358879265, Learning Rate: 0.021309999999999996\n",
      "Epoch: 15739, MSE: 0.23384133755231143, Learning Rate: 0.021304999999999998\n",
      "Epoch: 15740, MSE: 0.23383851149942286, Learning Rate: 0.0213\n",
      "Epoch: 15741, MSE: 0.2338356854301489, Learning Rate: 0.021294999999999998\n",
      "Epoch: 15742, MSE: 0.23383285934450873, Learning Rate: 0.02129\n",
      "Epoch: 15743, MSE: 0.23383003324252502, Learning Rate: 0.021285\n",
      "Epoch: 15744, MSE: 0.23382720712421878, Learning Rate: 0.02128\n",
      "Epoch: 15745, MSE: 0.23382438098960984, Learning Rate: 0.021275000000000002\n",
      "Epoch: 15746, MSE: 0.2338215548387213, Learning Rate: 0.02127\n",
      "Epoch: 15747, MSE: 0.23381872867157338, Learning Rate: 0.021265000000000003\n",
      "Epoch: 15748, MSE: 0.23381590248818832, Learning Rate: 0.02126\n",
      "Epoch: 15749, MSE: 0.23381307628858677, Learning Rate: 0.021255000000000003\n",
      "Epoch: 15750, MSE: 0.23381025007278936, Learning Rate: 0.021250000000000005\n",
      "Epoch: 15751, MSE: 0.23380742384081785, Learning Rate: 0.021245000000000003\n",
      "Epoch: 15752, MSE: 0.23380459759269495, Learning Rate: 0.021240000000000005\n",
      "Epoch: 15753, MSE: 0.23380177132843916, Learning Rate: 0.021235000000000004\n",
      "Epoch: 15754, MSE: 0.23379894504807522, Learning Rate: 0.021230000000000006\n",
      "Epoch: 15755, MSE: 0.23379611875162157, Learning Rate: 0.021225000000000008\n",
      "Epoch: 15756, MSE: 0.23379329243910188, Learning Rate: 0.021220000000000006\n",
      "Epoch: 15757, MSE: 0.2337904661105359, Learning Rate: 0.021214999999999998\n",
      "Epoch: 15758, MSE: 0.23378763976594688, Learning Rate: 0.021209999999999996\n",
      "Epoch: 15759, MSE: 0.23378481340535492, Learning Rate: 0.021204999999999998\n",
      "Epoch: 15760, MSE: 0.23378198702878195, Learning Rate: 0.021199999999999997\n",
      "Epoch: 15761, MSE: 0.2337791606362492, Learning Rate: 0.021195\n",
      "Epoch: 15762, MSE: 0.23377633422777908, Learning Rate: 0.02119\n",
      "Epoch: 15763, MSE: 0.23377350780339273, Learning Rate: 0.021185\n",
      "Epoch: 15764, MSE: 0.23377068136311108, Learning Rate: 0.02118\n",
      "Epoch: 15765, MSE: 0.2337678549069572, Learning Rate: 0.021175\n",
      "Epoch: 15766, MSE: 0.23376502843495184, Learning Rate: 0.02117\n",
      "Epoch: 15767, MSE: 0.2337622019471161, Learning Rate: 0.021165000000000003\n",
      "Epoch: 15768, MSE: 0.23375937544347297, Learning Rate: 0.02116\n",
      "Epoch: 15769, MSE: 0.23375654892404338, Learning Rate: 0.021155000000000004\n",
      "Epoch: 15770, MSE: 0.23375372238884878, Learning Rate: 0.021150000000000002\n",
      "Epoch: 15771, MSE: 0.23375089583791156, Learning Rate: 0.021145000000000004\n",
      "Epoch: 15772, MSE: 0.23374806927125386, Learning Rate: 0.021140000000000006\n",
      "Epoch: 15773, MSE: 0.23374524268889635, Learning Rate: 0.021135000000000004\n",
      "Epoch: 15774, MSE: 0.23374241609086127, Learning Rate: 0.021130000000000006\n",
      "Epoch: 15775, MSE: 0.23373958947717074, Learning Rate: 0.021125000000000005\n",
      "Epoch: 15776, MSE: 0.2337367628478464, Learning Rate: 0.021120000000000007\n",
      "Epoch: 15777, MSE: 0.2337339362029107, Learning Rate: 0.021114999999999995\n",
      "Epoch: 15778, MSE: 0.23373110954238466, Learning Rate: 0.021109999999999997\n",
      "Epoch: 15779, MSE: 0.23372828286629072, Learning Rate: 0.021105\n",
      "Epoch: 15780, MSE: 0.2337254561746502, Learning Rate: 0.021099999999999997\n",
      "Epoch: 15781, MSE: 0.2337226294674859, Learning Rate: 0.021095\n",
      "Epoch: 15782, MSE: 0.23371980274481993, Learning Rate: 0.021089999999999998\n",
      "Epoch: 15783, MSE: 0.23371697600667377, Learning Rate: 0.021085\n",
      "Epoch: 15784, MSE: 0.23371414925306966, Learning Rate: 0.02108\n",
      "Epoch: 15785, MSE: 0.2337113224840294, Learning Rate: 0.021075\n",
      "Epoch: 15786, MSE: 0.23370849569957472, Learning Rate: 0.021070000000000002\n",
      "Epoch: 15787, MSE: 0.23370566889972913, Learning Rate: 0.021065\n",
      "Epoch: 15788, MSE: 0.23370284208451297, Learning Rate: 0.021060000000000002\n",
      "Epoch: 15789, MSE: 0.23370001525394987, Learning Rate: 0.021055000000000004\n",
      "Epoch: 15790, MSE: 0.23369718840806133, Learning Rate: 0.021050000000000003\n",
      "Epoch: 15791, MSE: 0.23369436154686946, Learning Rate: 0.021045000000000005\n",
      "Epoch: 15792, MSE: 0.23369153467039636, Learning Rate: 0.021040000000000003\n",
      "Epoch: 15793, MSE: 0.2336887077786652, Learning Rate: 0.021035000000000005\n",
      "Epoch: 15794, MSE: 0.23368588087169712, Learning Rate: 0.021030000000000007\n",
      "Epoch: 15795, MSE: 0.23368305394951516, Learning Rate: 0.021025000000000005\n",
      "Epoch: 15796, MSE: 0.23368022701214097, Learning Rate: 0.021020000000000007\n",
      "Epoch: 15797, MSE: 0.23367740005959808, Learning Rate: 0.021014999999999995\n",
      "Epoch: 15798, MSE: 0.23367457309190717, Learning Rate: 0.021009999999999997\n",
      "Epoch: 15799, MSE: 0.23367174610909125, Learning Rate: 0.021004999999999996\n",
      "Epoch: 15800, MSE: 0.2336689191111732, Learning Rate: 0.020999999999999998\n",
      "Epoch: 15801, MSE: 0.23366609209817515, Learning Rate: 0.020995\n",
      "Epoch: 15802, MSE: 0.23366326507011978, Learning Rate: 0.020989999999999998\n",
      "Epoch: 15803, MSE: 0.23366043802702907, Learning Rate: 0.020985\n",
      "Epoch: 15804, MSE: 0.23365761096892526, Learning Rate: 0.02098\n",
      "Epoch: 15805, MSE: 0.233654783895832, Learning Rate: 0.020975\n",
      "Epoch: 15806, MSE: 0.23365195680777026, Learning Rate: 0.020970000000000003\n",
      "Epoch: 15807, MSE: 0.23364912970476392, Learning Rate: 0.020965\n",
      "Epoch: 15808, MSE: 0.23364630258683475, Learning Rate: 0.020960000000000003\n",
      "Epoch: 15809, MSE: 0.2336434754540067, Learning Rate: 0.020955\n",
      "Epoch: 15810, MSE: 0.23364064830630019, Learning Rate: 0.020950000000000003\n",
      "Epoch: 15811, MSE: 0.23363782114373854, Learning Rate: 0.020945000000000005\n",
      "Epoch: 15812, MSE: 0.23363499396634563, Learning Rate: 0.020940000000000004\n",
      "Epoch: 15813, MSE: 0.23363216677414372, Learning Rate: 0.020935000000000006\n",
      "Epoch: 15814, MSE: 0.23362933956715448, Learning Rate: 0.020930000000000004\n",
      "Epoch: 15815, MSE: 0.2336265123454021, Learning Rate: 0.020925000000000006\n",
      "Epoch: 15816, MSE: 0.23362368510890788, Learning Rate: 0.020920000000000008\n",
      "Epoch: 15817, MSE: 0.23362085785769524, Learning Rate: 0.020914999999999996\n",
      "Epoch: 15818, MSE: 0.23361803059178765, Learning Rate: 0.020909999999999998\n",
      "Epoch: 15819, MSE: 0.23361520331120644, Learning Rate: 0.020904999999999997\n",
      "Epoch: 15820, MSE: 0.23361237601597576, Learning Rate: 0.0209\n",
      "Epoch: 15821, MSE: 0.23360954870611758, Learning Rate: 0.020894999999999997\n",
      "Epoch: 15822, MSE: 0.23360672138165584, Learning Rate: 0.02089\n",
      "Epoch: 15823, MSE: 0.23360389404261242, Learning Rate: 0.020885\n",
      "Epoch: 15824, MSE: 0.23360106668901076, Learning Rate: 0.02088\n",
      "Epoch: 15825, MSE: 0.23359823932087348, Learning Rate: 0.020875\n",
      "Epoch: 15826, MSE: 0.23359541193822403, Learning Rate: 0.02087\n",
      "Epoch: 15827, MSE: 0.23359258454108522, Learning Rate: 0.020865\n",
      "Epoch: 15828, MSE: 0.2335897571294797, Learning Rate: 0.020860000000000004\n",
      "Epoch: 15829, MSE: 0.23358692970343115, Learning Rate: 0.020855000000000002\n",
      "Epoch: 15830, MSE: 0.2335841022629615, Learning Rate: 0.020850000000000004\n",
      "Epoch: 15831, MSE: 0.23358127480809593, Learning Rate: 0.020845000000000002\n",
      "Epoch: 15832, MSE: 0.23357844733885483, Learning Rate: 0.020840000000000004\n",
      "Epoch: 15833, MSE: 0.23357561985526412, Learning Rate: 0.020835000000000006\n",
      "Epoch: 15834, MSE: 0.23357279235734466, Learning Rate: 0.020830000000000005\n",
      "Epoch: 15835, MSE: 0.23356996484512138, Learning Rate: 0.020825000000000007\n",
      "Epoch: 15836, MSE: 0.23356713731861642, Learning Rate: 0.020820000000000005\n",
      "Epoch: 15837, MSE: 0.23356430977785295, Learning Rate: 0.020814999999999997\n",
      "Epoch: 15838, MSE: 0.23356148222285508, Learning Rate: 0.020809999999999995\n",
      "Epoch: 15839, MSE: 0.23355865465364545, Learning Rate: 0.020804999999999997\n",
      "Epoch: 15840, MSE: 0.23355582707024738, Learning Rate: 0.0208\n",
      "Epoch: 15841, MSE: 0.23355299947268415, Learning Rate: 0.020794999999999998\n",
      "Epoch: 15842, MSE: 0.23355017186097973, Learning Rate: 0.02079\n",
      "Epoch: 15843, MSE: 0.23354734423515655, Learning Rate: 0.020784999999999998\n",
      "Epoch: 15844, MSE: 0.23354451659523848, Learning Rate: 0.02078\n",
      "Epoch: 15845, MSE: 0.23354168894124963, Learning Rate: 0.020775000000000002\n",
      "Epoch: 15846, MSE: 0.23353886127321238, Learning Rate: 0.02077\n",
      "Epoch: 15847, MSE: 0.23353603359115024, Learning Rate: 0.020765000000000002\n",
      "Epoch: 15848, MSE: 0.23353320589508705, Learning Rate: 0.02076\n",
      "Epoch: 15849, MSE: 0.2335303781850468, Learning Rate: 0.020755000000000003\n",
      "Epoch: 15850, MSE: 0.23352755046105214, Learning Rate: 0.020750000000000005\n",
      "Epoch: 15851, MSE: 0.23352472272312771, Learning Rate: 0.020745000000000003\n",
      "Epoch: 15852, MSE: 0.2335218949712958, Learning Rate: 0.020740000000000005\n",
      "Epoch: 15853, MSE: 0.23351906720558038, Learning Rate: 0.020735000000000003\n",
      "Epoch: 15854, MSE: 0.233516239426006, Learning Rate: 0.020730000000000005\n",
      "Epoch: 15855, MSE: 0.23351341163259481, Learning Rate: 0.020725000000000007\n",
      "Epoch: 15856, MSE: 0.23351058382537238, Learning Rate: 0.020720000000000006\n",
      "Epoch: 15857, MSE: 0.23350775600436047, Learning Rate: 0.020714999999999997\n",
      "Epoch: 15858, MSE: 0.23350492816958374, Learning Rate: 0.020709999999999996\n",
      "Epoch: 15859, MSE: 0.2335021003210658, Learning Rate: 0.020704999999999998\n",
      "Epoch: 15860, MSE: 0.2334992724588307, Learning Rate: 0.020699999999999996\n",
      "Epoch: 15861, MSE: 0.2334964445829021, Learning Rate: 0.020694999999999998\n",
      "Epoch: 15862, MSE: 0.23349361669330415, Learning Rate: 0.02069\n",
      "Epoch: 15863, MSE: 0.2334907887900598, Learning Rate: 0.020685\n",
      "Epoch: 15864, MSE: 0.23348796087319362, Learning Rate: 0.02068\n",
      "Epoch: 15865, MSE: 0.23348513294272932, Learning Rate: 0.020675\n",
      "Epoch: 15866, MSE: 0.23348230499869088, Learning Rate: 0.02067\n",
      "Epoch: 15867, MSE: 0.2334794770411017, Learning Rate: 0.020665000000000003\n",
      "Epoch: 15868, MSE: 0.2334766490699872, Learning Rate: 0.02066\n",
      "Epoch: 15869, MSE: 0.23347382108536976, Learning Rate: 0.020655000000000003\n",
      "Epoch: 15870, MSE: 0.23347099308727454, Learning Rate: 0.02065\n",
      "Epoch: 15871, MSE: 0.2334681650757243, Learning Rate: 0.020645000000000004\n",
      "Epoch: 15872, MSE: 0.2334653370507441, Learning Rate: 0.020640000000000006\n",
      "Epoch: 15873, MSE: 0.2334625090123577, Learning Rate: 0.020635000000000004\n",
      "Epoch: 15874, MSE: 0.23345968096058975, Learning Rate: 0.020630000000000006\n",
      "Epoch: 15875, MSE: 0.23345685289546333, Learning Rate: 0.020625000000000004\n",
      "Epoch: 15876, MSE: 0.23345402481700356, Learning Rate: 0.020620000000000006\n",
      "Epoch: 15877, MSE: 0.2334511967252341, Learning Rate: 0.02061500000000001\n",
      "Epoch: 15878, MSE: 0.2334483686201797, Learning Rate: 0.020609999999999996\n",
      "Epoch: 15879, MSE: 0.23344554050186397, Learning Rate: 0.020605\n",
      "Epoch: 15880, MSE: 0.23344271237031125, Learning Rate: 0.020599999999999997\n",
      "Epoch: 15881, MSE: 0.2334398842255467, Learning Rate: 0.020595\n",
      "Epoch: 15882, MSE: 0.2334370560675935, Learning Rate: 0.020589999999999997\n",
      "Epoch: 15883, MSE: 0.23343422789647647, Learning Rate: 0.020585\n",
      "Epoch: 15884, MSE: 0.23343139971221943, Learning Rate: 0.02058\n",
      "Epoch: 15885, MSE: 0.23342857151484758, Learning Rate: 0.020575\n",
      "Epoch: 15886, MSE: 0.23342574330438495, Learning Rate: 0.02057\n",
      "Epoch: 15887, MSE: 0.233422915080856, Learning Rate: 0.020565\n",
      "Epoch: 15888, MSE: 0.233420086844285, Learning Rate: 0.020560000000000002\n",
      "Epoch: 15889, MSE: 0.23341725859469722, Learning Rate: 0.020555000000000004\n",
      "Epoch: 15890, MSE: 0.233414430332116, Learning Rate: 0.020550000000000002\n",
      "Epoch: 15891, MSE: 0.23341160205656714, Learning Rate: 0.020545000000000004\n",
      "Epoch: 15892, MSE: 0.23340877376807395, Learning Rate: 0.020540000000000003\n",
      "Epoch: 15893, MSE: 0.2334059454666615, Learning Rate: 0.020535000000000005\n",
      "Epoch: 15894, MSE: 0.23340311715235476, Learning Rate: 0.020530000000000007\n",
      "Epoch: 15895, MSE: 0.23340028882517697, Learning Rate: 0.020525000000000005\n",
      "Epoch: 15896, MSE: 0.2333974604851548, Learning Rate: 0.020520000000000007\n",
      "Epoch: 15897, MSE: 0.23339463213231212, Learning Rate: 0.020515000000000005\n",
      "Epoch: 15898, MSE: 0.23339180376667396, Learning Rate: 0.020509999999999997\n",
      "Epoch: 15899, MSE: 0.2333889753882638, Learning Rate: 0.020504999999999995\n",
      "Epoch: 15900, MSE: 0.23338614699710689, Learning Rate: 0.020499999999999997\n",
      "Epoch: 15901, MSE: 0.23338331859322886, Learning Rate: 0.020495\n",
      "Epoch: 15902, MSE: 0.23338049017665363, Learning Rate: 0.020489999999999998\n",
      "Epoch: 15903, MSE: 0.2333776617474067, Learning Rate: 0.020485\n",
      "Epoch: 15904, MSE: 0.23337483330551215, Learning Rate: 0.020479999999999998\n",
      "Epoch: 15905, MSE: 0.23337200485099613, Learning Rate: 0.020475\n",
      "Epoch: 15906, MSE: 0.2333691763838816, Learning Rate: 0.020470000000000002\n",
      "Epoch: 15907, MSE: 0.23336634790419505, Learning Rate: 0.020465\n",
      "Epoch: 15908, MSE: 0.23336351941196093, Learning Rate: 0.020460000000000002\n",
      "Epoch: 15909, MSE: 0.23336069090720477, Learning Rate: 0.020455\n",
      "Epoch: 15910, MSE: 0.23335786238995004, Learning Rate: 0.020450000000000003\n",
      "Epoch: 15911, MSE: 0.23335503386022383, Learning Rate: 0.020445000000000005\n",
      "Epoch: 15912, MSE: 0.23335220531804943, Learning Rate: 0.020440000000000003\n",
      "Epoch: 15913, MSE: 0.23334937676345324, Learning Rate: 0.020435000000000005\n",
      "Epoch: 15914, MSE: 0.23334654819645967, Learning Rate: 0.020430000000000004\n",
      "Epoch: 15915, MSE: 0.23334371961709355, Learning Rate: 0.020425000000000006\n",
      "Epoch: 15916, MSE: 0.23334089102538116, Learning Rate: 0.020420000000000008\n",
      "Epoch: 15917, MSE: 0.23333806242134658, Learning Rate: 0.020415000000000006\n",
      "Epoch: 15918, MSE: 0.23333523380501572, Learning Rate: 0.020409999999999998\n",
      "Epoch: 15919, MSE: 0.2333324051764131, Learning Rate: 0.020404999999999996\n",
      "Epoch: 15920, MSE: 0.23332957653556438, Learning Rate: 0.020399999999999998\n",
      "Epoch: 15921, MSE: 0.23332674788249558, Learning Rate: 0.020394999999999996\n",
      "Epoch: 15922, MSE: 0.23332391921723103, Learning Rate: 0.02039\n",
      "Epoch: 15923, MSE: 0.23332109053979644, Learning Rate: 0.020385\n",
      "Epoch: 15924, MSE: 0.23331826185021656, Learning Rate: 0.02038\n",
      "Epoch: 15925, MSE: 0.23331543314851752, Learning Rate: 0.020375\n",
      "Epoch: 15926, MSE: 0.23331260443472493, Learning Rate: 0.02037\n",
      "Epoch: 15927, MSE: 0.2333097757088636, Learning Rate: 0.020365\n",
      "Epoch: 15928, MSE: 0.233306946970959, Learning Rate: 0.020360000000000003\n",
      "Epoch: 15929, MSE: 0.23330411822103755, Learning Rate: 0.020355\n",
      "Epoch: 15930, MSE: 0.23330128945912346, Learning Rate: 0.020350000000000004\n",
      "Epoch: 15931, MSE: 0.233298460685243, Learning Rate: 0.020345000000000002\n",
      "Epoch: 15932, MSE: 0.23329563189942193, Learning Rate: 0.020340000000000004\n",
      "Epoch: 15933, MSE: 0.23329280310168563, Learning Rate: 0.020335000000000006\n",
      "Epoch: 15934, MSE: 0.23328997429205936, Learning Rate: 0.020330000000000004\n",
      "Epoch: 15935, MSE: 0.23328714547056856, Learning Rate: 0.020325000000000006\n",
      "Epoch: 15936, MSE: 0.23328431663724086, Learning Rate: 0.020320000000000005\n",
      "Epoch: 15937, MSE: 0.23328148779209953, Learning Rate: 0.020315000000000007\n",
      "Epoch: 15938, MSE: 0.23327865893517116, Learning Rate: 0.020309999999999995\n",
      "Epoch: 15939, MSE: 0.23327583006648256, Learning Rate: 0.020304999999999997\n",
      "Epoch: 15940, MSE: 0.23327300118605768, Learning Rate: 0.0203\n",
      "Epoch: 15941, MSE: 0.2332701722939238, Learning Rate: 0.020294999999999997\n",
      "Epoch: 15942, MSE: 0.23326734339010605, Learning Rate: 0.02029\n",
      "Epoch: 15943, MSE: 0.2332645144746305, Learning Rate: 0.020284999999999997\n",
      "Epoch: 15944, MSE: 0.2332616855475226, Learning Rate: 0.02028\n",
      "Epoch: 15945, MSE: 0.23325885660880927, Learning Rate: 0.020275\n",
      "Epoch: 15946, MSE: 0.23325602765851525, Learning Rate: 0.02027\n",
      "Epoch: 15947, MSE: 0.2332531986966679, Learning Rate: 0.020265000000000002\n",
      "Epoch: 15948, MSE: 0.2332503697232916, Learning Rate: 0.02026\n",
      "Epoch: 15949, MSE: 0.23324754073841364, Learning Rate: 0.020255000000000002\n",
      "Epoch: 15950, MSE: 0.23324471174205988, Learning Rate: 0.020250000000000004\n",
      "Epoch: 15951, MSE: 0.2332418827342554, Learning Rate: 0.020245000000000003\n",
      "Epoch: 15952, MSE: 0.233239053715027, Learning Rate: 0.020240000000000005\n",
      "Epoch: 15953, MSE: 0.23323622468440117, Learning Rate: 0.020235000000000003\n",
      "Epoch: 15954, MSE: 0.23323339564240367, Learning Rate: 0.020230000000000005\n",
      "Epoch: 15955, MSE: 0.2332305665890614, Learning Rate: 0.020225000000000007\n",
      "Epoch: 15956, MSE: 0.2332277375243995, Learning Rate: 0.020220000000000005\n",
      "Epoch: 15957, MSE: 0.23322490844844435, Learning Rate: 0.020215000000000007\n",
      "Epoch: 15958, MSE: 0.23322207936122247, Learning Rate: 0.020209999999999995\n",
      "Epoch: 15959, MSE: 0.23321925026276097, Learning Rate: 0.020204999999999997\n",
      "Epoch: 15960, MSE: 0.23321642115308444, Learning Rate: 0.020199999999999996\n",
      "Epoch: 15961, MSE: 0.23321359203222095, Learning Rate: 0.020194999999999998\n",
      "Epoch: 15962, MSE: 0.23321076290019566, Learning Rate: 0.02019\n",
      "Epoch: 15963, MSE: 0.23320793375703477, Learning Rate: 0.020184999999999998\n",
      "Epoch: 15964, MSE: 0.23320510460276656, Learning Rate: 0.02018\n",
      "Epoch: 15965, MSE: 0.2332022754374149, Learning Rate: 0.020175\n",
      "Epoch: 15966, MSE: 0.23319944626100933, Learning Rate: 0.02017\n",
      "Epoch: 15967, MSE: 0.23319661707357336, Learning Rate: 0.020165000000000002\n",
      "Epoch: 15968, MSE: 0.2331937878751351, Learning Rate: 0.02016\n",
      "Epoch: 15969, MSE: 0.23319095866572107, Learning Rate: 0.020155000000000003\n",
      "Epoch: 15970, MSE: 0.23318812944535677, Learning Rate: 0.02015\n",
      "Epoch: 15971, MSE: 0.23318530021407105, Learning Rate: 0.020145000000000003\n",
      "Epoch: 15972, MSE: 0.23318247097188852, Learning Rate: 0.020140000000000005\n",
      "Epoch: 15973, MSE: 0.23317964171883585, Learning Rate: 0.020135000000000004\n",
      "Epoch: 15974, MSE: 0.23317681245494123, Learning Rate: 0.020130000000000006\n",
      "Epoch: 15975, MSE: 0.2331739831802301, Learning Rate: 0.020125000000000004\n",
      "Epoch: 15976, MSE: 0.23317115389472975, Learning Rate: 0.020120000000000006\n",
      "Epoch: 15977, MSE: 0.23316832459846742, Learning Rate: 0.020115000000000008\n",
      "Epoch: 15978, MSE: 0.23316549529146915, Learning Rate: 0.020109999999999996\n",
      "Epoch: 15979, MSE: 0.23316266597376192, Learning Rate: 0.020104999999999998\n",
      "Epoch: 15980, MSE: 0.23315983664537254, Learning Rate: 0.020099999999999996\n",
      "Epoch: 15981, MSE: 0.23315700730632768, Learning Rate: 0.020095\n",
      "Epoch: 15982, MSE: 0.23315417795665527, Learning Rate: 0.020089999999999997\n",
      "Epoch: 15983, MSE: 0.23315134859638098, Learning Rate: 0.020085\n",
      "Epoch: 15984, MSE: 0.23314851922553292, Learning Rate: 0.02008\n",
      "Epoch: 15985, MSE: 0.2331456898441376, Learning Rate: 0.020075\n",
      "Epoch: 15986, MSE: 0.23314286045222168, Learning Rate: 0.02007\n",
      "Epoch: 15987, MSE: 0.23314003104981335, Learning Rate: 0.020065\n",
      "Epoch: 15988, MSE: 0.23313720163693813, Learning Rate: 0.02006\n",
      "Epoch: 15989, MSE: 0.23313437221362385, Learning Rate: 0.020055000000000003\n",
      "Epoch: 15990, MSE: 0.23313154277989814, Learning Rate: 0.020050000000000002\n",
      "Epoch: 15991, MSE: 0.23312871333578764, Learning Rate: 0.020045000000000004\n",
      "Epoch: 15992, MSE: 0.23312588388131966, Learning Rate: 0.020040000000000002\n",
      "Epoch: 15993, MSE: 0.233123054416522, Learning Rate: 0.020035000000000004\n",
      "Epoch: 15994, MSE: 0.2331202249414209, Learning Rate: 0.020030000000000006\n",
      "Epoch: 15995, MSE: 0.23311739545604415, Learning Rate: 0.020025000000000005\n",
      "Epoch: 15996, MSE: 0.2331145659604194, Learning Rate: 0.020020000000000007\n",
      "Epoch: 15997, MSE: 0.2331117364545734, Learning Rate: 0.020015000000000005\n",
      "Epoch: 15998, MSE: 0.23310890693853317, Learning Rate: 0.020009999999999997\n",
      "Epoch: 15999, MSE: 0.23310607741232683, Learning Rate: 0.020004999999999995\n",
      "Epoch: 16000, MSE: 0.2331032478759821, Learning Rate: 0.019999999999999997\n",
      "Epoch: 16001, MSE: 0.23310041832952588, Learning Rate: 0.019995\n",
      "Epoch: 16002, MSE: 0.2330975887729855, Learning Rate: 0.019989999999999997\n",
      "Epoch: 16003, MSE: 0.23309475920638936, Learning Rate: 0.019985\n",
      "Epoch: 16004, MSE: 0.23309192962976374, Learning Rate: 0.019979999999999998\n",
      "Epoch: 16005, MSE: 0.2330891000431372, Learning Rate: 0.019975\n",
      "Epoch: 16006, MSE: 0.23308627044653688, Learning Rate: 0.01997\n",
      "Epoch: 16007, MSE: 0.23308344083999039, Learning Rate: 0.019965\n",
      "Epoch: 16008, MSE: 0.23308061122352566, Learning Rate: 0.019960000000000002\n",
      "Epoch: 16009, MSE: 0.23307778159716996, Learning Rate: 0.019955\n",
      "Epoch: 16010, MSE: 0.23307495196095113, Learning Rate: 0.019950000000000002\n",
      "Epoch: 16011, MSE: 0.23307212231489746, Learning Rate: 0.019945000000000004\n",
      "Epoch: 16012, MSE: 0.23306929265903664, Learning Rate: 0.019940000000000003\n",
      "Epoch: 16013, MSE: 0.23306646299339467, Learning Rate: 0.019935000000000005\n",
      "Epoch: 16014, MSE: 0.23306363331800234, Learning Rate: 0.019930000000000003\n",
      "Epoch: 16015, MSE: 0.23306080363288553, Learning Rate: 0.019925000000000005\n",
      "Epoch: 16016, MSE: 0.23305797393807254, Learning Rate: 0.019920000000000007\n",
      "Epoch: 16017, MSE: 0.23305514423359155, Learning Rate: 0.019915000000000006\n",
      "Epoch: 16018, MSE: 0.2330523145194699, Learning Rate: 0.019910000000000008\n",
      "Epoch: 16019, MSE: 0.23304948479573628, Learning Rate: 0.019904999999999996\n",
      "Epoch: 16020, MSE: 0.23304665506241837, Learning Rate: 0.019899999999999998\n",
      "Epoch: 16021, MSE: 0.23304382531954393, Learning Rate: 0.019894999999999996\n",
      "Epoch: 16022, MSE: 0.23304099556714195, Learning Rate: 0.019889999999999998\n",
      "Epoch: 16023, MSE: 0.23303816580523917, Learning Rate: 0.019885\n",
      "Epoch: 16024, MSE: 0.2330353360338645, Learning Rate: 0.01988\n",
      "Epoch: 16025, MSE: 0.23303250625304606, Learning Rate: 0.019875\n",
      "Epoch: 16026, MSE: 0.2330296764628121, Learning Rate: 0.01987\n",
      "Epoch: 16027, MSE: 0.23302684666319068, Learning Rate: 0.019865\n",
      "Epoch: 16028, MSE: 0.23302401685420926, Learning Rate: 0.019860000000000003\n",
      "Epoch: 16029, MSE: 0.2330211870358982, Learning Rate: 0.019855\n",
      "Epoch: 16030, MSE: 0.23301835720828362, Learning Rate: 0.019850000000000003\n",
      "Epoch: 16031, MSE: 0.23301552737139514, Learning Rate: 0.019845\n",
      "Epoch: 16032, MSE: 0.2330126975252604, Learning Rate: 0.019840000000000003\n",
      "Epoch: 16033, MSE: 0.23300986766990786, Learning Rate: 0.019835000000000005\n",
      "Epoch: 16034, MSE: 0.23300703780536644, Learning Rate: 0.019830000000000004\n",
      "Epoch: 16035, MSE: 0.23300420793166457, Learning Rate: 0.019825000000000006\n",
      "Epoch: 16036, MSE: 0.23300137804882937, Learning Rate: 0.019820000000000004\n",
      "Epoch: 16037, MSE: 0.23299854815689167, Learning Rate: 0.019815000000000006\n",
      "Epoch: 16038, MSE: 0.23299571825587828, Learning Rate: 0.019810000000000008\n",
      "Epoch: 16039, MSE: 0.23299288834581802, Learning Rate: 0.019804999999999996\n",
      "Epoch: 16040, MSE: 0.2329900584267394, Learning Rate: 0.019799999999999998\n",
      "Epoch: 16041, MSE: 0.2329872284986719, Learning Rate: 0.019794999999999997\n",
      "Epoch: 16042, MSE: 0.23298439856164319, Learning Rate: 0.01979\n",
      "Epoch: 16043, MSE: 0.23298156861568287, Learning Rate: 0.019784999999999997\n",
      "Epoch: 16044, MSE: 0.23297873866081834, Learning Rate: 0.01978\n",
      "Epoch: 16045, MSE: 0.23297590869708024, Learning Rate: 0.019775\n",
      "Epoch: 16046, MSE: 0.23297307872449516, Learning Rate: 0.01977\n",
      "Epoch: 16047, MSE: 0.2329702487430938, Learning Rate: 0.019765\n",
      "Epoch: 16048, MSE: 0.2329674187529033, Learning Rate: 0.01976\n",
      "Epoch: 16049, MSE: 0.2329645887539542, Learning Rate: 0.019755\n",
      "Epoch: 16050, MSE: 0.23296175874627476, Learning Rate: 0.019750000000000004\n",
      "Epoch: 16051, MSE: 0.23295892872989293, Learning Rate: 0.019745000000000002\n",
      "Epoch: 16052, MSE: 0.23295609870483872, Learning Rate: 0.019740000000000004\n",
      "Epoch: 16053, MSE: 0.23295326867114133, Learning Rate: 0.019735000000000003\n",
      "Epoch: 16054, MSE: 0.2329504386288287, Learning Rate: 0.019730000000000004\n",
      "Epoch: 16055, MSE: 0.23294760857793043, Learning Rate: 0.019725000000000006\n",
      "Epoch: 16056, MSE: 0.23294477851847584, Learning Rate: 0.019720000000000005\n",
      "Epoch: 16057, MSE: 0.2329419484504934, Learning Rate: 0.019715000000000007\n",
      "Epoch: 16058, MSE: 0.2329391183740135, Learning Rate: 0.019710000000000005\n",
      "Epoch: 16059, MSE: 0.23293628828906413, Learning Rate: 0.019704999999999997\n",
      "Epoch: 16060, MSE: 0.23293345819567435, Learning Rate: 0.019699999999999995\n",
      "Epoch: 16061, MSE: 0.23293062809387477, Learning Rate: 0.019694999999999997\n",
      "Epoch: 16062, MSE: 0.23292779798369334, Learning Rate: 0.01969\n",
      "Epoch: 16063, MSE: 0.23292496786516012, Learning Rate: 0.019684999999999998\n",
      "Epoch: 16064, MSE: 0.23292213773830342, Learning Rate: 0.01968\n",
      "Epoch: 16065, MSE: 0.23291930760315385, Learning Rate: 0.019674999999999998\n",
      "Epoch: 16066, MSE: 0.23291647745973948, Learning Rate: 0.01967\n",
      "Epoch: 16067, MSE: 0.2329136473080909, Learning Rate: 0.019665000000000002\n",
      "Epoch: 16068, MSE: 0.23291081714823691, Learning Rate: 0.01966\n",
      "Epoch: 16069, MSE: 0.23290798698020695, Learning Rate: 0.019655000000000002\n",
      "Epoch: 16070, MSE: 0.2329051568040311, Learning Rate: 0.01965\n",
      "Epoch: 16071, MSE: 0.2329023266197382, Learning Rate: 0.019645000000000003\n",
      "Epoch: 16072, MSE: 0.23289949642735874, Learning Rate: 0.019640000000000005\n",
      "Epoch: 16073, MSE: 0.23289666622692157, Learning Rate: 0.019635000000000003\n",
      "Epoch: 16074, MSE: 0.2328938360184559, Learning Rate: 0.019630000000000005\n",
      "Epoch: 16075, MSE: 0.23289100580199212, Learning Rate: 0.019625000000000004\n",
      "Epoch: 16076, MSE: 0.23288817557756006, Learning Rate: 0.019620000000000005\n",
      "Epoch: 16077, MSE: 0.23288534534518923, Learning Rate: 0.019615000000000007\n",
      "Epoch: 16078, MSE: 0.2328825151049092, Learning Rate: 0.019610000000000006\n",
      "Epoch: 16079, MSE: 0.2328796848567494, Learning Rate: 0.019604999999999997\n",
      "Epoch: 16080, MSE: 0.2328768546007408, Learning Rate: 0.019599999999999996\n",
      "Epoch: 16081, MSE: 0.2328740243369118, Learning Rate: 0.019594999999999998\n",
      "Epoch: 16082, MSE: 0.23287119406529314, Learning Rate: 0.019589999999999996\n",
      "Epoch: 16083, MSE: 0.23286836378591502, Learning Rate: 0.019584999999999998\n",
      "Epoch: 16084, MSE: 0.2328655334988071, Learning Rate: 0.01958\n",
      "Epoch: 16085, MSE: 0.23286270320399885, Learning Rate: 0.019575\n",
      "Epoch: 16086, MSE: 0.23285987290152116, Learning Rate: 0.01957\n",
      "Epoch: 16087, MSE: 0.23285704259140297, Learning Rate: 0.019565\n",
      "Epoch: 16088, MSE: 0.23285421227367503, Learning Rate: 0.01956\n",
      "Epoch: 16089, MSE: 0.23285138194836735, Learning Rate: 0.019555000000000003\n",
      "Epoch: 16090, MSE: 0.2328485516155103, Learning Rate: 0.01955\n",
      "Epoch: 16091, MSE: 0.2328457212751338, Learning Rate: 0.019545000000000003\n",
      "Epoch: 16092, MSE: 0.23284289092726776, Learning Rate: 0.019540000000000002\n",
      "Epoch: 16093, MSE: 0.23284006057194348, Learning Rate: 0.019535000000000004\n",
      "Epoch: 16094, MSE: 0.2328372302091899, Learning Rate: 0.019530000000000006\n",
      "Epoch: 16095, MSE: 0.2328343998390378, Learning Rate: 0.019525000000000004\n",
      "Epoch: 16096, MSE: 0.23283156946151776, Learning Rate: 0.019520000000000006\n",
      "Epoch: 16097, MSE: 0.23282873907665994, Learning Rate: 0.019515000000000005\n",
      "Epoch: 16098, MSE: 0.23282590868449446, Learning Rate: 0.019510000000000007\n",
      "Epoch: 16099, MSE: 0.23282307828505222, Learning Rate: 0.019504999999999995\n",
      "Epoch: 16100, MSE: 0.23282024787836383, Learning Rate: 0.019499999999999997\n",
      "Epoch: 16101, MSE: 0.23281741746445858, Learning Rate: 0.019495\n",
      "Epoch: 16102, MSE: 0.23281458704336846, Learning Rate: 0.019489999999999997\n",
      "Epoch: 16103, MSE: 0.2328117566151235, Learning Rate: 0.019485\n",
      "Epoch: 16104, MSE: 0.23280892617975374, Learning Rate: 0.019479999999999997\n",
      "Epoch: 16105, MSE: 0.23280609573729005, Learning Rate: 0.019475\n",
      "Epoch: 16106, MSE: 0.2328032652877642, Learning Rate: 0.01947\n",
      "Epoch: 16107, MSE: 0.23280043483120563, Learning Rate: 0.019465\n",
      "Epoch: 16108, MSE: 0.23279760436764452, Learning Rate: 0.01946\n",
      "Epoch: 16109, MSE: 0.23279477389711303, Learning Rate: 0.019455\n",
      "Epoch: 16110, MSE: 0.23279194341964068, Learning Rate: 0.019450000000000002\n",
      "Epoch: 16111, MSE: 0.23278911293525947, Learning Rate: 0.019445000000000004\n",
      "Epoch: 16112, MSE: 0.23278628244399993, Learning Rate: 0.019440000000000002\n",
      "Epoch: 16113, MSE: 0.23278345194589312, Learning Rate: 0.019435000000000004\n",
      "Epoch: 16114, MSE: 0.2327806214409688, Learning Rate: 0.019430000000000003\n",
      "Epoch: 16115, MSE: 0.2327777909292585, Learning Rate: 0.019425000000000005\n",
      "Epoch: 16116, MSE: 0.23277496041079368, Learning Rate: 0.019420000000000007\n",
      "Epoch: 16117, MSE: 0.23277212988560472, Learning Rate: 0.019415000000000005\n",
      "Epoch: 16118, MSE: 0.23276929935372365, Learning Rate: 0.019410000000000007\n",
      "Epoch: 16119, MSE: 0.23276646881518037, Learning Rate: 0.019404999999999995\n",
      "Epoch: 16120, MSE: 0.2327636382700061, Learning Rate: 0.019399999999999997\n",
      "Epoch: 16121, MSE: 0.23276080771823313, Learning Rate: 0.019394999999999996\n",
      "Epoch: 16122, MSE: 0.23275797715989202, Learning Rate: 0.019389999999999998\n",
      "Epoch: 16123, MSE: 0.23275514659501345, Learning Rate: 0.019385\n",
      "Epoch: 16124, MSE: 0.23275231602362825, Learning Rate: 0.019379999999999998\n",
      "Epoch: 16125, MSE: 0.23274948544576912, Learning Rate: 0.019375\n",
      "Epoch: 16126, MSE: 0.2327466548614667, Learning Rate: 0.01937\n",
      "Epoch: 16127, MSE: 0.23274382427075224, Learning Rate: 0.019365\n",
      "Epoch: 16128, MSE: 0.2327409936736575, Learning Rate: 0.019360000000000002\n",
      "Epoch: 16129, MSE: 0.2327381630702129, Learning Rate: 0.019355\n",
      "Epoch: 16130, MSE: 0.23273533246045083, Learning Rate: 0.019350000000000003\n",
      "Epoch: 16131, MSE: 0.2327325018444029, Learning Rate: 0.019345\n",
      "Epoch: 16132, MSE: 0.2327296712220998, Learning Rate: 0.019340000000000003\n",
      "Epoch: 16133, MSE: 0.23272684059357396, Learning Rate: 0.019335000000000005\n",
      "Epoch: 16134, MSE: 0.23272400995885584, Learning Rate: 0.019330000000000003\n",
      "Epoch: 16135, MSE: 0.2327211793179775, Learning Rate: 0.019325000000000005\n",
      "Epoch: 16136, MSE: 0.23271834867097235, Learning Rate: 0.019320000000000004\n",
      "Epoch: 16137, MSE: 0.23271551801786858, Learning Rate: 0.019315000000000006\n",
      "Epoch: 16138, MSE: 0.23271268735870052, Learning Rate: 0.019310000000000008\n",
      "Epoch: 16139, MSE: 0.23270985669349906, Learning Rate: 0.019305000000000006\n",
      "Epoch: 16140, MSE: 0.23270702602229654, Learning Rate: 0.019299999999999998\n",
      "Epoch: 16141, MSE: 0.23270419534512413, Learning Rate: 0.019294999999999996\n",
      "Epoch: 16142, MSE: 0.23270136466201388, Learning Rate: 0.019289999999999998\n",
      "Epoch: 16143, MSE: 0.23269853397299714, Learning Rate: 0.019284999999999997\n",
      "Epoch: 16144, MSE: 0.2326957032781069, Learning Rate: 0.01928\n",
      "Epoch: 16145, MSE: 0.23269287257737437, Learning Rate: 0.019275\n",
      "Epoch: 16146, MSE: 0.232690041870831, Learning Rate: 0.01927\n",
      "Epoch: 16147, MSE: 0.23268721115851007, Learning Rate: 0.019265\n",
      "Epoch: 16148, MSE: 0.23268438044044384, Learning Rate: 0.01926\n",
      "Epoch: 16149, MSE: 0.23268154971666266, Learning Rate: 0.019255\n",
      "Epoch: 16150, MSE: 0.23267871898719986, Learning Rate: 0.019250000000000003\n",
      "Epoch: 16151, MSE: 0.23267588825208724, Learning Rate: 0.019245\n",
      "Epoch: 16152, MSE: 0.2326730575113575, Learning Rate: 0.019240000000000004\n",
      "Epoch: 16153, MSE: 0.2326702267650418, Learning Rate: 0.019235000000000002\n",
      "Epoch: 16154, MSE: 0.23266739601317332, Learning Rate: 0.019230000000000004\n",
      "Epoch: 16155, MSE: 0.23266456525578433, Learning Rate: 0.019225000000000006\n",
      "Epoch: 16156, MSE: 0.23266173449290625, Learning Rate: 0.019220000000000004\n",
      "Epoch: 16157, MSE: 0.23265890372457254, Learning Rate: 0.019215000000000006\n",
      "Epoch: 16158, MSE: 0.23265607295081456, Learning Rate: 0.019210000000000005\n",
      "Epoch: 16159, MSE: 0.23265324217166622, Learning Rate: 0.019205000000000007\n",
      "Epoch: 16160, MSE: 0.23265041138715814, Learning Rate: 0.019199999999999995\n",
      "Epoch: 16161, MSE: 0.23264758059732468, Learning Rate: 0.019194999999999997\n",
      "Epoch: 16162, MSE: 0.23264474980219627, Learning Rate: 0.01919\n",
      "Epoch: 16163, MSE: 0.2326419190018078, Learning Rate: 0.019184999999999997\n",
      "Epoch: 16164, MSE: 0.23263908819618984, Learning Rate: 0.01918\n",
      "Epoch: 16165, MSE: 0.23263625738537605, Learning Rate: 0.019174999999999998\n",
      "Epoch: 16166, MSE: 0.23263342656939903, Learning Rate: 0.01917\n",
      "Epoch: 16167, MSE: 0.23263059574829179, Learning Rate: 0.019165\n",
      "Epoch: 16168, MSE: 0.23262776492208612, Learning Rate: 0.01916\n",
      "Epoch: 16169, MSE: 0.23262493409081583, Learning Rate: 0.019155000000000002\n",
      "Epoch: 16170, MSE: 0.23262210325451316, Learning Rate: 0.01915\n",
      "Epoch: 16171, MSE: 0.23261927241321056, Learning Rate: 0.019145000000000002\n",
      "Epoch: 16172, MSE: 0.2326164415669418, Learning Rate: 0.019140000000000004\n",
      "Epoch: 16173, MSE: 0.23261361071573922, Learning Rate: 0.019135000000000003\n",
      "Epoch: 16174, MSE: 0.23261077985963602, Learning Rate: 0.019130000000000005\n",
      "Epoch: 16175, MSE: 0.23260794899866513, Learning Rate: 0.019125000000000003\n",
      "Epoch: 16176, MSE: 0.23260511813285922, Learning Rate: 0.019120000000000005\n",
      "Epoch: 16177, MSE: 0.23260228726225263, Learning Rate: 0.019115000000000007\n",
      "Epoch: 16178, MSE: 0.23259945638687626, Learning Rate: 0.019110000000000005\n",
      "Epoch: 16179, MSE: 0.2325966255067657, Learning Rate: 0.019105000000000007\n",
      "Epoch: 16180, MSE: 0.2325937946219522, Learning Rate: 0.019099999999999995\n",
      "Epoch: 16181, MSE: 0.23259096373246999, Learning Rate: 0.019094999999999997\n",
      "Epoch: 16182, MSE: 0.23258813283835142, Learning Rate: 0.019089999999999996\n",
      "Epoch: 16183, MSE: 0.2325853019396306, Learning Rate: 0.019084999999999998\n",
      "Epoch: 16184, MSE: 0.23258247103634144, Learning Rate: 0.01908\n",
      "Epoch: 16185, MSE: 0.2325796401285156, Learning Rate: 0.019074999999999998\n",
      "Epoch: 16186, MSE: 0.23257680921618748, Learning Rate: 0.01907\n",
      "Epoch: 16187, MSE: 0.2325739782993904, Learning Rate: 0.019065\n",
      "Epoch: 16188, MSE: 0.23257114737815754, Learning Rate: 0.01906\n",
      "Epoch: 16189, MSE: 0.23256831645252285, Learning Rate: 0.019055000000000002\n",
      "Epoch: 16190, MSE: 0.2325654855225194, Learning Rate: 0.01905\n",
      "Epoch: 16191, MSE: 0.23256265458818098, Learning Rate: 0.019045000000000003\n",
      "Epoch: 16192, MSE: 0.2325598236495408, Learning Rate: 0.01904\n",
      "Epoch: 16193, MSE: 0.23255699270663285, Learning Rate: 0.019035000000000003\n",
      "Epoch: 16194, MSE: 0.2325541617594913, Learning Rate: 0.019030000000000005\n",
      "Epoch: 16195, MSE: 0.2325513308081489, Learning Rate: 0.019025000000000004\n",
      "Epoch: 16196, MSE: 0.23254849985264037, Learning Rate: 0.019020000000000006\n",
      "Epoch: 16197, MSE: 0.23254566889299838, Learning Rate: 0.019015000000000004\n",
      "Epoch: 16198, MSE: 0.23254283792925703, Learning Rate: 0.019010000000000006\n",
      "Epoch: 16199, MSE: 0.2325400069614515, Learning Rate: 0.019005000000000008\n",
      "Epoch: 16200, MSE: 0.232537175989614, Learning Rate: 0.018999999999999996\n",
      "Epoch: 16201, MSE: 0.23253434501377895, Learning Rate: 0.018994999999999998\n",
      "Epoch: 16202, MSE: 0.23253151403398098, Learning Rate: 0.018989999999999996\n",
      "Epoch: 16203, MSE: 0.23252868305025337, Learning Rate: 0.018985\n",
      "Epoch: 16204, MSE: 0.23252585206262996, Learning Rate: 0.018979999999999997\n",
      "Epoch: 16205, MSE: 0.23252302107114503, Learning Rate: 0.018975\n",
      "Epoch: 16206, MSE: 0.2325201900758337, Learning Rate: 0.01897\n",
      "Epoch: 16207, MSE: 0.23251735907672882, Learning Rate: 0.018965\n",
      "Epoch: 16208, MSE: 0.23251452807386533, Learning Rate: 0.01896\n",
      "Epoch: 16209, MSE: 0.23251169706727698, Learning Rate: 0.018955\n",
      "Epoch: 16210, MSE: 0.23250886605699828, Learning Rate: 0.01895\n",
      "Epoch: 16211, MSE: 0.23250603504306303, Learning Rate: 0.018945000000000004\n",
      "Epoch: 16212, MSE: 0.23250320402550653, Learning Rate: 0.018940000000000002\n",
      "Epoch: 16213, MSE: 0.23250037300436266, Learning Rate: 0.018935000000000004\n",
      "Epoch: 16214, MSE: 0.23249754197966532, Learning Rate: 0.018930000000000002\n",
      "Epoch: 16215, MSE: 0.23249471095145008, Learning Rate: 0.018925000000000004\n",
      "Epoch: 16216, MSE: 0.23249187991975062, Learning Rate: 0.018920000000000006\n",
      "Epoch: 16217, MSE: 0.2324890488846003, Learning Rate: 0.018915000000000005\n",
      "Epoch: 16218, MSE: 0.23248621784603676, Learning Rate: 0.018910000000000007\n",
      "Epoch: 16219, MSE: 0.2324833868040915, Learning Rate: 0.018905000000000005\n",
      "Epoch: 16220, MSE: 0.2324805557588012, Learning Rate: 0.018899999999999997\n",
      "Epoch: 16221, MSE: 0.23247772471019987, Learning Rate: 0.018894999999999995\n",
      "Epoch: 16222, MSE: 0.23247489365832164, Learning Rate: 0.018889999999999997\n",
      "Epoch: 16223, MSE: 0.23247206260320188, Learning Rate: 0.018885\n",
      "Epoch: 16224, MSE: 0.23246923154487506, Learning Rate: 0.018879999999999997\n",
      "Epoch: 16225, MSE: 0.23246640048337702, Learning Rate: 0.018875\n",
      "Epoch: 16226, MSE: 0.23246356941874077, Learning Rate: 0.018869999999999998\n",
      "Epoch: 16227, MSE: 0.2324607383510028, Learning Rate: 0.018865\n",
      "Epoch: 16228, MSE: 0.23245790728019744, Learning Rate: 0.018860000000000002\n",
      "Epoch: 16229, MSE: 0.23245507620635927, Learning Rate: 0.018855\n",
      "Epoch: 16230, MSE: 0.232452245129524, Learning Rate: 0.018850000000000002\n",
      "Epoch: 16231, MSE: 0.23244941404972636, Learning Rate: 0.018845\n",
      "Epoch: 16232, MSE: 0.2324465829670014, Learning Rate: 0.018840000000000003\n",
      "Epoch: 16233, MSE: 0.23244375188138441, Learning Rate: 0.018835000000000005\n",
      "Epoch: 16234, MSE: 0.23244092079291026, Learning Rate: 0.018830000000000003\n",
      "Epoch: 16235, MSE: 0.23243808970161448, Learning Rate: 0.018825000000000005\n",
      "Epoch: 16236, MSE: 0.23243525860753236, Learning Rate: 0.018820000000000003\n",
      "Epoch: 16237, MSE: 0.2324324275106987, Learning Rate: 0.018815000000000005\n",
      "Epoch: 16238, MSE: 0.23242959641114883, Learning Rate: 0.018810000000000007\n",
      "Epoch: 16239, MSE: 0.2324267653089193, Learning Rate: 0.018805000000000006\n",
      "Epoch: 16240, MSE: 0.23242393420404406, Learning Rate: 0.018799999999999997\n",
      "Epoch: 16241, MSE: 0.23242110309655875, Learning Rate: 0.018794999999999996\n",
      "Epoch: 16242, MSE: 0.23241827198649923, Learning Rate: 0.018789999999999998\n",
      "Epoch: 16243, MSE: 0.23241544087390087, Learning Rate: 0.018784999999999996\n",
      "Epoch: 16244, MSE: 0.2324126097587996, Learning Rate: 0.018779999999999998\n",
      "Epoch: 16245, MSE: 0.23240977864123025, Learning Rate: 0.018775\n",
      "Epoch: 16246, MSE: 0.2324069475212294, Learning Rate: 0.01877\n",
      "Epoch: 16247, MSE: 0.2324041163988324, Learning Rate: 0.018765\n",
      "Epoch: 16248, MSE: 0.23240128527407386, Learning Rate: 0.01876\n",
      "Epoch: 16249, MSE: 0.23239845414699123, Learning Rate: 0.018755\n",
      "Epoch: 16250, MSE: 0.23239562301761918, Learning Rate: 0.018750000000000003\n",
      "Epoch: 16251, MSE: 0.23239279188599402, Learning Rate: 0.018745\n",
      "Epoch: 16252, MSE: 0.23238996075215088, Learning Rate: 0.018740000000000003\n",
      "Epoch: 16253, MSE: 0.23238712961612668, Learning Rate: 0.018735\n",
      "Epoch: 16254, MSE: 0.2323842984779565, Learning Rate: 0.018730000000000004\n",
      "Epoch: 16255, MSE: 0.2323814673376771, Learning Rate: 0.018725000000000002\n",
      "Epoch: 16256, MSE: 0.23237863619532337, Learning Rate: 0.018720000000000004\n",
      "Epoch: 16257, MSE: 0.23237580505093297, Learning Rate: 0.018715000000000006\n",
      "Epoch: 16258, MSE: 0.23237297390454073, Learning Rate: 0.018710000000000004\n",
      "Epoch: 16259, MSE: 0.23237014275618298, Learning Rate: 0.018705000000000006\n",
      "Epoch: 16260, MSE: 0.23236731160589666, Learning Rate: 0.018700000000000005\n",
      "Epoch: 16261, MSE: 0.23236448045371677, Learning Rate: 0.018694999999999996\n",
      "Epoch: 16262, MSE: 0.23236164929968, Learning Rate: 0.018689999999999995\n",
      "Epoch: 16263, MSE: 0.23235881814382317, Learning Rate: 0.018684999999999997\n",
      "Epoch: 16264, MSE: 0.23235598698618226, Learning Rate: 0.01868\n",
      "Epoch: 16265, MSE: 0.2323531558267936, Learning Rate: 0.018674999999999997\n",
      "Epoch: 16266, MSE: 0.2323503246656943, Learning Rate: 0.01867\n",
      "Epoch: 16267, MSE: 0.23234749350291944, Learning Rate: 0.018664999999999998\n",
      "Epoch: 16268, MSE: 0.23234466233850742, Learning Rate: 0.01866\n",
      "Epoch: 16269, MSE: 0.23234183117249219, Learning Rate: 0.018655\n",
      "Epoch: 16270, MSE: 0.23233900000491206, Learning Rate: 0.01865\n",
      "Epoch: 16271, MSE: 0.232336168835804, Learning Rate: 0.018645000000000002\n",
      "Epoch: 16272, MSE: 0.23233333766520312, Learning Rate: 0.01864\n",
      "Epoch: 16273, MSE: 0.23233050649314715, Learning Rate: 0.018635000000000002\n",
      "Epoch: 16274, MSE: 0.23232767531967302, Learning Rate: 0.018630000000000004\n",
      "Epoch: 16275, MSE: 0.23232484414481705, Learning Rate: 0.018625000000000003\n",
      "Epoch: 16276, MSE: 0.23232201296861646, Learning Rate: 0.018620000000000005\n",
      "Epoch: 16277, MSE: 0.23231918179110728, Learning Rate: 0.018615000000000003\n",
      "Epoch: 16278, MSE: 0.2323163506123273, Learning Rate: 0.018610000000000005\n",
      "Epoch: 16279, MSE: 0.2323135194323123, Learning Rate: 0.018605000000000007\n",
      "Epoch: 16280, MSE: 0.23231068825110057, Learning Rate: 0.018600000000000005\n",
      "Epoch: 16281, MSE: 0.2323078570687293, Learning Rate: 0.018594999999999997\n",
      "Epoch: 16282, MSE: 0.23230502588523363, Learning Rate: 0.018589999999999995\n",
      "Epoch: 16283, MSE: 0.2323021947006523, Learning Rate: 0.018584999999999997\n",
      "Epoch: 16284, MSE: 0.23229936351502226, Learning Rate: 0.018579999999999996\n",
      "Epoch: 16285, MSE: 0.2322965323283804, Learning Rate: 0.018574999999999998\n",
      "Epoch: 16286, MSE: 0.2322937011407637, Learning Rate: 0.01857\n",
      "Epoch: 16287, MSE: 0.2322908699522101, Learning Rate: 0.018564999999999998\n",
      "Epoch: 16288, MSE: 0.23228803876275636, Learning Rate: 0.01856\n",
      "Epoch: 16289, MSE: 0.23228520757244017, Learning Rate: 0.018555\n",
      "Epoch: 16290, MSE: 0.2322823763812989, Learning Rate: 0.01855\n",
      "Epoch: 16291, MSE: 0.23227954518936916, Learning Rate: 0.018545000000000002\n",
      "Epoch: 16292, MSE: 0.23227671399668914, Learning Rate: 0.01854\n",
      "Epoch: 16293, MSE: 0.23227388280329622, Learning Rate: 0.018535000000000003\n",
      "Epoch: 16294, MSE: 0.23227105160922876, Learning Rate: 0.01853\n",
      "Epoch: 16295, MSE: 0.23226822041452322, Learning Rate: 0.018525000000000003\n",
      "Epoch: 16296, MSE: 0.2322653892192178, Learning Rate: 0.018520000000000005\n",
      "Epoch: 16297, MSE: 0.23226255802334947, Learning Rate: 0.018515000000000004\n",
      "Epoch: 16298, MSE: 0.23225972682695753, Learning Rate: 0.018510000000000006\n",
      "Epoch: 16299, MSE: 0.23225689563007704, Learning Rate: 0.018505000000000004\n",
      "Epoch: 16300, MSE: 0.23225406443274874, Learning Rate: 0.018500000000000006\n",
      "Epoch: 16301, MSE: 0.2322512332350085, Learning Rate: 0.018494999999999994\n",
      "Epoch: 16302, MSE: 0.23224840203689506, Learning Rate: 0.018489999999999996\n",
      "Epoch: 16303, MSE: 0.23224557083844655, Learning Rate: 0.018484999999999998\n",
      "Epoch: 16304, MSE: 0.2322427396397005, Learning Rate: 0.018479999999999996\n",
      "Epoch: 16305, MSE: 0.23223990844069464, Learning Rate: 0.018475\n",
      "Epoch: 16306, MSE: 0.23223707724146767, Learning Rate: 0.018469999999999997\n",
      "Epoch: 16307, MSE: 0.23223424604205722, Learning Rate: 0.018465\n",
      "Epoch: 16308, MSE: 0.23223141484250187, Learning Rate: 0.01846\n",
      "Epoch: 16309, MSE: 0.23222858364283938, Learning Rate: 0.018455\n",
      "Epoch: 16310, MSE: 0.23222575244310772, Learning Rate: 0.01845\n",
      "Epoch: 16311, MSE: 0.23222292124334634, Learning Rate: 0.018445\n",
      "Epoch: 16312, MSE: 0.23222009004359198, Learning Rate: 0.01844\n",
      "Epoch: 16313, MSE: 0.2322172588438835, Learning Rate: 0.018435000000000003\n",
      "Epoch: 16314, MSE: 0.23221442764426065, Learning Rate: 0.018430000000000002\n",
      "Epoch: 16315, MSE: 0.23221159644476053, Learning Rate: 0.018425000000000004\n",
      "Epoch: 16316, MSE: 0.23220876524542097, Learning Rate: 0.018420000000000002\n",
      "Epoch: 16317, MSE: 0.23220593404628243, Learning Rate: 0.018415000000000004\n",
      "Epoch: 16318, MSE: 0.23220310284738188, Learning Rate: 0.018410000000000006\n",
      "Epoch: 16319, MSE: 0.23220027164875867, Learning Rate: 0.018405000000000005\n",
      "Epoch: 16320, MSE: 0.23219744045045096, Learning Rate: 0.018400000000000007\n",
      "Epoch: 16321, MSE: 0.23219460925249766, Learning Rate: 0.018394999999999995\n",
      "Epoch: 16322, MSE: 0.2321917780549379, Learning Rate: 0.018389999999999997\n",
      "Epoch: 16323, MSE: 0.23218894685780986, Learning Rate: 0.018384999999999995\n",
      "Epoch: 16324, MSE: 0.23218611566115327, Learning Rate: 0.018379999999999997\n",
      "Epoch: 16325, MSE: 0.23218328446500566, Learning Rate: 0.018375\n",
      "Epoch: 16326, MSE: 0.23218045326940603, Learning Rate: 0.018369999999999997\n",
      "Epoch: 16327, MSE: 0.2321776220743954, Learning Rate: 0.018365\n",
      "Epoch: 16328, MSE: 0.2321747908800107, Learning Rate: 0.018359999999999998\n",
      "Epoch: 16329, MSE: 0.2321719596862912, Learning Rate: 0.018355\n",
      "Epoch: 16330, MSE: 0.23216912849327648, Learning Rate: 0.01835\n",
      "Epoch: 16331, MSE: 0.23216629730100571, Learning Rate: 0.018345\n",
      "Epoch: 16332, MSE: 0.23216346610951777, Learning Rate: 0.018340000000000002\n",
      "Epoch: 16333, MSE: 0.2321606349188517, Learning Rate: 0.018335\n",
      "Epoch: 16334, MSE: 0.23215780372904757, Learning Rate: 0.018330000000000003\n",
      "Epoch: 16335, MSE: 0.2321549725401435, Learning Rate: 0.018325000000000004\n",
      "Epoch: 16336, MSE: 0.23215214135217999, Learning Rate: 0.018320000000000003\n",
      "Epoch: 16337, MSE: 0.23214931016519566, Learning Rate: 0.018315000000000005\n",
      "Epoch: 16338, MSE: 0.2321464789792304, Learning Rate: 0.018310000000000003\n",
      "Epoch: 16339, MSE: 0.23214364779432295, Learning Rate: 0.018305000000000005\n",
      "Epoch: 16340, MSE: 0.2321408166105129, Learning Rate: 0.018300000000000007\n",
      "Epoch: 16341, MSE: 0.2321379854278412, Learning Rate: 0.018294999999999995\n",
      "Epoch: 16342, MSE: 0.2321351542463464, Learning Rate: 0.018289999999999997\n",
      "Epoch: 16343, MSE: 0.2321323230660682, Learning Rate: 0.018284999999999996\n",
      "Epoch: 16344, MSE: 0.2321294918870465, Learning Rate: 0.018279999999999998\n",
      "Epoch: 16345, MSE: 0.2321266607093198, Learning Rate: 0.018274999999999996\n",
      "Epoch: 16346, MSE: 0.23212382953292998, Learning Rate: 0.018269999999999998\n",
      "Epoch: 16347, MSE: 0.23212099835791603, Learning Rate: 0.018265\n",
      "Epoch: 16348, MSE: 0.23211816718431702, Learning Rate: 0.01826\n",
      "Epoch: 16349, MSE: 0.23211533601217393, Learning Rate: 0.018255\n",
      "Epoch: 16350, MSE: 0.23211250484152546, Learning Rate: 0.01825\n",
      "Epoch: 16351, MSE: 0.2321096736724129, Learning Rate: 0.018245\n",
      "Epoch: 16352, MSE: 0.23210684250487615, Learning Rate: 0.018240000000000003\n",
      "Epoch: 16353, MSE: 0.23210401133895445, Learning Rate: 0.018235\n",
      "Epoch: 16354, MSE: 0.23210118017468842, Learning Rate: 0.018230000000000003\n",
      "Epoch: 16355, MSE: 0.2320983490121186, Learning Rate: 0.018225\n",
      "Epoch: 16356, MSE: 0.23209551785128507, Learning Rate: 0.018220000000000004\n",
      "Epoch: 16357, MSE: 0.23209268669222793, Learning Rate: 0.018215000000000005\n",
      "Epoch: 16358, MSE: 0.2320898555349874, Learning Rate: 0.018210000000000004\n",
      "Epoch: 16359, MSE: 0.2320870243796036, Learning Rate: 0.018205000000000006\n",
      "Epoch: 16360, MSE: 0.23208419322611756, Learning Rate: 0.018200000000000004\n",
      "Epoch: 16361, MSE: 0.23208136207456984, Learning Rate: 0.018194999999999996\n",
      "Epoch: 16362, MSE: 0.23207853092500022, Learning Rate: 0.018189999999999994\n",
      "Epoch: 16363, MSE: 0.2320756997774493, Learning Rate: 0.018184999999999996\n",
      "Epoch: 16364, MSE: 0.23207286863195828, Learning Rate: 0.018179999999999998\n",
      "Epoch: 16365, MSE: 0.2320700374885677, Learning Rate: 0.018174999999999997\n",
      "Epoch: 16366, MSE: 0.2320672063473181, Learning Rate: 0.01817\n",
      "Epoch: 16367, MSE: 0.23206437520825046, Learning Rate: 0.018164999999999997\n",
      "Epoch: 16368, MSE: 0.23206154407140372, Learning Rate: 0.01816\n",
      "Epoch: 16369, MSE: 0.23205871293682123, Learning Rate: 0.018155\n",
      "Epoch: 16370, MSE: 0.23205588180454273, Learning Rate: 0.01815\n",
      "Epoch: 16371, MSE: 0.23205305067460957, Learning Rate: 0.018145\n",
      "Epoch: 16372, MSE: 0.23205021954706195, Learning Rate: 0.01814\n",
      "Epoch: 16373, MSE: 0.2320473884219413, Learning Rate: 0.018135000000000002\n",
      "Epoch: 16374, MSE: 0.23204455729928913, Learning Rate: 0.018130000000000004\n",
      "Epoch: 16375, MSE: 0.2320417261791461, Learning Rate: 0.018125000000000002\n",
      "Epoch: 16376, MSE: 0.23203889506155273, Learning Rate: 0.018120000000000004\n",
      "Epoch: 16377, MSE: 0.2320360639465506, Learning Rate: 0.018115000000000003\n",
      "Epoch: 16378, MSE: 0.2320332328341816, Learning Rate: 0.018110000000000005\n",
      "Epoch: 16379, MSE: 0.23203040172448686, Learning Rate: 0.018105000000000007\n",
      "Epoch: 16380, MSE: 0.23202757061750698, Learning Rate: 0.018100000000000005\n",
      "Epoch: 16381, MSE: 0.23202473951328365, Learning Rate: 0.018095000000000007\n",
      "Epoch: 16382, MSE: 0.2320219084118584, Learning Rate: 0.018089999999999995\n",
      "Epoch: 16383, MSE: 0.23201907731327295, Learning Rate: 0.018084999999999997\n",
      "Epoch: 16384, MSE: 0.23201624621756878, Learning Rate: 0.018079999999999995\n",
      "Epoch: 16385, MSE: 0.23201341512478643, Learning Rate: 0.018074999999999997\n",
      "Epoch: 16386, MSE: 0.2320105840349692, Learning Rate: 0.01807\n",
      "Epoch: 16387, MSE: 0.23200775294815754, Learning Rate: 0.018064999999999998\n",
      "Epoch: 16388, MSE: 0.2320049218643934, Learning Rate: 0.01806\n",
      "Epoch: 16389, MSE: 0.23200209078371825, Learning Rate: 0.018054999999999998\n",
      "Epoch: 16390, MSE: 0.23199925970617485, Learning Rate: 0.01805\n",
      "Epoch: 16391, MSE: 0.23199642863180442, Learning Rate: 0.018045000000000002\n",
      "Epoch: 16392, MSE: 0.23199359756064822, Learning Rate: 0.01804\n",
      "Epoch: 16393, MSE: 0.2319907664927494, Learning Rate: 0.018035000000000002\n",
      "Epoch: 16394, MSE: 0.23198793542814822, Learning Rate: 0.01803\n",
      "Epoch: 16395, MSE: 0.23198510436688888, Learning Rate: 0.018025000000000003\n",
      "Epoch: 16396, MSE: 0.2319822733090123, Learning Rate: 0.018020000000000005\n",
      "Epoch: 16397, MSE: 0.23197944225456094, Learning Rate: 0.018015000000000003\n",
      "Epoch: 16398, MSE: 0.23197661120357624, Learning Rate: 0.018010000000000005\n",
      "Epoch: 16399, MSE: 0.23197378015610137, Learning Rate: 0.018005000000000004\n",
      "Epoch: 16400, MSE: 0.23197094911217786, Learning Rate: 0.018000000000000006\n",
      "Epoch: 16401, MSE: 0.23196811807184856, Learning Rate: 0.017995000000000008\n",
      "Epoch: 16402, MSE: 0.23196528703515598, Learning Rate: 0.017989999999999996\n",
      "Epoch: 16403, MSE: 0.23196245600214116, Learning Rate: 0.017984999999999998\n",
      "Epoch: 16404, MSE: 0.23195962497284794, Learning Rate: 0.017979999999999996\n",
      "Epoch: 16405, MSE: 0.23195679394731875, Learning Rate: 0.017974999999999998\n",
      "Epoch: 16406, MSE: 0.23195396292559545, Learning Rate: 0.017969999999999996\n",
      "Epoch: 16407, MSE: 0.23195113190772204, Learning Rate: 0.017965\n",
      "Epoch: 16408, MSE: 0.23194830089373894, Learning Rate: 0.01796\n",
      "Epoch: 16409, MSE: 0.23194546988369052, Learning Rate: 0.017955\n",
      "Epoch: 16410, MSE: 0.23194263887761868, Learning Rate: 0.01795\n",
      "Epoch: 16411, MSE: 0.23193980787556792, Learning Rate: 0.017945\n",
      "Epoch: 16412, MSE: 0.23193697687757864, Learning Rate: 0.01794\n",
      "Epoch: 16413, MSE: 0.23193414588369532, Learning Rate: 0.017935000000000003\n",
      "Epoch: 16414, MSE: 0.2319313148939609, Learning Rate: 0.01793\n",
      "Epoch: 16415, MSE: 0.2319284839084174, Learning Rate: 0.017925000000000003\n",
      "Epoch: 16416, MSE: 0.2319256529271087, Learning Rate: 0.017920000000000002\n",
      "Epoch: 16417, MSE: 0.23192282195007688, Learning Rate: 0.017915000000000004\n",
      "Epoch: 16418, MSE: 0.23191999097736687, Learning Rate: 0.017910000000000006\n",
      "Epoch: 16419, MSE: 0.2319171600090203, Learning Rate: 0.017905000000000004\n",
      "Epoch: 16420, MSE: 0.23191432904508072, Learning Rate: 0.017900000000000006\n",
      "Epoch: 16421, MSE: 0.2319114980855921, Learning Rate: 0.017895000000000005\n",
      "Epoch: 16422, MSE: 0.23190866713059707, Learning Rate: 0.017889999999999996\n",
      "Epoch: 16423, MSE: 0.23190583618013946, Learning Rate: 0.017884999999999995\n",
      "Epoch: 16424, MSE: 0.2319030052342614, Learning Rate: 0.017879999999999997\n",
      "Epoch: 16425, MSE: 0.23190017429300852, Learning Rate: 0.017875\n",
      "Epoch: 16426, MSE: 0.23189734335642306, Learning Rate: 0.017869999999999997\n",
      "Epoch: 16427, MSE: 0.23189451242454862, Learning Rate: 0.017865\n",
      "Epoch: 16428, MSE: 0.23189168149742914, Learning Rate: 0.017859999999999997\n",
      "Epoch: 16429, MSE: 0.23188885057510872, Learning Rate: 0.017855\n",
      "Epoch: 16430, MSE: 0.23188601965762964, Learning Rate: 0.01785\n",
      "Epoch: 16431, MSE: 0.23188318874503694, Learning Rate: 0.017845\n",
      "Epoch: 16432, MSE: 0.23188035783737462, Learning Rate: 0.01784\n",
      "Epoch: 16433, MSE: 0.2318775269346859, Learning Rate: 0.017835\n",
      "Epoch: 16434, MSE: 0.23187469603701422, Learning Rate: 0.017830000000000002\n",
      "Epoch: 16435, MSE: 0.23187186514440453, Learning Rate: 0.017825000000000004\n",
      "Epoch: 16436, MSE: 0.23186903425690045, Learning Rate: 0.017820000000000003\n",
      "Epoch: 16437, MSE: 0.23186620337454636, Learning Rate: 0.017815000000000004\n",
      "Epoch: 16438, MSE: 0.2318633724973863, Learning Rate: 0.017810000000000003\n",
      "Epoch: 16439, MSE: 0.2318605416254641, Learning Rate: 0.017805000000000005\n",
      "Epoch: 16440, MSE: 0.2318577107588247, Learning Rate: 0.017800000000000007\n",
      "Epoch: 16441, MSE: 0.23185487989751138, Learning Rate: 0.017795000000000005\n",
      "Epoch: 16442, MSE: 0.2318520490415691, Learning Rate: 0.017789999999999997\n",
      "Epoch: 16443, MSE: 0.23184921819104237, Learning Rate: 0.017784999999999995\n",
      "Epoch: 16444, MSE: 0.23184638734597512, Learning Rate: 0.017779999999999997\n",
      "Epoch: 16445, MSE: 0.23184355650641225, Learning Rate: 0.017774999999999996\n",
      "Epoch: 16446, MSE: 0.23184072567239836, Learning Rate: 0.017769999999999998\n",
      "Epoch: 16447, MSE: 0.23183789484397765, Learning Rate: 0.017765\n",
      "Epoch: 16448, MSE: 0.2318350640211953, Learning Rate: 0.017759999999999998\n",
      "Epoch: 16449, MSE: 0.23183223320409493, Learning Rate: 0.017755\n",
      "Epoch: 16450, MSE: 0.23182940239272226, Learning Rate: 0.01775\n",
      "Epoch: 16451, MSE: 0.2318265715871225, Learning Rate: 0.017745\n",
      "Epoch: 16452, MSE: 0.2318237407873389, Learning Rate: 0.017740000000000002\n",
      "Epoch: 16453, MSE: 0.2318209099934177, Learning Rate: 0.017735\n",
      "Epoch: 16454, MSE: 0.23181807920540357, Learning Rate: 0.017730000000000003\n",
      "Epoch: 16455, MSE: 0.23181524842334145, Learning Rate: 0.017725\n",
      "Epoch: 16456, MSE: 0.23181241764727603, Learning Rate: 0.017720000000000003\n",
      "Epoch: 16457, MSE: 0.2318095868772527, Learning Rate: 0.017715000000000005\n",
      "Epoch: 16458, MSE: 0.23180675611331655, Learning Rate: 0.017710000000000004\n",
      "Epoch: 16459, MSE: 0.23180392535551278, Learning Rate: 0.017705000000000005\n",
      "Epoch: 16460, MSE: 0.23180109460388723, Learning Rate: 0.017700000000000004\n",
      "Epoch: 16461, MSE: 0.2317982638584839, Learning Rate: 0.017695000000000006\n",
      "Epoch: 16462, MSE: 0.23179543311934914, Learning Rate: 0.017689999999999994\n",
      "Epoch: 16463, MSE: 0.2317926023865284, Learning Rate: 0.017684999999999996\n",
      "Epoch: 16464, MSE: 0.23178977166006673, Learning Rate: 0.017679999999999998\n",
      "Epoch: 16465, MSE: 0.2317869409400099, Learning Rate: 0.017674999999999996\n",
      "Epoch: 16466, MSE: 0.23178411022640302, Learning Rate: 0.017669999999999998\n",
      "Epoch: 16467, MSE: 0.23178127951929237, Learning Rate: 0.017664999999999997\n",
      "Epoch: 16468, MSE: 0.23177844881872314, Learning Rate: 0.01766\n",
      "Epoch: 16469, MSE: 0.23177561812474126, Learning Rate: 0.017655\n",
      "Epoch: 16470, MSE: 0.23177278743739263, Learning Rate: 0.01765\n",
      "Epoch: 16471, MSE: 0.2317699567567229, Learning Rate: 0.017645\n",
      "Epoch: 16472, MSE: 0.23176712608277808, Learning Rate: 0.01764\n",
      "Epoch: 16473, MSE: 0.231764295415604, Learning Rate: 0.017635\n",
      "Epoch: 16474, MSE: 0.23176146475524595, Learning Rate: 0.017630000000000003\n",
      "Epoch: 16475, MSE: 0.23175863410175157, Learning Rate: 0.017625000000000002\n",
      "Epoch: 16476, MSE: 0.2317558034551658, Learning Rate: 0.017620000000000004\n",
      "Epoch: 16477, MSE: 0.23175297281553525, Learning Rate: 0.017615000000000002\n",
      "Epoch: 16478, MSE: 0.23175014218290585, Learning Rate: 0.017610000000000004\n",
      "Epoch: 16479, MSE: 0.2317473115573237, Learning Rate: 0.017605000000000006\n",
      "Epoch: 16480, MSE: 0.23174448093883518, Learning Rate: 0.017600000000000005\n",
      "Epoch: 16481, MSE: 0.23174165032748753, Learning Rate: 0.017595000000000006\n",
      "Epoch: 16482, MSE: 0.2317388197233263, Learning Rate: 0.017589999999999995\n",
      "Epoch: 16483, MSE: 0.23173598912639798, Learning Rate: 0.017584999999999996\n",
      "Epoch: 16484, MSE: 0.23173315853674803, Learning Rate: 0.017579999999999995\n",
      "Epoch: 16485, MSE: 0.23173032795442564, Learning Rate: 0.017574999999999997\n",
      "Epoch: 16486, MSE: 0.23172749737947576, Learning Rate: 0.01757\n",
      "Epoch: 16487, MSE: 0.23172466681194473, Learning Rate: 0.017564999999999997\n",
      "Epoch: 16488, MSE: 0.23172183625188036, Learning Rate: 0.01756\n",
      "Epoch: 16489, MSE: 0.23171900569932916, Learning Rate: 0.017554999999999998\n",
      "Epoch: 16490, MSE: 0.23171617515433746, Learning Rate: 0.01755\n",
      "Epoch: 16491, MSE: 0.23171334461695298, Learning Rate: 0.017545\n",
      "Epoch: 16492, MSE: 0.2317105140872212, Learning Rate: 0.01754\n",
      "Epoch: 16493, MSE: 0.23170768356519014, Learning Rate: 0.017535000000000002\n",
      "Epoch: 16494, MSE: 0.231704853050907, Learning Rate: 0.01753\n",
      "Epoch: 16495, MSE: 0.2317020225444195, Learning Rate: 0.017525000000000002\n",
      "Epoch: 16496, MSE: 0.2316991920457735, Learning Rate: 0.017520000000000004\n",
      "Epoch: 16497, MSE: 0.23169636155501644, Learning Rate: 0.017515000000000003\n",
      "Epoch: 16498, MSE: 0.23169353107219573, Learning Rate: 0.017510000000000005\n",
      "Epoch: 16499, MSE: 0.23169070059735972, Learning Rate: 0.017505000000000003\n",
      "Epoch: 16500, MSE: 0.2316878701305546, Learning Rate: 0.017500000000000005\n",
      "Epoch: 16501, MSE: 0.23168503967182733, Learning Rate: 0.017495000000000007\n",
      "Epoch: 16502, MSE: 0.23168220922122737, Learning Rate: 0.017490000000000006\n",
      "Epoch: 16503, MSE: 0.231679378778801, Learning Rate: 0.017484999999999997\n",
      "Epoch: 16504, MSE: 0.23167654834459556, Learning Rate: 0.017479999999999996\n",
      "Epoch: 16505, MSE: 0.231673717918659, Learning Rate: 0.017474999999999997\n",
      "Epoch: 16506, MSE: 0.23167088750103998, Learning Rate: 0.017469999999999996\n",
      "Epoch: 16507, MSE: 0.2316680570917846, Learning Rate: 0.017464999999999998\n",
      "Epoch: 16508, MSE: 0.23166522669094186, Learning Rate: 0.01746\n",
      "Epoch: 16509, MSE: 0.2316623962985597, Learning Rate: 0.017455\n",
      "Epoch: 16510, MSE: 0.23165956591468498, Learning Rate: 0.01745\n",
      "Epoch: 16511, MSE: 0.2316567355393669, Learning Rate: 0.017445\n",
      "Epoch: 16512, MSE: 0.23165390517265222, Learning Rate: 0.01744\n",
      "Epoch: 16513, MSE: 0.2316510748145909, Learning Rate: 0.017435000000000003\n",
      "Epoch: 16514, MSE: 0.23164824446522955, Learning Rate: 0.01743\n",
      "Epoch: 16515, MSE: 0.23164541412461695, Learning Rate: 0.017425000000000003\n",
      "Epoch: 16516, MSE: 0.23164258379280128, Learning Rate: 0.01742\n",
      "Epoch: 16517, MSE: 0.2316397534698311, Learning Rate: 0.017415000000000003\n",
      "Epoch: 16518, MSE: 0.2316369231557546, Learning Rate: 0.017410000000000005\n",
      "Epoch: 16519, MSE: 0.23163409285062012, Learning Rate: 0.017405000000000004\n",
      "Epoch: 16520, MSE: 0.23163126255447627, Learning Rate: 0.017400000000000006\n",
      "Epoch: 16521, MSE: 0.23162843226737137, Learning Rate: 0.017395000000000004\n",
      "Epoch: 16522, MSE: 0.2316256019893549, Learning Rate: 0.017390000000000006\n",
      "Epoch: 16523, MSE: 0.23162277172047482, Learning Rate: 0.017384999999999994\n",
      "Epoch: 16524, MSE: 0.23161994146077913, Learning Rate: 0.017379999999999996\n",
      "Epoch: 16525, MSE: 0.23161711121031803, Learning Rate: 0.017374999999999998\n",
      "Epoch: 16526, MSE: 0.23161428096913955, Learning Rate: 0.017369999999999997\n",
      "Epoch: 16527, MSE: 0.231611450737293, Learning Rate: 0.017365\n",
      "Epoch: 16528, MSE: 0.23160862051482772, Learning Rate: 0.017359999999999997\n",
      "Epoch: 16529, MSE: 0.23160579030179002, Learning Rate: 0.017355\n",
      "Epoch: 16530, MSE: 0.23160296009823364, Learning Rate: 0.01735\n",
      "Epoch: 16531, MSE: 0.23160012990420373, Learning Rate: 0.017345\n",
      "Epoch: 16532, MSE: 0.23159729971975102, Learning Rate: 0.01734\n",
      "Epoch: 16533, MSE: 0.23159446954492519, Learning Rate: 0.017335\n",
      "Epoch: 16534, MSE: 0.23159163937977437, Learning Rate: 0.01733\n",
      "Epoch: 16535, MSE: 0.23158880922434863, Learning Rate: 0.017325000000000004\n",
      "Epoch: 16536, MSE: 0.2315859790786971, Learning Rate: 0.017320000000000002\n",
      "Epoch: 16537, MSE: 0.23158314894286983, Learning Rate: 0.017315000000000004\n",
      "Epoch: 16538, MSE: 0.23158031881691557, Learning Rate: 0.017310000000000002\n",
      "Epoch: 16539, MSE: 0.23157748870088468, Learning Rate: 0.017305000000000004\n",
      "Epoch: 16540, MSE: 0.23157465859482598, Learning Rate: 0.017300000000000006\n",
      "Epoch: 16541, MSE: 0.23157182849878957, Learning Rate: 0.017295000000000005\n",
      "Epoch: 16542, MSE: 0.23156899841282544, Learning Rate: 0.017290000000000007\n",
      "Epoch: 16543, MSE: 0.23156616833698324, Learning Rate: 0.017284999999999995\n",
      "Epoch: 16544, MSE: 0.23156333827131306, Learning Rate: 0.017279999999999997\n",
      "Epoch: 16545, MSE: 0.2315605082158639, Learning Rate: 0.017274999999999995\n",
      "Epoch: 16546, MSE: 0.23155767817068623, Learning Rate: 0.017269999999999997\n",
      "Epoch: 16547, MSE: 0.23155484813583155, Learning Rate: 0.017265\n",
      "Epoch: 16548, MSE: 0.23155201811134726, Learning Rate: 0.017259999999999998\n",
      "Epoch: 16549, MSE: 0.23154918809728564, Learning Rate: 0.017255\n",
      "Epoch: 16550, MSE: 0.2315463580936969, Learning Rate: 0.017249999999999998\n",
      "Epoch: 16551, MSE: 0.23154352810063078, Learning Rate: 0.017245\n",
      "Epoch: 16552, MSE: 0.23154069811813668, Learning Rate: 0.017240000000000002\n",
      "Epoch: 16553, MSE: 0.23153786814626603, Learning Rate: 0.017235\n",
      "Epoch: 16554, MSE: 0.23153503818506901, Learning Rate: 0.017230000000000002\n",
      "Epoch: 16555, MSE: 0.23153220823459586, Learning Rate: 0.017225\n",
      "Epoch: 16556, MSE: 0.23152937829489922, Learning Rate: 0.017220000000000003\n",
      "Epoch: 16557, MSE: 0.23152654836602685, Learning Rate: 0.017215000000000005\n",
      "Epoch: 16558, MSE: 0.23152371844803066, Learning Rate: 0.017210000000000003\n",
      "Epoch: 16559, MSE: 0.23152088854096198, Learning Rate: 0.017205000000000005\n",
      "Epoch: 16560, MSE: 0.23151805864487035, Learning Rate: 0.017200000000000003\n",
      "Epoch: 16561, MSE: 0.23151522875980793, Learning Rate: 0.017195000000000005\n",
      "Epoch: 16562, MSE: 0.2315123988858248, Learning Rate: 0.017190000000000007\n",
      "Epoch: 16563, MSE: 0.23150956902297307, Learning Rate: 0.017184999999999995\n",
      "Epoch: 16564, MSE: 0.2315067391713023, Learning Rate: 0.017179999999999997\n",
      "Epoch: 16565, MSE: 0.23150390933086434, Learning Rate: 0.017174999999999996\n",
      "Epoch: 16566, MSE: 0.2315010795017104, Learning Rate: 0.017169999999999998\n",
      "Epoch: 16567, MSE: 0.23149824968389202, Learning Rate: 0.017164999999999996\n",
      "Epoch: 16568, MSE: 0.23149541987745953, Learning Rate: 0.017159999999999998\n",
      "Epoch: 16569, MSE: 0.23149259008246562, Learning Rate: 0.017155\n",
      "Epoch: 16570, MSE: 0.23148976029896054, Learning Rate: 0.01715\n",
      "Epoch: 16571, MSE: 0.2314869305269963, Learning Rate: 0.017145\n",
      "Epoch: 16572, MSE: 0.2314841007666245, Learning Rate: 0.01714\n",
      "Epoch: 16573, MSE: 0.23148127101789653, Learning Rate: 0.017135\n",
      "Epoch: 16574, MSE: 0.23147844128086406, Learning Rate: 0.017130000000000003\n",
      "Epoch: 16575, MSE: 0.23147561155557947, Learning Rate: 0.017125\n",
      "Epoch: 16576, MSE: 0.2314727818420926, Learning Rate: 0.017120000000000003\n",
      "Epoch: 16577, MSE: 0.23146995214045807, Learning Rate: 0.017115000000000002\n",
      "Epoch: 16578, MSE: 0.2314671224507257, Learning Rate: 0.017110000000000004\n",
      "Epoch: 16579, MSE: 0.23146429277294825, Learning Rate: 0.017105000000000006\n",
      "Epoch: 16580, MSE: 0.23146146310717783, Learning Rate: 0.017100000000000004\n",
      "Epoch: 16581, MSE: 0.23145863345346646, Learning Rate: 0.017095000000000006\n",
      "Epoch: 16582, MSE: 0.23145580381186653, Learning Rate: 0.017090000000000004\n",
      "Epoch: 16583, MSE: 0.23145297418242866, Learning Rate: 0.017084999999999996\n",
      "Epoch: 16584, MSE: 0.23145014456520766, Learning Rate: 0.017079999999999994\n",
      "Epoch: 16585, MSE: 0.23144731496025356, Learning Rate: 0.017074999999999996\n",
      "Epoch: 16586, MSE: 0.23144448536762063, Learning Rate: 0.01707\n",
      "Epoch: 16587, MSE: 0.23144165578736048, Learning Rate: 0.017064999999999997\n",
      "Epoch: 16588, MSE: 0.23143882621952522, Learning Rate: 0.01706\n",
      "Epoch: 16589, MSE: 0.23143599666416823, Learning Rate: 0.017054999999999997\n",
      "Epoch: 16590, MSE: 0.23143316712134135, Learning Rate: 0.01705\n",
      "Epoch: 16591, MSE: 0.23143033759109816, Learning Rate: 0.017045\n",
      "Epoch: 16592, MSE: 0.2314275080734909, Learning Rate: 0.01704\n",
      "Epoch: 16593, MSE: 0.2314246785685718, Learning Rate: 0.017035\n",
      "Epoch: 16594, MSE: 0.23142184907639604, Learning Rate: 0.01703\n",
      "Epoch: 16595, MSE: 0.2314190195970146, Learning Rate: 0.017025000000000002\n",
      "Epoch: 16596, MSE: 0.23141619013047982, Learning Rate: 0.017020000000000004\n",
      "Epoch: 16597, MSE: 0.23141336067684692, Learning Rate: 0.017015000000000002\n",
      "Epoch: 16598, MSE: 0.23141053123616795, Learning Rate: 0.017010000000000004\n",
      "Epoch: 16599, MSE: 0.23140770180849582, Learning Rate: 0.017005000000000003\n",
      "Epoch: 16600, MSE: 0.2314048723938845, Learning Rate: 0.017000000000000005\n",
      "Epoch: 16601, MSE: 0.23140204299238698, Learning Rate: 0.016995000000000007\n",
      "Epoch: 16602, MSE: 0.2313992136040564, Learning Rate: 0.016990000000000005\n",
      "Epoch: 16603, MSE: 0.23139638422894707, Learning Rate: 0.016984999999999997\n",
      "Epoch: 16604, MSE: 0.23139355486711216, Learning Rate: 0.016979999999999995\n",
      "Epoch: 16605, MSE: 0.23139072551860465, Learning Rate: 0.016974999999999997\n",
      "Epoch: 16606, MSE: 0.23138789618347785, Learning Rate: 0.016969999999999996\n",
      "Epoch: 16607, MSE: 0.2313850668617875, Learning Rate: 0.016964999999999997\n",
      "Epoch: 16608, MSE: 0.23138223755358558, Learning Rate: 0.01696\n",
      "Epoch: 16609, MSE: 0.2313794082589269, Learning Rate: 0.016954999999999998\n",
      "Epoch: 16610, MSE: 0.2313765789778647, Learning Rate: 0.01695\n",
      "Epoch: 16611, MSE: 0.2313737497104532, Learning Rate: 0.016944999999999998\n",
      "Epoch: 16612, MSE: 0.23137092045674665, Learning Rate: 0.01694\n",
      "Epoch: 16613, MSE: 0.23136809121679888, Learning Rate: 0.016935000000000002\n",
      "Epoch: 16614, MSE: 0.23136526199066437, Learning Rate: 0.01693\n",
      "Epoch: 16615, MSE: 0.23136243277839716, Learning Rate: 0.016925000000000003\n",
      "Epoch: 16616, MSE: 0.23135960358005123, Learning Rate: 0.01692\n",
      "Epoch: 16617, MSE: 0.23135677439568147, Learning Rate: 0.016915000000000003\n",
      "Epoch: 16618, MSE: 0.23135394522534222, Learning Rate: 0.016910000000000005\n",
      "Epoch: 16619, MSE: 0.23135111606908754, Learning Rate: 0.016905000000000003\n",
      "Epoch: 16620, MSE: 0.2313482869269733, Learning Rate: 0.016900000000000005\n",
      "Epoch: 16621, MSE: 0.23134545779905216, Learning Rate: 0.016895000000000004\n",
      "Epoch: 16622, MSE: 0.23134262868537964, Learning Rate: 0.016890000000000006\n",
      "Epoch: 16623, MSE: 0.23133979958601156, Learning Rate: 0.016884999999999994\n",
      "Epoch: 16624, MSE: 0.2313369705010009, Learning Rate: 0.016879999999999996\n",
      "Epoch: 16625, MSE: 0.2313341414304036, Learning Rate: 0.016874999999999998\n",
      "Epoch: 16626, MSE: 0.23133131237427498, Learning Rate: 0.016869999999999996\n",
      "Epoch: 16627, MSE: 0.23132848333266945, Learning Rate: 0.016864999999999998\n",
      "Epoch: 16628, MSE: 0.23132565430564186, Learning Rate: 0.016859999999999997\n",
      "Epoch: 16629, MSE: 0.23132282529324794, Learning Rate: 0.016855\n",
      "Epoch: 16630, MSE: 0.23131999629554253, Learning Rate: 0.01685\n",
      "Epoch: 16631, MSE: 0.23131716731258078, Learning Rate: 0.016845\n",
      "Epoch: 16632, MSE: 0.23131433834441884, Learning Rate: 0.01684\n",
      "Epoch: 16633, MSE: 0.23131150939111156, Learning Rate: 0.016835\n",
      "Epoch: 16634, MSE: 0.231308680452714, Learning Rate: 0.01683\n",
      "Epoch: 16635, MSE: 0.23130585152928282, Learning Rate: 0.016825000000000003\n",
      "Epoch: 16636, MSE: 0.23130302262087216, Learning Rate: 0.01682\n",
      "Epoch: 16637, MSE: 0.2313001937275386, Learning Rate: 0.016815000000000004\n",
      "Epoch: 16638, MSE: 0.23129736484933783, Learning Rate: 0.016810000000000002\n",
      "Epoch: 16639, MSE: 0.23129453598632624, Learning Rate: 0.016805000000000004\n",
      "Epoch: 16640, MSE: 0.23129170713855907, Learning Rate: 0.016800000000000006\n",
      "Epoch: 16641, MSE: 0.2312888783060914, Learning Rate: 0.016795000000000004\n",
      "Epoch: 16642, MSE: 0.23128604948898077, Learning Rate: 0.016790000000000006\n",
      "Epoch: 16643, MSE: 0.23128322068728244, Learning Rate: 0.016785000000000005\n",
      "Epoch: 16644, MSE: 0.23128039190105304, Learning Rate: 0.016779999999999996\n",
      "Epoch: 16645, MSE: 0.23127756313034775, Learning Rate: 0.016774999999999995\n",
      "Epoch: 16646, MSE: 0.23127473437522356, Learning Rate: 0.016769999999999997\n",
      "Epoch: 16647, MSE: 0.23127190563573738, Learning Rate: 0.016765\n",
      "Epoch: 16648, MSE: 0.23126907691194495, Learning Rate: 0.016759999999999997\n",
      "Epoch: 16649, MSE: 0.23126624820390346, Learning Rate: 0.016755\n",
      "Epoch: 16650, MSE: 0.23126341951166743, Learning Rate: 0.016749999999999998\n",
      "Epoch: 16651, MSE: 0.23126059083529635, Learning Rate: 0.016745\n",
      "Epoch: 16652, MSE: 0.23125776217484456, Learning Rate: 0.01674\n",
      "Epoch: 16653, MSE: 0.23125493353037024, Learning Rate: 0.016735\n",
      "Epoch: 16654, MSE: 0.2312521049019298, Learning Rate: 0.016730000000000002\n",
      "Epoch: 16655, MSE: 0.23124927628957972, Learning Rate: 0.016725\n",
      "Epoch: 16656, MSE: 0.23124644769337782, Learning Rate: 0.016720000000000002\n",
      "Epoch: 16657, MSE: 0.23124361911337973, Learning Rate: 0.016715000000000004\n",
      "Epoch: 16658, MSE: 0.23124079054964486, Learning Rate: 0.016710000000000003\n",
      "Epoch: 16659, MSE: 0.23123796200222765, Learning Rate: 0.016705000000000005\n",
      "Epoch: 16660, MSE: 0.23123513347118688, Learning Rate: 0.016700000000000003\n",
      "Epoch: 16661, MSE: 0.23123230495658004, Learning Rate: 0.016695000000000005\n",
      "Epoch: 16662, MSE: 0.23122947645846406, Learning Rate: 0.016690000000000007\n",
      "Epoch: 16663, MSE: 0.231226647976896, Learning Rate: 0.016685000000000005\n",
      "Epoch: 16664, MSE: 0.23122381951193427, Learning Rate: 0.016679999999999997\n",
      "Epoch: 16665, MSE: 0.23122099106363567, Learning Rate: 0.016674999999999995\n",
      "Epoch: 16666, MSE: 0.2312181626320588, Learning Rate: 0.016669999999999997\n",
      "Epoch: 16667, MSE: 0.23121533421726007, Learning Rate: 0.016664999999999996\n",
      "Epoch: 16668, MSE: 0.23121250581929761, Learning Rate: 0.016659999999999998\n",
      "Epoch: 16669, MSE: 0.23120967743823054, Learning Rate: 0.016655\n",
      "Epoch: 16670, MSE: 0.231206849074115, Learning Rate: 0.016649999999999998\n",
      "Epoch: 16671, MSE: 0.2312040207270107, Learning Rate: 0.016645\n",
      "Epoch: 16672, MSE: 0.23120119239697412, Learning Rate: 0.01664\n",
      "Epoch: 16673, MSE: 0.23119836408406472, Learning Rate: 0.016635\n",
      "Epoch: 16674, MSE: 0.2311955357883401, Learning Rate: 0.016630000000000002\n",
      "Epoch: 16675, MSE: 0.23119270750985838, Learning Rate: 0.016625\n",
      "Epoch: 16676, MSE: 0.23118987924867807, Learning Rate: 0.016620000000000003\n",
      "Epoch: 16677, MSE: 0.23118705100485804, Learning Rate: 0.016615\n",
      "Epoch: 16678, MSE: 0.23118422277845518, Learning Rate: 0.016610000000000003\n",
      "Epoch: 16679, MSE: 0.23118139456953105, Learning Rate: 0.016605000000000005\n",
      "Epoch: 16680, MSE: 0.2311785663781411, Learning Rate: 0.016600000000000004\n",
      "Epoch: 16681, MSE: 0.2311757382043462, Learning Rate: 0.016595000000000006\n",
      "Epoch: 16682, MSE: 0.23117291004820387, Learning Rate: 0.016590000000000004\n",
      "Epoch: 16683, MSE: 0.23117008190977428, Learning Rate: 0.016585000000000006\n",
      "Epoch: 16684, MSE: 0.23116725378911485, Learning Rate: 0.016579999999999994\n",
      "Epoch: 16685, MSE: 0.2311644256862857, Learning Rate: 0.016574999999999996\n",
      "Epoch: 16686, MSE: 0.23116159760134478, Learning Rate: 0.016569999999999998\n",
      "Epoch: 16687, MSE: 0.2311587695343524, Learning Rate: 0.016564999999999996\n",
      "Epoch: 16688, MSE: 0.23115594148536722, Learning Rate: 0.01656\n",
      "Epoch: 16689, MSE: 0.23115311345444797, Learning Rate: 0.016554999999999997\n",
      "Epoch: 16690, MSE: 0.2311502854416554, Learning Rate: 0.01655\n",
      "Epoch: 16691, MSE: 0.23114745744704818, Learning Rate: 0.016545\n",
      "Epoch: 16692, MSE: 0.23114462947068534, Learning Rate: 0.01654\n",
      "Epoch: 16693, MSE: 0.2311418015126268, Learning Rate: 0.016535\n",
      "Epoch: 16694, MSE: 0.231138973572933, Learning Rate: 0.01653\n",
      "Epoch: 16695, MSE: 0.23113614565166207, Learning Rate: 0.016525\n",
      "Epoch: 16696, MSE: 0.23113331774887483, Learning Rate: 0.016520000000000003\n",
      "Epoch: 16697, MSE: 0.23113048986463117, Learning Rate: 0.016515000000000002\n",
      "Epoch: 16698, MSE: 0.23112766199899082, Learning Rate: 0.016510000000000004\n",
      "Epoch: 16699, MSE: 0.2311248341520139, Learning Rate: 0.016505000000000002\n",
      "Epoch: 16700, MSE: 0.23112200632375982, Learning Rate: 0.016500000000000004\n",
      "Epoch: 16701, MSE: 0.2311191785142898, Learning Rate: 0.016495000000000006\n",
      "Epoch: 16702, MSE: 0.23111635072366377, Learning Rate: 0.016490000000000005\n",
      "Epoch: 16703, MSE: 0.23111352295194124, Learning Rate: 0.016485000000000007\n",
      "Epoch: 16704, MSE: 0.2311106951991831, Learning Rate: 0.016479999999999995\n",
      "Epoch: 16705, MSE: 0.23110786746545034, Learning Rate: 0.016474999999999997\n",
      "Epoch: 16706, MSE: 0.2311050397508032, Learning Rate: 0.016469999999999995\n",
      "Epoch: 16707, MSE: 0.23110221205530165, Learning Rate: 0.016464999999999997\n",
      "Epoch: 16708, MSE: 0.23109938437900626, Learning Rate: 0.01646\n",
      "Epoch: 16709, MSE: 0.23109655672197818, Learning Rate: 0.016454999999999997\n",
      "Epoch: 16710, MSE: 0.2310937290842788, Learning Rate: 0.01645\n",
      "Epoch: 16711, MSE: 0.2310909014659688, Learning Rate: 0.016444999999999998\n",
      "Epoch: 16712, MSE: 0.23108807386710872, Learning Rate: 0.01644\n",
      "Epoch: 16713, MSE: 0.23108524628775964, Learning Rate: 0.016435\n",
      "Epoch: 16714, MSE: 0.23108241872798202, Learning Rate: 0.01643\n",
      "Epoch: 16715, MSE: 0.23107959118783875, Learning Rate: 0.016425000000000002\n",
      "Epoch: 16716, MSE: 0.23107676366739008, Learning Rate: 0.01642\n",
      "Epoch: 16717, MSE: 0.2310739361666973, Learning Rate: 0.016415000000000003\n",
      "Epoch: 16718, MSE: 0.2310711086858223, Learning Rate: 0.016410000000000004\n",
      "Epoch: 16719, MSE: 0.23106828122482537, Learning Rate: 0.016405000000000003\n",
      "Epoch: 16720, MSE: 0.23106545378376928, Learning Rate: 0.016400000000000005\n",
      "Epoch: 16721, MSE: 0.23106262636271538, Learning Rate: 0.016395000000000003\n",
      "Epoch: 16722, MSE: 0.2310597989617251, Learning Rate: 0.016390000000000005\n",
      "Epoch: 16723, MSE: 0.23105697158086025, Learning Rate: 0.016385000000000007\n",
      "Epoch: 16724, MSE: 0.23105414422018342, Learning Rate: 0.016379999999999995\n",
      "Epoch: 16725, MSE: 0.23105131687975547, Learning Rate: 0.016374999999999997\n",
      "Epoch: 16726, MSE: 0.23104848955963908, Learning Rate: 0.016369999999999996\n",
      "Epoch: 16727, MSE: 0.2310456622598964, Learning Rate: 0.016364999999999998\n",
      "Epoch: 16728, MSE: 0.23104283498058953, Learning Rate: 0.016359999999999996\n",
      "Epoch: 16729, MSE: 0.23104000772177988, Learning Rate: 0.016354999999999998\n",
      "Epoch: 16730, MSE: 0.2310371804835312, Learning Rate: 0.01635\n",
      "Epoch: 16731, MSE: 0.23103435326590477, Learning Rate: 0.016345\n",
      "Epoch: 16732, MSE: 0.23103152606896443, Learning Rate: 0.01634\n",
      "Epoch: 16733, MSE: 0.23102869889277028, Learning Rate: 0.016335\n",
      "Epoch: 16734, MSE: 0.23102587173738742, Learning Rate: 0.01633\n",
      "Epoch: 16735, MSE: 0.23102304460287704, Learning Rate: 0.016325000000000003\n",
      "Epoch: 16736, MSE: 0.23102021748930276, Learning Rate: 0.01632\n",
      "Epoch: 16737, MSE: 0.23101739039672692, Learning Rate: 0.016315000000000003\n",
      "Epoch: 16738, MSE: 0.23101456332521308, Learning Rate: 0.01631\n",
      "Epoch: 16739, MSE: 0.23101173627482255, Learning Rate: 0.016305000000000004\n",
      "Epoch: 16740, MSE: 0.23100890924562148, Learning Rate: 0.016300000000000005\n",
      "Epoch: 16741, MSE: 0.2310060822376708, Learning Rate: 0.016295000000000004\n",
      "Epoch: 16742, MSE: 0.23100325525103357, Learning Rate: 0.016290000000000006\n",
      "Epoch: 16743, MSE: 0.23100042828577405, Learning Rate: 0.016285000000000004\n",
      "Epoch: 16744, MSE: 0.2309976013419556, Learning Rate: 0.016279999999999996\n",
      "Epoch: 16745, MSE: 0.23099477441964136, Learning Rate: 0.016274999999999994\n",
      "Epoch: 16746, MSE: 0.23099194751889535, Learning Rate: 0.016269999999999996\n",
      "Epoch: 16747, MSE: 0.23098912063977992, Learning Rate: 0.016264999999999998\n",
      "Epoch: 16748, MSE: 0.23098629378236016, Learning Rate: 0.016259999999999997\n",
      "Epoch: 16749, MSE: 0.23098346694669977, Learning Rate: 0.016255\n",
      "Epoch: 16750, MSE: 0.23098064013286182, Learning Rate: 0.016249999999999997\n",
      "Epoch: 16751, MSE: 0.23097781334091105, Learning Rate: 0.016245\n",
      "Epoch: 16752, MSE: 0.23097498657091095, Learning Rate: 0.01624\n",
      "Epoch: 16753, MSE: 0.23097215982292577, Learning Rate: 0.016235\n",
      "Epoch: 16754, MSE: 0.23096933309702036, Learning Rate: 0.01623\n",
      "Epoch: 16755, MSE: 0.2309665063932577, Learning Rate: 0.016225\n",
      "Epoch: 16756, MSE: 0.23096367971170348, Learning Rate: 0.016220000000000002\n",
      "Epoch: 16757, MSE: 0.23096085305242062, Learning Rate: 0.016215000000000004\n",
      "Epoch: 16758, MSE: 0.23095802641547505, Learning Rate: 0.016210000000000002\n",
      "Epoch: 16759, MSE: 0.2309551998009315, Learning Rate: 0.016205000000000004\n",
      "Epoch: 16760, MSE: 0.23095237320885295, Learning Rate: 0.016200000000000003\n",
      "Epoch: 16761, MSE: 0.23094954663930625, Learning Rate: 0.016195000000000005\n",
      "Epoch: 16762, MSE: 0.23094672009235404, Learning Rate: 0.016190000000000006\n",
      "Epoch: 16763, MSE: 0.23094389356806233, Learning Rate: 0.016185000000000005\n",
      "Epoch: 16764, MSE: 0.23094106706649667, Learning Rate: 0.016180000000000007\n",
      "Epoch: 16765, MSE: 0.23093824058772083, Learning Rate: 0.016174999999999995\n",
      "Epoch: 16766, MSE: 0.23093541413180138, Learning Rate: 0.016169999999999997\n",
      "Epoch: 16767, MSE: 0.23093258769880237, Learning Rate: 0.016164999999999995\n",
      "Epoch: 16768, MSE: 0.23092976128879006, Learning Rate: 0.016159999999999997\n",
      "Epoch: 16769, MSE: 0.23092693490182903, Learning Rate: 0.016155\n",
      "Epoch: 16770, MSE: 0.23092410853798526, Learning Rate: 0.016149999999999998\n",
      "Epoch: 16771, MSE: 0.2309212821973238, Learning Rate: 0.016145\n",
      "Epoch: 16772, MSE: 0.23091845587991072, Learning Rate: 0.016139999999999998\n",
      "Epoch: 16773, MSE: 0.2309156295858124, Learning Rate: 0.016135\n",
      "Epoch: 16774, MSE: 0.23091280331509298, Learning Rate: 0.016130000000000002\n",
      "Epoch: 16775, MSE: 0.2309099770678199, Learning Rate: 0.016125\n",
      "Epoch: 16776, MSE: 0.23090715084405805, Learning Rate: 0.016120000000000002\n",
      "Epoch: 16777, MSE: 0.23090432464387395, Learning Rate: 0.016115\n",
      "Epoch: 16778, MSE: 0.23090149846733424, Learning Rate: 0.016110000000000003\n",
      "Epoch: 16779, MSE: 0.23089867231450387, Learning Rate: 0.016105000000000005\n",
      "Epoch: 16780, MSE: 0.23089584618545042, Learning Rate: 0.016100000000000003\n",
      "Epoch: 16781, MSE: 0.2308930200802392, Learning Rate: 0.016095000000000005\n",
      "Epoch: 16782, MSE: 0.23089019399893682, Learning Rate: 0.016090000000000004\n",
      "Epoch: 16783, MSE: 0.23088736794161108, Learning Rate: 0.016085000000000006\n",
      "Epoch: 16784, MSE: 0.23088454190832763, Learning Rate: 0.016080000000000007\n",
      "Epoch: 16785, MSE: 0.23088171589915227, Learning Rate: 0.016074999999999996\n",
      "Epoch: 16786, MSE: 0.23087888991415362, Learning Rate: 0.016069999999999997\n",
      "Epoch: 16787, MSE: 0.23087606395339708, Learning Rate: 0.016064999999999996\n",
      "Epoch: 16788, MSE: 0.23087323801694978, Learning Rate: 0.016059999999999998\n",
      "Epoch: 16789, MSE: 0.23087041210488035, Learning Rate: 0.016054999999999996\n",
      "Epoch: 16790, MSE: 0.23086758621725403, Learning Rate: 0.01605\n",
      "Epoch: 16791, MSE: 0.23086476035413936, Learning Rate: 0.016045\n",
      "Epoch: 16792, MSE: 0.23086193451560227, Learning Rate: 0.01604\n",
      "Epoch: 16793, MSE: 0.23085910870171172, Learning Rate: 0.016035\n",
      "Epoch: 16794, MSE: 0.2308562829125333, Learning Rate: 0.01603\n",
      "Epoch: 16795, MSE: 0.23085345714813585, Learning Rate: 0.016025\n",
      "Epoch: 16796, MSE: 0.230850631408587, Learning Rate: 0.016020000000000003\n",
      "Epoch: 16797, MSE: 0.23084780569395447, Learning Rate: 0.016015\n",
      "Epoch: 16798, MSE: 0.23084498000430448, Learning Rate: 0.016010000000000003\n",
      "Epoch: 16799, MSE: 0.2308421543397071, Learning Rate: 0.016005000000000002\n",
      "Epoch: 16800, MSE: 0.23083932870023, Learning Rate: 0.016000000000000004\n",
      "Epoch: 16801, MSE: 0.2308365030859398, Learning Rate: 0.015995000000000006\n",
      "Epoch: 16802, MSE: 0.2308336774969062, Learning Rate: 0.015990000000000004\n",
      "Epoch: 16803, MSE: 0.23083085193319547, Learning Rate: 0.015985000000000006\n",
      "Epoch: 16804, MSE: 0.2308280263948782, Learning Rate: 0.015980000000000005\n",
      "Epoch: 16805, MSE: 0.23082520088202105, Learning Rate: 0.015974999999999996\n",
      "Epoch: 16806, MSE: 0.2308223753946933, Learning Rate: 0.015969999999999995\n",
      "Epoch: 16807, MSE: 0.23081954993296375, Learning Rate: 0.015964999999999997\n",
      "Epoch: 16808, MSE: 0.23081672449690052, Learning Rate: 0.01596\n",
      "Epoch: 16809, MSE: 0.2308138990865723, Learning Rate: 0.015954999999999997\n",
      "Epoch: 16810, MSE: 0.23081107370204837, Learning Rate: 0.01595\n",
      "Epoch: 16811, MSE: 0.23080824834339775, Learning Rate: 0.015944999999999997\n",
      "Epoch: 16812, MSE: 0.23080542301068863, Learning Rate: 0.01594\n",
      "Epoch: 16813, MSE: 0.23080259770399061, Learning Rate: 0.015935\n",
      "Epoch: 16814, MSE: 0.23079977242337293, Learning Rate: 0.01593\n",
      "Epoch: 16815, MSE: 0.23079694716890464, Learning Rate: 0.015925\n",
      "Epoch: 16816, MSE: 0.23079412194065546, Learning Rate: 0.01592\n",
      "Epoch: 16817, MSE: 0.23079129673869359, Learning Rate: 0.015915000000000002\n",
      "Epoch: 16818, MSE: 0.23078847156309037, Learning Rate: 0.015910000000000004\n",
      "Epoch: 16819, MSE: 0.2307856464139136, Learning Rate: 0.015905000000000002\n",
      "Epoch: 16820, MSE: 0.23078282129123506, Learning Rate: 0.015900000000000004\n",
      "Epoch: 16821, MSE: 0.23077999619512216, Learning Rate: 0.015895000000000003\n",
      "Epoch: 16822, MSE: 0.2307771711256473, Learning Rate: 0.015890000000000005\n",
      "Epoch: 16823, MSE: 0.23077434608287906, Learning Rate: 0.015885000000000007\n",
      "Epoch: 16824, MSE: 0.23077152106688623, Learning Rate: 0.015880000000000005\n",
      "Epoch: 16825, MSE: 0.23076869607774045, Learning Rate: 0.015874999999999997\n",
      "Epoch: 16826, MSE: 0.23076587111551222, Learning Rate: 0.015869999999999995\n",
      "Epoch: 16827, MSE: 0.23076304618027185, Learning Rate: 0.015864999999999997\n",
      "Epoch: 16828, MSE: 0.23076022127208887, Learning Rate: 0.015859999999999996\n",
      "Epoch: 16829, MSE: 0.23075739639103335, Learning Rate: 0.015854999999999998\n",
      "Epoch: 16830, MSE: 0.23075457153717752, Learning Rate: 0.01585\n",
      "Epoch: 16831, MSE: 0.23075174671059082, Learning Rate: 0.015844999999999998\n",
      "Epoch: 16832, MSE: 0.23074892191134502, Learning Rate: 0.01584\n",
      "Epoch: 16833, MSE: 0.23074609713951005, Learning Rate: 0.015835\n",
      "Epoch: 16834, MSE: 0.2307432723951561, Learning Rate: 0.01583\n",
      "Epoch: 16835, MSE: 0.23074044767835722, Learning Rate: 0.015825000000000002\n",
      "Epoch: 16836, MSE: 0.2307376229891806, Learning Rate: 0.01582\n",
      "Epoch: 16837, MSE: 0.23073479832770052, Learning Rate: 0.015815000000000003\n",
      "Epoch: 16838, MSE: 0.2307319736939865, Learning Rate: 0.01581\n",
      "Epoch: 16839, MSE: 0.2307291490881105, Learning Rate: 0.015805000000000003\n",
      "Epoch: 16840, MSE: 0.23072632451014408, Learning Rate: 0.015800000000000005\n",
      "Epoch: 16841, MSE: 0.23072349996015948, Learning Rate: 0.015795000000000003\n",
      "Epoch: 16842, MSE: 0.23072067543822694, Learning Rate: 0.015790000000000005\n",
      "Epoch: 16843, MSE: 0.2307178509444193, Learning Rate: 0.015785000000000004\n",
      "Epoch: 16844, MSE: 0.23071502647880823, Learning Rate: 0.015780000000000006\n",
      "Epoch: 16845, MSE: 0.23071220204146467, Learning Rate: 0.015774999999999994\n",
      "Epoch: 16846, MSE: 0.2307093776324615, Learning Rate: 0.015769999999999996\n",
      "Epoch: 16847, MSE: 0.2307065532518712, Learning Rate: 0.015764999999999998\n",
      "Epoch: 16848, MSE: 0.23070372889976523, Learning Rate: 0.015759999999999996\n",
      "Epoch: 16849, MSE: 0.23070090457621642, Learning Rate: 0.015754999999999998\n",
      "Epoch: 16850, MSE: 0.23069808028129607, Learning Rate: 0.015749999999999997\n",
      "Epoch: 16851, MSE: 0.23069525601507815, Learning Rate: 0.015745\n",
      "Epoch: 16852, MSE: 0.23069243177763452, Learning Rate: 0.01574\n",
      "Epoch: 16853, MSE: 0.2306896075690378, Learning Rate: 0.015735\n",
      "Epoch: 16854, MSE: 0.23068678338936063, Learning Rate: 0.01573\n",
      "Epoch: 16855, MSE: 0.23068395923867593, Learning Rate: 0.015725\n",
      "Epoch: 16856, MSE: 0.23068113511705704, Learning Rate: 0.01572\n",
      "Epoch: 16857, MSE: 0.23067831102457687, Learning Rate: 0.015715000000000003\n",
      "Epoch: 16858, MSE: 0.23067548696130866, Learning Rate: 0.015710000000000002\n",
      "Epoch: 16859, MSE: 0.2306726629273244, Learning Rate: 0.015705000000000004\n",
      "Epoch: 16860, MSE: 0.23066983892269893, Learning Rate: 0.015700000000000002\n",
      "Epoch: 16861, MSE: 0.23066701494750483, Learning Rate: 0.015695000000000004\n",
      "Epoch: 16862, MSE: 0.23066419100181623, Learning Rate: 0.015690000000000006\n",
      "Epoch: 16863, MSE: 0.23066136708570548, Learning Rate: 0.015685000000000004\n",
      "Epoch: 16864, MSE: 0.23065854319924778, Learning Rate: 0.015680000000000006\n",
      "Epoch: 16865, MSE: 0.23065571934251636, Learning Rate: 0.015674999999999994\n",
      "Epoch: 16866, MSE: 0.2306528955155845, Learning Rate: 0.015669999999999996\n",
      "Epoch: 16867, MSE: 0.23065007171852736, Learning Rate: 0.015664999999999995\n",
      "Epoch: 16868, MSE: 0.23064724795141764, Learning Rate: 0.015659999999999997\n",
      "Epoch: 16869, MSE: 0.23064442421433015, Learning Rate: 0.015655\n",
      "Epoch: 16870, MSE: 0.23064160050733926, Learning Rate: 0.015649999999999997\n",
      "Epoch: 16871, MSE: 0.23063877683051945, Learning Rate: 0.015645\n",
      "Epoch: 16872, MSE: 0.23063595318394456, Learning Rate: 0.015639999999999998\n",
      "Epoch: 16873, MSE: 0.23063312956768928, Learning Rate: 0.015635\n",
      "Epoch: 16874, MSE: 0.23063030598182876, Learning Rate: 0.01563\n",
      "Epoch: 16875, MSE: 0.23062748242643757, Learning Rate: 0.015625\n",
      "Epoch: 16876, MSE: 0.2306246589015899, Learning Rate: 0.015620000000000002\n",
      "Epoch: 16877, MSE: 0.23062183540736123, Learning Rate: 0.015615000000000002\n",
      "Epoch: 16878, MSE: 0.2306190119438269, Learning Rate: 0.015610000000000002\n",
      "Epoch: 16879, MSE: 0.2306161885110613, Learning Rate: 0.015605000000000003\n",
      "Epoch: 16880, MSE: 0.23061336510913952, Learning Rate: 0.015600000000000003\n",
      "Epoch: 16881, MSE: 0.23061054173813772, Learning Rate: 0.015595000000000005\n",
      "Epoch: 16882, MSE: 0.2306077183981309, Learning Rate: 0.015590000000000005\n",
      "Epoch: 16883, MSE: 0.23060489508919385, Learning Rate: 0.015585000000000005\n",
      "Epoch: 16884, MSE: 0.2306020718114035, Learning Rate: 0.015580000000000005\n",
      "Epoch: 16885, MSE: 0.23059924856483435, Learning Rate: 0.015575000000000006\n",
      "Epoch: 16886, MSE: 0.2305964253495632, Learning Rate: 0.015569999999999995\n",
      "Epoch: 16887, MSE: 0.23059360216566424, Learning Rate: 0.015564999999999996\n",
      "Epoch: 16888, MSE: 0.23059077901321637, Learning Rate: 0.015559999999999997\n",
      "Epoch: 16889, MSE: 0.23058795589229325, Learning Rate: 0.015554999999999998\n",
      "Epoch: 16890, MSE: 0.2305851328029709, Learning Rate: 0.015549999999999998\n",
      "Epoch: 16891, MSE: 0.23058230974532695, Learning Rate: 0.015544999999999998\n",
      "Epoch: 16892, MSE: 0.23057948671943734, Learning Rate: 0.015539999999999998\n",
      "Epoch: 16893, MSE: 0.23057666372537808, Learning Rate: 0.015535\n",
      "Epoch: 16894, MSE: 0.2305738407632268, Learning Rate: 0.01553\n",
      "Epoch: 16895, MSE: 0.23057101783305875, Learning Rate: 0.015525\n",
      "Epoch: 16896, MSE: 0.2305681949349521, Learning Rate: 0.01552\n",
      "Epoch: 16897, MSE: 0.2305653720689823, Learning Rate: 0.015515000000000001\n",
      "Epoch: 16898, MSE: 0.23056254923522757, Learning Rate: 0.015510000000000003\n",
      "Epoch: 16899, MSE: 0.2305597264337637, Learning Rate: 0.015505000000000003\n",
      "Epoch: 16900, MSE: 0.23055690366466972, Learning Rate: 0.015500000000000003\n",
      "Epoch: 16901, MSE: 0.23055408092802007, Learning Rate: 0.015495000000000004\n",
      "Epoch: 16902, MSE: 0.2305512582238955, Learning Rate: 0.015490000000000004\n",
      "Epoch: 16903, MSE: 0.23054843555237134, Learning Rate: 0.015485000000000006\n",
      "Epoch: 16904, MSE: 0.23054561291352532, Learning Rate: 0.015480000000000006\n",
      "Epoch: 16905, MSE: 0.2305427903074348, Learning Rate: 0.015475000000000006\n",
      "Epoch: 16906, MSE: 0.23053996773417842, Learning Rate: 0.015469999999999996\n",
      "Epoch: 16907, MSE: 0.23053714519383403, Learning Rate: 0.015464999999999996\n",
      "Epoch: 16908, MSE: 0.23053432268647914, Learning Rate: 0.015459999999999996\n",
      "Epoch: 16909, MSE: 0.23053150021219226, Learning Rate: 0.015454999999999997\n",
      "Epoch: 16910, MSE: 0.23052867777105057, Learning Rate: 0.015449999999999998\n",
      "Epoch: 16911, MSE: 0.2305258553631326, Learning Rate: 0.015444999999999999\n",
      "Epoch: 16912, MSE: 0.23052303298851826, Learning Rate: 0.015439999999999999\n",
      "Epoch: 16913, MSE: 0.23052021064728426, Learning Rate: 0.015434999999999999\n",
      "Epoch: 16914, MSE: 0.23051738833950974, Learning Rate: 0.01543\n",
      "Epoch: 16915, MSE: 0.23051456606527382, Learning Rate: 0.015425000000000001\n",
      "Epoch: 16916, MSE: 0.23051174382465445, Learning Rate: 0.015420000000000001\n",
      "Epoch: 16917, MSE: 0.2305089216177312, Learning Rate: 0.015415000000000002\n",
      "Epoch: 16918, MSE: 0.23050609944458256, Learning Rate: 0.015410000000000002\n",
      "Epoch: 16919, MSE: 0.23050327730528727, Learning Rate: 0.015405000000000002\n",
      "Epoch: 16920, MSE: 0.2305004551999253, Learning Rate: 0.015400000000000004\n",
      "Epoch: 16921, MSE: 0.23049763312857632, Learning Rate: 0.015395000000000004\n",
      "Epoch: 16922, MSE: 0.23049481109131803, Learning Rate: 0.015390000000000004\n",
      "Epoch: 16923, MSE: 0.2304919890882316, Learning Rate: 0.015385000000000005\n",
      "Epoch: 16924, MSE: 0.23048916711939535, Learning Rate: 0.015380000000000005\n",
      "Epoch: 16925, MSE: 0.23048634518489014, Learning Rate: 0.015375000000000007\n",
      "Epoch: 16926, MSE: 0.23048352328479488, Learning Rate: 0.015369999999999995\n",
      "Epoch: 16927, MSE: 0.23048070141919058, Learning Rate: 0.015364999999999997\n",
      "Epoch: 16928, MSE: 0.23047787958815527, Learning Rate: 0.015359999999999997\n",
      "Epoch: 16929, MSE: 0.2304750577917707, Learning Rate: 0.015354999999999997\n",
      "Epoch: 16930, MSE: 0.23047223603011707, Learning Rate: 0.015349999999999997\n",
      "Epoch: 16931, MSE: 0.23046941430327372, Learning Rate: 0.015344999999999998\n",
      "Epoch: 16932, MSE: 0.23046659261132174, Learning Rate: 0.01534\n",
      "Epoch: 16933, MSE: 0.23046377095434115, Learning Rate: 0.015335\n",
      "Epoch: 16934, MSE: 0.23046094933241387, Learning Rate: 0.01533\n",
      "Epoch: 16935, MSE: 0.23045812774561833, Learning Rate: 0.015325\n",
      "Epoch: 16936, MSE: 0.23045530619403765, Learning Rate: 0.01532\n",
      "Epoch: 16937, MSE: 0.23045248467775212, Learning Rate: 0.015315000000000002\n",
      "Epoch: 16938, MSE: 0.23044966319684212, Learning Rate: 0.015310000000000002\n",
      "Epoch: 16939, MSE: 0.23044684175138885, Learning Rate: 0.015305000000000003\n",
      "Epoch: 16940, MSE: 0.23044402034147413, Learning Rate: 0.015300000000000003\n",
      "Epoch: 16941, MSE: 0.23044119896718004, Learning Rate: 0.015295000000000003\n",
      "Epoch: 16942, MSE: 0.2304383776285866, Learning Rate: 0.015290000000000005\n",
      "Epoch: 16943, MSE: 0.23043555632577534, Learning Rate: 0.015285000000000005\n",
      "Epoch: 16944, MSE: 0.23043273505882866, Learning Rate: 0.015280000000000005\n",
      "Epoch: 16945, MSE: 0.23042991382782896, Learning Rate: 0.015275000000000006\n",
      "Epoch: 16946, MSE: 0.2304270926328566, Learning Rate: 0.015269999999999995\n",
      "Epoch: 16947, MSE: 0.2304242714739947, Learning Rate: 0.015264999999999996\n",
      "Epoch: 16948, MSE: 0.23042145035132497, Learning Rate: 0.015259999999999996\n",
      "Epoch: 16949, MSE: 0.23041862926493048, Learning Rate: 0.015254999999999998\n",
      "Epoch: 16950, MSE: 0.2304158082148923, Learning Rate: 0.015249999999999998\n",
      "Epoch: 16951, MSE: 0.23041298720129313, Learning Rate: 0.015244999999999998\n",
      "Epoch: 16952, MSE: 0.2304101662242155, Learning Rate: 0.015239999999999998\n",
      "Epoch: 16953, MSE: 0.2304073452837432, Learning Rate: 0.015234999999999999\n",
      "Epoch: 16954, MSE: 0.23040452437995773, Learning Rate: 0.01523\n",
      "Epoch: 16955, MSE: 0.23040170351294234, Learning Rate: 0.015225\n",
      "Epoch: 16956, MSE: 0.23039888268277964, Learning Rate: 0.015220000000000001\n",
      "Epoch: 16957, MSE: 0.23039606188955375, Learning Rate: 0.015215000000000001\n",
      "Epoch: 16958, MSE: 0.23039324113334647, Learning Rate: 0.015210000000000001\n",
      "Epoch: 16959, MSE: 0.23039042041424243, Learning Rate: 0.015205000000000003\n",
      "Epoch: 16960, MSE: 0.23038759973232334, Learning Rate: 0.015200000000000003\n",
      "Epoch: 16961, MSE: 0.23038477908767524, Learning Rate: 0.015195000000000004\n",
      "Epoch: 16962, MSE: 0.23038195848037996, Learning Rate: 0.015190000000000004\n",
      "Epoch: 16963, MSE: 0.2303791379105215, Learning Rate: 0.015185000000000004\n",
      "Epoch: 16964, MSE: 0.23037631737818348, Learning Rate: 0.015180000000000006\n",
      "Epoch: 16965, MSE: 0.2303734968834505, Learning Rate: 0.015175000000000006\n",
      "Epoch: 16966, MSE: 0.23037067642640593, Learning Rate: 0.015169999999999996\n",
      "Epoch: 16967, MSE: 0.23036785600713544, Learning Rate: 0.015164999999999996\n",
      "Epoch: 16968, MSE: 0.23036503562572053, Learning Rate: 0.015159999999999996\n",
      "Epoch: 16969, MSE: 0.23036221528224893, Learning Rate: 0.015154999999999997\n",
      "Epoch: 16970, MSE: 0.23035939497680305, Learning Rate: 0.015149999999999997\n",
      "Epoch: 16971, MSE: 0.23035657470946777, Learning Rate: 0.015144999999999999\n",
      "Epoch: 16972, MSE: 0.23035375448032783, Learning Rate: 0.015139999999999999\n",
      "Epoch: 16973, MSE: 0.23035093428946846, Learning Rate: 0.015135\n",
      "Epoch: 16974, MSE: 0.23034811413697465, Learning Rate: 0.01513\n",
      "Epoch: 16975, MSE: 0.23034529402293127, Learning Rate: 0.015125\n",
      "Epoch: 16976, MSE: 0.2303424739474233, Learning Rate: 0.015120000000000001\n",
      "Epoch: 16977, MSE: 0.23033965391053599, Learning Rate: 0.015115000000000002\n",
      "Epoch: 16978, MSE: 0.23033683391235565, Learning Rate: 0.015110000000000002\n",
      "Epoch: 16979, MSE: 0.230334013952967, Learning Rate: 0.015105000000000002\n",
      "Epoch: 16980, MSE: 0.23033119403245575, Learning Rate: 0.015100000000000002\n",
      "Epoch: 16981, MSE: 0.23032837415090762, Learning Rate: 0.015095000000000004\n",
      "Epoch: 16982, MSE: 0.2303255543084089, Learning Rate: 0.015090000000000004\n",
      "Epoch: 16983, MSE: 0.23032273450504503, Learning Rate: 0.015085000000000005\n",
      "Epoch: 16984, MSE: 0.23031991474090144, Learning Rate: 0.015080000000000005\n",
      "Epoch: 16985, MSE: 0.23031709501606604, Learning Rate: 0.015075000000000005\n",
      "Epoch: 16986, MSE: 0.23031427533062412, Learning Rate: 0.015069999999999995\n",
      "Epoch: 16987, MSE: 0.23031145568466224, Learning Rate: 0.015064999999999995\n",
      "Epoch: 16988, MSE: 0.230308636078267, Learning Rate: 0.015059999999999997\n",
      "Epoch: 16989, MSE: 0.23030581651152535, Learning Rate: 0.015054999999999997\n",
      "Epoch: 16990, MSE: 0.23030299698452297, Learning Rate: 0.015049999999999997\n",
      "Epoch: 16991, MSE: 0.23030017749734838, Learning Rate: 0.015044999999999998\n",
      "Epoch: 16992, MSE: 0.23029735805008686, Learning Rate: 0.015039999999999998\n",
      "Epoch: 16993, MSE: 0.2302945386428275, Learning Rate: 0.015035\n",
      "Epoch: 16994, MSE: 0.2302917192756554, Learning Rate: 0.01503\n",
      "Epoch: 16995, MSE: 0.23028889994865895, Learning Rate: 0.015025\n",
      "Epoch: 16996, MSE: 0.23028608066192566, Learning Rate: 0.01502\n",
      "Epoch: 16997, MSE: 0.23028326141554362, Learning Rate: 0.015015\n",
      "Epoch: 16998, MSE: 0.23028044220959967, Learning Rate: 0.015010000000000003\n",
      "Epoch: 16999, MSE: 0.23027762304418167, Learning Rate: 0.015005000000000003\n",
      "Epoch: 17000, MSE: 0.23027480391937774, Learning Rate: 0.015000000000000003\n",
      "Epoch: 17001, MSE: 0.23027198483527578, Learning Rate: 0.014995000000000003\n",
      "Epoch: 17002, MSE: 0.23026916579196446, Learning Rate: 0.014990000000000003\n",
      "Epoch: 17003, MSE: 0.23026634678953137, Learning Rate: 0.014985000000000005\n",
      "Epoch: 17004, MSE: 0.23026352782806567, Learning Rate: 0.014980000000000005\n",
      "Epoch: 17005, MSE: 0.23026070890765474, Learning Rate: 0.014975000000000006\n",
      "Epoch: 17006, MSE: 0.23025789002838895, Learning Rate: 0.014970000000000006\n",
      "Epoch: 17007, MSE: 0.2302550711903546, Learning Rate: 0.014964999999999996\n",
      "Epoch: 17008, MSE: 0.23025225239364241, Learning Rate: 0.014959999999999996\n",
      "Epoch: 17009, MSE: 0.23024943363834155, Learning Rate: 0.014954999999999996\n",
      "Epoch: 17010, MSE: 0.23024661492453985, Learning Rate: 0.014949999999999998\n",
      "Epoch: 17011, MSE: 0.23024379625232752, Learning Rate: 0.014944999999999998\n",
      "Epoch: 17012, MSE: 0.23024097762179335, Learning Rate: 0.014939999999999998\n",
      "Epoch: 17013, MSE: 0.23023815903302652, Learning Rate: 0.014934999999999999\n",
      "Epoch: 17014, MSE: 0.23023534048611743, Learning Rate: 0.014929999999999999\n",
      "Epoch: 17015, MSE: 0.230232521981156, Learning Rate: 0.014925\n",
      "Epoch: 17016, MSE: 0.23022970351823044, Learning Rate: 0.014920000000000001\n",
      "Epoch: 17017, MSE: 0.2302268850974323, Learning Rate: 0.014915000000000001\n",
      "Epoch: 17018, MSE: 0.23022406671885104, Learning Rate: 0.014910000000000001\n",
      "Epoch: 17019, MSE: 0.23022124838257696, Learning Rate: 0.014905000000000002\n",
      "Epoch: 17020, MSE: 0.23021843008869958, Learning Rate: 0.014900000000000004\n",
      "Epoch: 17021, MSE: 0.23021561183731024, Learning Rate: 0.014895000000000004\n",
      "Epoch: 17022, MSE: 0.23021279362849933, Learning Rate: 0.014890000000000004\n",
      "Epoch: 17023, MSE: 0.23020997546235691, Learning Rate: 0.014885000000000004\n",
      "Epoch: 17024, MSE: 0.2302071573389752, Learning Rate: 0.014880000000000004\n",
      "Epoch: 17025, MSE: 0.23020433925844322, Learning Rate: 0.014875000000000006\n",
      "Epoch: 17026, MSE: 0.2302015212208533, Learning Rate: 0.014870000000000006\n",
      "Epoch: 17027, MSE: 0.23019870322629596, Learning Rate: 0.014864999999999996\n",
      "Epoch: 17028, MSE: 0.23019588527486268, Learning Rate: 0.014859999999999996\n",
      "Epoch: 17029, MSE: 0.23019306736664474, Learning Rate: 0.014854999999999997\n",
      "Epoch: 17030, MSE: 0.23019024950173456, Learning Rate: 0.014849999999999997\n",
      "Epoch: 17031, MSE: 0.23018743168022202, Learning Rate: 0.014844999999999997\n",
      "Epoch: 17032, MSE: 0.23018461390219977, Learning Rate: 0.014839999999999999\n",
      "Epoch: 17033, MSE: 0.23018179616776002, Learning Rate: 0.014835\n",
      "Epoch: 17034, MSE: 0.23017897847699487, Learning Rate: 0.01483\n",
      "Epoch: 17035, MSE: 0.23017616082999626, Learning Rate: 0.014825\n",
      "Epoch: 17036, MSE: 0.2301733432268554, Learning Rate: 0.01482\n",
      "Epoch: 17037, MSE: 0.23017052566766602, Learning Rate: 0.014815000000000002\n",
      "Epoch: 17038, MSE: 0.23016770815251944, Learning Rate: 0.014810000000000002\n",
      "Epoch: 17039, MSE: 0.23016489068150997, Learning Rate: 0.014805000000000002\n",
      "Epoch: 17040, MSE: 0.2301620732547289, Learning Rate: 0.014800000000000002\n",
      "Epoch: 17041, MSE: 0.23015925587226935, Learning Rate: 0.014795000000000003\n",
      "Epoch: 17042, MSE: 0.23015643853422416, Learning Rate: 0.014790000000000005\n",
      "Epoch: 17043, MSE: 0.23015362124068786, Learning Rate: 0.014785000000000005\n",
      "Epoch: 17044, MSE: 0.23015080399175114, Learning Rate: 0.014780000000000005\n",
      "Epoch: 17045, MSE: 0.2301479867875097, Learning Rate: 0.014775000000000005\n",
      "Epoch: 17046, MSE: 0.23014516962805628, Learning Rate: 0.014770000000000005\n",
      "Epoch: 17047, MSE: 0.23014235251348394, Learning Rate: 0.014764999999999995\n",
      "Epoch: 17048, MSE: 0.230139535443887, Learning Rate: 0.014759999999999995\n",
      "Epoch: 17049, MSE: 0.23013671841935926, Learning Rate: 0.014754999999999997\n",
      "Epoch: 17050, MSE: 0.23013390143999501, Learning Rate: 0.014749999999999997\n",
      "Epoch: 17051, MSE: 0.23013108450588762, Learning Rate: 0.014744999999999998\n",
      "Epoch: 17052, MSE: 0.23012826761713154, Learning Rate: 0.014739999999999998\n",
      "Epoch: 17053, MSE: 0.23012545077382204, Learning Rate: 0.014734999999999998\n",
      "Epoch: 17054, MSE: 0.23012263397605232, Learning Rate: 0.01473\n",
      "Epoch: 17055, MSE: 0.23011981722391792, Learning Rate: 0.014725\n",
      "Epoch: 17056, MSE: 0.23011700051751355, Learning Rate: 0.01472\n",
      "Epoch: 17057, MSE: 0.23011418385693316, Learning Rate: 0.014715\n",
      "Epoch: 17058, MSE: 0.23011136724227277, Learning Rate: 0.01471\n",
      "Epoch: 17059, MSE: 0.23010855067362726, Learning Rate: 0.014705000000000003\n",
      "Epoch: 17060, MSE: 0.23010573415109248, Learning Rate: 0.014700000000000003\n",
      "Epoch: 17061, MSE: 0.23010291767476215, Learning Rate: 0.014695000000000003\n",
      "Epoch: 17062, MSE: 0.23010010124473337, Learning Rate: 0.014690000000000003\n",
      "Epoch: 17063, MSE: 0.2300972848611021, Learning Rate: 0.014685000000000004\n",
      "Epoch: 17064, MSE: 0.2300944685239623, Learning Rate: 0.014680000000000006\n",
      "Epoch: 17065, MSE: 0.2300916522334113, Learning Rate: 0.014675000000000006\n",
      "Epoch: 17066, MSE: 0.23008883598954485, Learning Rate: 0.014670000000000006\n",
      "Epoch: 17067, MSE: 0.23008601979245866, Learning Rate: 0.014664999999999996\n",
      "Epoch: 17068, MSE: 0.23008320364224938, Learning Rate: 0.014659999999999996\n",
      "Epoch: 17069, MSE: 0.23008038753901439, Learning Rate: 0.014654999999999996\n",
      "Epoch: 17070, MSE: 0.2300775714828488, Learning Rate: 0.014649999999999996\n",
      "Epoch: 17071, MSE: 0.23007475547384984, Learning Rate: 0.014644999999999998\n",
      "Epoch: 17072, MSE: 0.23007193951211494, Learning Rate: 0.014639999999999999\n",
      "Epoch: 17073, MSE: 0.23006912359773993, Learning Rate: 0.014634999999999999\n",
      "Epoch: 17074, MSE: 0.2300663077308221, Learning Rate: 0.014629999999999999\n",
      "Epoch: 17075, MSE: 0.23006349191145986, Learning Rate: 0.014624999999999999\n",
      "Epoch: 17076, MSE: 0.23006067613974965, Learning Rate: 0.014620000000000001\n",
      "Epoch: 17077, MSE: 0.23005786041578888, Learning Rate: 0.014615000000000001\n",
      "Epoch: 17078, MSE: 0.23005504473967528, Learning Rate: 0.014610000000000001\n",
      "Epoch: 17079, MSE: 0.2300522291115066, Learning Rate: 0.014605000000000002\n",
      "Epoch: 17080, MSE: 0.23004941353138142, Learning Rate: 0.014600000000000002\n",
      "Epoch: 17081, MSE: 0.23004659799939717, Learning Rate: 0.014595000000000004\n",
      "Epoch: 17082, MSE: 0.23004378251565197, Learning Rate: 0.014590000000000004\n",
      "Epoch: 17083, MSE: 0.23004096708024405, Learning Rate: 0.014585000000000004\n",
      "Epoch: 17084, MSE: 0.23003815169327174, Learning Rate: 0.014580000000000004\n",
      "Epoch: 17085, MSE: 0.23003533635483392, Learning Rate: 0.014575000000000005\n",
      "Epoch: 17086, MSE: 0.23003252106502867, Learning Rate: 0.014570000000000007\n",
      "Epoch: 17087, MSE: 0.23002970582395565, Learning Rate: 0.014564999999999995\n",
      "Epoch: 17088, MSE: 0.23002689063171453, Learning Rate: 0.014559999999999997\n",
      "Epoch: 17089, MSE: 0.23002407548840217, Learning Rate: 0.014554999999999997\n",
      "Epoch: 17090, MSE: 0.23002126039411916, Learning Rate: 0.014549999999999997\n",
      "Epoch: 17091, MSE: 0.23001844534896512, Learning Rate: 0.014544999999999997\n",
      "Epoch: 17092, MSE: 0.23001563035303804, Learning Rate: 0.014539999999999997\n",
      "Epoch: 17093, MSE: 0.2300128154064396, Learning Rate: 0.014535\n",
      "Epoch: 17094, MSE: 0.23001000050926879, Learning Rate: 0.01453\n",
      "Epoch: 17095, MSE: 0.2300071856616254, Learning Rate: 0.014525\n",
      "Epoch: 17096, MSE: 0.2300043708636082, Learning Rate: 0.01452\n",
      "Epoch: 17097, MSE: 0.23000155611532033, Learning Rate: 0.014515\n",
      "Epoch: 17098, MSE: 0.22999874141685842, Learning Rate: 0.014510000000000002\n",
      "Epoch: 17099, MSE: 0.22999592676832686, Learning Rate: 0.014505000000000002\n",
      "Epoch: 17100, MSE: 0.22999311216982313, Learning Rate: 0.014500000000000002\n",
      "Epoch: 17101, MSE: 0.22999029762144896, Learning Rate: 0.014495000000000003\n",
      "Epoch: 17102, MSE: 0.2299874831233057, Learning Rate: 0.014490000000000003\n",
      "Epoch: 17103, MSE: 0.22998466867549416, Learning Rate: 0.014485000000000005\n",
      "Epoch: 17104, MSE: 0.2299818542781149, Learning Rate: 0.014480000000000005\n",
      "Epoch: 17105, MSE: 0.22997903993127045, Learning Rate: 0.014475000000000005\n",
      "Epoch: 17106, MSE: 0.2299762256350605, Learning Rate: 0.014470000000000005\n",
      "Epoch: 17107, MSE: 0.2299734113895882, Learning Rate: 0.014464999999999995\n",
      "Epoch: 17108, MSE: 0.22997059719495416, Learning Rate: 0.014459999999999995\n",
      "Epoch: 17109, MSE: 0.22996778305126062, Learning Rate: 0.014454999999999996\n",
      "Epoch: 17110, MSE: 0.2299649689586103, Learning Rate: 0.014449999999999998\n",
      "Epoch: 17111, MSE: 0.2299621549171037, Learning Rate: 0.014444999999999998\n",
      "Epoch: 17112, MSE: 0.22995934092684436, Learning Rate: 0.014439999999999998\n",
      "Epoch: 17113, MSE: 0.2299565269879345, Learning Rate: 0.014434999999999998\n",
      "Epoch: 17114, MSE: 0.22995371310047585, Learning Rate: 0.014429999999999998\n",
      "Epoch: 17115, MSE: 0.2299508992645723, Learning Rate: 0.014425\n",
      "Epoch: 17116, MSE: 0.22994808548032564, Learning Rate: 0.01442\n",
      "Epoch: 17117, MSE: 0.2299452717478398, Learning Rate: 0.014415\n",
      "Epoch: 17118, MSE: 0.22994245806721786, Learning Rate: 0.014410000000000001\n",
      "Epoch: 17119, MSE: 0.22993964443856138, Learning Rate: 0.014405000000000001\n",
      "Epoch: 17120, MSE: 0.22993683086197542, Learning Rate: 0.014400000000000003\n",
      "Epoch: 17121, MSE: 0.22993401733756297, Learning Rate: 0.014395000000000003\n",
      "Epoch: 17122, MSE: 0.22993120386542834, Learning Rate: 0.014390000000000003\n",
      "Epoch: 17123, MSE: 0.2299283904456739, Learning Rate: 0.014385000000000004\n",
      "Epoch: 17124, MSE: 0.22992557707840508, Learning Rate: 0.014380000000000004\n",
      "Epoch: 17125, MSE: 0.22992276376372506, Learning Rate: 0.014375000000000006\n",
      "Epoch: 17126, MSE: 0.2299199505017389, Learning Rate: 0.014370000000000006\n",
      "Epoch: 17127, MSE: 0.22991713729254992, Learning Rate: 0.014365000000000006\n",
      "Epoch: 17128, MSE: 0.22991432413626392, Learning Rate: 0.014359999999999996\n",
      "Epoch: 17129, MSE: 0.2299115110329847, Learning Rate: 0.014354999999999996\n",
      "Epoch: 17130, MSE: 0.22990869798281702, Learning Rate: 0.014349999999999996\n",
      "Epoch: 17131, MSE: 0.2299058849858661, Learning Rate: 0.014344999999999997\n",
      "Epoch: 17132, MSE: 0.22990307204223773, Learning Rate: 0.014339999999999999\n",
      "Epoch: 17133, MSE: 0.22990025915203505, Learning Rate: 0.014334999999999999\n",
      "Epoch: 17134, MSE: 0.2298974463153667, Learning Rate: 0.014329999999999999\n",
      "Epoch: 17135, MSE: 0.22989463353233575, Learning Rate: 0.014325\n",
      "Epoch: 17136, MSE: 0.2298918208030485, Learning Rate: 0.01432\n",
      "Epoch: 17137, MSE: 0.22988900812761134, Learning Rate: 0.014315000000000001\n",
      "Epoch: 17138, MSE: 0.22988619550612904, Learning Rate: 0.014310000000000002\n",
      "Epoch: 17139, MSE: 0.22988338293870936, Learning Rate: 0.014305000000000002\n",
      "Epoch: 17140, MSE: 0.22988057042545718, Learning Rate: 0.014300000000000002\n",
      "Epoch: 17141, MSE: 0.22987775796647944, Learning Rate: 0.014295000000000002\n",
      "Epoch: 17142, MSE: 0.22987494556188356, Learning Rate: 0.014290000000000004\n",
      "Epoch: 17143, MSE: 0.2298721332117742, Learning Rate: 0.014285000000000004\n",
      "Epoch: 17144, MSE: 0.22986932091626092, Learning Rate: 0.014280000000000004\n",
      "Epoch: 17145, MSE: 0.22986650867544844, Learning Rate: 0.014275000000000005\n",
      "Epoch: 17146, MSE: 0.2298636964894451, Learning Rate: 0.014270000000000005\n",
      "Epoch: 17147, MSE: 0.22986088435835852, Learning Rate: 0.014265000000000007\n",
      "Epoch: 17148, MSE: 0.22985807228229466, Learning Rate: 0.014259999999999995\n",
      "Epoch: 17149, MSE: 0.22985526026136238, Learning Rate: 0.014254999999999997\n",
      "Epoch: 17150, MSE: 0.229852448295669, Learning Rate: 0.014249999999999997\n",
      "Epoch: 17151, MSE: 0.22984963638532227, Learning Rate: 0.014244999999999997\n",
      "Epoch: 17152, MSE: 0.22984682453043134, Learning Rate: 0.014239999999999997\n",
      "Epoch: 17153, MSE: 0.22984401273110294, Learning Rate: 0.014234999999999998\n",
      "Epoch: 17154, MSE: 0.2298412009874467, Learning Rate: 0.01423\n",
      "Epoch: 17155, MSE: 0.22983838929957043, Learning Rate: 0.014225\n",
      "Epoch: 17156, MSE: 0.22983557766758303, Learning Rate: 0.01422\n",
      "Epoch: 17157, MSE: 0.22983276609159334, Learning Rate: 0.014215\n",
      "Epoch: 17158, MSE: 0.22982995457170932, Learning Rate: 0.01421\n",
      "Epoch: 17159, MSE: 0.22982714310804214, Learning Rate: 0.014205000000000002\n",
      "Epoch: 17160, MSE: 0.2298243317006996, Learning Rate: 0.014200000000000003\n",
      "Epoch: 17161, MSE: 0.22982152034979045, Learning Rate: 0.014195000000000003\n",
      "Epoch: 17162, MSE: 0.22981870905542637, Learning Rate: 0.014190000000000003\n",
      "Epoch: 17163, MSE: 0.22981589781771583, Learning Rate: 0.014185000000000003\n",
      "Epoch: 17164, MSE: 0.2298130866367687, Learning Rate: 0.014180000000000005\n",
      "Epoch: 17165, MSE: 0.22981027551269603, Learning Rate: 0.014175000000000005\n",
      "Epoch: 17166, MSE: 0.22980746444560604, Learning Rate: 0.014170000000000006\n",
      "Epoch: 17167, MSE: 0.2298046534356103, Learning Rate: 0.014165000000000006\n",
      "Epoch: 17168, MSE: 0.22980184248281985, Learning Rate: 0.014159999999999996\n",
      "Epoch: 17169, MSE: 0.22979903158734458, Learning Rate: 0.014154999999999996\n",
      "Epoch: 17170, MSE: 0.22979622074929545, Learning Rate: 0.014149999999999996\n",
      "Epoch: 17171, MSE: 0.22979340996878364, Learning Rate: 0.014144999999999998\n",
      "Epoch: 17172, MSE: 0.22979059924591977, Learning Rate: 0.014139999999999998\n",
      "Epoch: 17173, MSE: 0.22978778858081533, Learning Rate: 0.014134999999999998\n",
      "Epoch: 17174, MSE: 0.22978497797358147, Learning Rate: 0.014129999999999998\n",
      "Epoch: 17175, MSE: 0.22978216742433058, Learning Rate: 0.014124999999999999\n",
      "Epoch: 17176, MSE: 0.22977935693317447, Learning Rate: 0.01412\n",
      "Epoch: 17177, MSE: 0.2297765465002239, Learning Rate: 0.014115\n",
      "Epoch: 17178, MSE: 0.229773736125592, Learning Rate: 0.014110000000000001\n",
      "Epoch: 17179, MSE: 0.22977092580939007, Learning Rate: 0.014105000000000001\n",
      "Epoch: 17180, MSE: 0.2297681155517305, Learning Rate: 0.014100000000000001\n",
      "Epoch: 17181, MSE: 0.2297653053527268, Learning Rate: 0.014095000000000003\n",
      "Epoch: 17182, MSE: 0.2297624952124919, Learning Rate: 0.014090000000000004\n",
      "Epoch: 17183, MSE: 0.22975968513113704, Learning Rate: 0.014085000000000004\n",
      "Epoch: 17184, MSE: 0.22975687510877588, Learning Rate: 0.014080000000000004\n",
      "Epoch: 17185, MSE: 0.2297540651455224, Learning Rate: 0.014075000000000004\n",
      "Epoch: 17186, MSE: 0.2297512552414886, Learning Rate: 0.014070000000000006\n",
      "Epoch: 17187, MSE: 0.22974844539678888, Learning Rate: 0.014065000000000006\n",
      "Epoch: 17188, MSE: 0.22974563561153685, Learning Rate: 0.014059999999999996\n",
      "Epoch: 17189, MSE: 0.22974282588584624, Learning Rate: 0.014054999999999996\n",
      "Epoch: 17190, MSE: 0.22974001621983098, Learning Rate: 0.014049999999999997\n",
      "Epoch: 17191, MSE: 0.22973720661360444, Learning Rate: 0.014044999999999997\n",
      "Epoch: 17192, MSE: 0.22973439706728185, Learning Rate: 0.014039999999999997\n",
      "Epoch: 17193, MSE: 0.22973158758097775, Learning Rate: 0.014034999999999999\n",
      "Epoch: 17194, MSE: 0.22972877815480539, Learning Rate: 0.014029999999999999\n",
      "Epoch: 17195, MSE: 0.22972596878888063, Learning Rate: 0.014025\n",
      "Epoch: 17196, MSE: 0.22972315948331873, Learning Rate: 0.01402\n",
      "Epoch: 17197, MSE: 0.22972035023823445, Learning Rate: 0.014015\n",
      "Epoch: 17198, MSE: 0.22971754105374234, Learning Rate: 0.014010000000000002\n",
      "Epoch: 17199, MSE: 0.22971473192995903, Learning Rate: 0.014005000000000002\n",
      "Epoch: 17200, MSE: 0.22971192286699882, Learning Rate: 0.014000000000000002\n",
      "Epoch: 17201, MSE: 0.229709113864978, Learning Rate: 0.013995000000000002\n",
      "Epoch: 17202, MSE: 0.22970630492401223, Learning Rate: 0.013990000000000002\n",
      "Epoch: 17203, MSE: 0.22970349604421827, Learning Rate: 0.013985000000000004\n",
      "Epoch: 17204, MSE: 0.2297006872257126, Learning Rate: 0.013980000000000005\n",
      "Epoch: 17205, MSE: 0.22969787846861023, Learning Rate: 0.013975000000000005\n",
      "Epoch: 17206, MSE: 0.2296950697730283, Learning Rate: 0.013970000000000005\n",
      "Epoch: 17207, MSE: 0.2296922611390846, Learning Rate: 0.013965000000000005\n",
      "Epoch: 17208, MSE: 0.22968945256689374, Learning Rate: 0.013959999999999995\n",
      "Epoch: 17209, MSE: 0.22968664405657496, Learning Rate: 0.013954999999999995\n",
      "Epoch: 17210, MSE: 0.22968383560824462, Learning Rate: 0.013949999999999997\n",
      "Epoch: 17211, MSE: 0.2296810272220199, Learning Rate: 0.013944999999999997\n",
      "Epoch: 17212, MSE: 0.22967821889801848, Learning Rate: 0.013939999999999998\n",
      "Epoch: 17213, MSE: 0.22967541063635866, Learning Rate: 0.013934999999999998\n",
      "Epoch: 17214, MSE: 0.22967260243715823, Learning Rate: 0.013929999999999998\n",
      "Epoch: 17215, MSE: 0.22966979430053427, Learning Rate: 0.013925\n",
      "Epoch: 17216, MSE: 0.22966698622660517, Learning Rate: 0.01392\n",
      "Epoch: 17217, MSE: 0.22966417821549018, Learning Rate: 0.013915\n",
      "Epoch: 17218, MSE: 0.22966137026730724, Learning Rate: 0.01391\n",
      "Epoch: 17219, MSE: 0.22965856238217536, Learning Rate: 0.013905\n",
      "Epoch: 17220, MSE: 0.22965575456021392, Learning Rate: 0.013900000000000003\n",
      "Epoch: 17221, MSE: 0.2296529468015407, Learning Rate: 0.013895000000000003\n",
      "Epoch: 17222, MSE: 0.2296501391062756, Learning Rate: 0.013890000000000003\n",
      "Epoch: 17223, MSE: 0.2296473314745378, Learning Rate: 0.013885000000000003\n",
      "Epoch: 17224, MSE: 0.2296445239064475, Learning Rate: 0.013880000000000003\n",
      "Epoch: 17225, MSE: 0.2296417164021242, Learning Rate: 0.013875000000000005\n",
      "Epoch: 17226, MSE: 0.22963890896168732, Learning Rate: 0.013870000000000006\n",
      "Epoch: 17227, MSE: 0.2296361015852583, Learning Rate: 0.013865000000000006\n",
      "Epoch: 17228, MSE: 0.22963329427295506, Learning Rate: 0.013859999999999996\n",
      "Epoch: 17229, MSE: 0.22963048702489985, Learning Rate: 0.013854999999999996\n",
      "Epoch: 17230, MSE: 0.22962767984121285, Learning Rate: 0.013849999999999996\n",
      "Epoch: 17231, MSE: 0.22962487272201432, Learning Rate: 0.013844999999999996\n",
      "Epoch: 17232, MSE: 0.22962206566742546, Learning Rate: 0.013839999999999998\n",
      "Epoch: 17233, MSE: 0.22961925867756788, Learning Rate: 0.013834999999999998\n",
      "Epoch: 17234, MSE: 0.22961645175256273, Learning Rate: 0.013829999999999999\n",
      "Epoch: 17235, MSE: 0.22961364489253125, Learning Rate: 0.013824999999999999\n",
      "Epoch: 17236, MSE: 0.22961083809759403, Learning Rate: 0.013819999999999999\n",
      "Epoch: 17237, MSE: 0.22960803136787516, Learning Rate: 0.013815000000000001\n",
      "Epoch: 17238, MSE: 0.2296052247034952, Learning Rate: 0.013810000000000001\n",
      "Epoch: 17239, MSE: 0.2296024181045761, Learning Rate: 0.013805000000000001\n",
      "Epoch: 17240, MSE: 0.22959961157124031, Learning Rate: 0.013800000000000002\n",
      "Epoch: 17241, MSE: 0.22959680510361102, Learning Rate: 0.013795000000000002\n",
      "Epoch: 17242, MSE: 0.22959399870180974, Learning Rate: 0.013790000000000004\n",
      "Epoch: 17243, MSE: 0.22959119236596082, Learning Rate: 0.013785000000000004\n",
      "Epoch: 17244, MSE: 0.2295883860961864, Learning Rate: 0.013780000000000004\n",
      "Epoch: 17245, MSE: 0.22958557989261028, Learning Rate: 0.013775000000000004\n",
      "Epoch: 17246, MSE: 0.22958277375535374, Learning Rate: 0.013770000000000004\n",
      "Epoch: 17247, MSE: 0.2295799676845428, Learning Rate: 0.013765000000000006\n",
      "Epoch: 17248, MSE: 0.22957716168030085, Learning Rate: 0.013759999999999994\n",
      "Epoch: 17249, MSE: 0.229574355742751, Learning Rate: 0.013754999999999996\n",
      "Epoch: 17250, MSE: 0.22957154987201728, Learning Rate: 0.013749999999999997\n",
      "Epoch: 17251, MSE: 0.2295687440682239, Learning Rate: 0.013744999999999997\n",
      "Epoch: 17252, MSE: 0.2295659383314965, Learning Rate: 0.013739999999999997\n",
      "Epoch: 17253, MSE: 0.22956313266195957, Learning Rate: 0.013734999999999997\n",
      "Epoch: 17254, MSE: 0.2295603270597362, Learning Rate: 0.01373\n",
      "Epoch: 17255, MSE: 0.22955752152495235, Learning Rate: 0.013725\n",
      "Epoch: 17256, MSE: 0.22955471605773362, Learning Rate: 0.01372\n",
      "Epoch: 17257, MSE: 0.22955191065820454, Learning Rate: 0.013715\n",
      "Epoch: 17258, MSE: 0.22954910532649173, Learning Rate: 0.01371\n",
      "Epoch: 17259, MSE: 0.22954630006271978, Learning Rate: 0.013705000000000002\n",
      "Epoch: 17260, MSE: 0.2295434948670154, Learning Rate: 0.013700000000000002\n",
      "Epoch: 17261, MSE: 0.2295406897395044, Learning Rate: 0.013695000000000002\n",
      "Epoch: 17262, MSE: 0.22953788468031242, Learning Rate: 0.013690000000000003\n",
      "Epoch: 17263, MSE: 0.2295350796895662, Learning Rate: 0.013685000000000003\n",
      "Epoch: 17264, MSE: 0.22953227476739294, Learning Rate: 0.013680000000000005\n",
      "Epoch: 17265, MSE: 0.22952946991391923, Learning Rate: 0.013675000000000005\n",
      "Epoch: 17266, MSE: 0.229526665129271, Learning Rate: 0.013670000000000005\n",
      "Epoch: 17267, MSE: 0.22952386041357697, Learning Rate: 0.013665000000000005\n",
      "Epoch: 17268, MSE: 0.22952105576696366, Learning Rate: 0.013660000000000005\n",
      "Epoch: 17269, MSE: 0.229518251189558, Learning Rate: 0.013654999999999995\n",
      "Epoch: 17270, MSE: 0.22951544668148913, Learning Rate: 0.013649999999999995\n",
      "Epoch: 17271, MSE: 0.2295126422428842, Learning Rate: 0.013644999999999997\n",
      "Epoch: 17272, MSE: 0.22950983787387094, Learning Rate: 0.013639999999999998\n",
      "Epoch: 17273, MSE: 0.22950703357457844, Learning Rate: 0.013634999999999998\n",
      "Epoch: 17274, MSE: 0.22950422934513384, Learning Rate: 0.013629999999999998\n",
      "Epoch: 17275, MSE: 0.2295014251856667, Learning Rate: 0.013624999999999998\n",
      "Epoch: 17276, MSE: 0.22949862109630592, Learning Rate: 0.01362\n",
      "Epoch: 17277, MSE: 0.22949581707718084, Learning Rate: 0.013615\n",
      "Epoch: 17278, MSE: 0.22949301312841897, Learning Rate: 0.01361\n",
      "Epoch: 17279, MSE: 0.22949020925015198, Learning Rate: 0.013605\n",
      "Epoch: 17280, MSE: 0.22948740544250829, Learning Rate: 0.013600000000000001\n",
      "Epoch: 17281, MSE: 0.229484601705617, Learning Rate: 0.013595000000000003\n",
      "Epoch: 17282, MSE: 0.22948179803960825, Learning Rate: 0.013590000000000003\n",
      "Epoch: 17283, MSE: 0.2294789944446132, Learning Rate: 0.013585000000000003\n",
      "Epoch: 17284, MSE: 0.2294761909207616, Learning Rate: 0.013580000000000004\n",
      "Epoch: 17285, MSE: 0.2294733874681841, Learning Rate: 0.013575000000000004\n",
      "Epoch: 17286, MSE: 0.22947058408701104, Learning Rate: 0.013570000000000006\n",
      "Epoch: 17287, MSE: 0.22946778077737345, Learning Rate: 0.013565000000000006\n",
      "Epoch: 17288, MSE: 0.2294649775394028, Learning Rate: 0.013560000000000006\n",
      "Epoch: 17289, MSE: 0.22946217437322952, Learning Rate: 0.013554999999999996\n",
      "Epoch: 17290, MSE: 0.22945937127898605, Learning Rate: 0.013549999999999996\n",
      "Epoch: 17291, MSE: 0.22945656825680336, Learning Rate: 0.013544999999999996\n",
      "Epoch: 17292, MSE: 0.2294537653068132, Learning Rate: 0.013539999999999996\n",
      "Epoch: 17293, MSE: 0.22945096242914856, Learning Rate: 0.013534999999999998\n",
      "Epoch: 17294, MSE: 0.22944815962394075, Learning Rate: 0.013529999999999999\n",
      "Epoch: 17295, MSE: 0.2294453568913215, Learning Rate: 0.013524999999999999\n",
      "Epoch: 17296, MSE: 0.2294425542314251, Learning Rate: 0.013519999999999999\n",
      "Epoch: 17297, MSE: 0.22943975164438307, Learning Rate: 0.013515\n",
      "Epoch: 17298, MSE: 0.22943694913032975, Learning Rate: 0.013510000000000001\n",
      "Epoch: 17299, MSE: 0.22943414668939688, Learning Rate: 0.013505000000000001\n",
      "Epoch: 17300, MSE: 0.2294313443217182, Learning Rate: 0.013500000000000002\n",
      "Epoch: 17301, MSE: 0.22942854202742827, Learning Rate: 0.013495000000000002\n",
      "Epoch: 17302, MSE: 0.22942573980665976, Learning Rate: 0.013490000000000002\n",
      "Epoch: 17303, MSE: 0.22942293765954636, Learning Rate: 0.013485000000000004\n",
      "Epoch: 17304, MSE: 0.22942013558622432, Learning Rate: 0.013480000000000004\n",
      "Epoch: 17305, MSE: 0.22941733358682512, Learning Rate: 0.013475000000000004\n",
      "Epoch: 17306, MSE: 0.22941453166148554, Learning Rate: 0.013470000000000005\n",
      "Epoch: 17307, MSE: 0.22941172981033894, Learning Rate: 0.013465000000000005\n",
      "Epoch: 17308, MSE: 0.2294089280335211, Learning Rate: 0.013460000000000007\n",
      "Epoch: 17309, MSE: 0.2294061263311673, Learning Rate: 0.013454999999999995\n",
      "Epoch: 17310, MSE: 0.22940332470341188, Learning Rate: 0.013449999999999997\n",
      "Epoch: 17311, MSE: 0.22940052315039136, Learning Rate: 0.013444999999999997\n",
      "Epoch: 17312, MSE: 0.22939772167224023, Learning Rate: 0.013439999999999997\n",
      "Epoch: 17313, MSE: 0.22939492026909597, Learning Rate: 0.013434999999999997\n",
      "Epoch: 17314, MSE: 0.229392118941094, Learning Rate: 0.013429999999999997\n",
      "Epoch: 17315, MSE: 0.22938931768837054, Learning Rate: 0.013425\n",
      "Epoch: 17316, MSE: 0.22938651651106234, Learning Rate: 0.01342\n",
      "Epoch: 17317, MSE: 0.22938371540930677, Learning Rate: 0.013415\n",
      "Epoch: 17318, MSE: 0.22938091438323902, Learning Rate: 0.01341\n",
      "Epoch: 17319, MSE: 0.22937811343299758, Learning Rate: 0.013405\n",
      "Epoch: 17320, MSE: 0.22937531255871987, Learning Rate: 0.013400000000000002\n",
      "Epoch: 17321, MSE: 0.2293725117605419, Learning Rate: 0.013395000000000002\n",
      "Epoch: 17322, MSE: 0.2293697110386039, Learning Rate: 0.013390000000000003\n",
      "Epoch: 17323, MSE: 0.22936691039304158, Learning Rate: 0.013385000000000003\n",
      "Epoch: 17324, MSE: 0.22936410982399405, Learning Rate: 0.013380000000000003\n",
      "Epoch: 17325, MSE: 0.229361309331599, Learning Rate: 0.013375000000000005\n",
      "Epoch: 17326, MSE: 0.2293585089159965, Learning Rate: 0.013370000000000005\n",
      "Epoch: 17327, MSE: 0.2293557085773231, Learning Rate: 0.013365000000000005\n",
      "Epoch: 17328, MSE: 0.22935290831572014, Learning Rate: 0.013360000000000006\n",
      "Epoch: 17329, MSE: 0.22935010813132484, Learning Rate: 0.013354999999999995\n",
      "Epoch: 17330, MSE: 0.22934730802427786, Learning Rate: 0.013349999999999996\n",
      "Epoch: 17331, MSE: 0.22934450799471748, Learning Rate: 0.013344999999999996\n",
      "Epoch: 17332, MSE: 0.22934170804278486, Learning Rate: 0.013339999999999998\n",
      "Epoch: 17333, MSE: 0.2293389081686194, Learning Rate: 0.013334999999999998\n",
      "Epoch: 17334, MSE: 0.22933610837236063, Learning Rate: 0.013329999999999998\n",
      "Epoch: 17335, MSE: 0.2293333086541497, Learning Rate: 0.013324999999999998\n",
      "Epoch: 17336, MSE: 0.2293305090141274, Learning Rate: 0.013319999999999999\n",
      "Epoch: 17337, MSE: 0.22932770945243378, Learning Rate: 0.013315\n",
      "Epoch: 17338, MSE: 0.2293249099692104, Learning Rate: 0.01331\n",
      "Epoch: 17339, MSE: 0.2293221105645985, Learning Rate: 0.013305\n",
      "Epoch: 17340, MSE: 0.22931931123873892, Learning Rate: 0.013300000000000001\n",
      "Epoch: 17341, MSE: 0.22931651199177425, Learning Rate: 0.013295000000000001\n",
      "Epoch: 17342, MSE: 0.22931371282384463, Learning Rate: 0.013290000000000003\n",
      "Epoch: 17343, MSE: 0.22931091373509443, Learning Rate: 0.013285000000000003\n",
      "Epoch: 17344, MSE: 0.22930811472566515, Learning Rate: 0.013280000000000004\n",
      "Epoch: 17345, MSE: 0.2293053157956975, Learning Rate: 0.013275000000000004\n",
      "Epoch: 17346, MSE: 0.229302516945337, Learning Rate: 0.013270000000000004\n",
      "Epoch: 17347, MSE: 0.229299718174724, Learning Rate: 0.013265000000000006\n",
      "Epoch: 17348, MSE: 0.22929691948400302, Learning Rate: 0.013260000000000006\n",
      "Epoch: 17349, MSE: 0.22929412087331727, Learning Rate: 0.013254999999999996\n",
      "Epoch: 17350, MSE: 0.2292913223428099, Learning Rate: 0.013249999999999996\n",
      "Epoch: 17351, MSE: 0.2292885238926251, Learning Rate: 0.013244999999999996\n",
      "Epoch: 17352, MSE: 0.22928572552290616, Learning Rate: 0.013239999999999997\n",
      "Epoch: 17353, MSE: 0.2292829272337977, Learning Rate: 0.013234999999999997\n",
      "Epoch: 17354, MSE: 0.2292801290254444, Learning Rate: 0.013229999999999999\n",
      "Epoch: 17355, MSE: 0.22927733089799066, Learning Rate: 0.013224999999999999\n",
      "Epoch: 17356, MSE: 0.22927453285158025, Learning Rate: 0.013219999999999999\n",
      "Epoch: 17357, MSE: 0.22927173488636016, Learning Rate: 0.013215\n",
      "Epoch: 17358, MSE: 0.22926893700247422, Learning Rate: 0.01321\n",
      "Epoch: 17359, MSE: 0.2292661392000684, Learning Rate: 0.013205000000000001\n",
      "Epoch: 17360, MSE: 0.22926334147928784, Learning Rate: 0.013200000000000002\n",
      "Epoch: 17361, MSE: 0.22926054384027858, Learning Rate: 0.013195000000000002\n",
      "Epoch: 17362, MSE: 0.22925774628318765, Learning Rate: 0.013190000000000002\n",
      "Epoch: 17363, MSE: 0.2292549488081609, Learning Rate: 0.013185000000000002\n",
      "Epoch: 17364, MSE: 0.22925215141534397, Learning Rate: 0.013180000000000004\n",
      "Epoch: 17365, MSE: 0.2292493541048848, Learning Rate: 0.013175000000000004\n",
      "Epoch: 17366, MSE: 0.22924655687692957, Learning Rate: 0.013170000000000005\n",
      "Epoch: 17367, MSE: 0.2292437597316259, Learning Rate: 0.013165000000000005\n",
      "Epoch: 17368, MSE: 0.22924096266912117, Learning Rate: 0.013160000000000005\n",
      "Epoch: 17369, MSE: 0.22923816568956332, Learning Rate: 0.013154999999999995\n",
      "Epoch: 17370, MSE: 0.2292353687930992, Learning Rate: 0.013149999999999995\n",
      "Epoch: 17371, MSE: 0.22923257197987773, Learning Rate: 0.013144999999999997\n",
      "Epoch: 17372, MSE: 0.22922977525004717, Learning Rate: 0.013139999999999997\n",
      "Epoch: 17373, MSE: 0.22922697860375582, Learning Rate: 0.013134999999999997\n",
      "Epoch: 17374, MSE: 0.22922418204115244, Learning Rate: 0.013129999999999998\n",
      "Epoch: 17375, MSE: 0.2292213855623854, Learning Rate: 0.013124999999999998\n",
      "Epoch: 17376, MSE: 0.22921858916760532, Learning Rate: 0.01312\n",
      "Epoch: 17377, MSE: 0.2292157928569599, Learning Rate: 0.013115\n",
      "Epoch: 17378, MSE: 0.2292129966306009, Learning Rate: 0.01311\n",
      "Epoch: 17379, MSE: 0.22921020048867669, Learning Rate: 0.013105\n",
      "Epoch: 17380, MSE: 0.22920740443133733, Learning Rate: 0.0131\n",
      "Epoch: 17381, MSE: 0.2292046084587328, Learning Rate: 0.013095000000000002\n",
      "Epoch: 17382, MSE: 0.2292018125710152, Learning Rate: 0.013090000000000003\n",
      "Epoch: 17383, MSE: 0.22919901676833354, Learning Rate: 0.013085000000000003\n",
      "Epoch: 17384, MSE: 0.22919622105084003, Learning Rate: 0.013080000000000003\n",
      "Epoch: 17385, MSE: 0.22919342541868465, Learning Rate: 0.013075000000000003\n",
      "Epoch: 17386, MSE: 0.22919062987202096, Learning Rate: 0.013070000000000005\n",
      "Epoch: 17387, MSE: 0.229187834410998, Learning Rate: 0.013065000000000005\n",
      "Epoch: 17388, MSE: 0.22918503903576914, Learning Rate: 0.013060000000000006\n",
      "Epoch: 17389, MSE: 0.22918224374648657, Learning Rate: 0.013055000000000006\n",
      "Epoch: 17390, MSE: 0.22917944854330177, Learning Rate: 0.013049999999999996\n",
      "Epoch: 17391, MSE: 0.22917665342636842, Learning Rate: 0.013044999999999996\n",
      "Epoch: 17392, MSE: 0.22917385839583823, Learning Rate: 0.013039999999999996\n",
      "Epoch: 17393, MSE: 0.22917106345186514, Learning Rate: 0.013034999999999998\n",
      "Epoch: 17394, MSE: 0.2291682685946018, Learning Rate: 0.013029999999999998\n",
      "Epoch: 17395, MSE: 0.22916547382420177, Learning Rate: 0.013024999999999998\n",
      "Epoch: 17396, MSE: 0.22916267914081903, Learning Rate: 0.013019999999999999\n",
      "Epoch: 17397, MSE: 0.2291598845446071, Learning Rate: 0.013014999999999999\n",
      "Epoch: 17398, MSE: 0.22915709003572043, Learning Rate: 0.01301\n",
      "Epoch: 17399, MSE: 0.229154295614314, Learning Rate: 0.013005000000000001\n",
      "Epoch: 17400, MSE: 0.22915150128054154, Learning Rate: 0.013000000000000001\n",
      "Epoch: 17401, MSE: 0.22914870703455723, Learning Rate: 0.012995000000000001\n",
      "Epoch: 17402, MSE: 0.2291459128765187, Learning Rate: 0.012990000000000002\n",
      "Epoch: 17403, MSE: 0.22914311880657995, Learning Rate: 0.012985000000000003\n",
      "Epoch: 17404, MSE: 0.22914032482489521, Learning Rate: 0.012980000000000004\n",
      "Epoch: 17405, MSE: 0.229137530931622, Learning Rate: 0.012975000000000004\n",
      "Epoch: 17406, MSE: 0.2291347371269156, Learning Rate: 0.012970000000000004\n",
      "Epoch: 17407, MSE: 0.2291319434109325, Learning Rate: 0.012965000000000004\n",
      "Epoch: 17408, MSE: 0.2291291497838298, Learning Rate: 0.012960000000000006\n",
      "Epoch: 17409, MSE: 0.22912635624576308, Learning Rate: 0.012955000000000006\n",
      "Epoch: 17410, MSE: 0.22912356279689075, Learning Rate: 0.012949999999999996\n",
      "Epoch: 17411, MSE: 0.2291207694373685, Learning Rate: 0.012944999999999996\n",
      "Epoch: 17412, MSE: 0.2291179761673548, Learning Rate: 0.012939999999999997\n",
      "Epoch: 17413, MSE: 0.2291151829870069, Learning Rate: 0.012934999999999997\n",
      "Epoch: 17414, MSE: 0.22911238989648333, Learning Rate: 0.012929999999999997\n",
      "Epoch: 17415, MSE: 0.22910959689594138, Learning Rate: 0.012924999999999999\n",
      "Epoch: 17416, MSE: 0.22910680398553976, Learning Rate: 0.01292\n",
      "Epoch: 17417, MSE: 0.22910401116543766, Learning Rate: 0.012915\n",
      "Epoch: 17418, MSE: 0.22910121843579367, Learning Rate: 0.01291\n",
      "Epoch: 17419, MSE: 0.229098425796766, Learning Rate: 0.012905\n",
      "Epoch: 17420, MSE: 0.2290956332485156, Learning Rate: 0.012900000000000002\n",
      "Epoch: 17421, MSE: 0.22909284079120187, Learning Rate: 0.012895000000000002\n",
      "Epoch: 17422, MSE: 0.22909004842498287, Learning Rate: 0.012890000000000002\n",
      "Epoch: 17423, MSE: 0.22908725615002087, Learning Rate: 0.012885000000000002\n",
      "Epoch: 17424, MSE: 0.22908446396647542, Learning Rate: 0.012880000000000003\n",
      "Epoch: 17425, MSE: 0.22908167187450673, Learning Rate: 0.012875000000000004\n",
      "Epoch: 17426, MSE: 0.22907887987427497, Learning Rate: 0.012870000000000005\n",
      "Epoch: 17427, MSE: 0.22907608796594325, Learning Rate: 0.012865000000000005\n",
      "Epoch: 17428, MSE: 0.22907329614967145, Learning Rate: 0.012860000000000005\n",
      "Epoch: 17429, MSE: 0.22907050442562182, Learning Rate: 0.012855000000000005\n",
      "Epoch: 17430, MSE: 0.2290677127939552, Learning Rate: 0.012849999999999995\n",
      "Epoch: 17431, MSE: 0.22906492125483507, Learning Rate: 0.012844999999999995\n",
      "Epoch: 17432, MSE: 0.2290621298084225, Learning Rate: 0.012839999999999997\n",
      "Epoch: 17433, MSE: 0.22905933845488005, Learning Rate: 0.012834999999999997\n",
      "Epoch: 17434, MSE: 0.22905654719437146, Learning Rate: 0.012829999999999998\n",
      "Epoch: 17435, MSE: 0.22905375602705913, Learning Rate: 0.012824999999999998\n",
      "Epoch: 17436, MSE: 0.2290509649531059, Learning Rate: 0.012819999999999998\n",
      "Epoch: 17437, MSE: 0.22904817397267693, Learning Rate: 0.012815\n",
      "Epoch: 17438, MSE: 0.2290453830859336, Learning Rate: 0.01281\n",
      "Epoch: 17439, MSE: 0.2290425922930422, Learning Rate: 0.012805\n",
      "Epoch: 17440, MSE: 0.22903980159416554, Learning Rate: 0.0128\n",
      "Epoch: 17441, MSE: 0.229037010989469, Learning Rate: 0.012795\n",
      "Epoch: 17442, MSE: 0.2290342204791169, Learning Rate: 0.012790000000000003\n",
      "Epoch: 17443, MSE: 0.22903143006327467, Learning Rate: 0.012785000000000003\n",
      "Epoch: 17444, MSE: 0.22902863974210733, Learning Rate: 0.012780000000000003\n",
      "Epoch: 17445, MSE: 0.2290258495157803, Learning Rate: 0.012775000000000003\n",
      "Epoch: 17446, MSE: 0.22902305938445935, Learning Rate: 0.012770000000000004\n",
      "Epoch: 17447, MSE: 0.22902026934831096, Learning Rate: 0.012765000000000006\n",
      "Epoch: 17448, MSE: 0.22901747940750114, Learning Rate: 0.012760000000000006\n",
      "Epoch: 17449, MSE: 0.22901468956219617, Learning Rate: 0.012755000000000006\n",
      "Epoch: 17450, MSE: 0.2290118998125632, Learning Rate: 0.012749999999999996\n",
      "Epoch: 17451, MSE: 0.2290091101587693, Learning Rate: 0.012744999999999996\n",
      "Epoch: 17452, MSE: 0.22900632060098147, Learning Rate: 0.012739999999999996\n",
      "Epoch: 17453, MSE: 0.22900353113936758, Learning Rate: 0.012734999999999996\n",
      "Epoch: 17454, MSE: 0.22900074177409654, Learning Rate: 0.012729999999999998\n",
      "Epoch: 17455, MSE: 0.22899795250533464, Learning Rate: 0.012724999999999998\n",
      "Epoch: 17456, MSE: 0.22899516333325073, Learning Rate: 0.012719999999999999\n",
      "Epoch: 17457, MSE: 0.22899237425801308, Learning Rate: 0.012714999999999999\n",
      "Epoch: 17458, MSE: 0.22898958527979157, Learning Rate: 0.012709999999999999\n",
      "Epoch: 17459, MSE: 0.22898679639875427, Learning Rate: 0.012705000000000001\n",
      "Epoch: 17460, MSE: 0.22898400761507204, Learning Rate: 0.012700000000000001\n",
      "Epoch: 17461, MSE: 0.22898121892891357, Learning Rate: 0.012695000000000001\n",
      "Epoch: 17462, MSE: 0.22897843034044796, Learning Rate: 0.012690000000000002\n",
      "Epoch: 17463, MSE: 0.2289756418498466, Learning Rate: 0.012685000000000002\n",
      "Epoch: 17464, MSE: 0.22897285345727902, Learning Rate: 0.012680000000000004\n",
      "Epoch: 17465, MSE: 0.22897006516291651, Learning Rate: 0.012675000000000004\n",
      "Epoch: 17466, MSE: 0.22896727696692987, Learning Rate: 0.012670000000000004\n",
      "Epoch: 17467, MSE: 0.2289644888694901, Learning Rate: 0.012665000000000004\n",
      "Epoch: 17468, MSE: 0.22896170087077003, Learning Rate: 0.012660000000000005\n",
      "Epoch: 17469, MSE: 0.22895891297093882, Learning Rate: 0.012655000000000007\n",
      "Epoch: 17470, MSE: 0.22895612517016983, Learning Rate: 0.012649999999999995\n",
      "Epoch: 17471, MSE: 0.22895333746863628, Learning Rate: 0.012644999999999997\n",
      "Epoch: 17472, MSE: 0.22895054986650887, Learning Rate: 0.012639999999999997\n",
      "Epoch: 17473, MSE: 0.22894776236396192, Learning Rate: 0.012634999999999997\n",
      "Epoch: 17474, MSE: 0.22894497496116714, Learning Rate: 0.012629999999999997\n",
      "Epoch: 17475, MSE: 0.22894218765829885, Learning Rate: 0.012624999999999997\n",
      "Epoch: 17476, MSE: 0.22893940045553043, Learning Rate: 0.01262\n",
      "Epoch: 17477, MSE: 0.2289366133530361, Learning Rate: 0.012615\n",
      "Epoch: 17478, MSE: 0.22893382635098838, Learning Rate: 0.01261\n",
      "Epoch: 17479, MSE: 0.22893103944956356, Learning Rate: 0.012605\n",
      "Epoch: 17480, MSE: 0.22892825264893543, Learning Rate: 0.0126\n",
      "Epoch: 17481, MSE: 0.2289254659492796, Learning Rate: 0.012595000000000002\n",
      "Epoch: 17482, MSE: 0.22892267935076988, Learning Rate: 0.012590000000000002\n",
      "Epoch: 17483, MSE: 0.2289198928535829, Learning Rate: 0.012585000000000002\n",
      "Epoch: 17484, MSE: 0.22891710645789407, Learning Rate: 0.012580000000000003\n",
      "Epoch: 17485, MSE: 0.22891432016387944, Learning Rate: 0.012575000000000003\n",
      "Epoch: 17486, MSE: 0.2289115339717152, Learning Rate: 0.012570000000000005\n",
      "Epoch: 17487, MSE: 0.22890874788157767, Learning Rate: 0.012565000000000005\n",
      "Epoch: 17488, MSE: 0.22890596189364412, Learning Rate: 0.012560000000000005\n",
      "Epoch: 17489, MSE: 0.22890317600809168, Learning Rate: 0.012555000000000005\n",
      "Epoch: 17490, MSE: 0.22890039022509678, Learning Rate: 0.012549999999999995\n",
      "Epoch: 17491, MSE: 0.2288976045448392, Learning Rate: 0.012544999999999995\n",
      "Epoch: 17492, MSE: 0.22889481896749467, Learning Rate: 0.012539999999999996\n",
      "Epoch: 17493, MSE: 0.22889203349324283, Learning Rate: 0.012534999999999998\n",
      "Epoch: 17494, MSE: 0.2288892481222606, Learning Rate: 0.012529999999999998\n",
      "Epoch: 17495, MSE: 0.22888646285472858, Learning Rate: 0.012524999999999998\n",
      "Epoch: 17496, MSE: 0.22888367769082482, Learning Rate: 0.012519999999999998\n",
      "Epoch: 17497, MSE: 0.2288808926307285, Learning Rate: 0.012514999999999998\n",
      "Epoch: 17498, MSE: 0.22887810767461914, Learning Rate: 0.01251\n",
      "Epoch: 17499, MSE: 0.22887532282267675, Learning Rate: 0.012505\n",
      "Epoch: 17500, MSE: 0.22887253807508187, Learning Rate: 0.0125\n",
      "Epoch: 17501, MSE: 0.22886975343201532, Learning Rate: 0.012495000000000001\n",
      "Epoch: 17502, MSE: 0.22886696889365687, Learning Rate: 0.012490000000000001\n",
      "Epoch: 17503, MSE: 0.22886418446018783, Learning Rate: 0.012485000000000003\n",
      "Epoch: 17504, MSE: 0.22886140013178904, Learning Rate: 0.012480000000000003\n",
      "Epoch: 17505, MSE: 0.22885861590864237, Learning Rate: 0.012475000000000003\n",
      "Epoch: 17506, MSE: 0.22885583179093022, Learning Rate: 0.012470000000000004\n",
      "Epoch: 17507, MSE: 0.22885304777883386, Learning Rate: 0.012465000000000004\n",
      "Epoch: 17508, MSE: 0.22885026387253668, Learning Rate: 0.012460000000000006\n",
      "Epoch: 17509, MSE: 0.2288474800722202, Learning Rate: 0.012455000000000006\n",
      "Epoch: 17510, MSE: 0.22884469637806779, Learning Rate: 0.012450000000000006\n",
      "Epoch: 17511, MSE: 0.22884191279026347, Learning Rate: 0.012444999999999996\n",
      "Epoch: 17512, MSE: 0.2288391293089893, Learning Rate: 0.012439999999999996\n",
      "Epoch: 17513, MSE: 0.22883634593442972, Learning Rate: 0.012434999999999996\n",
      "Epoch: 17514, MSE: 0.22883356266677005, Learning Rate: 0.012429999999999997\n",
      "Epoch: 17515, MSE: 0.22883077950619357, Learning Rate: 0.012424999999999999\n",
      "Epoch: 17516, MSE: 0.2288279964528842, Learning Rate: 0.012419999999999999\n",
      "Epoch: 17517, MSE: 0.2288252135070288, Learning Rate: 0.012414999999999999\n",
      "Epoch: 17518, MSE: 0.22882243066881075, Learning Rate: 0.01241\n",
      "Epoch: 17519, MSE: 0.22881964793841666, Learning Rate: 0.012405\n",
      "Epoch: 17520, MSE: 0.22881686531603224, Learning Rate: 0.012400000000000001\n",
      "Epoch: 17521, MSE: 0.2288140828018437, Learning Rate: 0.012395000000000002\n",
      "Epoch: 17522, MSE: 0.22881130039603723, Learning Rate: 0.012390000000000002\n",
      "Epoch: 17523, MSE: 0.2288085180987994, Learning Rate: 0.012385000000000002\n",
      "Epoch: 17524, MSE: 0.228805735910318, Learning Rate: 0.012380000000000002\n",
      "Epoch: 17525, MSE: 0.22880295383077853, Learning Rate: 0.012375000000000004\n",
      "Epoch: 17526, MSE: 0.22880017186037038, Learning Rate: 0.012370000000000004\n",
      "Epoch: 17527, MSE: 0.22879738999928118, Learning Rate: 0.012365000000000004\n",
      "Epoch: 17528, MSE: 0.22879460824769868, Learning Rate: 0.012360000000000005\n",
      "Epoch: 17529, MSE: 0.22879182660581127, Learning Rate: 0.012355000000000005\n",
      "Epoch: 17530, MSE: 0.2287890450738078, Learning Rate: 0.012350000000000007\n",
      "Epoch: 17531, MSE: 0.22878626365187751, Learning Rate: 0.012344999999999995\n",
      "Epoch: 17532, MSE: 0.22878348234020973, Learning Rate: 0.012339999999999997\n",
      "Epoch: 17533, MSE: 0.22878070113899412, Learning Rate: 0.012334999999999997\n",
      "Epoch: 17534, MSE: 0.22877792004841999, Learning Rate: 0.012329999999999997\n",
      "Epoch: 17535, MSE: 0.22877513906867855, Learning Rate: 0.012324999999999997\n",
      "Epoch: 17536, MSE: 0.22877235819995936, Learning Rate: 0.012319999999999998\n",
      "Epoch: 17537, MSE: 0.22876957744245488, Learning Rate: 0.012315\n",
      "Epoch: 17538, MSE: 0.2287667967963546, Learning Rate: 0.01231\n",
      "Epoch: 17539, MSE: 0.2287640162618504, Learning Rate: 0.012305\n",
      "Epoch: 17540, MSE: 0.228761235839135, Learning Rate: 0.0123\n",
      "Epoch: 17541, MSE: 0.2287584555283989, Learning Rate: 0.012295\n",
      "Epoch: 17542, MSE: 0.2287556753298354, Learning Rate: 0.012290000000000002\n",
      "Epoch: 17543, MSE: 0.22875289524363662, Learning Rate: 0.012285000000000003\n",
      "Epoch: 17544, MSE: 0.22875011526999645, Learning Rate: 0.012280000000000003\n",
      "Epoch: 17545, MSE: 0.2287473354091074, Learning Rate: 0.012275000000000003\n",
      "Epoch: 17546, MSE: 0.228744555661163, Learning Rate: 0.012270000000000003\n",
      "Epoch: 17547, MSE: 0.22874177602635715, Learning Rate: 0.012265000000000005\n",
      "Epoch: 17548, MSE: 0.22873899650488477, Learning Rate: 0.012260000000000005\n",
      "Epoch: 17549, MSE: 0.228736217096939, Learning Rate: 0.012255000000000005\n",
      "Epoch: 17550, MSE: 0.22873343780271602, Learning Rate: 0.012250000000000006\n",
      "Epoch: 17551, MSE: 0.2287306586224098, Learning Rate: 0.012244999999999995\n",
      "Epoch: 17552, MSE: 0.2287278795562165, Learning Rate: 0.012239999999999996\n",
      "Epoch: 17553, MSE: 0.22872510060433138, Learning Rate: 0.012234999999999996\n",
      "Epoch: 17554, MSE: 0.22872232176695048, Learning Rate: 0.012229999999999998\n",
      "Epoch: 17555, MSE: 0.2287195430442706, Learning Rate: 0.012224999999999998\n",
      "Epoch: 17556, MSE: 0.2287167644364881, Learning Rate: 0.012219999999999998\n",
      "Epoch: 17557, MSE: 0.2287139859437995, Learning Rate: 0.012214999999999998\n",
      "Epoch: 17558, MSE: 0.2287112075664024, Learning Rate: 0.012209999999999999\n",
      "Epoch: 17559, MSE: 0.22870842930449395, Learning Rate: 0.012205\n",
      "Epoch: 17560, MSE: 0.228705651158273, Learning Rate: 0.0122\n",
      "Epoch: 17561, MSE: 0.22870287312793747, Learning Rate: 0.012195000000000001\n",
      "Epoch: 17562, MSE: 0.22870009521368453, Learning Rate: 0.012190000000000001\n",
      "Epoch: 17563, MSE: 0.22869731741571567, Learning Rate: 0.012185000000000001\n",
      "Epoch: 17564, MSE: 0.22869453973422726, Learning Rate: 0.012180000000000003\n",
      "Epoch: 17565, MSE: 0.22869176216942033, Learning Rate: 0.012175000000000004\n",
      "Epoch: 17566, MSE: 0.22868898472149465, Learning Rate: 0.012170000000000004\n",
      "Epoch: 17567, MSE: 0.22868620739064932, Learning Rate: 0.012165000000000004\n",
      "Epoch: 17568, MSE: 0.22868343017708506, Learning Rate: 0.012160000000000004\n",
      "Epoch: 17569, MSE: 0.22868065308100394, Learning Rate: 0.012155000000000006\n",
      "Epoch: 17570, MSE: 0.22867787610260443, Learning Rate: 0.012150000000000006\n",
      "Epoch: 17571, MSE: 0.2286750992420901, Learning Rate: 0.012144999999999996\n",
      "Epoch: 17572, MSE: 0.22867232249966196, Learning Rate: 0.012139999999999996\n",
      "Epoch: 17573, MSE: 0.2286695458755219, Learning Rate: 0.012134999999999996\n",
      "Epoch: 17574, MSE: 0.2286667693698721, Learning Rate: 0.012129999999999997\n",
      "Epoch: 17575, MSE: 0.22866399298291526, Learning Rate: 0.012124999999999997\n",
      "Epoch: 17576, MSE: 0.228661216714855, Learning Rate: 0.012119999999999999\n",
      "Epoch: 17577, MSE: 0.2286584405658936, Learning Rate: 0.012114999999999999\n",
      "Epoch: 17578, MSE: 0.22865566453623512, Learning Rate: 0.01211\n",
      "Epoch: 17579, MSE: 0.22865288862608307, Learning Rate: 0.012105\n",
      "Epoch: 17580, MSE: 0.22865011283564265, Learning Rate: 0.0121\n",
      "Epoch: 17581, MSE: 0.22864733716511815, Learning Rate: 0.012095000000000002\n",
      "Epoch: 17582, MSE: 0.22864456161471355, Learning Rate: 0.012090000000000002\n",
      "Epoch: 17583, MSE: 0.22864178618463502, Learning Rate: 0.012085000000000002\n",
      "Epoch: 17584, MSE: 0.22863901087508776, Learning Rate: 0.012080000000000002\n",
      "Epoch: 17585, MSE: 0.22863623568627778, Learning Rate: 0.012075000000000002\n",
      "Epoch: 17586, MSE: 0.22863346061841083, Learning Rate: 0.012070000000000004\n",
      "Epoch: 17587, MSE: 0.22863068567169428, Learning Rate: 0.012065000000000005\n",
      "Epoch: 17588, MSE: 0.2286279108463347, Learning Rate: 0.012060000000000005\n",
      "Epoch: 17589, MSE: 0.22862513614253904, Learning Rate: 0.012055000000000005\n",
      "Epoch: 17590, MSE: 0.2286223615605147, Learning Rate: 0.012050000000000005\n",
      "Epoch: 17591, MSE: 0.2286195871004697, Learning Rate: 0.012044999999999995\n",
      "Epoch: 17592, MSE: 0.22861681276261273, Learning Rate: 0.012039999999999995\n",
      "Epoch: 17593, MSE: 0.22861403854715145, Learning Rate: 0.012034999999999997\n",
      "Epoch: 17594, MSE: 0.2286112644542956, Learning Rate: 0.012029999999999997\n",
      "Epoch: 17595, MSE: 0.22860849048425366, Learning Rate: 0.012024999999999997\n",
      "Epoch: 17596, MSE: 0.22860571663723517, Learning Rate: 0.012019999999999998\n",
      "Epoch: 17597, MSE: 0.22860294291345098, Learning Rate: 0.012014999999999998\n",
      "Epoch: 17598, MSE: 0.22860016931311047, Learning Rate: 0.01201\n",
      "Epoch: 17599, MSE: 0.2285973958364234, Learning Rate: 0.012005\n",
      "Epoch: 17600, MSE: 0.2285946224836024, Learning Rate: 0.012\n",
      "Epoch: 17601, MSE: 0.22859184925485737, Learning Rate: 0.011995\n",
      "Epoch: 17602, MSE: 0.22858907615040058, Learning Rate: 0.01199\n",
      "Epoch: 17603, MSE: 0.22858630317044362, Learning Rate: 0.011985000000000003\n",
      "Epoch: 17604, MSE: 0.22858353031519776, Learning Rate: 0.011980000000000003\n",
      "Epoch: 17605, MSE: 0.22858075758487775, Learning Rate: 0.011975000000000003\n",
      "Epoch: 17606, MSE: 0.22857798497969434, Learning Rate: 0.011970000000000003\n",
      "Epoch: 17607, MSE: 0.22857521249986235, Learning Rate: 0.011965000000000003\n",
      "Epoch: 17608, MSE: 0.22857244014559364, Learning Rate: 0.011960000000000005\n",
      "Epoch: 17609, MSE: 0.22856966791710454, Learning Rate: 0.011955000000000006\n",
      "Epoch: 17610, MSE: 0.22856689581460682, Learning Rate: 0.011950000000000006\n",
      "Epoch: 17611, MSE: 0.22856412383831692, Learning Rate: 0.011944999999999996\n",
      "Epoch: 17612, MSE: 0.2285613519884488, Learning Rate: 0.011939999999999996\n",
      "Epoch: 17613, MSE: 0.2285585802652177, Learning Rate: 0.011934999999999996\n",
      "Epoch: 17614, MSE: 0.22855580866883973, Learning Rate: 0.011929999999999996\n",
      "Epoch: 17615, MSE: 0.22855303719953102, Learning Rate: 0.011924999999999998\n",
      "Epoch: 17616, MSE: 0.22855026585750784, Learning Rate: 0.011919999999999998\n",
      "Epoch: 17617, MSE: 0.2285474946429872, Learning Rate: 0.011914999999999999\n",
      "Epoch: 17618, MSE: 0.2285447235561846, Learning Rate: 0.011909999999999999\n",
      "Epoch: 17619, MSE: 0.22854195259731935, Learning Rate: 0.011904999999999999\n",
      "Epoch: 17620, MSE: 0.22853918176660745, Learning Rate: 0.0119\n",
      "Epoch: 17621, MSE: 0.2285364110642689, Learning Rate: 0.011895000000000001\n",
      "Epoch: 17622, MSE: 0.22853364049052152, Learning Rate: 0.011890000000000001\n",
      "Epoch: 17623, MSE: 0.2285308700455824, Learning Rate: 0.011885000000000001\n",
      "Epoch: 17624, MSE: 0.22852809972967222, Learning Rate: 0.011880000000000002\n",
      "Epoch: 17625, MSE: 0.22852532954301114, Learning Rate: 0.011875000000000004\n",
      "Epoch: 17626, MSE: 0.22852255948581734, Learning Rate: 0.011870000000000004\n",
      "Epoch: 17627, MSE: 0.22851978955831245, Learning Rate: 0.011865000000000004\n",
      "Epoch: 17628, MSE: 0.22851701976071537, Learning Rate: 0.011860000000000004\n",
      "Epoch: 17629, MSE: 0.22851425009324922, Learning Rate: 0.011855000000000004\n",
      "Epoch: 17630, MSE: 0.22851148055613446, Learning Rate: 0.011850000000000006\n",
      "Epoch: 17631, MSE: 0.2285087111495906, Learning Rate: 0.011845000000000007\n",
      "Epoch: 17632, MSE: 0.22850594187384313, Learning Rate: 0.011839999999999996\n",
      "Epoch: 17633, MSE: 0.2285031727291118, Learning Rate: 0.011834999999999997\n",
      "Epoch: 17634, MSE: 0.2285004037156205, Learning Rate: 0.011829999999999997\n",
      "Epoch: 17635, MSE: 0.22849763483359223, Learning Rate: 0.011824999999999997\n",
      "Epoch: 17636, MSE: 0.2284948660832503, Learning Rate: 0.011819999999999997\n",
      "Epoch: 17637, MSE: 0.22849209746481755, Learning Rate: 0.011814999999999999\n",
      "Epoch: 17638, MSE: 0.22848932897851967, Learning Rate: 0.01181\n",
      "Epoch: 17639, MSE: 0.2284865606245801, Learning Rate: 0.011805\n",
      "Epoch: 17640, MSE: 0.2284837924032244, Learning Rate: 0.0118\n",
      "Epoch: 17641, MSE: 0.2284810243146775, Learning Rate: 0.011795\n",
      "Epoch: 17642, MSE: 0.22847825635916494, Learning Rate: 0.011790000000000002\n",
      "Epoch: 17643, MSE: 0.22847548853691235, Learning Rate: 0.011785000000000002\n",
      "Epoch: 17644, MSE: 0.2284727208481474, Learning Rate: 0.011780000000000002\n",
      "Epoch: 17645, MSE: 0.2284699532930956, Learning Rate: 0.011775000000000002\n",
      "Epoch: 17646, MSE: 0.2284671858719844, Learning Rate: 0.011770000000000003\n",
      "Epoch: 17647, MSE: 0.228464418585041, Learning Rate: 0.011765000000000005\n",
      "Epoch: 17648, MSE: 0.22846165143249322, Learning Rate: 0.011760000000000005\n",
      "Epoch: 17649, MSE: 0.2284588844145696, Learning Rate: 0.011755000000000005\n",
      "Epoch: 17650, MSE: 0.22845611753149833, Learning Rate: 0.011750000000000005\n",
      "Epoch: 17651, MSE: 0.22845335078350903, Learning Rate: 0.011745000000000005\n",
      "Epoch: 17652, MSE: 0.22845058417083058, Learning Rate: 0.011739999999999995\n",
      "Epoch: 17653, MSE: 0.22844781769369188, Learning Rate: 0.011734999999999995\n",
      "Epoch: 17654, MSE: 0.2284450513523245, Learning Rate: 0.011729999999999997\n",
      "Epoch: 17655, MSE: 0.2284422851469568, Learning Rate: 0.011724999999999998\n",
      "Epoch: 17656, MSE: 0.2284395190778216, Learning Rate: 0.011719999999999998\n",
      "Epoch: 17657, MSE: 0.22843675314514933, Learning Rate: 0.011714999999999998\n",
      "Epoch: 17658, MSE: 0.22843398734917153, Learning Rate: 0.011709999999999998\n",
      "Epoch: 17659, MSE: 0.22843122169011967, Learning Rate: 0.011705\n",
      "Epoch: 17660, MSE: 0.22842845616822682, Learning Rate: 0.0117\n",
      "Epoch: 17661, MSE: 0.22842569078372504, Learning Rate: 0.011695\n",
      "Epoch: 17662, MSE: 0.2284229255368472, Learning Rate: 0.01169\n",
      "Epoch: 17663, MSE: 0.22842016042782767, Learning Rate: 0.011685000000000001\n",
      "Epoch: 17664, MSE: 0.22841739545689912, Learning Rate: 0.011680000000000003\n",
      "Epoch: 17665, MSE: 0.228414630624297, Learning Rate: 0.011675000000000003\n",
      "Epoch: 17666, MSE: 0.2284118659302552, Learning Rate: 0.011670000000000003\n",
      "Epoch: 17667, MSE: 0.22840910137500858, Learning Rate: 0.011665000000000003\n",
      "Epoch: 17668, MSE: 0.22840633695879273, Learning Rate: 0.011660000000000004\n",
      "Epoch: 17669, MSE: 0.2284035726818428, Learning Rate: 0.011655000000000006\n",
      "Epoch: 17670, MSE: 0.22840080854439623, Learning Rate: 0.011650000000000006\n",
      "Epoch: 17671, MSE: 0.2283980445466883, Learning Rate: 0.011645000000000006\n",
      "Epoch: 17672, MSE: 0.22839528068895648, Learning Rate: 0.011639999999999996\n",
      "Epoch: 17673, MSE: 0.2283925169714376, Learning Rate: 0.011634999999999996\n",
      "Epoch: 17674, MSE: 0.22838975339436998, Learning Rate: 0.011629999999999996\n",
      "Epoch: 17675, MSE: 0.22838698995799112, Learning Rate: 0.011624999999999996\n",
      "Epoch: 17676, MSE: 0.22838422666253932, Learning Rate: 0.011619999999999998\n",
      "Epoch: 17677, MSE: 0.228381463508254, Learning Rate: 0.011614999999999999\n",
      "Epoch: 17678, MSE: 0.2283787004953742, Learning Rate: 0.011609999999999999\n",
      "Epoch: 17679, MSE: 0.2283759376241392, Learning Rate: 0.011604999999999999\n",
      "Epoch: 17680, MSE: 0.228373174894789, Learning Rate: 0.0116\n",
      "Epoch: 17681, MSE: 0.2283704123075647, Learning Rate: 0.011595000000000001\n",
      "Epoch: 17682, MSE: 0.22836764986270636, Learning Rate: 0.011590000000000001\n",
      "Epoch: 17683, MSE: 0.22836488756045567, Learning Rate: 0.011585000000000002\n",
      "Epoch: 17684, MSE: 0.22836212540105358, Learning Rate: 0.011580000000000002\n",
      "Epoch: 17685, MSE: 0.228359363384743, Learning Rate: 0.011575000000000002\n",
      "Epoch: 17686, MSE: 0.22835660151176515, Learning Rate: 0.011570000000000004\n",
      "Epoch: 17687, MSE: 0.22835383978236393, Learning Rate: 0.011565000000000004\n",
      "Epoch: 17688, MSE: 0.22835107819678255, Learning Rate: 0.011560000000000004\n",
      "Epoch: 17689, MSE: 0.22834831675526318, Learning Rate: 0.011555000000000005\n",
      "Epoch: 17690, MSE: 0.2283455554580504, Learning Rate: 0.011550000000000005\n",
      "Epoch: 17691, MSE: 0.22834279430538992, Learning Rate: 0.011545000000000007\n",
      "Epoch: 17692, MSE: 0.228340033297525, Learning Rate: 0.011539999999999995\n",
      "Epoch: 17693, MSE: 0.22833727243470153, Learning Rate: 0.011534999999999997\n",
      "Epoch: 17694, MSE: 0.22833451171716468, Learning Rate: 0.011529999999999997\n",
      "Epoch: 17695, MSE: 0.22833175114516072, Learning Rate: 0.011524999999999997\n",
      "Epoch: 17696, MSE: 0.2283289907189348, Learning Rate: 0.011519999999999997\n",
      "Epoch: 17697, MSE: 0.2283262304387361, Learning Rate: 0.011514999999999997\n",
      "Epoch: 17698, MSE: 0.22832347030480965, Learning Rate: 0.01151\n",
      "Epoch: 17699, MSE: 0.22832071031740453, Learning Rate: 0.011505\n",
      "Epoch: 17700, MSE: 0.22831795047676853, Learning Rate: 0.0115\n",
      "Epoch: 17701, MSE: 0.22831519078314924, Learning Rate: 0.011495\n",
      "Epoch: 17702, MSE: 0.2283124312367964, Learning Rate: 0.01149\n",
      "Epoch: 17703, MSE: 0.2283096718379582, Learning Rate: 0.011485000000000002\n",
      "Epoch: 17704, MSE: 0.22830691258688557, Learning Rate: 0.011480000000000002\n",
      "Epoch: 17705, MSE: 0.2283041534838278, Learning Rate: 0.011475000000000003\n",
      "Epoch: 17706, MSE: 0.22830139452903586, Learning Rate: 0.011470000000000003\n",
      "Epoch: 17707, MSE: 0.22829863572276007, Learning Rate: 0.011465000000000003\n",
      "Epoch: 17708, MSE: 0.22829587706525195, Learning Rate: 0.011460000000000005\n",
      "Epoch: 17709, MSE: 0.22829311855676326, Learning Rate: 0.011455000000000005\n",
      "Epoch: 17710, MSE: 0.22829036019754612, Learning Rate: 0.011450000000000005\n",
      "Epoch: 17711, MSE: 0.22828760198785297, Learning Rate: 0.011445000000000006\n",
      "Epoch: 17712, MSE: 0.2282848439279372, Learning Rate: 0.011439999999999995\n",
      "Epoch: 17713, MSE: 0.22828208601805178, Learning Rate: 0.011434999999999996\n",
      "Epoch: 17714, MSE: 0.22827932825845137, Learning Rate: 0.011429999999999996\n",
      "Epoch: 17715, MSE: 0.22827657064938922, Learning Rate: 0.011424999999999998\n",
      "Epoch: 17716, MSE: 0.22827381319112006, Learning Rate: 0.011419999999999998\n",
      "Epoch: 17717, MSE: 0.22827105588389837, Learning Rate: 0.011414999999999998\n",
      "Epoch: 17718, MSE: 0.22826829872798146, Learning Rate: 0.011409999999999998\n",
      "Epoch: 17719, MSE: 0.22826554172362468, Learning Rate: 0.011404999999999998\n",
      "Epoch: 17720, MSE: 0.22826278487108326, Learning Rate: 0.0114\n",
      "Epoch: 17721, MSE: 0.22826002817061491, Learning Rate: 0.011395\n",
      "Epoch: 17722, MSE: 0.2282572716224768, Learning Rate: 0.01139\n",
      "Epoch: 17723, MSE: 0.22825451522692553, Learning Rate: 0.011385000000000001\n",
      "Epoch: 17724, MSE: 0.22825175898422068, Learning Rate: 0.011380000000000001\n",
      "Epoch: 17725, MSE: 0.22824900289462025, Learning Rate: 0.011375000000000003\n",
      "Epoch: 17726, MSE: 0.22824624695838175, Learning Rate: 0.011370000000000003\n",
      "Epoch: 17727, MSE: 0.22824349117576678, Learning Rate: 0.011365000000000004\n",
      "Epoch: 17728, MSE: 0.22824073554703384, Learning Rate: 0.011360000000000004\n",
      "Epoch: 17729, MSE: 0.22823798007244317, Learning Rate: 0.011355000000000004\n",
      "Epoch: 17730, MSE: 0.2282352247522553, Learning Rate: 0.011350000000000006\n",
      "Epoch: 17731, MSE: 0.2282324695867315, Learning Rate: 0.011345000000000006\n",
      "Epoch: 17732, MSE: 0.22822971457613372, Learning Rate: 0.011339999999999996\n",
      "Epoch: 17733, MSE: 0.2282269597207234, Learning Rate: 0.011334999999999996\n",
      "Epoch: 17734, MSE: 0.22822420502076277, Learning Rate: 0.011329999999999996\n",
      "Epoch: 17735, MSE: 0.2282214504765147, Learning Rate: 0.011324999999999997\n",
      "Epoch: 17736, MSE: 0.22821869608824294, Learning Rate: 0.011319999999999997\n",
      "Epoch: 17737, MSE: 0.22821594185621114, Learning Rate: 0.011314999999999999\n",
      "Epoch: 17738, MSE: 0.2282131877806819, Learning Rate: 0.011309999999999999\n",
      "Epoch: 17739, MSE: 0.22821043386192202, Learning Rate: 0.011304999999999999\n",
      "Epoch: 17740, MSE: 0.22820768010019482, Learning Rate: 0.0113\n",
      "Epoch: 17741, MSE: 0.22820492649576693, Learning Rate: 0.011295\n",
      "Epoch: 17742, MSE: 0.22820217304890336, Learning Rate: 0.011290000000000001\n",
      "Epoch: 17743, MSE: 0.228199419759871, Learning Rate: 0.011285000000000002\n",
      "Epoch: 17744, MSE: 0.22819666662893634, Learning Rate: 0.011280000000000002\n",
      "Epoch: 17745, MSE: 0.22819391365636674, Learning Rate: 0.011275000000000002\n",
      "Epoch: 17746, MSE: 0.22819116084242919, Learning Rate: 0.011270000000000002\n",
      "Epoch: 17747, MSE: 0.2281884081873933, Learning Rate: 0.011265000000000004\n",
      "Epoch: 17748, MSE: 0.22818565569152618, Learning Rate: 0.011260000000000004\n",
      "Epoch: 17749, MSE: 0.22818290335509672, Learning Rate: 0.011255000000000005\n",
      "Epoch: 17750, MSE: 0.228180151178376, Learning Rate: 0.011250000000000005\n",
      "Epoch: 17751, MSE: 0.22817739916163263, Learning Rate: 0.011245000000000005\n",
      "Epoch: 17752, MSE: 0.22817464730513773, Learning Rate: 0.011240000000000007\n",
      "Epoch: 17753, MSE: 0.22817189560916085, Learning Rate: 0.011234999999999995\n",
      "Epoch: 17754, MSE: 0.22816914407397515, Learning Rate: 0.011229999999999997\n",
      "Epoch: 17755, MSE: 0.22816639269985028, Learning Rate: 0.011224999999999997\n",
      "Epoch: 17756, MSE: 0.22816364148705995, Learning Rate: 0.011219999999999997\n",
      "Epoch: 17757, MSE: 0.22816089043587556, Learning Rate: 0.011214999999999998\n",
      "Epoch: 17758, MSE: 0.2281581395465722, Learning Rate: 0.011209999999999998\n",
      "Epoch: 17759, MSE: 0.22815538881942124, Learning Rate: 0.011205\n",
      "Epoch: 17760, MSE: 0.2281526382546977, Learning Rate: 0.0112\n",
      "Epoch: 17761, MSE: 0.22814988785267584, Learning Rate: 0.011195\n",
      "Epoch: 17762, MSE: 0.22814713761363048, Learning Rate: 0.01119\n",
      "Epoch: 17763, MSE: 0.22814438753783708, Learning Rate: 0.011185\n",
      "Epoch: 17764, MSE: 0.2281416376255714, Learning Rate: 0.011180000000000002\n",
      "Epoch: 17765, MSE: 0.22813888787711123, Learning Rate: 0.011175000000000003\n",
      "Epoch: 17766, MSE: 0.22813613829273072, Learning Rate: 0.011170000000000003\n",
      "Epoch: 17767, MSE: 0.22813338887270887, Learning Rate: 0.011165000000000003\n",
      "Epoch: 17768, MSE: 0.22813063961732313, Learning Rate: 0.011160000000000003\n",
      "Epoch: 17769, MSE: 0.2281278905268511, Learning Rate: 0.011155000000000005\n",
      "Epoch: 17770, MSE: 0.2281251416015713, Learning Rate: 0.011150000000000005\n",
      "Epoch: 17771, MSE: 0.22812239284176394, Learning Rate: 0.011145000000000006\n",
      "Epoch: 17772, MSE: 0.2281196442477081, Learning Rate: 0.011140000000000006\n",
      "Epoch: 17773, MSE: 0.22811689581968278, Learning Rate: 0.011134999999999996\n",
      "Epoch: 17774, MSE: 0.2281141475579703, Learning Rate: 0.011129999999999996\n",
      "Epoch: 17775, MSE: 0.22811139946285053, Learning Rate: 0.011124999999999996\n",
      "Epoch: 17776, MSE: 0.22810865153460508, Learning Rate: 0.011119999999999998\n",
      "Epoch: 17777, MSE: 0.22810590377351597, Learning Rate: 0.011114999999999998\n",
      "Epoch: 17778, MSE: 0.22810315617986496, Learning Rate: 0.011109999999999998\n",
      "Epoch: 17779, MSE: 0.22810040875393614, Learning Rate: 0.011104999999999999\n",
      "Epoch: 17780, MSE: 0.22809766149601265, Learning Rate: 0.011099999999999999\n",
      "Epoch: 17781, MSE: 0.22809491440637653, Learning Rate: 0.011095\n",
      "Epoch: 17782, MSE: 0.22809216748531455, Learning Rate: 0.011090000000000001\n",
      "Epoch: 17783, MSE: 0.2280894207331099, Learning Rate: 0.011085000000000001\n",
      "Epoch: 17784, MSE: 0.2280866741500488, Learning Rate: 0.011080000000000001\n",
      "Epoch: 17785, MSE: 0.22808392773641703, Learning Rate: 0.011075000000000002\n",
      "Epoch: 17786, MSE: 0.22808118149249934, Learning Rate: 0.011070000000000003\n",
      "Epoch: 17787, MSE: 0.22807843541858452, Learning Rate: 0.011065000000000004\n",
      "Epoch: 17788, MSE: 0.22807568951495827, Learning Rate: 0.011060000000000004\n",
      "Epoch: 17789, MSE: 0.22807294378190934, Learning Rate: 0.011055000000000004\n",
      "Epoch: 17790, MSE: 0.2280701982197246, Learning Rate: 0.011050000000000004\n",
      "Epoch: 17791, MSE: 0.22806745282869406, Learning Rate: 0.011045000000000006\n",
      "Epoch: 17792, MSE: 0.22806470760910566, Learning Rate: 0.011040000000000006\n",
      "Epoch: 17793, MSE: 0.22806196256124986, Learning Rate: 0.011034999999999996\n",
      "Epoch: 17794, MSE: 0.22805921768541745, Learning Rate: 0.011029999999999996\n",
      "Epoch: 17795, MSE: 0.22805647298189732, Learning Rate: 0.011024999999999997\n",
      "Epoch: 17796, MSE: 0.22805372845098146, Learning Rate: 0.011019999999999997\n",
      "Epoch: 17797, MSE: 0.2280509840929615, Learning Rate: 0.011014999999999997\n",
      "Epoch: 17798, MSE: 0.2280482399081294, Learning Rate: 0.011009999999999999\n",
      "Epoch: 17799, MSE: 0.22804549589677894, Learning Rate: 0.011005\n",
      "Epoch: 17800, MSE: 0.22804275205920063, Learning Rate: 0.011\n",
      "Epoch: 17801, MSE: 0.22804000839569039, Learning Rate: 0.010995\n",
      "Epoch: 17802, MSE: 0.2280372649065412, Learning Rate: 0.01099\n",
      "Epoch: 17803, MSE: 0.2280345215920482, Learning Rate: 0.010985000000000002\n",
      "Epoch: 17804, MSE: 0.22803177845250552, Learning Rate: 0.010980000000000002\n",
      "Epoch: 17805, MSE: 0.22802903548821044, Learning Rate: 0.010975000000000002\n",
      "Epoch: 17806, MSE: 0.22802629269945673, Learning Rate: 0.010970000000000002\n",
      "Epoch: 17807, MSE: 0.22802355008654301, Learning Rate: 0.010965000000000003\n",
      "Epoch: 17808, MSE: 0.22802080764976573, Learning Rate: 0.010960000000000004\n",
      "Epoch: 17809, MSE: 0.2280180653894217, Learning Rate: 0.010955000000000005\n",
      "Epoch: 17810, MSE: 0.2280153233058102, Learning Rate: 0.010950000000000005\n",
      "Epoch: 17811, MSE: 0.22801258139922898, Learning Rate: 0.010945000000000005\n",
      "Epoch: 17812, MSE: 0.2280098396699777, Learning Rate: 0.010940000000000005\n",
      "Epoch: 17813, MSE: 0.22800709811835626, Learning Rate: 0.010934999999999995\n",
      "Epoch: 17814, MSE: 0.2280043567446635, Learning Rate: 0.010929999999999995\n",
      "Epoch: 17815, MSE: 0.22800161554920098, Learning Rate: 0.010924999999999997\n",
      "Epoch: 17816, MSE: 0.22799887453227, Learning Rate: 0.010919999999999997\n",
      "Epoch: 17817, MSE: 0.22799613369417193, Learning Rate: 0.010914999999999998\n",
      "Epoch: 17818, MSE: 0.22799339303520835, Learning Rate: 0.010909999999999998\n",
      "Epoch: 17819, MSE: 0.22799065255568274, Learning Rate: 0.010904999999999998\n",
      "Epoch: 17820, MSE: 0.22798791225589912, Learning Rate: 0.0109\n",
      "Epoch: 17821, MSE: 0.22798517213615943, Learning Rate: 0.010895\n",
      "Epoch: 17822, MSE: 0.22798243219676861, Learning Rate: 0.01089\n",
      "Epoch: 17823, MSE: 0.2279796924380318, Learning Rate: 0.010885\n",
      "Epoch: 17824, MSE: 0.22797695286025393, Learning Rate: 0.01088\n",
      "Epoch: 17825, MSE: 0.22797421346374122, Learning Rate: 0.010875000000000003\n",
      "Epoch: 17826, MSE: 0.22797147424879874, Learning Rate: 0.010870000000000003\n",
      "Epoch: 17827, MSE: 0.22796873521573535, Learning Rate: 0.010865000000000003\n",
      "Epoch: 17828, MSE: 0.22796599636485607, Learning Rate: 0.010860000000000003\n",
      "Epoch: 17829, MSE: 0.22796325769647077, Learning Rate: 0.010855000000000004\n",
      "Epoch: 17830, MSE: 0.227960519210887, Learning Rate: 0.010850000000000005\n",
      "Epoch: 17831, MSE: 0.22795778090841404, Learning Rate: 0.010845000000000006\n",
      "Epoch: 17832, MSE: 0.2279550427893613, Learning Rate: 0.010840000000000006\n",
      "Epoch: 17833, MSE: 0.22795230485403742, Learning Rate: 0.010834999999999996\n",
      "Epoch: 17834, MSE: 0.22794956710275524, Learning Rate: 0.010829999999999996\n",
      "Epoch: 17835, MSE: 0.22794682953582432, Learning Rate: 0.010824999999999996\n",
      "Epoch: 17836, MSE: 0.2279440921535568, Learning Rate: 0.010819999999999996\n",
      "Epoch: 17837, MSE: 0.22794135495626483, Learning Rate: 0.010814999999999998\n",
      "Epoch: 17838, MSE: 0.22793861794426037, Learning Rate: 0.010809999999999998\n",
      "Epoch: 17839, MSE: 0.22793588111785779, Learning Rate: 0.010804999999999999\n",
      "Epoch: 17840, MSE: 0.22793314447736976, Learning Rate: 0.010799999999999999\n",
      "Epoch: 17841, MSE: 0.22793040802311096, Learning Rate: 0.010794999999999999\n",
      "Epoch: 17842, MSE: 0.22792767175539644, Learning Rate: 0.010790000000000001\n",
      "Epoch: 17843, MSE: 0.2279249356745412, Learning Rate: 0.010785000000000001\n",
      "Epoch: 17844, MSE: 0.2279221997808611, Learning Rate: 0.010780000000000001\n",
      "Epoch: 17845, MSE: 0.22791946407467314, Learning Rate: 0.010775000000000002\n",
      "Epoch: 17846, MSE: 0.22791672855629358, Learning Rate: 0.010770000000000002\n",
      "Epoch: 17847, MSE: 0.22791399322603978, Learning Rate: 0.010765000000000004\n",
      "Epoch: 17848, MSE: 0.22791125808423035, Learning Rate: 0.010760000000000004\n",
      "Epoch: 17849, MSE: 0.22790852313118348, Learning Rate: 0.010755000000000004\n",
      "Epoch: 17850, MSE: 0.22790578836721936, Learning Rate: 0.010750000000000004\n",
      "Epoch: 17851, MSE: 0.2279030537926573, Learning Rate: 0.010745000000000005\n",
      "Epoch: 17852, MSE: 0.22790031940781577, Learning Rate: 0.010740000000000006\n",
      "Epoch: 17853, MSE: 0.22789758521301792, Learning Rate: 0.010734999999999995\n",
      "Epoch: 17854, MSE: 0.22789485120858408, Learning Rate: 0.010729999999999996\n",
      "Epoch: 17855, MSE: 0.22789211739483634, Learning Rate: 0.010724999999999997\n",
      "Epoch: 17856, MSE: 0.22788938377209672, Learning Rate: 0.010719999999999997\n",
      "Epoch: 17857, MSE: 0.22788665034068842, Learning Rate: 0.010714999999999997\n",
      "Epoch: 17858, MSE: 0.22788391710093553, Learning Rate: 0.010709999999999997\n",
      "Epoch: 17859, MSE: 0.22788118405316182, Learning Rate: 0.010705\n",
      "Epoch: 17860, MSE: 0.2278784511976917, Learning Rate: 0.0107\n",
      "Epoch: 17861, MSE: 0.2278757185348508, Learning Rate: 0.010695\n",
      "Epoch: 17862, MSE: 0.2278729860649645, Learning Rate: 0.01069\n",
      "Epoch: 17863, MSE: 0.22787025378835934, Learning Rate: 0.010685\n",
      "Epoch: 17864, MSE: 0.22786752170536223, Learning Rate: 0.010680000000000002\n",
      "Epoch: 17865, MSE: 0.2278647898163009, Learning Rate: 0.010675000000000002\n",
      "Epoch: 17866, MSE: 0.2278620581215032, Learning Rate: 0.010670000000000002\n",
      "Epoch: 17867, MSE: 0.2278593266212981, Learning Rate: 0.010665000000000003\n",
      "Epoch: 17868, MSE: 0.22785659531601413, Learning Rate: 0.010660000000000003\n",
      "Epoch: 17869, MSE: 0.22785386420598108, Learning Rate: 0.010655000000000005\n",
      "Epoch: 17870, MSE: 0.2278511332915299, Learning Rate: 0.010650000000000005\n",
      "Epoch: 17871, MSE: 0.2278484025729904, Learning Rate: 0.010645000000000005\n",
      "Epoch: 17872, MSE: 0.22784567205069634, Learning Rate: 0.010640000000000005\n",
      "Epoch: 17873, MSE: 0.22784294172497724, Learning Rate: 0.010634999999999995\n",
      "Epoch: 17874, MSE: 0.2278402115961661, Learning Rate: 0.010629999999999995\n",
      "Epoch: 17875, MSE: 0.227837481664597, Learning Rate: 0.010624999999999996\n",
      "Epoch: 17876, MSE: 0.22783475193060337, Learning Rate: 0.010619999999999997\n",
      "Epoch: 17877, MSE: 0.22783202239451877, Learning Rate: 0.010614999999999998\n",
      "Epoch: 17878, MSE: 0.22782929305668018, Learning Rate: 0.010609999999999998\n",
      "Epoch: 17879, MSE: 0.22782656391742054, Learning Rate: 0.010604999999999998\n",
      "Epoch: 17880, MSE: 0.22782383497707723, Learning Rate: 0.010599999999999998\n",
      "Epoch: 17881, MSE: 0.22782110623598703, Learning Rate: 0.010595\n",
      "Epoch: 17882, MSE: 0.22781837769448698, Learning Rate: 0.01059\n",
      "Epoch: 17883, MSE: 0.22781564935291443, Learning Rate: 0.010585\n",
      "Epoch: 17884, MSE: 0.22781292121160843, Learning Rate: 0.01058\n",
      "Epoch: 17885, MSE: 0.22781019327090785, Learning Rate: 0.010575000000000001\n",
      "Epoch: 17886, MSE: 0.22780746553115153, Learning Rate: 0.010570000000000003\n",
      "Epoch: 17887, MSE: 0.2278047379926803, Learning Rate: 0.010565000000000003\n",
      "Epoch: 17888, MSE: 0.2278020106558347, Learning Rate: 0.010560000000000003\n",
      "Epoch: 17889, MSE: 0.22779928352095677, Learning Rate: 0.010555000000000004\n",
      "Epoch: 17890, MSE: 0.22779655658838746, Learning Rate: 0.010550000000000004\n",
      "Epoch: 17891, MSE: 0.22779382985846958, Learning Rate: 0.010545000000000006\n",
      "Epoch: 17892, MSE: 0.2277911033315462, Learning Rate: 0.010540000000000006\n",
      "Epoch: 17893, MSE: 0.22778837700796126, Learning Rate: 0.010535000000000006\n",
      "Epoch: 17894, MSE: 0.227785650888059, Learning Rate: 0.010529999999999996\n",
      "Epoch: 17895, MSE: 0.2277829249721836, Learning Rate: 0.010524999999999996\n",
      "Epoch: 17896, MSE: 0.2277801992606821, Learning Rate: 0.010519999999999996\n",
      "Epoch: 17897, MSE: 0.2277774737538992, Learning Rate: 0.010514999999999997\n",
      "Epoch: 17898, MSE: 0.22777474845218254, Learning Rate: 0.010509999999999999\n",
      "Epoch: 17899, MSE: 0.22777202335587934, Learning Rate: 0.010504999999999999\n",
      "Epoch: 17900, MSE: 0.22776929846533664, Learning Rate: 0.010499999999999999\n",
      "Epoch: 17901, MSE: 0.22776657378090287, Learning Rate: 0.010494999999999999\n",
      "Epoch: 17902, MSE: 0.22776384930292834, Learning Rate: 0.01049\n",
      "Epoch: 17903, MSE: 0.22776112503176274, Learning Rate: 0.010485000000000001\n",
      "Epoch: 17904, MSE: 0.22775840096775557, Learning Rate: 0.010480000000000001\n",
      "Epoch: 17905, MSE: 0.22775567711125788, Learning Rate: 0.010475000000000002\n",
      "Epoch: 17906, MSE: 0.22775295346262175, Learning Rate: 0.010470000000000002\n",
      "Epoch: 17907, MSE: 0.22775023002219844, Learning Rate: 0.010465000000000002\n",
      "Epoch: 17908, MSE: 0.2277475067903422, Learning Rate: 0.010460000000000004\n",
      "Epoch: 17909, MSE: 0.22774478376740415, Learning Rate: 0.010455000000000004\n",
      "Epoch: 17910, MSE: 0.22774206095374144, Learning Rate: 0.010450000000000004\n",
      "Epoch: 17911, MSE: 0.227739338349706, Learning Rate: 0.010445000000000005\n",
      "Epoch: 17912, MSE: 0.22773661595565423, Learning Rate: 0.010440000000000005\n",
      "Epoch: 17913, MSE: 0.22773389377194134, Learning Rate: 0.010435000000000007\n",
      "Epoch: 17914, MSE: 0.2277311717989248, Learning Rate: 0.010429999999999995\n",
      "Epoch: 17915, MSE: 0.22772845003696077, Learning Rate: 0.010424999999999997\n",
      "Epoch: 17916, MSE: 0.22772572848640812, Learning Rate: 0.010419999999999997\n",
      "Epoch: 17917, MSE: 0.22772300714762347, Learning Rate: 0.010414999999999997\n",
      "Epoch: 17918, MSE: 0.2277202860209677, Learning Rate: 0.010409999999999997\n",
      "Epoch: 17919, MSE: 0.2277175651067984, Learning Rate: 0.010404999999999998\n",
      "Epoch: 17920, MSE: 0.22771484440547807, Learning Rate: 0.0104\n",
      "Epoch: 17921, MSE: 0.22771212391736614, Learning Rate: 0.010395\n",
      "Epoch: 17922, MSE: 0.2277094036428239, Learning Rate: 0.01039\n",
      "Epoch: 17923, MSE: 0.22770668358221474, Learning Rate: 0.010385\n",
      "Epoch: 17924, MSE: 0.22770396373590007, Learning Rate: 0.01038\n",
      "Epoch: 17925, MSE: 0.2277012441042441, Learning Rate: 0.010375000000000002\n",
      "Epoch: 17926, MSE: 0.22769852468761, Learning Rate: 0.010370000000000002\n",
      "Epoch: 17927, MSE: 0.22769580548636323, Learning Rate: 0.010365000000000003\n",
      "Epoch: 17928, MSE: 0.2276930865008693, Learning Rate: 0.010360000000000003\n",
      "Epoch: 17929, MSE: 0.22769036773149348, Learning Rate: 0.010355000000000003\n",
      "Epoch: 17930, MSE: 0.22768764917860262, Learning Rate: 0.010350000000000005\n",
      "Epoch: 17931, MSE: 0.2276849308425645, Learning Rate: 0.010345000000000005\n",
      "Epoch: 17932, MSE: 0.22768221272374553, Learning Rate: 0.010340000000000005\n",
      "Epoch: 17933, MSE: 0.22767949482251515, Learning Rate: 0.010335000000000006\n",
      "Epoch: 17934, MSE: 0.22767677713924275, Learning Rate: 0.010329999999999995\n",
      "Epoch: 17935, MSE: 0.22767405967429788, Learning Rate: 0.010324999999999996\n",
      "Epoch: 17936, MSE: 0.22767134242805112, Learning Rate: 0.010319999999999996\n",
      "Epoch: 17937, MSE: 0.22766862540087282, Learning Rate: 0.010314999999999998\n",
      "Epoch: 17938, MSE: 0.2276659085931357, Learning Rate: 0.010309999999999998\n",
      "Epoch: 17939, MSE: 0.22766319200521154, Learning Rate: 0.010304999999999998\n",
      "Epoch: 17940, MSE: 0.22766047563747396, Learning Rate: 0.010299999999999998\n",
      "Epoch: 17941, MSE: 0.22765775949029554, Learning Rate: 0.010294999999999999\n",
      "Epoch: 17942, MSE: 0.2276550435640522, Learning Rate: 0.01029\n",
      "Epoch: 17943, MSE: 0.22765232785911793, Learning Rate: 0.010285\n",
      "Epoch: 17944, MSE: 0.22764961237586867, Learning Rate: 0.010280000000000001\n",
      "Epoch: 17945, MSE: 0.2276468971146804, Learning Rate: 0.010275000000000001\n",
      "Epoch: 17946, MSE: 0.2276441820759317, Learning Rate: 0.010270000000000001\n",
      "Epoch: 17947, MSE: 0.2276414672599973, Learning Rate: 0.010265000000000003\n",
      "Epoch: 17948, MSE: 0.22763875266725817, Learning Rate: 0.010260000000000003\n",
      "Epoch: 17949, MSE: 0.2276360382980925, Learning Rate: 0.010255000000000004\n",
      "Epoch: 17950, MSE: 0.2276333241528798, Learning Rate: 0.010250000000000004\n",
      "Epoch: 17951, MSE: 0.22763061023199993, Learning Rate: 0.010245000000000004\n",
      "Epoch: 17952, MSE: 0.22762789653583457, Learning Rate: 0.010240000000000006\n",
      "Epoch: 17953, MSE: 0.2276251830647653, Learning Rate: 0.010235000000000006\n",
      "Epoch: 17954, MSE: 0.22762246981917356, Learning Rate: 0.010229999999999996\n",
      "Epoch: 17955, MSE: 0.22761975679944363, Learning Rate: 0.010224999999999996\n",
      "Epoch: 17956, MSE: 0.2276170440059594, Learning Rate: 0.010219999999999996\n",
      "Epoch: 17957, MSE: 0.22761433143910403, Learning Rate: 0.010214999999999997\n",
      "Epoch: 17958, MSE: 0.2276116190992625, Learning Rate: 0.010209999999999997\n",
      "Epoch: 17959, MSE: 0.2276089069868211, Learning Rate: 0.010204999999999999\n",
      "Epoch: 17960, MSE: 0.22760619510216676, Learning Rate: 0.010199999999999999\n",
      "Epoch: 17961, MSE: 0.22760348344568582, Learning Rate: 0.010195\n",
      "Epoch: 17962, MSE: 0.22760077201776577, Learning Rate: 0.01019\n",
      "Epoch: 17963, MSE: 0.22759806081879602, Learning Rate: 0.010185\n",
      "Epoch: 17964, MSE: 0.227595349849165, Learning Rate: 0.010180000000000002\n",
      "Epoch: 17965, MSE: 0.22759263910926233, Learning Rate: 0.010175000000000002\n",
      "Epoch: 17966, MSE: 0.22758992859947952, Learning Rate: 0.010170000000000002\n",
      "Epoch: 17967, MSE: 0.22758721832020615, Learning Rate: 0.010165000000000002\n",
      "Epoch: 17968, MSE: 0.22758450827183538, Learning Rate: 0.010160000000000002\n",
      "Epoch: 17969, MSE: 0.22758179845475948, Learning Rate: 0.010155000000000004\n",
      "Epoch: 17970, MSE: 0.2275790888693718, Learning Rate: 0.010150000000000005\n",
      "Epoch: 17971, MSE: 0.22757637951606588, Learning Rate: 0.010145000000000005\n",
      "Epoch: 17972, MSE: 0.22757367039523677, Learning Rate: 0.010140000000000005\n",
      "Epoch: 17973, MSE: 0.2275709615072797, Learning Rate: 0.010135000000000005\n",
      "Epoch: 17974, MSE: 0.22756825285259072, Learning Rate: 0.010129999999999995\n",
      "Epoch: 17975, MSE: 0.22756554443156715, Learning Rate: 0.010124999999999995\n",
      "Epoch: 17976, MSE: 0.22756283624460502, Learning Rate: 0.010119999999999997\n",
      "Epoch: 17977, MSE: 0.2275601282921037, Learning Rate: 0.010114999999999997\n",
      "Epoch: 17978, MSE: 0.22755742057446132, Learning Rate: 0.010109999999999997\n",
      "Epoch: 17979, MSE: 0.22755471309207836, Learning Rate: 0.010104999999999998\n",
      "Epoch: 17980, MSE: 0.22755200584535434, Learning Rate: 0.010099999999999998\n",
      "Epoch: 17981, MSE: 0.22754929883469022, Learning Rate: 0.010095\n",
      "Epoch: 17982, MSE: 0.227546592060488, Learning Rate: 0.01009\n",
      "Epoch: 17983, MSE: 0.22754388552315033, Learning Rate: 0.010085\n",
      "Epoch: 17984, MSE: 0.22754117922307973, Learning Rate: 0.01008\n",
      "Epoch: 17985, MSE: 0.22753847316068065, Learning Rate: 0.010075\n",
      "Epoch: 17986, MSE: 0.22753576733635628, Learning Rate: 0.010070000000000003\n",
      "Epoch: 17987, MSE: 0.2275330617505136, Learning Rate: 0.010065000000000003\n",
      "Epoch: 17988, MSE: 0.22753035640355787, Learning Rate: 0.010060000000000003\n",
      "Epoch: 17989, MSE: 0.22752765129589633, Learning Rate: 0.010055000000000003\n",
      "Epoch: 17990, MSE: 0.22752494642793492, Learning Rate: 0.010050000000000003\n",
      "Epoch: 17991, MSE: 0.22752224180008235, Learning Rate: 0.010045000000000005\n",
      "Epoch: 17992, MSE: 0.2275195374127488, Learning Rate: 0.010040000000000006\n",
      "Epoch: 17993, MSE: 0.2275168332663428, Learning Rate: 0.010035000000000006\n",
      "Epoch: 17994, MSE: 0.22751412936127446, Learning Rate: 0.010029999999999996\n",
      "Epoch: 17995, MSE: 0.2275114256979556, Learning Rate: 0.010024999999999996\n",
      "Epoch: 17996, MSE: 0.2275087222767966, Learning Rate: 0.010019999999999996\n",
      "Epoch: 17997, MSE: 0.22750601909821186, Learning Rate: 0.010014999999999996\n",
      "Epoch: 17998, MSE: 0.2275033161626129, Learning Rate: 0.010009999999999998\n",
      "Epoch: 17999, MSE: 0.2275006134704156, Learning Rate: 0.010004999999999998\n",
      "Epoch: 18000, MSE: 0.22749791102203268, Learning Rate: 0.01\n",
      "Epoch: 18001, MSE: 0.22749520881788032, Learning Rate: 0.01\n",
      "Epoch: 18002, MSE: 0.22749514811970356, Learning Rate: 0.01\n",
      "Epoch: 18003, MSE: 0.22749514816347494, Learning Rate: 0.01\n",
      "Epoch: 18004, MSE: 0.22749514819286062, Learning Rate: 0.01\n",
      "Epoch: 18005, MSE: 0.2274951482125881, Learning Rate: 0.01\n",
      "Epoch: 18006, MSE: 0.2274951482258329, Learning Rate: 0.01\n",
      "Epoch: 18007, MSE: 0.22749514823472516, Learning Rate: 0.01\n",
      "Epoch: 18008, MSE: 0.22749514824069714, Learning Rate: 0.01\n",
      "Epoch: 18009, MSE: 0.2274951482447093, Learning Rate: 0.01\n",
      "Epoch: 18010, MSE: 0.22749514824740577, Learning Rate: 0.01\n",
      "Epoch: 18011, MSE: 0.22749514824921896, Learning Rate: 0.01\n",
      "Epoch: 18012, MSE: 0.22749514825044087, Learning Rate: 0.01\n",
      "Epoch: 18013, MSE: 0.2274951482512646, Learning Rate: 0.01\n",
      "Epoch: 18014, MSE: 0.22749514825182132, Learning Rate: 0.01\n",
      "Epoch: 18015, MSE: 0.22749514825219921, Learning Rate: 0.01\n",
      "Epoch: 18016, MSE: 0.2274951482524572, Learning Rate: 0.01\n",
      "Epoch: 18017, MSE: 0.22749514825263403, Learning Rate: 0.01\n",
      "Epoch: 18018, MSE: 0.2274951482527577, Learning Rate: 0.01\n",
      "Epoch: 18019, MSE: 0.2274951482528443, Learning Rate: 0.01\n",
      "Epoch: 18020, MSE: 0.22749514825290748, Learning Rate: 0.01\n",
      "Epoch: 18021, MSE: 0.22749514825295325, Learning Rate: 0.01\n",
      "Epoch: 18022, MSE: 0.22749514825298772, Learning Rate: 0.01\n",
      "Epoch: 18023, MSE: 0.22749514825301556, Learning Rate: 0.01\n",
      "Epoch: 18024, MSE: 0.2274951482530389, Learning Rate: 0.01\n",
      "Epoch: 18025, MSE: 0.2274951482530577, Learning Rate: 0.01\n",
      "Epoch: 18026, MSE: 0.2274951482530755, Learning Rate: 0.01\n",
      "Epoch: 18027, MSE: 0.22749514825309147, Learning Rate: 0.01\n",
      "Epoch: 18028, MSE: 0.22749514825310604, Learning Rate: 0.01\n",
      "Epoch: 18029, MSE: 0.22749514825311998, Learning Rate: 0.01\n",
      "Epoch: 18030, MSE: 0.227495148253133, Learning Rate: 0.01\n",
      "Epoch: 18031, MSE: 0.22749514825314698, Learning Rate: 0.01\n",
      "Epoch: 18032, MSE: 0.22749514825316036, Learning Rate: 0.01\n",
      "Epoch: 18033, MSE: 0.2274951482531729, Learning Rate: 0.01\n",
      "Epoch: 18034, MSE: 0.22749514825318667, Learning Rate: 0.01\n",
      "Epoch: 18035, MSE: 0.22749514825319925, Learning Rate: 0.01\n",
      "Epoch: 18036, MSE: 0.22749514825321254, Learning Rate: 0.01\n",
      "Epoch: 18037, MSE: 0.22749514825322428, Learning Rate: 0.01\n",
      "Epoch: 18038, MSE: 0.22749514825323744, Learning Rate: 0.01\n",
      "Epoch: 18039, MSE: 0.2274951482532502, Learning Rate: 0.01\n",
      "Epoch: 18040, MSE: 0.22749514825326306, Learning Rate: 0.01\n",
      "Epoch: 18041, MSE: 0.2274951482532755, Learning Rate: 0.01\n",
      "Epoch: 18042, MSE: 0.22749514825328865, Learning Rate: 0.01\n",
      "Epoch: 18043, MSE: 0.22749514825330164, Learning Rate: 0.01\n",
      "Epoch: 18044, MSE: 0.22749514825331427, Learning Rate: 0.01\n",
      "Epoch: 18045, MSE: 0.2274951482533268, Learning Rate: 0.01\n",
      "Epoch: 18046, MSE: 0.2274951482533396, Learning Rate: 0.01\n",
      "Epoch: 18047, MSE: 0.2274951482533526, Learning Rate: 0.01\n",
      "Epoch: 18048, MSE: 0.22749514825336534, Learning Rate: 0.01\n",
      "Epoch: 18049, MSE: 0.22749514825337755, Learning Rate: 0.01\n",
      "Epoch: 18050, MSE: 0.22749514825339065, Learning Rate: 0.01\n",
      "Epoch: 18051, MSE: 0.227495148253404, Learning Rate: 0.01\n",
      "Epoch: 18052, MSE: 0.22749514825341596, Learning Rate: 0.01\n",
      "Epoch: 18053, MSE: 0.22749514825342912, Learning Rate: 0.01\n",
      "Epoch: 18054, MSE: 0.22749514825344175, Learning Rate: 0.01\n",
      "Epoch: 18055, MSE: 0.22749514825345435, Learning Rate: 0.01\n",
      "Epoch: 18056, MSE: 0.22749514825346698, Learning Rate: 0.01\n",
      "Epoch: 18057, MSE: 0.22749514825347997, Learning Rate: 0.01\n",
      "Epoch: 18058, MSE: 0.2274951482534927, Learning Rate: 0.01\n",
      "Epoch: 18059, MSE: 0.22749514825350536, Learning Rate: 0.01\n",
      "Epoch: 18060, MSE: 0.22749514825351813, Learning Rate: 0.01\n",
      "Epoch: 18061, MSE: 0.22749514825353054, Learning Rate: 0.01\n",
      "Epoch: 18062, MSE: 0.22749514825354383, Learning Rate: 0.01\n",
      "Epoch: 18063, MSE: 0.2274951482535561, Learning Rate: 0.01\n",
      "Epoch: 18064, MSE: 0.22749514825356906, Learning Rate: 0.01\n",
      "Epoch: 18065, MSE: 0.22749514825358153, Learning Rate: 0.01\n",
      "Epoch: 18066, MSE: 0.2274951482535948, Learning Rate: 0.01\n",
      "Epoch: 18067, MSE: 0.2274951482536073, Learning Rate: 0.01\n",
      "Epoch: 18068, MSE: 0.22749514825362, Learning Rate: 0.01\n",
      "Epoch: 18069, MSE: 0.22749514825363265, Learning Rate: 0.01\n",
      "Epoch: 18070, MSE: 0.22749514825364517, Learning Rate: 0.01\n",
      "Epoch: 18071, MSE: 0.22749514825365816, Learning Rate: 0.01\n",
      "Epoch: 18072, MSE: 0.22749514825367095, Learning Rate: 0.01\n",
      "Epoch: 18073, MSE: 0.2274951482536836, Learning Rate: 0.01\n",
      "Epoch: 18074, MSE: 0.2274951482536964, Learning Rate: 0.01\n",
      "Epoch: 18075, MSE: 0.22749514825370917, Learning Rate: 0.01\n",
      "Epoch: 18076, MSE: 0.22749514825372188, Learning Rate: 0.01\n",
      "Epoch: 18077, MSE: 0.22749514825373432, Learning Rate: 0.01\n",
      "Epoch: 18078, MSE: 0.22749514825374775, Learning Rate: 0.01\n",
      "Epoch: 18079, MSE: 0.22749514825375983, Learning Rate: 0.01\n",
      "Epoch: 18080, MSE: 0.22749514825377265, Learning Rate: 0.01\n",
      "Epoch: 18081, MSE: 0.2274951482537855, Learning Rate: 0.01\n",
      "Epoch: 18082, MSE: 0.2274951482537983, Learning Rate: 0.01\n",
      "Epoch: 18083, MSE: 0.22749514825381145, Learning Rate: 0.01\n",
      "Epoch: 18084, MSE: 0.22749514825382364, Learning Rate: 0.01\n",
      "Epoch: 18085, MSE: 0.22749514825383665, Learning Rate: 0.01\n",
      "Epoch: 18086, MSE: 0.2274951482538493, Learning Rate: 0.01\n",
      "Epoch: 18087, MSE: 0.22749514825386216, Learning Rate: 0.01\n",
      "Epoch: 18088, MSE: 0.22749514825387485, Learning Rate: 0.01\n",
      "Epoch: 18089, MSE: 0.2274951482538879, Learning Rate: 0.01\n",
      "Epoch: 18090, MSE: 0.22749514825390008, Learning Rate: 0.01\n",
      "Epoch: 18091, MSE: 0.22749514825391304, Learning Rate: 0.01\n",
      "Epoch: 18092, MSE: 0.22749514825392617, Learning Rate: 0.01\n",
      "Epoch: 18093, MSE: 0.22749514825393893, Learning Rate: 0.01\n",
      "Epoch: 18094, MSE: 0.22749514825395112, Learning Rate: 0.01\n",
      "Epoch: 18095, MSE: 0.22749514825396433, Learning Rate: 0.01\n",
      "Epoch: 18096, MSE: 0.227495148253977, Learning Rate: 0.01\n",
      "Epoch: 18097, MSE: 0.2274951482539895, Learning Rate: 0.01\n",
      "Epoch: 18098, MSE: 0.22749514825400252, Learning Rate: 0.01\n",
      "Epoch: 18099, MSE: 0.22749514825401507, Learning Rate: 0.01\n",
      "Epoch: 18100, MSE: 0.22749514825402803, Learning Rate: 0.01\n",
      "Epoch: 18101, MSE: 0.2274951482540404, Learning Rate: 0.01\n",
      "Epoch: 18102, MSE: 0.2274951482540537, Learning Rate: 0.01\n",
      "Epoch: 18103, MSE: 0.22749514825406594, Learning Rate: 0.01\n",
      "Epoch: 18104, MSE: 0.22749514825407816, Learning Rate: 0.01\n",
      "Epoch: 18105, MSE: 0.22749514825409134, Learning Rate: 0.01\n",
      "Epoch: 18106, MSE: 0.22749514825410408, Learning Rate: 0.01\n",
      "Epoch: 18107, MSE: 0.22749514825411712, Learning Rate: 0.01\n",
      "Epoch: 18108, MSE: 0.22749514825413006, Learning Rate: 0.01\n",
      "Epoch: 18109, MSE: 0.22749514825414274, Learning Rate: 0.01\n",
      "Epoch: 18110, MSE: 0.22749514825415526, Learning Rate: 0.01\n",
      "Epoch: 18111, MSE: 0.22749514825416786, Learning Rate: 0.01\n",
      "Epoch: 18112, MSE: 0.22749514825418116, Learning Rate: 0.01\n",
      "Epoch: 18113, MSE: 0.2274951482541937, Learning Rate: 0.01\n",
      "Epoch: 18114, MSE: 0.22749514825420608, Learning Rate: 0.01\n",
      "Epoch: 18115, MSE: 0.22749514825421874, Learning Rate: 0.01\n",
      "Epoch: 18116, MSE: 0.22749514825423178, Learning Rate: 0.01\n",
      "Epoch: 18117, MSE: 0.22749514825424424, Learning Rate: 0.01\n",
      "Epoch: 18118, MSE: 0.22749514825425732, Learning Rate: 0.01\n",
      "Epoch: 18119, MSE: 0.22749514825426975, Learning Rate: 0.01\n",
      "Epoch: 18120, MSE: 0.22749514825428233, Learning Rate: 0.01\n",
      "Epoch: 18121, MSE: 0.22749514825429504, Learning Rate: 0.01\n",
      "Epoch: 18122, MSE: 0.22749514825430805, Learning Rate: 0.01\n",
      "Epoch: 18123, MSE: 0.22749514825432035, Learning Rate: 0.01\n",
      "Epoch: 18124, MSE: 0.2274951482543335, Learning Rate: 0.01\n",
      "Epoch: 18125, MSE: 0.2274951482543464, Learning Rate: 0.01\n",
      "Epoch: 18126, MSE: 0.22749514825435893, Learning Rate: 0.01\n",
      "Epoch: 18127, MSE: 0.22749514825437148, Learning Rate: 0.01\n",
      "Epoch: 18128, MSE: 0.22749514825438488, Learning Rate: 0.01\n",
      "Epoch: 18129, MSE: 0.22749514825439776, Learning Rate: 0.01\n",
      "Epoch: 18130, MSE: 0.22749514825441006, Learning Rate: 0.01\n",
      "Epoch: 18131, MSE: 0.22749514825442277, Learning Rate: 0.01\n",
      "Epoch: 18132, MSE: 0.22749514825443554, Learning Rate: 0.01\n",
      "Epoch: 18133, MSE: 0.22749514825444828, Learning Rate: 0.01\n",
      "Epoch: 18134, MSE: 0.22749514825446074, Learning Rate: 0.01\n",
      "Epoch: 18135, MSE: 0.2274951482544737, Learning Rate: 0.01\n",
      "Epoch: 18136, MSE: 0.22749514825448644, Learning Rate: 0.01\n",
      "Epoch: 18137, MSE: 0.22749514825449949, Learning Rate: 0.01\n",
      "Epoch: 18138, MSE: 0.22749514825451206, Learning Rate: 0.01\n",
      "Epoch: 18139, MSE: 0.2274951482545245, Learning Rate: 0.01\n",
      "Epoch: 18140, MSE: 0.22749514825453757, Learning Rate: 0.01\n",
      "Epoch: 18141, MSE: 0.22749514825455025, Learning Rate: 0.01\n",
      "Epoch: 18142, MSE: 0.22749514825456257, Learning Rate: 0.01\n",
      "Epoch: 18143, MSE: 0.22749514825457584, Learning Rate: 0.01\n",
      "Epoch: 18144, MSE: 0.22749514825458853, Learning Rate: 0.01\n",
      "Epoch: 18145, MSE: 0.2274951482546013, Learning Rate: 0.01\n",
      "Epoch: 18146, MSE: 0.22749514825461373, Learning Rate: 0.01\n",
      "Epoch: 18147, MSE: 0.2274951482546267, Learning Rate: 0.01\n",
      "Epoch: 18148, MSE: 0.22749514825463985, Learning Rate: 0.01\n",
      "Epoch: 18149, MSE: 0.2274951482546519, Learning Rate: 0.01\n",
      "Epoch: 18150, MSE: 0.22749514825466485, Learning Rate: 0.01\n",
      "Epoch: 18151, MSE: 0.22749514825467773, Learning Rate: 0.01\n",
      "Epoch: 18152, MSE: 0.22749514825469055, Learning Rate: 0.01\n",
      "Epoch: 18153, MSE: 0.2274951482547031, Learning Rate: 0.01\n",
      "Epoch: 18154, MSE: 0.2274951482547157, Learning Rate: 0.01\n",
      "Epoch: 18155, MSE: 0.22749514825472883, Learning Rate: 0.01\n",
      "Epoch: 18156, MSE: 0.22749514825474101, Learning Rate: 0.01\n",
      "Epoch: 18157, MSE: 0.22749514825475387, Learning Rate: 0.01\n",
      "Epoch: 18158, MSE: 0.22749514825476713, Learning Rate: 0.01\n",
      "Epoch: 18159, MSE: 0.22749514825477965, Learning Rate: 0.01\n",
      "Epoch: 18160, MSE: 0.22749514825479214, Learning Rate: 0.01\n",
      "Epoch: 18161, MSE: 0.22749514825480507, Learning Rate: 0.01\n",
      "Epoch: 18162, MSE: 0.22749514825481773, Learning Rate: 0.01\n",
      "Epoch: 18163, MSE: 0.227495148254831, Learning Rate: 0.01\n",
      "Epoch: 18164, MSE: 0.22749514825484327, Learning Rate: 0.01\n",
      "Epoch: 18165, MSE: 0.22749514825485567, Learning Rate: 0.01\n",
      "Epoch: 18166, MSE: 0.22749514825486794, Learning Rate: 0.01\n",
      "Epoch: 18167, MSE: 0.22749514825488143, Learning Rate: 0.01\n",
      "Epoch: 18168, MSE: 0.2274951482548944, Learning Rate: 0.01\n",
      "Epoch: 18169, MSE: 0.22749514825490647, Learning Rate: 0.01\n",
      "Epoch: 18170, MSE: 0.2274951482549198, Learning Rate: 0.01\n",
      "Epoch: 18171, MSE: 0.22749514825493275, Learning Rate: 0.01\n",
      "Epoch: 18172, MSE: 0.2274951482549452, Learning Rate: 0.01\n",
      "Epoch: 18173, MSE: 0.2274951482549582, Learning Rate: 0.01\n",
      "Epoch: 18174, MSE: 0.22749514825497094, Learning Rate: 0.01\n",
      "Epoch: 18175, MSE: 0.22749514825498351, Learning Rate: 0.01\n",
      "Epoch: 18176, MSE: 0.22749514825499584, Learning Rate: 0.01\n",
      "Epoch: 18177, MSE: 0.22749514825500883, Learning Rate: 0.01\n",
      "Epoch: 18178, MSE: 0.2274951482550219, Learning Rate: 0.01\n",
      "Epoch: 18179, MSE: 0.22749514825503425, Learning Rate: 0.01\n",
      "Epoch: 18180, MSE: 0.22749514825504744, Learning Rate: 0.01\n",
      "Epoch: 18181, MSE: 0.22749514825506026, Learning Rate: 0.01\n",
      "Epoch: 18182, MSE: 0.22749514825507292, Learning Rate: 0.01\n",
      "Epoch: 18183, MSE: 0.2274951482550855, Learning Rate: 0.01\n",
      "Epoch: 18184, MSE: 0.2274951482550988, Learning Rate: 0.01\n",
      "Epoch: 18185, MSE: 0.2274951482551108, Learning Rate: 0.01\n",
      "Epoch: 18186, MSE: 0.2274951482551233, Learning Rate: 0.01\n",
      "Epoch: 18187, MSE: 0.22749514825513628, Learning Rate: 0.01\n",
      "Epoch: 18188, MSE: 0.22749514825514888, Learning Rate: 0.01\n",
      "Epoch: 18189, MSE: 0.22749514825516154, Learning Rate: 0.01\n",
      "Epoch: 18190, MSE: 0.22749514825517428, Learning Rate: 0.01\n",
      "Epoch: 18191, MSE: 0.227495148255187, Learning Rate: 0.01\n",
      "Epoch: 18192, MSE: 0.22749514825520006, Learning Rate: 0.01\n",
      "Epoch: 18193, MSE: 0.22749514825521308, Learning Rate: 0.01\n",
      "Epoch: 18194, MSE: 0.22749514825522593, Learning Rate: 0.01\n",
      "Epoch: 18195, MSE: 0.22749514825523845, Learning Rate: 0.01\n",
      "Epoch: 18196, MSE: 0.22749514825525063, Learning Rate: 0.01\n",
      "Epoch: 18197, MSE: 0.22749514825526376, Learning Rate: 0.01\n",
      "Epoch: 18198, MSE: 0.22749514825527656, Learning Rate: 0.01\n",
      "Epoch: 18199, MSE: 0.2274951482552894, Learning Rate: 0.01\n",
      "Epoch: 18200, MSE: 0.22749514825530257, Learning Rate: 0.01\n",
      "Epoch: 18201, MSE: 0.22749514825531464, Learning Rate: 0.01\n",
      "Epoch: 18202, MSE: 0.22749514825532766, Learning Rate: 0.01\n",
      "Epoch: 18203, MSE: 0.22749514825534015, Learning Rate: 0.01\n",
      "Epoch: 18204, MSE: 0.22749514825535322, Learning Rate: 0.01\n",
      "Epoch: 18205, MSE: 0.22749514825536565, Learning Rate: 0.01\n",
      "Epoch: 18206, MSE: 0.2274951482553784, Learning Rate: 0.01\n",
      "Epoch: 18207, MSE: 0.22749514825539136, Learning Rate: 0.01\n",
      "Epoch: 18208, MSE: 0.22749514825540426, Learning Rate: 0.01\n",
      "Epoch: 18209, MSE: 0.22749514825541634, Learning Rate: 0.01\n",
      "Epoch: 18210, MSE: 0.22749514825542977, Learning Rate: 0.01\n",
      "Epoch: 18211, MSE: 0.22749514825544184, Learning Rate: 0.01\n",
      "Epoch: 18212, MSE: 0.22749514825545478, Learning Rate: 0.01\n",
      "Epoch: 18213, MSE: 0.22749514825546768, Learning Rate: 0.01\n",
      "Epoch: 18214, MSE: 0.22749514825547984, Learning Rate: 0.01\n",
      "Epoch: 18215, MSE: 0.22749514825549322, Learning Rate: 0.01\n",
      "Epoch: 18216, MSE: 0.2274951482555058, Learning Rate: 0.01\n",
      "Epoch: 18217, MSE: 0.22749514825551864, Learning Rate: 0.01\n",
      "Epoch: 18218, MSE: 0.22749514825553108, Learning Rate: 0.01\n",
      "Epoch: 18219, MSE: 0.22749514825554396, Learning Rate: 0.01\n",
      "Epoch: 18220, MSE: 0.227495148255557, Learning Rate: 0.01\n",
      "Epoch: 18221, MSE: 0.22749514825556966, Learning Rate: 0.01\n",
      "Epoch: 18222, MSE: 0.22749514825558192, Learning Rate: 0.01\n",
      "Epoch: 18223, MSE: 0.2274951482555949, Learning Rate: 0.01\n",
      "Epoch: 18224, MSE: 0.22749514825560782, Learning Rate: 0.01\n",
      "Epoch: 18225, MSE: 0.22749514825562028, Learning Rate: 0.01\n",
      "Epoch: 18226, MSE: 0.22749514825563333, Learning Rate: 0.01\n",
      "Epoch: 18227, MSE: 0.22749514825564568, Learning Rate: 0.01\n",
      "Epoch: 18228, MSE: 0.22749514825565828, Learning Rate: 0.01\n",
      "Epoch: 18229, MSE: 0.2274951482556714, Learning Rate: 0.01\n",
      "Epoch: 18230, MSE: 0.22749514825568454, Learning Rate: 0.01\n",
      "Epoch: 18231, MSE: 0.22749514825569664, Learning Rate: 0.01\n",
      "Epoch: 18232, MSE: 0.22749514825570927, Learning Rate: 0.01\n",
      "Epoch: 18233, MSE: 0.22749514825572248, Learning Rate: 0.01\n",
      "Epoch: 18234, MSE: 0.22749514825573458, Learning Rate: 0.01\n",
      "Epoch: 18235, MSE: 0.22749514825574785, Learning Rate: 0.01\n",
      "Epoch: 18236, MSE: 0.22749514825576053, Learning Rate: 0.01\n",
      "Epoch: 18237, MSE: 0.22749514825577338, Learning Rate: 0.01\n",
      "Epoch: 18238, MSE: 0.22749514825578634, Learning Rate: 0.01\n",
      "Epoch: 18239, MSE: 0.2274951482557989, Learning Rate: 0.01\n",
      "Epoch: 18240, MSE: 0.22749514825581155, Learning Rate: 0.01\n",
      "Epoch: 18241, MSE: 0.22749514825582454, Learning Rate: 0.01\n",
      "Epoch: 18242, MSE: 0.22749514825583697, Learning Rate: 0.01\n",
      "Epoch: 18243, MSE: 0.22749514825585004, Learning Rate: 0.01\n",
      "Epoch: 18244, MSE: 0.22749514825586217, Learning Rate: 0.01\n",
      "Epoch: 18245, MSE: 0.22749514825587516, Learning Rate: 0.01\n",
      "Epoch: 18246, MSE: 0.22749514825588854, Learning Rate: 0.01\n",
      "Epoch: 18247, MSE: 0.22749514825590064, Learning Rate: 0.01\n",
      "Epoch: 18248, MSE: 0.22749514825591347, Learning Rate: 0.01\n",
      "Epoch: 18249, MSE: 0.22749514825592598, Learning Rate: 0.01\n",
      "Epoch: 18250, MSE: 0.22749514825593872, Learning Rate: 0.01\n",
      "Epoch: 18251, MSE: 0.2274951482559516, Learning Rate: 0.01\n",
      "Epoch: 18252, MSE: 0.22749514825596398, Learning Rate: 0.01\n",
      "Epoch: 18253, MSE: 0.22749514825597694, Learning Rate: 0.01\n",
      "Epoch: 18254, MSE: 0.22749514825599007, Learning Rate: 0.01\n",
      "Epoch: 18255, MSE: 0.2274951482560023, Learning Rate: 0.01\n",
      "Epoch: 18256, MSE: 0.22749514825601527, Learning Rate: 0.01\n",
      "Epoch: 18257, MSE: 0.22749514825602782, Learning Rate: 0.01\n",
      "Epoch: 18258, MSE: 0.2274951482560406, Learning Rate: 0.01\n",
      "Epoch: 18259, MSE: 0.22749514825605333, Learning Rate: 0.01\n",
      "Epoch: 18260, MSE: 0.2274951482560661, Learning Rate: 0.01\n",
      "Epoch: 18261, MSE: 0.2274951482560787, Learning Rate: 0.01\n",
      "Epoch: 18262, MSE: 0.22749514825609155, Learning Rate: 0.01\n",
      "Epoch: 18263, MSE: 0.22749514825610442, Learning Rate: 0.01\n",
      "Epoch: 18264, MSE: 0.2274951482561175, Learning Rate: 0.01\n",
      "Epoch: 18265, MSE: 0.22749514825612968, Learning Rate: 0.01\n",
      "Epoch: 18266, MSE: 0.22749514825614328, Learning Rate: 0.01\n",
      "Epoch: 18267, MSE: 0.22749514825615533, Learning Rate: 0.01\n",
      "Epoch: 18268, MSE: 0.22749514825616796, Learning Rate: 0.01\n",
      "Epoch: 18269, MSE: 0.22749514825618067, Learning Rate: 0.01\n",
      "Epoch: 18270, MSE: 0.22749514825619402, Learning Rate: 0.01\n",
      "Epoch: 18271, MSE: 0.22749514825620626, Learning Rate: 0.01\n",
      "Epoch: 18272, MSE: 0.22749514825621925, Learning Rate: 0.01\n",
      "Epoch: 18273, MSE: 0.2274951482562316, Learning Rate: 0.01\n",
      "Epoch: 18274, MSE: 0.22749514825624467, Learning Rate: 0.01\n",
      "Epoch: 18275, MSE: 0.2274951482562573, Learning Rate: 0.01\n",
      "Epoch: 18276, MSE: 0.22749514825626985, Learning Rate: 0.01\n",
      "Epoch: 18277, MSE: 0.2274951482562823, Learning Rate: 0.01\n",
      "Epoch: 18278, MSE: 0.22749514825629558, Learning Rate: 0.01\n",
      "Epoch: 18279, MSE: 0.22749514825630832, Learning Rate: 0.01\n",
      "Epoch: 18280, MSE: 0.2274951482563211, Learning Rate: 0.01\n",
      "Epoch: 18281, MSE: 0.2274951482563336, Learning Rate: 0.01\n",
      "Epoch: 18282, MSE: 0.22749514825634626, Learning Rate: 0.01\n",
      "Epoch: 18283, MSE: 0.22749514825635903, Learning Rate: 0.01\n",
      "Epoch: 18284, MSE: 0.22749514825637204, Learning Rate: 0.01\n",
      "Epoch: 18285, MSE: 0.2274951482563847, Learning Rate: 0.01\n",
      "Epoch: 18286, MSE: 0.2274951482563974, Learning Rate: 0.01\n",
      "Epoch: 18287, MSE: 0.2274951482564102, Learning Rate: 0.01\n",
      "Epoch: 18288, MSE: 0.22749514825642322, Learning Rate: 0.01\n",
      "Epoch: 18289, MSE: 0.22749514825643552, Learning Rate: 0.01\n",
      "Epoch: 18290, MSE: 0.22749514825644826, Learning Rate: 0.01\n",
      "Epoch: 18291, MSE: 0.22749514825646136, Learning Rate: 0.01\n",
      "Epoch: 18292, MSE: 0.22749514825647346, Learning Rate: 0.01\n",
      "Epoch: 18293, MSE: 0.22749514825648642, Learning Rate: 0.01\n",
      "Epoch: 18294, MSE: 0.2274951482564987, Learning Rate: 0.01\n",
      "Epoch: 18295, MSE: 0.22749514825651188, Learning Rate: 0.01\n",
      "Epoch: 18296, MSE: 0.2274951482565248, Learning Rate: 0.01\n",
      "Epoch: 18297, MSE: 0.22749514825653733, Learning Rate: 0.01\n",
      "Epoch: 18298, MSE: 0.2274951482565499, Learning Rate: 0.01\n",
      "Epoch: 18299, MSE: 0.22749514825656286, Learning Rate: 0.01\n",
      "Epoch: 18300, MSE: 0.22749514825657574, Learning Rate: 0.01\n",
      "Epoch: 18301, MSE: 0.22749514825658843, Learning Rate: 0.01\n",
      "Epoch: 18302, MSE: 0.22749514825660133, Learning Rate: 0.01\n",
      "Epoch: 18303, MSE: 0.2274951482566139, Learning Rate: 0.01\n",
      "Epoch: 18304, MSE: 0.22749514825662612, Learning Rate: 0.01\n",
      "Epoch: 18305, MSE: 0.22749514825663913, Learning Rate: 0.01\n",
      "Epoch: 18306, MSE: 0.227495148256652, Learning Rate: 0.01\n",
      "Epoch: 18307, MSE: 0.22749514825666506, Learning Rate: 0.01\n",
      "Epoch: 18308, MSE: 0.22749514825667772, Learning Rate: 0.01\n",
      "Epoch: 18309, MSE: 0.2274951482566908, Learning Rate: 0.01\n",
      "Epoch: 18310, MSE: 0.22749514825670308, Learning Rate: 0.01\n",
      "Epoch: 18311, MSE: 0.22749514825671574, Learning Rate: 0.01\n",
      "Epoch: 18312, MSE: 0.2274951482567284, Learning Rate: 0.01\n",
      "Epoch: 18313, MSE: 0.2274951482567413, Learning Rate: 0.01\n",
      "Epoch: 18314, MSE: 0.22749514825675415, Learning Rate: 0.01\n",
      "Epoch: 18315, MSE: 0.22749514825676662, Learning Rate: 0.01\n",
      "Epoch: 18316, MSE: 0.22749514825677933, Learning Rate: 0.01\n",
      "Epoch: 18317, MSE: 0.22749514825679173, Learning Rate: 0.01\n",
      "Epoch: 18318, MSE: 0.22749514825680506, Learning Rate: 0.01\n",
      "Epoch: 18319, MSE: 0.22749514825681744, Learning Rate: 0.01\n",
      "Epoch: 18320, MSE: 0.2274951482568304, Learning Rate: 0.01\n",
      "Epoch: 18321, MSE: 0.22749514825684328, Learning Rate: 0.01\n",
      "Epoch: 18322, MSE: 0.2274951482568558, Learning Rate: 0.01\n",
      "Epoch: 18323, MSE: 0.22749514825686853, Learning Rate: 0.01\n",
      "Epoch: 18324, MSE: 0.2274951482568811, Learning Rate: 0.01\n",
      "Epoch: 18325, MSE: 0.22749514825689376, Learning Rate: 0.01\n",
      "Epoch: 18326, MSE: 0.22749514825690634, Learning Rate: 0.01\n",
      "Epoch: 18327, MSE: 0.22749514825691933, Learning Rate: 0.01\n",
      "Epoch: 18328, MSE: 0.22749514825693207, Learning Rate: 0.01\n",
      "Epoch: 18329, MSE: 0.22749514825694503, Learning Rate: 0.01\n",
      "Epoch: 18330, MSE: 0.2274951482569578, Learning Rate: 0.01\n",
      "Epoch: 18331, MSE: 0.2274951482569701, Learning Rate: 0.01\n",
      "Epoch: 18332, MSE: 0.22749514825698336, Learning Rate: 0.01\n",
      "Epoch: 18333, MSE: 0.22749514825699618, Learning Rate: 0.01\n",
      "Epoch: 18334, MSE: 0.22749514825700862, Learning Rate: 0.01\n",
      "Epoch: 18335, MSE: 0.22749514825702166, Learning Rate: 0.01\n",
      "Epoch: 18336, MSE: 0.227495148257034, Learning Rate: 0.01\n",
      "Epoch: 18337, MSE: 0.227495148257047, Learning Rate: 0.01\n",
      "Epoch: 18338, MSE: 0.22749514825705977, Learning Rate: 0.01\n",
      "Epoch: 18339, MSE: 0.22749514825707184, Learning Rate: 0.01\n",
      "Epoch: 18340, MSE: 0.22749514825708528, Learning Rate: 0.01\n",
      "Epoch: 18341, MSE: 0.22749514825709763, Learning Rate: 0.01\n",
      "Epoch: 18342, MSE: 0.22749514825711037, Learning Rate: 0.01\n",
      "Epoch: 18343, MSE: 0.22749514825712353, Learning Rate: 0.01\n",
      "Epoch: 18344, MSE: 0.2274951482571355, Learning Rate: 0.01\n",
      "Epoch: 18345, MSE: 0.22749514825714864, Learning Rate: 0.01\n",
      "Epoch: 18346, MSE: 0.22749514825716158, Learning Rate: 0.01\n",
      "Epoch: 18347, MSE: 0.2274951482571737, Learning Rate: 0.01\n",
      "Epoch: 18348, MSE: 0.22749514825718684, Learning Rate: 0.01\n",
      "Epoch: 18349, MSE: 0.22749514825719935, Learning Rate: 0.01\n",
      "Epoch: 18350, MSE: 0.2274951482572122, Learning Rate: 0.01\n",
      "Epoch: 18351, MSE: 0.22749514825722497, Learning Rate: 0.01\n",
      "Epoch: 18352, MSE: 0.22749514825723763, Learning Rate: 0.01\n",
      "Epoch: 18353, MSE: 0.22749514825725028, Learning Rate: 0.01\n",
      "Epoch: 18354, MSE: 0.22749514825726308, Learning Rate: 0.01\n",
      "Epoch: 18355, MSE: 0.22749514825727563, Learning Rate: 0.01\n",
      "Epoch: 18356, MSE: 0.2274951482572889, Learning Rate: 0.01\n",
      "Epoch: 18357, MSE: 0.22749514825730163, Learning Rate: 0.01\n",
      "Epoch: 18358, MSE: 0.22749514825731373, Learning Rate: 0.01\n",
      "Epoch: 18359, MSE: 0.22749514825732725, Learning Rate: 0.01\n",
      "Epoch: 18360, MSE: 0.2274951482573395, Learning Rate: 0.01\n",
      "Epoch: 18361, MSE: 0.22749514825735198, Learning Rate: 0.01\n",
      "Epoch: 18362, MSE: 0.227495148257365, Learning Rate: 0.01\n",
      "Epoch: 18363, MSE: 0.22749514825737788, Learning Rate: 0.01\n",
      "Epoch: 18364, MSE: 0.22749514825739045, Learning Rate: 0.01\n",
      "Epoch: 18365, MSE: 0.22749514825740308, Learning Rate: 0.01\n",
      "Epoch: 18366, MSE: 0.22749514825741593, Learning Rate: 0.01\n",
      "Epoch: 18367, MSE: 0.2274951482574287, Learning Rate: 0.01\n",
      "Epoch: 18368, MSE: 0.22749514825744174, Learning Rate: 0.01\n",
      "Epoch: 18369, MSE: 0.2274951482574541, Learning Rate: 0.01\n",
      "Epoch: 18370, MSE: 0.22749514825746653, Learning Rate: 0.01\n",
      "Epoch: 18371, MSE: 0.22749514825748013, Learning Rate: 0.01\n",
      "Epoch: 18372, MSE: 0.2274951482574924, Learning Rate: 0.01\n",
      "Epoch: 18373, MSE: 0.22749514825750514, Learning Rate: 0.01\n",
      "Epoch: 18374, MSE: 0.22749514825751804, Learning Rate: 0.01\n",
      "Epoch: 18375, MSE: 0.22749514825753078, Learning Rate: 0.01\n",
      "Epoch: 18376, MSE: 0.227495148257543, Learning Rate: 0.01\n",
      "Epoch: 18377, MSE: 0.2274951482575561, Learning Rate: 0.01\n",
      "Epoch: 18378, MSE: 0.2274951482575685, Learning Rate: 0.01\n",
      "Epoch: 18379, MSE: 0.2274951482575816, Learning Rate: 0.01\n",
      "Epoch: 18380, MSE: 0.22749514825759423, Learning Rate: 0.01\n",
      "Epoch: 18381, MSE: 0.22749514825760692, Learning Rate: 0.01\n",
      "Epoch: 18382, MSE: 0.22749514825761946, Learning Rate: 0.01\n",
      "Epoch: 18383, MSE: 0.2274951482576325, Learning Rate: 0.01\n",
      "Epoch: 18384, MSE: 0.22749514825764489, Learning Rate: 0.01\n",
      "Epoch: 18385, MSE: 0.22749514825765754, Learning Rate: 0.01\n",
      "Epoch: 18386, MSE: 0.22749514825767062, Learning Rate: 0.01\n",
      "Epoch: 18387, MSE: 0.22749514825768322, Learning Rate: 0.01\n",
      "Epoch: 18388, MSE: 0.22749514825769573, Learning Rate: 0.01\n",
      "Epoch: 18389, MSE: 0.22749514825770878, Learning Rate: 0.01\n",
      "Epoch: 18390, MSE: 0.2274951482577214, Learning Rate: 0.01\n",
      "Epoch: 18391, MSE: 0.227495148257734, Learning Rate: 0.01\n",
      "Epoch: 18392, MSE: 0.2274951482577465, Learning Rate: 0.01\n",
      "Epoch: 18393, MSE: 0.22749514825775963, Learning Rate: 0.01\n",
      "Epoch: 18394, MSE: 0.22749514825777253, Learning Rate: 0.01\n",
      "Epoch: 18395, MSE: 0.22749514825778494, Learning Rate: 0.01\n",
      "Epoch: 18396, MSE: 0.22749514825779807, Learning Rate: 0.01\n",
      "Epoch: 18397, MSE: 0.22749514825781056, Learning Rate: 0.01\n",
      "Epoch: 18398, MSE: 0.22749514825782338, Learning Rate: 0.01\n",
      "Epoch: 18399, MSE: 0.22749514825783576, Learning Rate: 0.01\n",
      "Epoch: 18400, MSE: 0.2274951482578486, Learning Rate: 0.01\n",
      "Epoch: 18401, MSE: 0.22749514825786138, Learning Rate: 0.01\n",
      "Epoch: 18402, MSE: 0.2274951482578743, Learning Rate: 0.01\n",
      "Epoch: 18403, MSE: 0.2274951482578873, Learning Rate: 0.01\n",
      "Epoch: 18404, MSE: 0.22749514825790002, Learning Rate: 0.01\n",
      "Epoch: 18405, MSE: 0.2274951482579122, Learning Rate: 0.01\n",
      "Epoch: 18406, MSE: 0.22749514825792505, Learning Rate: 0.01\n",
      "Epoch: 18407, MSE: 0.22749514825793832, Learning Rate: 0.01\n",
      "Epoch: 18408, MSE: 0.2274951482579501, Learning Rate: 0.01\n",
      "Epoch: 18409, MSE: 0.22749514825796324, Learning Rate: 0.01\n",
      "Epoch: 18410, MSE: 0.22749514825797554, Learning Rate: 0.01\n",
      "Epoch: 18411, MSE: 0.22749514825798842, Learning Rate: 0.01\n",
      "Epoch: 18412, MSE: 0.22749514825800163, Learning Rate: 0.01\n",
      "Epoch: 18413, MSE: 0.227495148258014, Learning Rate: 0.01\n",
      "Epoch: 18414, MSE: 0.2274951482580273, Learning Rate: 0.01\n",
      "Epoch: 18415, MSE: 0.22749514825803968, Learning Rate: 0.01\n",
      "Epoch: 18416, MSE: 0.2274951482580528, Learning Rate: 0.01\n",
      "Epoch: 18417, MSE: 0.2274951482580652, Learning Rate: 0.01\n",
      "Epoch: 18418, MSE: 0.22749514825807776, Learning Rate: 0.01\n",
      "Epoch: 18419, MSE: 0.22749514825809072, Learning Rate: 0.01\n",
      "Epoch: 18420, MSE: 0.22749514825810355, Learning Rate: 0.01\n",
      "Epoch: 18421, MSE: 0.22749514825811615, Learning Rate: 0.01\n",
      "Epoch: 18422, MSE: 0.22749514825812905, Learning Rate: 0.01\n",
      "Epoch: 18423, MSE: 0.22749514825814166, Learning Rate: 0.01\n",
      "Epoch: 18424, MSE: 0.2274951482581539, Learning Rate: 0.01\n",
      "Epoch: 18425, MSE: 0.22749514825816725, Learning Rate: 0.01\n",
      "Epoch: 18426, MSE: 0.22749514825817962, Learning Rate: 0.01\n",
      "Epoch: 18427, MSE: 0.2274951482581926, Learning Rate: 0.01\n",
      "Epoch: 18428, MSE: 0.22749514825820535, Learning Rate: 0.01\n",
      "Epoch: 18429, MSE: 0.22749514825821784, Learning Rate: 0.01\n",
      "Epoch: 18430, MSE: 0.22749514825823014, Learning Rate: 0.01\n",
      "Epoch: 18431, MSE: 0.22749514825824338, Learning Rate: 0.01\n",
      "Epoch: 18432, MSE: 0.22749514825825584, Learning Rate: 0.01\n",
      "Epoch: 18433, MSE: 0.227495148258269, Learning Rate: 0.01\n",
      "Epoch: 18434, MSE: 0.2274951482582818, Learning Rate: 0.01\n",
      "Epoch: 18435, MSE: 0.2274951482582942, Learning Rate: 0.01\n",
      "Epoch: 18436, MSE: 0.22749514825830708, Learning Rate: 0.01\n",
      "Epoch: 18437, MSE: 0.2274951482583197, Learning Rate: 0.01\n",
      "Epoch: 18438, MSE: 0.2274951482583325, Learning Rate: 0.01\n",
      "Epoch: 18439, MSE: 0.22749514825834544, Learning Rate: 0.01\n",
      "Epoch: 18440, MSE: 0.22749514825835812, Learning Rate: 0.01\n",
      "Epoch: 18441, MSE: 0.22749514825837058, Learning Rate: 0.01\n",
      "Epoch: 18442, MSE: 0.2274951482583834, Learning Rate: 0.01\n",
      "Epoch: 18443, MSE: 0.22749514825839615, Learning Rate: 0.01\n",
      "Epoch: 18444, MSE: 0.22749514825840894, Learning Rate: 0.01\n",
      "Epoch: 18445, MSE: 0.2274951482584216, Learning Rate: 0.01\n",
      "Epoch: 18446, MSE: 0.22749514825843445, Learning Rate: 0.01\n",
      "Epoch: 18447, MSE: 0.22749514825844702, Learning Rate: 0.01\n",
      "Epoch: 18448, MSE: 0.22749514825845957, Learning Rate: 0.01\n",
      "Epoch: 18449, MSE: 0.22749514825847267, Learning Rate: 0.01\n",
      "Epoch: 18450, MSE: 0.22749514825848535, Learning Rate: 0.01\n",
      "Epoch: 18451, MSE: 0.22749514825849823, Learning Rate: 0.01\n",
      "Epoch: 18452, MSE: 0.22749514825851114, Learning Rate: 0.01\n",
      "Epoch: 18453, MSE: 0.22749514825852313, Learning Rate: 0.01\n",
      "Epoch: 18454, MSE: 0.22749514825853656, Learning Rate: 0.01\n",
      "Epoch: 18455, MSE: 0.2274951482585493, Learning Rate: 0.01\n",
      "Epoch: 18456, MSE: 0.22749514825856104, Learning Rate: 0.01\n",
      "Epoch: 18457, MSE: 0.22749514825857442, Learning Rate: 0.01\n",
      "Epoch: 18458, MSE: 0.22749514825858697, Learning Rate: 0.01\n",
      "Epoch: 18459, MSE: 0.22749514825859987, Learning Rate: 0.01\n",
      "Epoch: 18460, MSE: 0.22749514825861253, Learning Rate: 0.01\n",
      "Epoch: 18461, MSE: 0.22749514825862535, Learning Rate: 0.01\n",
      "Epoch: 18462, MSE: 0.22749514825863806, Learning Rate: 0.01\n",
      "Epoch: 18463, MSE: 0.22749514825865053, Learning Rate: 0.01\n",
      "Epoch: 18464, MSE: 0.22749514825866315, Learning Rate: 0.01\n",
      "Epoch: 18465, MSE: 0.22749514825867637, Learning Rate: 0.01\n",
      "Epoch: 18466, MSE: 0.22749514825868888, Learning Rate: 0.01\n",
      "Epoch: 18467, MSE: 0.22749514825870135, Learning Rate: 0.01\n",
      "Epoch: 18468, MSE: 0.2274951482587139, Learning Rate: 0.01\n",
      "Epoch: 18469, MSE: 0.2274951482587274, Learning Rate: 0.01\n",
      "Epoch: 18470, MSE: 0.22749514825873943, Learning Rate: 0.01\n",
      "Epoch: 18471, MSE: 0.2274951482587528, Learning Rate: 0.01\n",
      "Epoch: 18472, MSE: 0.22749514825876507, Learning Rate: 0.01\n",
      "Epoch: 18473, MSE: 0.2274951482587781, Learning Rate: 0.01\n",
      "Epoch: 18474, MSE: 0.2274951482587904, Learning Rate: 0.01\n",
      "Epoch: 18475, MSE: 0.22749514825880351, Learning Rate: 0.01\n",
      "Epoch: 18476, MSE: 0.22749514825881625, Learning Rate: 0.01\n",
      "Epoch: 18477, MSE: 0.2274951482588286, Learning Rate: 0.01\n",
      "Epoch: 18478, MSE: 0.2274951482588412, Learning Rate: 0.01\n",
      "Epoch: 18479, MSE: 0.22749514825885417, Learning Rate: 0.01\n",
      "Epoch: 18480, MSE: 0.227495148258867, Learning Rate: 0.01\n",
      "Epoch: 18481, MSE: 0.22749514825887973, Learning Rate: 0.01\n",
      "Epoch: 18482, MSE: 0.22749514825889253, Learning Rate: 0.01\n",
      "Epoch: 18483, MSE: 0.2274951482589053, Learning Rate: 0.01\n",
      "Epoch: 18484, MSE: 0.22749514825891806, Learning Rate: 0.01\n",
      "Epoch: 18485, MSE: 0.22749514825893102, Learning Rate: 0.01\n",
      "Epoch: 18486, MSE: 0.2274951482589429, Learning Rate: 0.01\n",
      "Epoch: 18487, MSE: 0.2274951482589559, Learning Rate: 0.01\n",
      "Epoch: 18488, MSE: 0.22749514825896908, Learning Rate: 0.01\n",
      "Epoch: 18489, MSE: 0.22749514825898165, Learning Rate: 0.01\n",
      "Epoch: 18490, MSE: 0.22749514825899425, Learning Rate: 0.01\n",
      "Epoch: 18491, MSE: 0.2274951482590069, Learning Rate: 0.01\n",
      "Epoch: 18492, MSE: 0.22749514825901967, Learning Rate: 0.01\n",
      "Epoch: 18493, MSE: 0.22749514825903236, Learning Rate: 0.01\n",
      "Epoch: 18494, MSE: 0.22749514825904493, Learning Rate: 0.01\n",
      "Epoch: 18495, MSE: 0.2274951482590581, Learning Rate: 0.01\n",
      "Epoch: 18496, MSE: 0.22749514825907075, Learning Rate: 0.01\n",
      "Epoch: 18497, MSE: 0.22749514825908307, Learning Rate: 0.01\n",
      "Epoch: 18498, MSE: 0.22749514825909584, Learning Rate: 0.01\n",
      "Epoch: 18499, MSE: 0.22749514825910924, Learning Rate: 0.01\n",
      "Epoch: 18500, MSE: 0.22749514825912157, Learning Rate: 0.01\n",
      "Epoch: 18501, MSE: 0.2274951482591344, Learning Rate: 0.01\n",
      "Epoch: 18502, MSE: 0.22749514825914688, Learning Rate: 0.01\n",
      "Epoch: 18503, MSE: 0.22749514825915973, Learning Rate: 0.01\n",
      "Epoch: 18504, MSE: 0.2274951482591726, Learning Rate: 0.01\n",
      "Epoch: 18505, MSE: 0.22749514825918474, Learning Rate: 0.01\n",
      "Epoch: 18506, MSE: 0.2274951482591982, Learning Rate: 0.01\n",
      "Epoch: 18507, MSE: 0.22749514825921077, Learning Rate: 0.01\n",
      "Epoch: 18508, MSE: 0.22749514825922335, Learning Rate: 0.01\n",
      "Epoch: 18509, MSE: 0.22749514825923578, Learning Rate: 0.01\n",
      "Epoch: 18510, MSE: 0.22749514825924882, Learning Rate: 0.01\n",
      "Epoch: 18511, MSE: 0.22749514825926173, Learning Rate: 0.01\n",
      "Epoch: 18512, MSE: 0.2274951482592738, Learning Rate: 0.01\n",
      "Epoch: 18513, MSE: 0.22749514825928663, Learning Rate: 0.01\n",
      "Epoch: 18514, MSE: 0.22749514825929973, Learning Rate: 0.01\n",
      "Epoch: 18515, MSE: 0.22749514825931208, Learning Rate: 0.01\n",
      "Epoch: 18516, MSE: 0.22749514825932463, Learning Rate: 0.01\n",
      "Epoch: 18517, MSE: 0.22749514825933803, Learning Rate: 0.01\n",
      "Epoch: 18518, MSE: 0.2274951482593504, Learning Rate: 0.01\n",
      "Epoch: 18519, MSE: 0.2274951482593636, Learning Rate: 0.01\n",
      "Epoch: 18520, MSE: 0.22749514825937558, Learning Rate: 0.01\n",
      "Epoch: 18521, MSE: 0.22749514825938874, Learning Rate: 0.01\n",
      "Epoch: 18522, MSE: 0.2274951482594016, Learning Rate: 0.01\n",
      "Epoch: 18523, MSE: 0.22749514825941397, Learning Rate: 0.01\n",
      "Epoch: 18524, MSE: 0.2274951482594262, Learning Rate: 0.01\n",
      "Epoch: 18525, MSE: 0.2274951482594399, Learning Rate: 0.01\n",
      "Epoch: 18526, MSE: 0.22749514825945202, Learning Rate: 0.01\n",
      "Epoch: 18527, MSE: 0.2274951482594652, Learning Rate: 0.01\n",
      "Epoch: 18528, MSE: 0.22749514825947784, Learning Rate: 0.01\n",
      "Epoch: 18529, MSE: 0.22749514825949071, Learning Rate: 0.01\n",
      "Epoch: 18530, MSE: 0.22749514825950326, Learning Rate: 0.01\n",
      "Epoch: 18531, MSE: 0.22749514825951575, Learning Rate: 0.01\n",
      "Epoch: 18532, MSE: 0.2274951482595287, Learning Rate: 0.01\n",
      "Epoch: 18533, MSE: 0.22749514825954148, Learning Rate: 0.01\n",
      "Epoch: 18534, MSE: 0.2274951482595539, Learning Rate: 0.01\n",
      "Epoch: 18535, MSE: 0.22749514825956677, Learning Rate: 0.01\n",
      "Epoch: 18536, MSE: 0.2274951482595794, Learning Rate: 0.01\n",
      "Epoch: 18537, MSE: 0.22749514825959208, Learning Rate: 0.01\n",
      "Epoch: 18538, MSE: 0.22749514825960476, Learning Rate: 0.01\n",
      "Epoch: 18539, MSE: 0.22749514825961786, Learning Rate: 0.01\n",
      "Epoch: 18540, MSE: 0.22749514825963052, Learning Rate: 0.01\n",
      "Epoch: 18541, MSE: 0.22749514825964323, Learning Rate: 0.01\n",
      "Epoch: 18542, MSE: 0.22749514825965586, Learning Rate: 0.01\n",
      "Epoch: 18543, MSE: 0.22749514825966854, Learning Rate: 0.01\n",
      "Epoch: 18544, MSE: 0.2274951482596813, Learning Rate: 0.01\n",
      "Epoch: 18545, MSE: 0.22749514825969427, Learning Rate: 0.01\n",
      "Epoch: 18546, MSE: 0.2274951482597064, Learning Rate: 0.01\n",
      "Epoch: 18547, MSE: 0.22749514825971956, Learning Rate: 0.01\n",
      "Epoch: 18548, MSE: 0.22749514825973272, Learning Rate: 0.01\n",
      "Epoch: 18549, MSE: 0.2274951482597453, Learning Rate: 0.01\n",
      "Epoch: 18550, MSE: 0.2274951482597577, Learning Rate: 0.01\n",
      "Epoch: 18551, MSE: 0.22749514825977046, Learning Rate: 0.01\n",
      "Epoch: 18552, MSE: 0.22749514825978318, Learning Rate: 0.01\n",
      "Epoch: 18553, MSE: 0.22749514825979622, Learning Rate: 0.01\n",
      "Epoch: 18554, MSE: 0.2274951482598085, Learning Rate: 0.01\n",
      "Epoch: 18555, MSE: 0.22749514825982098, Learning Rate: 0.01\n",
      "Epoch: 18556, MSE: 0.22749514825983383, Learning Rate: 0.01\n",
      "Epoch: 18557, MSE: 0.22749514825984649, Learning Rate: 0.01\n",
      "Epoch: 18558, MSE: 0.22749514825985948, Learning Rate: 0.01\n",
      "Epoch: 18559, MSE: 0.22749514825987247, Learning Rate: 0.01\n",
      "Epoch: 18560, MSE: 0.22749514825988468, Learning Rate: 0.01\n",
      "Epoch: 18561, MSE: 0.22749514825989725, Learning Rate: 0.01\n",
      "Epoch: 18562, MSE: 0.22749514825991024, Learning Rate: 0.01\n",
      "Epoch: 18563, MSE: 0.22749514825992304, Learning Rate: 0.01\n",
      "Epoch: 18564, MSE: 0.22749514825993575, Learning Rate: 0.01\n",
      "Epoch: 18565, MSE: 0.2274951482599485, Learning Rate: 0.01\n",
      "Epoch: 18566, MSE: 0.227495148259961, Learning Rate: 0.01\n",
      "Epoch: 18567, MSE: 0.22749514825997388, Learning Rate: 0.01\n",
      "Epoch: 18568, MSE: 0.22749514825998668, Learning Rate: 0.01\n",
      "Epoch: 18569, MSE: 0.22749514825999945, Learning Rate: 0.01\n",
      "Epoch: 18570, MSE: 0.22749514826001246, Learning Rate: 0.01\n",
      "Epoch: 18571, MSE: 0.22749514826002512, Learning Rate: 0.01\n",
      "Epoch: 18572, MSE: 0.22749514826003742, Learning Rate: 0.01\n",
      "Epoch: 18573, MSE: 0.2274951482600502, Learning Rate: 0.01\n",
      "Epoch: 18574, MSE: 0.227495148260063, Learning Rate: 0.01\n",
      "Epoch: 18575, MSE: 0.2274951482600762, Learning Rate: 0.01\n",
      "Epoch: 18576, MSE: 0.2274951482600886, Learning Rate: 0.01\n",
      "Epoch: 18577, MSE: 0.2274951482601012, Learning Rate: 0.01\n",
      "Epoch: 18578, MSE: 0.22749514826011416, Learning Rate: 0.01\n",
      "Epoch: 18579, MSE: 0.22749514826012698, Learning Rate: 0.01\n",
      "Epoch: 18580, MSE: 0.22749514826013958, Learning Rate: 0.01\n",
      "Epoch: 18581, MSE: 0.22749514826015202, Learning Rate: 0.01\n",
      "Epoch: 18582, MSE: 0.22749514826016468, Learning Rate: 0.01\n",
      "Epoch: 18583, MSE: 0.2274951482601778, Learning Rate: 0.01\n",
      "Epoch: 18584, MSE: 0.22749514826019018, Learning Rate: 0.01\n",
      "Epoch: 18585, MSE: 0.22749514826020353, Learning Rate: 0.01\n",
      "Epoch: 18586, MSE: 0.227495148260216, Learning Rate: 0.01\n",
      "Epoch: 18587, MSE: 0.22749514826022862, Learning Rate: 0.01\n",
      "Epoch: 18588, MSE: 0.22749514826024128, Learning Rate: 0.01\n",
      "Epoch: 18589, MSE: 0.22749514826025388, Learning Rate: 0.01\n",
      "Epoch: 18590, MSE: 0.22749514826026654, Learning Rate: 0.01\n",
      "Epoch: 18591, MSE: 0.22749514826027936, Learning Rate: 0.01\n",
      "Epoch: 18592, MSE: 0.22749514826029246, Learning Rate: 0.01\n",
      "Epoch: 18593, MSE: 0.2274951482603045, Learning Rate: 0.01\n",
      "Epoch: 18594, MSE: 0.22749514826031778, Learning Rate: 0.01\n",
      "Epoch: 18595, MSE: 0.2274951482603298, Learning Rate: 0.01\n",
      "Epoch: 18596, MSE: 0.22749514826034278, Learning Rate: 0.01\n",
      "Epoch: 18597, MSE: 0.22749514826035572, Learning Rate: 0.01\n",
      "Epoch: 18598, MSE: 0.22749514826036876, Learning Rate: 0.01\n",
      "Epoch: 18599, MSE: 0.22749514826038117, Learning Rate: 0.01\n",
      "Epoch: 18600, MSE: 0.22749514826039388, Learning Rate: 0.01\n",
      "Epoch: 18601, MSE: 0.22749514826040612, Learning Rate: 0.01\n",
      "Epoch: 18602, MSE: 0.22749514826041944, Learning Rate: 0.01\n",
      "Epoch: 18603, MSE: 0.22749514826043207, Learning Rate: 0.01\n",
      "Epoch: 18604, MSE: 0.2274951482604446, Learning Rate: 0.01\n",
      "Epoch: 18605, MSE: 0.2274951482604573, Learning Rate: 0.01\n",
      "Epoch: 18606, MSE: 0.22749514826046993, Learning Rate: 0.01\n",
      "Epoch: 18607, MSE: 0.2274951482604828, Learning Rate: 0.01\n",
      "Epoch: 18608, MSE: 0.22749514826049552, Learning Rate: 0.01\n",
      "Epoch: 18609, MSE: 0.22749514826050843, Learning Rate: 0.01\n",
      "Epoch: 18610, MSE: 0.22749514826052117, Learning Rate: 0.01\n",
      "Epoch: 18611, MSE: 0.22749514826053296, Learning Rate: 0.01\n",
      "Epoch: 18612, MSE: 0.22749514826054637, Learning Rate: 0.01\n",
      "Epoch: 18613, MSE: 0.2274951482605591, Learning Rate: 0.01\n",
      "Epoch: 18614, MSE: 0.22749514826057188, Learning Rate: 0.01\n",
      "Epoch: 18615, MSE: 0.22749514826058467, Learning Rate: 0.01\n",
      "Epoch: 18616, MSE: 0.2274951482605974, Learning Rate: 0.01\n",
      "Epoch: 18617, MSE: 0.22749514826061068, Learning Rate: 0.01\n",
      "Epoch: 18618, MSE: 0.2274951482606225, Learning Rate: 0.01\n",
      "Epoch: 18619, MSE: 0.2274951482606361, Learning Rate: 0.01\n",
      "Epoch: 18620, MSE: 0.2274951482606482, Learning Rate: 0.01\n",
      "Epoch: 18621, MSE: 0.22749514826066078, Learning Rate: 0.01\n",
      "Epoch: 18622, MSE: 0.22749514826067407, Learning Rate: 0.01\n",
      "Epoch: 18623, MSE: 0.2274951482606861, Learning Rate: 0.01\n",
      "Epoch: 18624, MSE: 0.22749514826069897, Learning Rate: 0.01\n",
      "Epoch: 18625, MSE: 0.22749514826071185, Learning Rate: 0.01\n",
      "Epoch: 18626, MSE: 0.22749514826072448, Learning Rate: 0.01\n",
      "Epoch: 18627, MSE: 0.22749514826073733, Learning Rate: 0.01\n",
      "Epoch: 18628, MSE: 0.22749514826075, Learning Rate: 0.01\n",
      "Epoch: 18629, MSE: 0.22749514826076278, Learning Rate: 0.01\n",
      "Epoch: 18630, MSE: 0.22749514826077533, Learning Rate: 0.01\n",
      "Epoch: 18631, MSE: 0.22749514826078787, Learning Rate: 0.01\n",
      "Epoch: 18632, MSE: 0.2274951482608008, Learning Rate: 0.01\n",
      "Epoch: 18633, MSE: 0.2274951482608137, Learning Rate: 0.01\n",
      "Epoch: 18634, MSE: 0.22749514826082606, Learning Rate: 0.01\n",
      "Epoch: 18635, MSE: 0.22749514826083886, Learning Rate: 0.01\n",
      "Epoch: 18636, MSE: 0.22749514826085207, Learning Rate: 0.01\n",
      "Epoch: 18637, MSE: 0.22749514826086423, Learning Rate: 0.01\n",
      "Epoch: 18638, MSE: 0.2274951482608775, Learning Rate: 0.01\n",
      "Epoch: 18639, MSE: 0.22749514826089007, Learning Rate: 0.01\n",
      "Epoch: 18640, MSE: 0.22749514826090214, Learning Rate: 0.01\n",
      "Epoch: 18641, MSE: 0.22749514826091558, Learning Rate: 0.01\n",
      "Epoch: 18642, MSE: 0.22749514826092715, Learning Rate: 0.01\n",
      "Epoch: 18643, MSE: 0.22749514826094086, Learning Rate: 0.01\n",
      "Epoch: 18644, MSE: 0.22749514826095318, Learning Rate: 0.01\n",
      "Epoch: 18645, MSE: 0.22749514826096595, Learning Rate: 0.01\n",
      "Epoch: 18646, MSE: 0.22749514826097844, Learning Rate: 0.01\n",
      "Epoch: 18647, MSE: 0.22749514826099151, Learning Rate: 0.01\n",
      "Epoch: 18648, MSE: 0.2274951482610039, Learning Rate: 0.01\n",
      "Epoch: 18649, MSE: 0.22749514826101697, Learning Rate: 0.01\n",
      "Epoch: 18650, MSE: 0.22749514826102946, Learning Rate: 0.01\n",
      "Epoch: 18651, MSE: 0.227495148261042, Learning Rate: 0.01\n",
      "Epoch: 18652, MSE: 0.22749514826105535, Learning Rate: 0.01\n",
      "Epoch: 18653, MSE: 0.2274951482610678, Learning Rate: 0.01\n",
      "Epoch: 18654, MSE: 0.2274951482610807, Learning Rate: 0.01\n",
      "Epoch: 18655, MSE: 0.22749514826109327, Learning Rate: 0.01\n",
      "Epoch: 18656, MSE: 0.2274951482611061, Learning Rate: 0.01\n",
      "Epoch: 18657, MSE: 0.22749514826111886, Learning Rate: 0.01\n",
      "Epoch: 18658, MSE: 0.22749514826113132, Learning Rate: 0.01\n",
      "Epoch: 18659, MSE: 0.22749514826114395, Learning Rate: 0.01\n",
      "Epoch: 18660, MSE: 0.22749514826115652, Learning Rate: 0.01\n",
      "Epoch: 18661, MSE: 0.2274951482611698, Learning Rate: 0.01\n",
      "Epoch: 18662, MSE: 0.22749514826118244, Learning Rate: 0.01\n",
      "Epoch: 18663, MSE: 0.227495148261195, Learning Rate: 0.01\n",
      "Epoch: 18664, MSE: 0.22749514826120731, Learning Rate: 0.01\n",
      "Epoch: 18665, MSE: 0.22749514826122053, Learning Rate: 0.01\n",
      "Epoch: 18666, MSE: 0.22749514826123338, Learning Rate: 0.01\n",
      "Epoch: 18667, MSE: 0.2274951482612458, Learning Rate: 0.01\n",
      "Epoch: 18668, MSE: 0.2274951482612588, Learning Rate: 0.01\n",
      "Epoch: 18669, MSE: 0.227495148261271, Learning Rate: 0.01\n",
      "Epoch: 18670, MSE: 0.2274951482612837, Learning Rate: 0.01\n",
      "Epoch: 18671, MSE: 0.22749514826129694, Learning Rate: 0.01\n",
      "Epoch: 18672, MSE: 0.2274951482613091, Learning Rate: 0.01\n",
      "Epoch: 18673, MSE: 0.2274951482613224, Learning Rate: 0.01\n",
      "Epoch: 18674, MSE: 0.2274951482613349, Learning Rate: 0.01\n",
      "Epoch: 18675, MSE: 0.2274951482613479, Learning Rate: 0.01\n",
      "Epoch: 18676, MSE: 0.22749514826136052, Learning Rate: 0.01\n",
      "Epoch: 18677, MSE: 0.22749514826137363, Learning Rate: 0.01\n",
      "Epoch: 18678, MSE: 0.2274951482613861, Learning Rate: 0.01\n",
      "Epoch: 18679, MSE: 0.22749514826139813, Learning Rate: 0.01\n",
      "Epoch: 18680, MSE: 0.22749514826141123, Learning Rate: 0.01\n",
      "Epoch: 18681, MSE: 0.2274951482614238, Learning Rate: 0.01\n",
      "Epoch: 18682, MSE: 0.22749514826143558, Learning Rate: 0.01\n",
      "Epoch: 18683, MSE: 0.22749514826144931, Learning Rate: 0.01\n",
      "Epoch: 18684, MSE: 0.2274951482614615, Learning Rate: 0.01\n",
      "Epoch: 18685, MSE: 0.22749514826147446, Learning Rate: 0.01\n",
      "Epoch: 18686, MSE: 0.2274951482614873, Learning Rate: 0.01\n",
      "Epoch: 18687, MSE: 0.22749514826150086, Learning Rate: 0.01\n",
      "Epoch: 18688, MSE: 0.22749514826151296, Learning Rate: 0.01\n",
      "Epoch: 18689, MSE: 0.22749514826152598, Learning Rate: 0.01\n",
      "Epoch: 18690, MSE: 0.22749514826153872, Learning Rate: 0.01\n",
      "Epoch: 18691, MSE: 0.22749514826155098, Learning Rate: 0.01\n",
      "Epoch: 18692, MSE: 0.22749514826156378, Learning Rate: 0.01\n",
      "Epoch: 18693, MSE: 0.22749514826157652, Learning Rate: 0.01\n",
      "Epoch: 18694, MSE: 0.22749514826158937, Learning Rate: 0.01\n",
      "Epoch: 18695, MSE: 0.22749514826160194, Learning Rate: 0.01\n",
      "Epoch: 18696, MSE: 0.2274951482616147, Learning Rate: 0.01\n",
      "Epoch: 18697, MSE: 0.22749514826162692, Learning Rate: 0.01\n",
      "Epoch: 18698, MSE: 0.22749514826164022, Learning Rate: 0.01\n",
      "Epoch: 18699, MSE: 0.22749514826165254, Learning Rate: 0.01\n",
      "Epoch: 18700, MSE: 0.2274951482616658, Learning Rate: 0.01\n",
      "Epoch: 18701, MSE: 0.22749514826167855, Learning Rate: 0.01\n",
      "Epoch: 18702, MSE: 0.22749514826169073, Learning Rate: 0.01\n",
      "Epoch: 18703, MSE: 0.2274951482617035, Learning Rate: 0.01\n",
      "Epoch: 18704, MSE: 0.22749514826171624, Learning Rate: 0.01\n",
      "Epoch: 18705, MSE: 0.22749514826172892, Learning Rate: 0.01\n",
      "Epoch: 18706, MSE: 0.22749514826174214, Learning Rate: 0.01\n",
      "Epoch: 18707, MSE: 0.22749514826175452, Learning Rate: 0.01\n",
      "Epoch: 18708, MSE: 0.22749514826176695, Learning Rate: 0.01\n",
      "Epoch: 18709, MSE: 0.2274951482617797, Learning Rate: 0.01\n",
      "Epoch: 18710, MSE: 0.22749514826179248, Learning Rate: 0.01\n",
      "Epoch: 18711, MSE: 0.22749514826180547, Learning Rate: 0.01\n",
      "Epoch: 18712, MSE: 0.2274951482618186, Learning Rate: 0.01\n",
      "Epoch: 18713, MSE: 0.22749514826183106, Learning Rate: 0.01\n",
      "Epoch: 18714, MSE: 0.22749514826184308, Learning Rate: 0.01\n",
      "Epoch: 18715, MSE: 0.22749514826185668, Learning Rate: 0.01\n",
      "Epoch: 18716, MSE: 0.22749514826186906, Learning Rate: 0.01\n",
      "Epoch: 18717, MSE: 0.22749514826188158, Learning Rate: 0.01\n",
      "Epoch: 18718, MSE: 0.22749514826189451, Learning Rate: 0.01\n",
      "Epoch: 18719, MSE: 0.2274951482619071, Learning Rate: 0.01\n",
      "Epoch: 18720, MSE: 0.22749514826191963, Learning Rate: 0.01\n",
      "Epoch: 18721, MSE: 0.22749514826193296, Learning Rate: 0.01\n",
      "Epoch: 18722, MSE: 0.22749514826194528, Learning Rate: 0.01\n",
      "Epoch: 18723, MSE: 0.22749514826195824, Learning Rate: 0.01\n",
      "Epoch: 18724, MSE: 0.22749514826197045, Learning Rate: 0.01\n",
      "Epoch: 18725, MSE: 0.22749514826198305, Learning Rate: 0.01\n",
      "Epoch: 18726, MSE: 0.22749514826199596, Learning Rate: 0.01\n",
      "Epoch: 18727, MSE: 0.22749514826200853, Learning Rate: 0.01\n",
      "Epoch: 18728, MSE: 0.22749514826202138, Learning Rate: 0.01\n",
      "Epoch: 18729, MSE: 0.22749514826203407, Learning Rate: 0.01\n",
      "Epoch: 18730, MSE: 0.22749514826204673, Learning Rate: 0.01\n",
      "Epoch: 18731, MSE: 0.2274951482620598, Learning Rate: 0.01\n",
      "Epoch: 18732, MSE: 0.22749514826207243, Learning Rate: 0.01\n",
      "Epoch: 18733, MSE: 0.227495148262085, Learning Rate: 0.01\n",
      "Epoch: 18734, MSE: 0.22749514826209735, Learning Rate: 0.01\n",
      "Epoch: 18735, MSE: 0.22749514826211062, Learning Rate: 0.01\n",
      "Epoch: 18736, MSE: 0.2274951482621235, Learning Rate: 0.01\n",
      "Epoch: 18737, MSE: 0.22749514826213582, Learning Rate: 0.01\n",
      "Epoch: 18738, MSE: 0.22749514826214887, Learning Rate: 0.01\n",
      "Epoch: 18739, MSE: 0.22749514826216186, Learning Rate: 0.01\n",
      "Epoch: 18740, MSE: 0.2274951482621744, Learning Rate: 0.01\n",
      "Epoch: 18741, MSE: 0.22749514826218717, Learning Rate: 0.01\n",
      "Epoch: 18742, MSE: 0.22749514826220005, Learning Rate: 0.01\n",
      "Epoch: 18743, MSE: 0.22749514826221204, Learning Rate: 0.01\n",
      "Epoch: 18744, MSE: 0.22749514826222514, Learning Rate: 0.01\n",
      "Epoch: 18745, MSE: 0.2274951482622378, Learning Rate: 0.01\n",
      "Epoch: 18746, MSE: 0.22749514826225026, Learning Rate: 0.01\n",
      "Epoch: 18747, MSE: 0.2274951482622632, Learning Rate: 0.01\n",
      "Epoch: 18748, MSE: 0.22749514826227574, Learning Rate: 0.01\n",
      "Epoch: 18749, MSE: 0.22749514826228862, Learning Rate: 0.01\n",
      "Epoch: 18750, MSE: 0.2274951482623012, Learning Rate: 0.01\n",
      "Epoch: 18751, MSE: 0.2274951482623138, Learning Rate: 0.01\n",
      "Epoch: 18752, MSE: 0.22749514826232678, Learning Rate: 0.01\n",
      "Epoch: 18753, MSE: 0.22749514826233944, Learning Rate: 0.01\n",
      "Epoch: 18754, MSE: 0.22749514826235176, Learning Rate: 0.01\n",
      "Epoch: 18755, MSE: 0.22749514826236464, Learning Rate: 0.01\n",
      "Epoch: 18756, MSE: 0.22749514826237768, Learning Rate: 0.01\n",
      "Epoch: 18757, MSE: 0.22749514826239023, Learning Rate: 0.01\n",
      "Epoch: 18758, MSE: 0.2274951482624029, Learning Rate: 0.01\n",
      "Epoch: 18759, MSE: 0.22749514826241596, Learning Rate: 0.01\n",
      "Epoch: 18760, MSE: 0.2274951482624282, Learning Rate: 0.01\n",
      "Epoch: 18761, MSE: 0.22749514826244088, Learning Rate: 0.01\n",
      "Epoch: 18762, MSE: 0.22749514826245376, Learning Rate: 0.01\n",
      "Epoch: 18763, MSE: 0.22749514826246642, Learning Rate: 0.01\n",
      "Epoch: 18764, MSE: 0.2274951482624795, Learning Rate: 0.01\n",
      "Epoch: 18765, MSE: 0.2274951482624922, Learning Rate: 0.01\n",
      "Epoch: 18766, MSE: 0.22749514826250425, Learning Rate: 0.01\n",
      "Epoch: 18767, MSE: 0.22749514826251752, Learning Rate: 0.01\n",
      "Epoch: 18768, MSE: 0.2274951482625302, Learning Rate: 0.01\n",
      "Epoch: 18769, MSE: 0.22749514826254288, Learning Rate: 0.01\n",
      "Epoch: 18770, MSE: 0.22749514826255562, Learning Rate: 0.01\n",
      "Epoch: 18771, MSE: 0.2274951482625684, Learning Rate: 0.01\n",
      "Epoch: 18772, MSE: 0.2274951482625809, Learning Rate: 0.01\n",
      "Epoch: 18773, MSE: 0.22749514826259346, Learning Rate: 0.01\n",
      "Epoch: 18774, MSE: 0.2274951482626065, Learning Rate: 0.01\n",
      "Epoch: 18775, MSE: 0.22749514826261868, Learning Rate: 0.01\n",
      "Epoch: 18776, MSE: 0.22749514826263226, Learning Rate: 0.01\n",
      "Epoch: 18777, MSE: 0.2274951482626442, Learning Rate: 0.01\n",
      "Epoch: 18778, MSE: 0.22749514826265715, Learning Rate: 0.01\n",
      "Epoch: 18779, MSE: 0.2274951482626698, Learning Rate: 0.01\n",
      "Epoch: 18780, MSE: 0.22749514826268286, Learning Rate: 0.01\n",
      "Epoch: 18781, MSE: 0.22749514826269554, Learning Rate: 0.01\n",
      "Epoch: 18782, MSE: 0.22749514826270775, Learning Rate: 0.01\n",
      "Epoch: 18783, MSE: 0.22749514826272055, Learning Rate: 0.01\n",
      "Epoch: 18784, MSE: 0.2274951482627333, Learning Rate: 0.01\n",
      "Epoch: 18785, MSE: 0.22749514826274592, Learning Rate: 0.01\n",
      "Epoch: 18786, MSE: 0.22749514826275882, Learning Rate: 0.01\n",
      "Epoch: 18787, MSE: 0.22749514826277134, Learning Rate: 0.01\n",
      "Epoch: 18788, MSE: 0.22749514826278436, Learning Rate: 0.01\n",
      "Epoch: 18789, MSE: 0.22749514826279696, Learning Rate: 0.01\n",
      "Epoch: 18790, MSE: 0.22749514826280964, Learning Rate: 0.01\n",
      "Epoch: 18791, MSE: 0.2274951482628221, Learning Rate: 0.01\n",
      "Epoch: 18792, MSE: 0.22749514826283526, Learning Rate: 0.01\n",
      "Epoch: 18793, MSE: 0.2274951482628478, Learning Rate: 0.01\n",
      "Epoch: 18794, MSE: 0.22749514826286046, Learning Rate: 0.01\n",
      "Epoch: 18795, MSE: 0.22749514826287262, Learning Rate: 0.01\n",
      "Epoch: 18796, MSE: 0.2274951482628862, Learning Rate: 0.01\n",
      "Epoch: 18797, MSE: 0.22749514826289902, Learning Rate: 0.01\n",
      "Epoch: 18798, MSE: 0.22749514826291184, Learning Rate: 0.01\n",
      "Epoch: 18799, MSE: 0.2274951482629248, Learning Rate: 0.01\n",
      "Epoch: 18800, MSE: 0.22749514826293663, Learning Rate: 0.01\n",
      "Epoch: 18801, MSE: 0.22749514826294953, Learning Rate: 0.01\n",
      "Epoch: 18802, MSE: 0.2274951482629624, Learning Rate: 0.01\n",
      "Epoch: 18803, MSE: 0.22749514826297496, Learning Rate: 0.01\n",
      "Epoch: 18804, MSE: 0.2274951482629875, Learning Rate: 0.01\n",
      "Epoch: 18805, MSE: 0.2274951482630006, Learning Rate: 0.01\n",
      "Epoch: 18806, MSE: 0.22749514826301304, Learning Rate: 0.01\n",
      "Epoch: 18807, MSE: 0.227495148263026, Learning Rate: 0.01\n",
      "Epoch: 18808, MSE: 0.22749514826303824, Learning Rate: 0.01\n",
      "Epoch: 18809, MSE: 0.22749514826305153, Learning Rate: 0.01\n",
      "Epoch: 18810, MSE: 0.22749514826306358, Learning Rate: 0.01\n",
      "Epoch: 18811, MSE: 0.2274951482630767, Learning Rate: 0.01\n",
      "Epoch: 18812, MSE: 0.22749514826308967, Learning Rate: 0.01\n",
      "Epoch: 18813, MSE: 0.2274951482631019, Learning Rate: 0.01\n",
      "Epoch: 18814, MSE: 0.2274951482631148, Learning Rate: 0.01\n",
      "Epoch: 18815, MSE: 0.22749514826312756, Learning Rate: 0.01\n",
      "Epoch: 18816, MSE: 0.22749514826314055, Learning Rate: 0.01\n",
      "Epoch: 18817, MSE: 0.227495148263153, Learning Rate: 0.01\n",
      "Epoch: 18818, MSE: 0.22749514826316597, Learning Rate: 0.01\n",
      "Epoch: 18819, MSE: 0.22749514826317843, Learning Rate: 0.01\n",
      "Epoch: 18820, MSE: 0.22749514826319103, Learning Rate: 0.01\n",
      "Epoch: 18821, MSE: 0.22749514826320363, Learning Rate: 0.01\n",
      "Epoch: 18822, MSE: 0.227495148263216, Learning Rate: 0.01\n",
      "Epoch: 18823, MSE: 0.2274951482632291, Learning Rate: 0.01\n",
      "Epoch: 18824, MSE: 0.22749514826324146, Learning Rate: 0.01\n",
      "Epoch: 18825, MSE: 0.22749514826325476, Learning Rate: 0.01\n",
      "Epoch: 18826, MSE: 0.2274951482632674, Learning Rate: 0.01\n",
      "Epoch: 18827, MSE: 0.22749514826328016, Learning Rate: 0.01\n",
      "Epoch: 18828, MSE: 0.2274951482632931, Learning Rate: 0.01\n",
      "Epoch: 18829, MSE: 0.22749514826330536, Learning Rate: 0.01\n",
      "Epoch: 18830, MSE: 0.22749514826331815, Learning Rate: 0.01\n",
      "Epoch: 18831, MSE: 0.22749514826333095, Learning Rate: 0.01\n",
      "Epoch: 18832, MSE: 0.22749514826334363, Learning Rate: 0.01\n",
      "Epoch: 18833, MSE: 0.22749514826335587, Learning Rate: 0.01\n",
      "Epoch: 18834, MSE: 0.22749514826336867, Learning Rate: 0.01\n",
      "Epoch: 18835, MSE: 0.22749514826338152, Learning Rate: 0.01\n",
      "Epoch: 18836, MSE: 0.2274951482633946, Learning Rate: 0.01\n",
      "Epoch: 18837, MSE: 0.22749514826340678, Learning Rate: 0.01\n",
      "Epoch: 18838, MSE: 0.22749514826341932, Learning Rate: 0.01\n",
      "Epoch: 18839, MSE: 0.22749514826343253, Learning Rate: 0.01\n",
      "Epoch: 18840, MSE: 0.22749514826344489, Learning Rate: 0.01\n",
      "Epoch: 18841, MSE: 0.22749514826345765, Learning Rate: 0.01\n",
      "Epoch: 18842, MSE: 0.22749514826347061, Learning Rate: 0.01\n",
      "Epoch: 18843, MSE: 0.22749514826348308, Learning Rate: 0.01\n",
      "Epoch: 18844, MSE: 0.22749514826349657, Learning Rate: 0.01\n",
      "Epoch: 18845, MSE: 0.22749514826350858, Learning Rate: 0.01\n",
      "Epoch: 18846, MSE: 0.2274951482635216, Learning Rate: 0.01\n",
      "Epoch: 18847, MSE: 0.2274951482635346, Learning Rate: 0.01\n",
      "Epoch: 18848, MSE: 0.22749514826354708, Learning Rate: 0.01\n",
      "Epoch: 18849, MSE: 0.2274951482635596, Learning Rate: 0.01\n",
      "Epoch: 18850, MSE: 0.22749514826357217, Learning Rate: 0.01\n",
      "Epoch: 18851, MSE: 0.2274951482635846, Learning Rate: 0.01\n",
      "Epoch: 18852, MSE: 0.22749514826359787, Learning Rate: 0.01\n",
      "Epoch: 18853, MSE: 0.2274951482636101, Learning Rate: 0.01\n",
      "Epoch: 18854, MSE: 0.2274951482636229, Learning Rate: 0.01\n",
      "Epoch: 18855, MSE: 0.22749514826363607, Learning Rate: 0.01\n",
      "Epoch: 18856, MSE: 0.2274951482636487, Learning Rate: 0.01\n",
      "Epoch: 18857, MSE: 0.22749514826366113, Learning Rate: 0.01\n",
      "Epoch: 18858, MSE: 0.22749514826367398, Learning Rate: 0.01\n",
      "Epoch: 18859, MSE: 0.22749514826368678, Learning Rate: 0.01\n",
      "Epoch: 18860, MSE: 0.2274951482636992, Learning Rate: 0.01\n",
      "Epoch: 18861, MSE: 0.22749514826371167, Learning Rate: 0.01\n",
      "Epoch: 18862, MSE: 0.22749514826372463, Learning Rate: 0.01\n",
      "Epoch: 18863, MSE: 0.22749514826373762, Learning Rate: 0.01\n",
      "Epoch: 18864, MSE: 0.2274951482637501, Learning Rate: 0.01\n",
      "Epoch: 18865, MSE: 0.2274951482637631, Learning Rate: 0.01\n",
      "Epoch: 18866, MSE: 0.22749514826377573, Learning Rate: 0.01\n",
      "Epoch: 18867, MSE: 0.22749514826378814, Learning Rate: 0.01\n",
      "Epoch: 18868, MSE: 0.22749514826380132, Learning Rate: 0.01\n",
      "Epoch: 18869, MSE: 0.22749514826381387, Learning Rate: 0.01\n",
      "Epoch: 18870, MSE: 0.22749514826382672, Learning Rate: 0.01\n",
      "Epoch: 18871, MSE: 0.22749514826383954, Learning Rate: 0.01\n",
      "Epoch: 18872, MSE: 0.22749514826385225, Learning Rate: 0.01\n",
      "Epoch: 18873, MSE: 0.22749514826386474, Learning Rate: 0.01\n",
      "Epoch: 18874, MSE: 0.22749514826387743, Learning Rate: 0.01\n",
      "Epoch: 18875, MSE: 0.22749514826388958, Learning Rate: 0.01\n",
      "Epoch: 18876, MSE: 0.22749514826390266, Learning Rate: 0.01\n",
      "Epoch: 18877, MSE: 0.22749514826391526, Learning Rate: 0.01\n",
      "Epoch: 18878, MSE: 0.2274951482639284, Learning Rate: 0.01\n",
      "Epoch: 18879, MSE: 0.22749514826394077, Learning Rate: 0.01\n",
      "Epoch: 18880, MSE: 0.22749514826395337, Learning Rate: 0.01\n",
      "Epoch: 18881, MSE: 0.22749514826396608, Learning Rate: 0.01\n",
      "Epoch: 18882, MSE: 0.22749514826397874, Learning Rate: 0.01\n",
      "Epoch: 18883, MSE: 0.22749514826399156, Learning Rate: 0.01\n",
      "Epoch: 18884, MSE: 0.22749514826400452, Learning Rate: 0.01\n",
      "Epoch: 18885, MSE: 0.22749514826401718, Learning Rate: 0.01\n",
      "Epoch: 18886, MSE: 0.22749514826402972, Learning Rate: 0.01\n",
      "Epoch: 18887, MSE: 0.22749514826404246, Learning Rate: 0.01\n",
      "Epoch: 18888, MSE: 0.2274951482640551, Learning Rate: 0.01\n",
      "Epoch: 18889, MSE: 0.227495148264068, Learning Rate: 0.01\n",
      "Epoch: 18890, MSE: 0.22749514826408032, Learning Rate: 0.01\n",
      "Epoch: 18891, MSE: 0.22749514826409284, Learning Rate: 0.01\n",
      "Epoch: 18892, MSE: 0.22749514826410605, Learning Rate: 0.01\n",
      "Epoch: 18893, MSE: 0.2274951482641186, Learning Rate: 0.01\n",
      "Epoch: 18894, MSE: 0.22749514826413156, Learning Rate: 0.01\n",
      "Epoch: 18895, MSE: 0.2274951482641439, Learning Rate: 0.01\n",
      "Epoch: 18896, MSE: 0.2274951482641569, Learning Rate: 0.01\n",
      "Epoch: 18897, MSE: 0.22749514826416903, Learning Rate: 0.01\n",
      "Epoch: 18898, MSE: 0.22749514826418252, Learning Rate: 0.01\n",
      "Epoch: 18899, MSE: 0.22749514826419495, Learning Rate: 0.01\n",
      "Epoch: 18900, MSE: 0.2274951482642075, Learning Rate: 0.01\n",
      "Epoch: 18901, MSE: 0.22749514826422057, Learning Rate: 0.01\n",
      "Epoch: 18902, MSE: 0.22749514826423287, Learning Rate: 0.01\n",
      "Epoch: 18903, MSE: 0.22749514826424538, Learning Rate: 0.01\n",
      "Epoch: 18904, MSE: 0.22749514826425843, Learning Rate: 0.01\n",
      "Epoch: 18905, MSE: 0.2274951482642712, Learning Rate: 0.01\n",
      "Epoch: 18906, MSE: 0.22749514826428466, Learning Rate: 0.01\n",
      "Epoch: 18907, MSE: 0.2274951482642966, Learning Rate: 0.01\n",
      "Epoch: 18908, MSE: 0.22749514826430894, Learning Rate: 0.01\n",
      "Epoch: 18909, MSE: 0.22749514826432177, Learning Rate: 0.01\n",
      "Epoch: 18910, MSE: 0.22749514826433467, Learning Rate: 0.01\n",
      "Epoch: 18911, MSE: 0.22749514826434739, Learning Rate: 0.01\n",
      "Epoch: 18912, MSE: 0.22749514826435976, Learning Rate: 0.01\n",
      "Epoch: 18913, MSE: 0.22749514826437303, Learning Rate: 0.01\n",
      "Epoch: 18914, MSE: 0.22749514826438583, Learning Rate: 0.01\n",
      "Epoch: 18915, MSE: 0.22749514826439837, Learning Rate: 0.01\n",
      "Epoch: 18916, MSE: 0.22749514826441078, Learning Rate: 0.01\n",
      "Epoch: 18917, MSE: 0.22749514826442352, Learning Rate: 0.01\n",
      "Epoch: 18918, MSE: 0.2274951482644365, Learning Rate: 0.01\n",
      "Epoch: 18919, MSE: 0.22749514826444905, Learning Rate: 0.01\n",
      "Epoch: 18920, MSE: 0.22749514826446193, Learning Rate: 0.01\n",
      "Epoch: 18921, MSE: 0.22749514826447406, Learning Rate: 0.01\n",
      "Epoch: 18922, MSE: 0.22749514826448722, Learning Rate: 0.01\n",
      "Epoch: 18923, MSE: 0.2274951482645, Learning Rate: 0.01\n",
      "Epoch: 18924, MSE: 0.22749514826451275, Learning Rate: 0.01\n",
      "Epoch: 18925, MSE: 0.22749514826452502, Learning Rate: 0.01\n",
      "Epoch: 18926, MSE: 0.22749514826453762, Learning Rate: 0.01\n",
      "Epoch: 18927, MSE: 0.22749514826455014, Learning Rate: 0.01\n",
      "Epoch: 18928, MSE: 0.22749514826456393, Learning Rate: 0.01\n",
      "Epoch: 18929, MSE: 0.2274951482645757, Learning Rate: 0.01\n",
      "Epoch: 18930, MSE: 0.2274951482645893, Learning Rate: 0.01\n",
      "Epoch: 18931, MSE: 0.22749514826460157, Learning Rate: 0.01\n",
      "Epoch: 18932, MSE: 0.22749514826461392, Learning Rate: 0.01\n",
      "Epoch: 18933, MSE: 0.22749514826462655, Learning Rate: 0.01\n",
      "Epoch: 18934, MSE: 0.22749514826463982, Learning Rate: 0.01\n",
      "Epoch: 18935, MSE: 0.22749514826465173, Learning Rate: 0.01\n",
      "Epoch: 18936, MSE: 0.22749514826466502, Learning Rate: 0.01\n",
      "Epoch: 18937, MSE: 0.227495148264678, Learning Rate: 0.01\n",
      "Epoch: 18938, MSE: 0.22749514826469058, Learning Rate: 0.01\n",
      "Epoch: 18939, MSE: 0.2274951482647031, Learning Rate: 0.01\n",
      "Epoch: 18940, MSE: 0.22749514826471567, Learning Rate: 0.01\n",
      "Epoch: 18941, MSE: 0.22749514826472864, Learning Rate: 0.01\n",
      "Epoch: 18942, MSE: 0.22749514826474115, Learning Rate: 0.01\n",
      "Epoch: 18943, MSE: 0.22749514826475373, Learning Rate: 0.01\n",
      "Epoch: 18944, MSE: 0.2274951482647671, Learning Rate: 0.01\n",
      "Epoch: 18945, MSE: 0.22749514826477943, Learning Rate: 0.01\n",
      "Epoch: 18946, MSE: 0.22749514826479197, Learning Rate: 0.01\n",
      "Epoch: 18947, MSE: 0.22749514826480433, Learning Rate: 0.01\n",
      "Epoch: 18948, MSE: 0.2274951482648171, Learning Rate: 0.01\n",
      "Epoch: 18949, MSE: 0.2274951482648304, Learning Rate: 0.01\n",
      "Epoch: 18950, MSE: 0.22749514826484285, Learning Rate: 0.01\n",
      "Epoch: 18951, MSE: 0.22749514826485556, Learning Rate: 0.01\n",
      "Epoch: 18952, MSE: 0.22749514826486816, Learning Rate: 0.01\n",
      "Epoch: 18953, MSE: 0.2274951482648809, Learning Rate: 0.01\n",
      "Epoch: 18954, MSE: 0.22749514826489345, Learning Rate: 0.01\n",
      "Epoch: 18955, MSE: 0.2274951482649064, Learning Rate: 0.01\n",
      "Epoch: 18956, MSE: 0.22749514826491885, Learning Rate: 0.01\n",
      "Epoch: 18957, MSE: 0.2274951482649318, Learning Rate: 0.01\n",
      "Epoch: 18958, MSE: 0.22749514826494477, Learning Rate: 0.01\n",
      "Epoch: 18959, MSE: 0.22749514826495723, Learning Rate: 0.01\n",
      "Epoch: 18960, MSE: 0.22749514826497033, Learning Rate: 0.01\n",
      "Epoch: 18961, MSE: 0.22749514826498257, Learning Rate: 0.01\n",
      "Epoch: 18962, MSE: 0.2274951482649954, Learning Rate: 0.01\n",
      "Epoch: 18963, MSE: 0.22749514826500827, Learning Rate: 0.01\n",
      "Epoch: 18964, MSE: 0.22749514826502104, Learning Rate: 0.01\n",
      "Epoch: 18965, MSE: 0.22749514826503345, Learning Rate: 0.01\n",
      "Epoch: 18966, MSE: 0.22749514826504616, Learning Rate: 0.01\n",
      "Epoch: 18967, MSE: 0.22749514826505887, Learning Rate: 0.01\n",
      "Epoch: 18968, MSE: 0.22749514826507167, Learning Rate: 0.01\n",
      "Epoch: 18969, MSE: 0.22749514826508418, Learning Rate: 0.01\n",
      "Epoch: 18970, MSE: 0.22749514826509684, Learning Rate: 0.01\n",
      "Epoch: 18971, MSE: 0.22749514826510953, Learning Rate: 0.01\n",
      "Epoch: 18972, MSE: 0.22749514826512252, Learning Rate: 0.01\n",
      "Epoch: 18973, MSE: 0.22749514826513526, Learning Rate: 0.01\n",
      "Epoch: 18974, MSE: 0.22749514826514777, Learning Rate: 0.01\n",
      "Epoch: 18975, MSE: 0.2274951482651605, Learning Rate: 0.01\n",
      "Epoch: 18976, MSE: 0.22749514826517328, Learning Rate: 0.01\n",
      "Epoch: 18977, MSE: 0.22749514826518596, Learning Rate: 0.01\n",
      "Epoch: 18978, MSE: 0.22749514826519912, Learning Rate: 0.01\n",
      "Epoch: 18979, MSE: 0.22749514826521125, Learning Rate: 0.01\n",
      "Epoch: 18980, MSE: 0.22749514826522405, Learning Rate: 0.01\n",
      "Epoch: 18981, MSE: 0.22749514826523687, Learning Rate: 0.01\n",
      "Epoch: 18982, MSE: 0.22749514826524964, Learning Rate: 0.01\n",
      "Epoch: 18983, MSE: 0.227495148265262, Learning Rate: 0.01\n",
      "Epoch: 18984, MSE: 0.22749514826527462, Learning Rate: 0.01\n",
      "Epoch: 18985, MSE: 0.22749514826528688, Learning Rate: 0.01\n",
      "Epoch: 18986, MSE: 0.2274951482653004, Learning Rate: 0.01\n",
      "Epoch: 18987, MSE: 0.22749514826531259, Learning Rate: 0.01\n",
      "Epoch: 18988, MSE: 0.22749514826532527, Learning Rate: 0.01\n",
      "Epoch: 18989, MSE: 0.22749514826533815, Learning Rate: 0.01\n",
      "Epoch: 18990, MSE: 0.227495148265351, Learning Rate: 0.01\n",
      "Epoch: 18991, MSE: 0.22749514826536335, Learning Rate: 0.01\n",
      "Epoch: 18992, MSE: 0.2274951482653764, Learning Rate: 0.01\n",
      "Epoch: 18993, MSE: 0.22749514826538916, Learning Rate: 0.01\n",
      "Epoch: 18994, MSE: 0.22749514826540174, Learning Rate: 0.01\n",
      "Epoch: 18995, MSE: 0.22749514826541445, Learning Rate: 0.01\n",
      "Epoch: 18996, MSE: 0.22749514826542724, Learning Rate: 0.01\n",
      "Epoch: 18997, MSE: 0.2274951482654398, Learning Rate: 0.01\n",
      "Epoch: 18998, MSE: 0.22749514826545242, Learning Rate: 0.01\n",
      "Epoch: 18999, MSE: 0.2274951482654651, Learning Rate: 0.01\n",
      "Epoch: 19000, MSE: 0.22749514826547798, Learning Rate: 0.01\n",
      "Epoch: 19001, MSE: 0.22749514826549086, Learning Rate: 0.01\n",
      "Epoch: 19002, MSE: 0.2274951482655036, Learning Rate: 0.01\n",
      "Epoch: 19003, MSE: 0.22749514826551642, Learning Rate: 0.01\n",
      "Epoch: 19004, MSE: 0.22749514826552866, Learning Rate: 0.01\n",
      "Epoch: 19005, MSE: 0.22749514826554146, Learning Rate: 0.01\n",
      "Epoch: 19006, MSE: 0.22749514826555434, Learning Rate: 0.01\n",
      "Epoch: 19007, MSE: 0.22749514826556674, Learning Rate: 0.01\n",
      "Epoch: 19008, MSE: 0.22749514826557937, Learning Rate: 0.01\n",
      "Epoch: 19009, MSE: 0.22749514826559217, Learning Rate: 0.01\n",
      "Epoch: 19010, MSE: 0.22749514826560552, Learning Rate: 0.01\n",
      "Epoch: 19011, MSE: 0.22749514826561765, Learning Rate: 0.01\n",
      "Epoch: 19012, MSE: 0.22749514826563014, Learning Rate: 0.01\n",
      "Epoch: 19013, MSE: 0.22749514826564296, Learning Rate: 0.01\n",
      "Epoch: 19014, MSE: 0.22749514826565553, Learning Rate: 0.01\n",
      "Epoch: 19015, MSE: 0.2274951482656682, Learning Rate: 0.01\n",
      "Epoch: 19016, MSE: 0.2274951482656813, Learning Rate: 0.01\n",
      "Epoch: 19017, MSE: 0.2274951482656939, Learning Rate: 0.01\n",
      "Epoch: 19018, MSE: 0.2274951482657063, Learning Rate: 0.01\n",
      "Epoch: 19019, MSE: 0.22749514826571915, Learning Rate: 0.01\n",
      "Epoch: 19020, MSE: 0.22749514826573217, Learning Rate: 0.01\n",
      "Epoch: 19021, MSE: 0.2274951482657442, Learning Rate: 0.01\n",
      "Epoch: 19022, MSE: 0.2274951482657572, Learning Rate: 0.01\n",
      "Epoch: 19023, MSE: 0.22749514826577005, Learning Rate: 0.01\n",
      "Epoch: 19024, MSE: 0.22749514826578282, Learning Rate: 0.01\n",
      "Epoch: 19025, MSE: 0.22749514826579537, Learning Rate: 0.01\n",
      "Epoch: 19026, MSE: 0.22749514826580775, Learning Rate: 0.01\n",
      "Epoch: 19027, MSE: 0.22749514826582065, Learning Rate: 0.01\n",
      "Epoch: 19028, MSE: 0.2274951482658339, Learning Rate: 0.01\n",
      "Epoch: 19029, MSE: 0.22749514826584658, Learning Rate: 0.01\n",
      "Epoch: 19030, MSE: 0.22749514826585854, Learning Rate: 0.01\n",
      "Epoch: 19031, MSE: 0.2274951482658714, Learning Rate: 0.01\n",
      "Epoch: 19032, MSE: 0.22749514826588435, Learning Rate: 0.01\n",
      "Epoch: 19033, MSE: 0.22749514826589742, Learning Rate: 0.01\n",
      "Epoch: 19034, MSE: 0.22749514826590997, Learning Rate: 0.01\n",
      "Epoch: 19035, MSE: 0.22749514826592235, Learning Rate: 0.01\n",
      "Epoch: 19036, MSE: 0.22749514826593534, Learning Rate: 0.01\n",
      "Epoch: 19037, MSE: 0.22749514826594786, Learning Rate: 0.01\n",
      "Epoch: 19038, MSE: 0.22749514826596068, Learning Rate: 0.01\n",
      "Epoch: 19039, MSE: 0.22749514826597336, Learning Rate: 0.01\n",
      "Epoch: 19040, MSE: 0.2274951482659862, Learning Rate: 0.01\n",
      "Epoch: 19041, MSE: 0.227495148265999, Learning Rate: 0.01\n",
      "Epoch: 19042, MSE: 0.22749514826601144, Learning Rate: 0.01\n",
      "Epoch: 19043, MSE: 0.2274951482660242, Learning Rate: 0.01\n",
      "Epoch: 19044, MSE: 0.22749514826603706, Learning Rate: 0.01\n",
      "Epoch: 19045, MSE: 0.22749514826604963, Learning Rate: 0.01\n",
      "Epoch: 19046, MSE: 0.22749514826606204, Learning Rate: 0.01\n",
      "Epoch: 19047, MSE: 0.22749514826607448, Learning Rate: 0.01\n",
      "Epoch: 19048, MSE: 0.2274951482660876, Learning Rate: 0.01\n",
      "Epoch: 19049, MSE: 0.2274951482661, Learning Rate: 0.01\n",
      "Epoch: 19050, MSE: 0.22749514826611278, Learning Rate: 0.01\n",
      "Epoch: 19051, MSE: 0.22749514826612577, Learning Rate: 0.01\n",
      "Epoch: 19052, MSE: 0.22749514826613812, Learning Rate: 0.01\n",
      "Epoch: 19053, MSE: 0.22749514826615014, Learning Rate: 0.01\n",
      "Epoch: 19054, MSE: 0.2274951482661635, Learning Rate: 0.01\n",
      "Epoch: 19055, MSE: 0.22749514826617606, Learning Rate: 0.01\n",
      "Epoch: 19056, MSE: 0.22749514826618916, Learning Rate: 0.01\n",
      "Epoch: 19057, MSE: 0.2274951482662018, Learning Rate: 0.01\n",
      "Epoch: 19058, MSE: 0.22749514826621484, Learning Rate: 0.01\n",
      "Epoch: 19059, MSE: 0.22749514826622738, Learning Rate: 0.01\n",
      "Epoch: 19060, MSE: 0.22749514826623995, Learning Rate: 0.01\n",
      "Epoch: 19061, MSE: 0.22749514826625253, Learning Rate: 0.01\n",
      "Epoch: 19062, MSE: 0.22749514826626518, Learning Rate: 0.01\n",
      "Epoch: 19063, MSE: 0.22749514826627795, Learning Rate: 0.01\n",
      "Epoch: 19064, MSE: 0.22749514826629047, Learning Rate: 0.01\n",
      "Epoch: 19065, MSE: 0.2274951482663029, Learning Rate: 0.01\n",
      "Epoch: 19066, MSE: 0.22749514826631648, Learning Rate: 0.01\n",
      "Epoch: 19067, MSE: 0.2274951482663286, Learning Rate: 0.01\n",
      "Epoch: 19068, MSE: 0.22749514826634132, Learning Rate: 0.01\n",
      "Epoch: 19069, MSE: 0.22749514826635422, Learning Rate: 0.01\n",
      "Epoch: 19070, MSE: 0.22749514826636671, Learning Rate: 0.01\n",
      "Epoch: 19071, MSE: 0.2274951482663801, Learning Rate: 0.01\n",
      "Epoch: 19072, MSE: 0.22749514826639236, Learning Rate: 0.01\n",
      "Epoch: 19073, MSE: 0.2274951482664049, Learning Rate: 0.01\n",
      "Epoch: 19074, MSE: 0.22749514826641803, Learning Rate: 0.01\n",
      "Epoch: 19075, MSE: 0.22749514826643008, Learning Rate: 0.01\n",
      "Epoch: 19076, MSE: 0.22749514826644296, Learning Rate: 0.01\n",
      "Epoch: 19077, MSE: 0.22749514826645603, Learning Rate: 0.01\n",
      "Epoch: 19078, MSE: 0.22749514826646838, Learning Rate: 0.01\n",
      "Epoch: 19079, MSE: 0.22749514826648085, Learning Rate: 0.01\n",
      "Epoch: 19080, MSE: 0.22749514826649378, Learning Rate: 0.01\n",
      "Epoch: 19081, MSE: 0.22749514826650646, Learning Rate: 0.01\n",
      "Epoch: 19082, MSE: 0.2274951482665194, Learning Rate: 0.01\n",
      "Epoch: 19083, MSE: 0.22749514826653192, Learning Rate: 0.01\n",
      "Epoch: 19084, MSE: 0.22749514826654474, Learning Rate: 0.01\n",
      "Epoch: 19085, MSE: 0.22749514826655728, Learning Rate: 0.01\n",
      "Epoch: 19086, MSE: 0.2274951482665702, Learning Rate: 0.01\n",
      "Epoch: 19087, MSE: 0.22749514826658246, Learning Rate: 0.01\n",
      "Epoch: 19088, MSE: 0.22749514826659542, Learning Rate: 0.01\n",
      "Epoch: 19089, MSE: 0.2274951482666085, Learning Rate: 0.01\n",
      "Epoch: 19090, MSE: 0.22749514826662087, Learning Rate: 0.01\n",
      "Epoch: 19091, MSE: 0.22749514826663364, Learning Rate: 0.01\n",
      "Epoch: 19092, MSE: 0.2274951482666465, Learning Rate: 0.01\n",
      "Epoch: 19093, MSE: 0.22749514826665868, Learning Rate: 0.01\n",
      "Epoch: 19094, MSE: 0.2274951482666714, Learning Rate: 0.01\n",
      "Epoch: 19095, MSE: 0.227495148266684, Learning Rate: 0.01\n",
      "Epoch: 19096, MSE: 0.227495148266697, Learning Rate: 0.01\n",
      "Epoch: 19097, MSE: 0.2274951482667095, Learning Rate: 0.01\n",
      "Epoch: 19098, MSE: 0.22749514826672243, Learning Rate: 0.01\n",
      "Epoch: 19099, MSE: 0.2274951482667351, Learning Rate: 0.01\n",
      "Epoch: 19100, MSE: 0.2274951482667475, Learning Rate: 0.01\n",
      "Epoch: 19101, MSE: 0.22749514826676054, Learning Rate: 0.01\n",
      "Epoch: 19102, MSE: 0.22749514826677342, Learning Rate: 0.01\n",
      "Epoch: 19103, MSE: 0.22749514826678585, Learning Rate: 0.01\n",
      "Epoch: 19104, MSE: 0.2274951482667984, Learning Rate: 0.01\n",
      "Epoch: 19105, MSE: 0.22749514826681153, Learning Rate: 0.01\n",
      "Epoch: 19106, MSE: 0.22749514826682443, Learning Rate: 0.01\n",
      "Epoch: 19107, MSE: 0.22749514826683678, Learning Rate: 0.01\n",
      "Epoch: 19108, MSE: 0.22749514826684938, Learning Rate: 0.01\n",
      "Epoch: 19109, MSE: 0.22749514826686204, Learning Rate: 0.01\n",
      "Epoch: 19110, MSE: 0.22749514826687486, Learning Rate: 0.01\n",
      "Epoch: 19111, MSE: 0.2274951482668872, Learning Rate: 0.01\n",
      "Epoch: 19112, MSE: 0.22749514826690048, Learning Rate: 0.01\n",
      "Epoch: 19113, MSE: 0.22749514826691283, Learning Rate: 0.01\n",
      "Epoch: 19114, MSE: 0.2274951482669255, Learning Rate: 0.01\n",
      "Epoch: 19115, MSE: 0.22749514826693865, Learning Rate: 0.01\n",
      "Epoch: 19116, MSE: 0.22749514826695083, Learning Rate: 0.01\n",
      "Epoch: 19117, MSE: 0.22749514826696354, Learning Rate: 0.01\n",
      "Epoch: 19118, MSE: 0.2274951482669763, Learning Rate: 0.01\n",
      "Epoch: 19119, MSE: 0.22749514826698922, Learning Rate: 0.01\n",
      "Epoch: 19120, MSE: 0.22749514826700207, Learning Rate: 0.01\n",
      "Epoch: 19121, MSE: 0.22749514826701409, Learning Rate: 0.01\n",
      "Epoch: 19122, MSE: 0.22749514826702744, Learning Rate: 0.01\n",
      "Epoch: 19123, MSE: 0.2274951482670405, Learning Rate: 0.01\n",
      "Epoch: 19124, MSE: 0.22749514826705206, Learning Rate: 0.01\n",
      "Epoch: 19125, MSE: 0.22749514826706543, Learning Rate: 0.01\n",
      "Epoch: 19126, MSE: 0.22749514826707848, Learning Rate: 0.01\n",
      "Epoch: 19127, MSE: 0.2274951482670908, Learning Rate: 0.01\n",
      "Epoch: 19128, MSE: 0.22749514826710346, Learning Rate: 0.01\n",
      "Epoch: 19129, MSE: 0.22749514826711625, Learning Rate: 0.01\n",
      "Epoch: 19130, MSE: 0.22749514826712902, Learning Rate: 0.01\n",
      "Epoch: 19131, MSE: 0.22749514826714157, Learning Rate: 0.01\n",
      "Epoch: 19132, MSE: 0.2274951482671541, Learning Rate: 0.01\n",
      "Epoch: 19133, MSE: 0.2274951482671668, Learning Rate: 0.01\n",
      "Epoch: 19134, MSE: 0.2274951482671797, Learning Rate: 0.01\n",
      "Epoch: 19135, MSE: 0.22749514826719175, Learning Rate: 0.01\n",
      "Epoch: 19136, MSE: 0.22749514826720527, Learning Rate: 0.01\n",
      "Epoch: 19137, MSE: 0.22749514826721773, Learning Rate: 0.01\n",
      "Epoch: 19138, MSE: 0.22749514826723016, Learning Rate: 0.01\n",
      "Epoch: 19139, MSE: 0.2274951482672432, Learning Rate: 0.01\n",
      "Epoch: 19140, MSE: 0.2274951482672557, Learning Rate: 0.01\n",
      "Epoch: 19141, MSE: 0.2274951482672685, Learning Rate: 0.01\n",
      "Epoch: 19142, MSE: 0.22749514826728087, Learning Rate: 0.01\n",
      "Epoch: 19143, MSE: 0.22749514826729372, Learning Rate: 0.01\n",
      "Epoch: 19144, MSE: 0.22749514826730616, Learning Rate: 0.01\n",
      "Epoch: 19145, MSE: 0.22749514826731917, Learning Rate: 0.01\n",
      "Epoch: 19146, MSE: 0.2274951482673316, Learning Rate: 0.01\n",
      "Epoch: 19147, MSE: 0.22749514826734435, Learning Rate: 0.01\n",
      "Epoch: 19148, MSE: 0.2274951482673573, Learning Rate: 0.01\n",
      "Epoch: 19149, MSE: 0.2274951482673698, Learning Rate: 0.01\n",
      "Epoch: 19150, MSE: 0.22749514826738224, Learning Rate: 0.01\n",
      "Epoch: 19151, MSE: 0.22749514826739548, Learning Rate: 0.01\n",
      "Epoch: 19152, MSE: 0.22749514826740821, Learning Rate: 0.01\n",
      "Epoch: 19153, MSE: 0.227495148267421, Learning Rate: 0.01\n",
      "Epoch: 19154, MSE: 0.22749514826743356, Learning Rate: 0.01\n",
      "Epoch: 19155, MSE: 0.2274951482674459, Learning Rate: 0.01\n",
      "Epoch: 19156, MSE: 0.22749514826745856, Learning Rate: 0.01\n",
      "Epoch: 19157, MSE: 0.2274951482674714, Learning Rate: 0.01\n",
      "Epoch: 19158, MSE: 0.2274951482674843, Learning Rate: 0.01\n",
      "Epoch: 19159, MSE: 0.22749514826749717, Learning Rate: 0.01\n",
      "Epoch: 19160, MSE: 0.22749514826750952, Learning Rate: 0.01\n",
      "Epoch: 19161, MSE: 0.22749514826752232, Learning Rate: 0.01\n",
      "Epoch: 19162, MSE: 0.22749514826753467, Learning Rate: 0.01\n",
      "Epoch: 19163, MSE: 0.2274951482675477, Learning Rate: 0.01\n",
      "Epoch: 19164, MSE: 0.22749514826756045, Learning Rate: 0.01\n",
      "Epoch: 19165, MSE: 0.2274951482675729, Learning Rate: 0.01\n",
      "Epoch: 19166, MSE: 0.22749514826758596, Learning Rate: 0.01\n",
      "Epoch: 19167, MSE: 0.227495148267598, Learning Rate: 0.01\n",
      "Epoch: 19168, MSE: 0.22749514826761136, Learning Rate: 0.01\n",
      "Epoch: 19169, MSE: 0.22749514826762357, Learning Rate: 0.01\n",
      "Epoch: 19170, MSE: 0.22749514826763684, Learning Rate: 0.01\n",
      "Epoch: 19171, MSE: 0.22749514826764963, Learning Rate: 0.01\n",
      "Epoch: 19172, MSE: 0.2274951482676618, Learning Rate: 0.01\n",
      "Epoch: 19173, MSE: 0.22749514826767492, Learning Rate: 0.01\n",
      "Epoch: 19174, MSE: 0.227495148267688, Learning Rate: 0.01\n",
      "Epoch: 19175, MSE: 0.22749514826769973, Learning Rate: 0.01\n",
      "Epoch: 19176, MSE: 0.22749514826771228, Learning Rate: 0.01\n",
      "Epoch: 19177, MSE: 0.22749514826772513, Learning Rate: 0.01\n",
      "Epoch: 19178, MSE: 0.22749514826773798, Learning Rate: 0.01\n",
      "Epoch: 19179, MSE: 0.22749514826775036, Learning Rate: 0.01\n",
      "Epoch: 19180, MSE: 0.22749514826776362, Learning Rate: 0.01\n",
      "Epoch: 19181, MSE: 0.2274951482677764, Learning Rate: 0.01\n",
      "Epoch: 19182, MSE: 0.22749514826778885, Learning Rate: 0.01\n",
      "Epoch: 19183, MSE: 0.22749514826780118, Learning Rate: 0.01\n",
      "Epoch: 19184, MSE: 0.22749514826781422, Learning Rate: 0.01\n",
      "Epoch: 19185, MSE: 0.22749514826782666, Learning Rate: 0.01\n",
      "Epoch: 19186, MSE: 0.22749514826783948, Learning Rate: 0.01\n",
      "Epoch: 19187, MSE: 0.22749514826785222, Learning Rate: 0.01\n",
      "Epoch: 19188, MSE: 0.22749514826786535, Learning Rate: 0.01\n",
      "Epoch: 19189, MSE: 0.22749514826787745, Learning Rate: 0.01\n",
      "Epoch: 19190, MSE: 0.22749514826789038, Learning Rate: 0.01\n",
      "Epoch: 19191, MSE: 0.2274951482679028, Learning Rate: 0.01\n",
      "Epoch: 19192, MSE: 0.227495148267916, Learning Rate: 0.01\n",
      "Epoch: 19193, MSE: 0.22749514826792877, Learning Rate: 0.01\n",
      "Epoch: 19194, MSE: 0.22749514826794148, Learning Rate: 0.01\n",
      "Epoch: 19195, MSE: 0.22749514826795378, Learning Rate: 0.01\n",
      "Epoch: 19196, MSE: 0.2274951482679663, Learning Rate: 0.01\n",
      "Epoch: 19197, MSE: 0.2274951482679791, Learning Rate: 0.01\n",
      "Epoch: 19198, MSE: 0.2274951482679918, Learning Rate: 0.01\n",
      "Epoch: 19199, MSE: 0.2274951482680047, Learning Rate: 0.01\n",
      "Epoch: 19200, MSE: 0.22749514826801695, Learning Rate: 0.01\n",
      "Epoch: 19201, MSE: 0.22749514826802983, Learning Rate: 0.01\n",
      "Epoch: 19202, MSE: 0.22749514826804249, Learning Rate: 0.01\n",
      "Epoch: 19203, MSE: 0.22749514826805545, Learning Rate: 0.01\n",
      "Epoch: 19204, MSE: 0.22749514826806824, Learning Rate: 0.01\n",
      "Epoch: 19205, MSE: 0.22749514826808048, Learning Rate: 0.01\n",
      "Epoch: 19206, MSE: 0.22749514826809317, Learning Rate: 0.01\n",
      "Epoch: 19207, MSE: 0.2274951482681056, Learning Rate: 0.01\n",
      "Epoch: 19208, MSE: 0.22749514826811798, Learning Rate: 0.01\n",
      "Epoch: 19209, MSE: 0.22749514826813164, Learning Rate: 0.01\n",
      "Epoch: 19210, MSE: 0.22749514826814482, Learning Rate: 0.01\n",
      "Epoch: 19211, MSE: 0.22749514826815667, Learning Rate: 0.01\n",
      "Epoch: 19212, MSE: 0.22749514826816972, Learning Rate: 0.01\n",
      "Epoch: 19213, MSE: 0.22749514826818235, Learning Rate: 0.01\n",
      "Epoch: 19214, MSE: 0.22749514826819492, Learning Rate: 0.01\n",
      "Epoch: 19215, MSE: 0.2274951482682078, Learning Rate: 0.01\n",
      "Epoch: 19216, MSE: 0.22749514826822023, Learning Rate: 0.01\n",
      "Epoch: 19217, MSE: 0.22749514826823314, Learning Rate: 0.01\n",
      "Epoch: 19218, MSE: 0.22749514826824582, Learning Rate: 0.01\n",
      "Epoch: 19219, MSE: 0.2274951482682582, Learning Rate: 0.01\n",
      "Epoch: 19220, MSE: 0.22749514826827116, Learning Rate: 0.01\n",
      "Epoch: 19221, MSE: 0.22749514826828424, Learning Rate: 0.01\n",
      "Epoch: 19222, MSE: 0.2274951482682967, Learning Rate: 0.01\n",
      "Epoch: 19223, MSE: 0.2274951482683089, Learning Rate: 0.01\n",
      "Epoch: 19224, MSE: 0.227495148268322, Learning Rate: 0.01\n",
      "Epoch: 19225, MSE: 0.22749514826833447, Learning Rate: 0.01\n",
      "Epoch: 19226, MSE: 0.22749514826834683, Learning Rate: 0.01\n",
      "Epoch: 19227, MSE: 0.2274951482683598, Learning Rate: 0.01\n",
      "Epoch: 19228, MSE: 0.22749514826837275, Learning Rate: 0.01\n",
      "Epoch: 19229, MSE: 0.2274951482683856, Learning Rate: 0.01\n",
      "Epoch: 19230, MSE: 0.22749514826839784, Learning Rate: 0.01\n",
      "Epoch: 19231, MSE: 0.22749514826841058, Learning Rate: 0.01\n",
      "Epoch: 19232, MSE: 0.2274951482684238, Learning Rate: 0.01\n",
      "Epoch: 19233, MSE: 0.22749514826843567, Learning Rate: 0.01\n",
      "Epoch: 19234, MSE: 0.22749514826844877, Learning Rate: 0.01\n",
      "Epoch: 19235, MSE: 0.2274951482684616, Learning Rate: 0.01\n",
      "Epoch: 19236, MSE: 0.22749514826847403, Learning Rate: 0.01\n",
      "Epoch: 19237, MSE: 0.22749514826848694, Learning Rate: 0.01\n",
      "Epoch: 19238, MSE: 0.22749514826849968, Learning Rate: 0.01\n",
      "Epoch: 19239, MSE: 0.22749514826851236, Learning Rate: 0.01\n",
      "Epoch: 19240, MSE: 0.22749514826852513, Learning Rate: 0.01\n",
      "Epoch: 19241, MSE: 0.22749514826853726, Learning Rate: 0.01\n",
      "Epoch: 19242, MSE: 0.22749514826855, Learning Rate: 0.01\n",
      "Epoch: 19243, MSE: 0.22749514826856265, Learning Rate: 0.01\n",
      "Epoch: 19244, MSE: 0.22749514826857548, Learning Rate: 0.01\n",
      "Epoch: 19245, MSE: 0.2274951482685889, Learning Rate: 0.01\n",
      "Epoch: 19246, MSE: 0.2274951482686009, Learning Rate: 0.01\n",
      "Epoch: 19247, MSE: 0.2274951482686132, Learning Rate: 0.01\n",
      "Epoch: 19248, MSE: 0.22749514826862677, Learning Rate: 0.01\n",
      "Epoch: 19249, MSE: 0.2274951482686392, Learning Rate: 0.01\n",
      "Epoch: 19250, MSE: 0.22749514826865183, Learning Rate: 0.01\n",
      "Epoch: 19251, MSE: 0.22749514826866443, Learning Rate: 0.01\n",
      "Epoch: 19252, MSE: 0.22749514826867726, Learning Rate: 0.01\n",
      "Epoch: 19253, MSE: 0.22749514826868994, Learning Rate: 0.01\n",
      "Epoch: 19254, MSE: 0.22749514826870235, Learning Rate: 0.01\n",
      "Epoch: 19255, MSE: 0.22749514826871522, Learning Rate: 0.01\n",
      "Epoch: 19256, MSE: 0.22749514826872802, Learning Rate: 0.01\n",
      "Epoch: 19257, MSE: 0.22749514826874045, Learning Rate: 0.01\n",
      "Epoch: 19258, MSE: 0.22749514826875333, Learning Rate: 0.01\n",
      "Epoch: 19259, MSE: 0.227495148268766, Learning Rate: 0.01\n",
      "Epoch: 19260, MSE: 0.22749514826877873, Learning Rate: 0.01\n",
      "Epoch: 19261, MSE: 0.22749514826879147, Learning Rate: 0.01\n",
      "Epoch: 19262, MSE: 0.22749514826880465, Learning Rate: 0.01\n",
      "Epoch: 19263, MSE: 0.2274951482688168, Learning Rate: 0.01\n",
      "Epoch: 19264, MSE: 0.22749514826882894, Learning Rate: 0.01\n",
      "Epoch: 19265, MSE: 0.22749514826884182, Learning Rate: 0.01\n",
      "Epoch: 19266, MSE: 0.2274951482688552, Learning Rate: 0.01\n",
      "Epoch: 19267, MSE: 0.2274951482688676, Learning Rate: 0.01\n",
      "Epoch: 19268, MSE: 0.22749514826888018, Learning Rate: 0.01\n",
      "Epoch: 19269, MSE: 0.22749514826889333, Learning Rate: 0.01\n",
      "Epoch: 19270, MSE: 0.2274951482689053, Learning Rate: 0.01\n",
      "Epoch: 19271, MSE: 0.22749514826891792, Learning Rate: 0.01\n",
      "Epoch: 19272, MSE: 0.22749514826893075, Learning Rate: 0.01\n",
      "Epoch: 19273, MSE: 0.2274951482689431, Learning Rate: 0.01\n",
      "Epoch: 19274, MSE: 0.22749514826895664, Learning Rate: 0.01\n",
      "Epoch: 19275, MSE: 0.22749514826896855, Learning Rate: 0.01\n",
      "Epoch: 19276, MSE: 0.2274951482689819, Learning Rate: 0.01\n",
      "Epoch: 19277, MSE: 0.2274951482689944, Learning Rate: 0.01\n",
      "Epoch: 19278, MSE: 0.2274951482690074, Learning Rate: 0.01\n",
      "Epoch: 19279, MSE: 0.2274951482690198, Learning Rate: 0.01\n",
      "Epoch: 19280, MSE: 0.2274951482690321, Learning Rate: 0.01\n",
      "Epoch: 19281, MSE: 0.22749514826904502, Learning Rate: 0.01\n",
      "Epoch: 19282, MSE: 0.22749514826905767, Learning Rate: 0.01\n",
      "Epoch: 19283, MSE: 0.22749514826907027, Learning Rate: 0.01\n",
      "Epoch: 19284, MSE: 0.22749514826908243, Learning Rate: 0.01\n",
      "Epoch: 19285, MSE: 0.22749514826909578, Learning Rate: 0.01\n",
      "Epoch: 19286, MSE: 0.2274951482691085, Learning Rate: 0.01\n",
      "Epoch: 19287, MSE: 0.22749514826912134, Learning Rate: 0.01\n",
      "Epoch: 19288, MSE: 0.22749514826913378, Learning Rate: 0.01\n",
      "Epoch: 19289, MSE: 0.22749514826914663, Learning Rate: 0.01\n",
      "Epoch: 19290, MSE: 0.22749514826915962, Learning Rate: 0.01\n",
      "Epoch: 19291, MSE: 0.22749514826917155, Learning Rate: 0.01\n",
      "Epoch: 19292, MSE: 0.22749514826918485, Learning Rate: 0.01\n",
      "Epoch: 19293, MSE: 0.22749514826919728, Learning Rate: 0.01\n",
      "Epoch: 19294, MSE: 0.2274951482692097, Learning Rate: 0.01\n",
      "Epoch: 19295, MSE: 0.227495148269223, Learning Rate: 0.01\n",
      "Epoch: 19296, MSE: 0.22749514826923567, Learning Rate: 0.01\n",
      "Epoch: 19297, MSE: 0.22749514826924808, Learning Rate: 0.01\n",
      "Epoch: 19298, MSE: 0.22749514826926065, Learning Rate: 0.01\n",
      "Epoch: 19299, MSE: 0.2274951482692734, Learning Rate: 0.01\n",
      "Epoch: 19300, MSE: 0.22749514826928594, Learning Rate: 0.01\n",
      "Epoch: 19301, MSE: 0.22749514826929879, Learning Rate: 0.01\n",
      "Epoch: 19302, MSE: 0.22749514826931133, Learning Rate: 0.01\n",
      "Epoch: 19303, MSE: 0.227495148269324, Learning Rate: 0.01\n",
      "Epoch: 19304, MSE: 0.22749514826933676, Learning Rate: 0.01\n",
      "Epoch: 19305, MSE: 0.22749514826934966, Learning Rate: 0.01\n",
      "Epoch: 19306, MSE: 0.22749514826936243, Learning Rate: 0.01\n",
      "Epoch: 19307, MSE: 0.22749514826937517, Learning Rate: 0.01\n",
      "Epoch: 19308, MSE: 0.22749514826938738, Learning Rate: 0.01\n",
      "Epoch: 19309, MSE: 0.2274951482694004, Learning Rate: 0.01\n",
      "Epoch: 19310, MSE: 0.2274951482694129, Learning Rate: 0.01\n",
      "Epoch: 19311, MSE: 0.22749514826942557, Learning Rate: 0.01\n",
      "Epoch: 19312, MSE: 0.22749514826943865, Learning Rate: 0.01\n",
      "Epoch: 19313, MSE: 0.227495148269451, Learning Rate: 0.01\n",
      "Epoch: 19314, MSE: 0.22749514826946346, Learning Rate: 0.01\n",
      "Epoch: 19315, MSE: 0.22749514826947653, Learning Rate: 0.01\n",
      "Epoch: 19316, MSE: 0.22749514826948944, Learning Rate: 0.01\n",
      "Epoch: 19317, MSE: 0.22749514826950232, Learning Rate: 0.01\n",
      "Epoch: 19318, MSE: 0.22749514826951475, Learning Rate: 0.01\n",
      "Epoch: 19319, MSE: 0.22749514826952721, Learning Rate: 0.01\n",
      "Epoch: 19320, MSE: 0.22749514826954, Learning Rate: 0.01\n",
      "Epoch: 19321, MSE: 0.22749514826955292, Learning Rate: 0.01\n",
      "Epoch: 19322, MSE: 0.22749514826956532, Learning Rate: 0.01\n",
      "Epoch: 19323, MSE: 0.22749514826957792, Learning Rate: 0.01\n",
      "Epoch: 19324, MSE: 0.22749514826959064, Learning Rate: 0.01\n",
      "Epoch: 19325, MSE: 0.22749514826960318, Learning Rate: 0.01\n",
      "Epoch: 19326, MSE: 0.22749514826961625, Learning Rate: 0.01\n",
      "Epoch: 19327, MSE: 0.22749514826962858, Learning Rate: 0.01\n",
      "Epoch: 19328, MSE: 0.2274951482696415, Learning Rate: 0.01\n",
      "Epoch: 19329, MSE: 0.22749514826965386, Learning Rate: 0.01\n",
      "Epoch: 19330, MSE: 0.22749514826966666, Learning Rate: 0.01\n",
      "Epoch: 19331, MSE: 0.22749514826967937, Learning Rate: 0.01\n",
      "Epoch: 19332, MSE: 0.22749514826969205, Learning Rate: 0.01\n",
      "Epoch: 19333, MSE: 0.22749514826970504, Learning Rate: 0.01\n",
      "Epoch: 19334, MSE: 0.22749514826971756, Learning Rate: 0.01\n",
      "Epoch: 19335, MSE: 0.22749514826972994, Learning Rate: 0.01\n",
      "Epoch: 19336, MSE: 0.22749514826974285, Learning Rate: 0.01\n",
      "Epoch: 19337, MSE: 0.22749514826975561, Learning Rate: 0.01\n",
      "Epoch: 19338, MSE: 0.2274951482697684, Learning Rate: 0.01\n",
      "Epoch: 19339, MSE: 0.22749514826978096, Learning Rate: 0.01\n",
      "Epoch: 19340, MSE: 0.22749514826979297, Learning Rate: 0.01\n",
      "Epoch: 19341, MSE: 0.22749514826980646, Learning Rate: 0.01\n",
      "Epoch: 19342, MSE: 0.22749514826981884, Learning Rate: 0.01\n",
      "Epoch: 19343, MSE: 0.22749514826983133, Learning Rate: 0.01\n",
      "Epoch: 19344, MSE: 0.22749514826984393, Learning Rate: 0.01\n",
      "Epoch: 19345, MSE: 0.22749514826985695, Learning Rate: 0.01\n",
      "Epoch: 19346, MSE: 0.22749514826986983, Learning Rate: 0.01\n",
      "Epoch: 19347, MSE: 0.2274951482698823, Learning Rate: 0.01\n",
      "Epoch: 19348, MSE: 0.22749514826989523, Learning Rate: 0.01\n",
      "Epoch: 19349, MSE: 0.22749514826990777, Learning Rate: 0.01\n",
      "Epoch: 19350, MSE: 0.22749514826991965, Learning Rate: 0.01\n",
      "Epoch: 19351, MSE: 0.22749514826993303, Learning Rate: 0.01\n",
      "Epoch: 19352, MSE: 0.22749514826994616, Learning Rate: 0.01\n",
      "Epoch: 19353, MSE: 0.2274951482699584, Learning Rate: 0.01\n",
      "Epoch: 19354, MSE: 0.227495148269971, Learning Rate: 0.01\n",
      "Epoch: 19355, MSE: 0.22749514826998424, Learning Rate: 0.01\n",
      "Epoch: 19356, MSE: 0.22749514826999617, Learning Rate: 0.01\n",
      "Epoch: 19357, MSE: 0.22749514827000966, Learning Rate: 0.01\n",
      "Epoch: 19358, MSE: 0.22749514827002168, Learning Rate: 0.01\n",
      "Epoch: 19359, MSE: 0.22749514827003467, Learning Rate: 0.01\n",
      "Epoch: 19360, MSE: 0.22749514827004808, Learning Rate: 0.01\n",
      "Epoch: 19361, MSE: 0.22749514827006018, Learning Rate: 0.01\n",
      "Epoch: 19362, MSE: 0.22749514827007286, Learning Rate: 0.01\n",
      "Epoch: 19363, MSE: 0.22749514827008552, Learning Rate: 0.01\n",
      "Epoch: 19364, MSE: 0.22749514827009745, Learning Rate: 0.01\n",
      "Epoch: 19365, MSE: 0.22749514827011091, Learning Rate: 0.01\n",
      "Epoch: 19366, MSE: 0.22749514827012343, Learning Rate: 0.01\n",
      "Epoch: 19367, MSE: 0.22749514827013612, Learning Rate: 0.01\n",
      "Epoch: 19368, MSE: 0.22749514827014916, Learning Rate: 0.01\n",
      "Epoch: 19369, MSE: 0.22749514827016143, Learning Rate: 0.01\n",
      "Epoch: 19370, MSE: 0.2274951482701743, Learning Rate: 0.01\n",
      "Epoch: 19371, MSE: 0.22749514827018694, Learning Rate: 0.01\n",
      "Epoch: 19372, MSE: 0.2274951482701998, Learning Rate: 0.01\n",
      "Epoch: 19373, MSE: 0.22749514827021225, Learning Rate: 0.01\n",
      "Epoch: 19374, MSE: 0.22749514827022482, Learning Rate: 0.01\n",
      "Epoch: 19375, MSE: 0.2274951482702381, Learning Rate: 0.01\n",
      "Epoch: 19376, MSE: 0.22749514827024991, Learning Rate: 0.01\n",
      "Epoch: 19377, MSE: 0.22749514827026263, Learning Rate: 0.01\n",
      "Epoch: 19378, MSE: 0.2274951482702754, Learning Rate: 0.01\n",
      "Epoch: 19379, MSE: 0.2274951482702886, Learning Rate: 0.01\n",
      "Epoch: 19380, MSE: 0.22749514827030043, Learning Rate: 0.01\n",
      "Epoch: 19381, MSE: 0.2274951482703137, Learning Rate: 0.01\n",
      "Epoch: 19382, MSE: 0.2274951482703258, Learning Rate: 0.01\n",
      "Epoch: 19383, MSE: 0.227495148270339, Learning Rate: 0.01\n",
      "Epoch: 19384, MSE: 0.2274951482703521, Learning Rate: 0.01\n",
      "Epoch: 19385, MSE: 0.22749514827036463, Learning Rate: 0.01\n",
      "Epoch: 19386, MSE: 0.227495148270377, Learning Rate: 0.01\n",
      "Epoch: 19387, MSE: 0.22749514827038939, Learning Rate: 0.01\n",
      "Epoch: 19388, MSE: 0.2274951482704024, Learning Rate: 0.01\n",
      "Epoch: 19389, MSE: 0.22749514827041548, Learning Rate: 0.01\n",
      "Epoch: 19390, MSE: 0.2274951482704277, Learning Rate: 0.01\n",
      "Epoch: 19391, MSE: 0.22749514827044048, Learning Rate: 0.01\n",
      "Epoch: 19392, MSE: 0.22749514827045328, Learning Rate: 0.01\n",
      "Epoch: 19393, MSE: 0.22749514827046546, Learning Rate: 0.01\n",
      "Epoch: 19394, MSE: 0.22749514827047881, Learning Rate: 0.01\n",
      "Epoch: 19395, MSE: 0.2274951482704918, Learning Rate: 0.01\n",
      "Epoch: 19396, MSE: 0.2274951482705038, Learning Rate: 0.01\n",
      "Epoch: 19397, MSE: 0.2274951482705162, Learning Rate: 0.01\n",
      "Epoch: 19398, MSE: 0.22749514827052947, Learning Rate: 0.01\n",
      "Epoch: 19399, MSE: 0.22749514827054193, Learning Rate: 0.01\n",
      "Epoch: 19400, MSE: 0.22749514827055464, Learning Rate: 0.01\n",
      "Epoch: 19401, MSE: 0.22749514827056688, Learning Rate: 0.01\n",
      "Epoch: 19402, MSE: 0.22749514827058018, Learning Rate: 0.01\n",
      "Epoch: 19403, MSE: 0.2274951482705922, Learning Rate: 0.01\n",
      "Epoch: 19404, MSE: 0.2274951482706054, Learning Rate: 0.01\n",
      "Epoch: 19405, MSE: 0.22749514827061812, Learning Rate: 0.01\n",
      "Epoch: 19406, MSE: 0.22749514827063042, Learning Rate: 0.01\n",
      "Epoch: 19407, MSE: 0.22749514827064357, Learning Rate: 0.01\n",
      "Epoch: 19408, MSE: 0.22749514827065598, Learning Rate: 0.01\n",
      "Epoch: 19409, MSE: 0.2274951482706692, Learning Rate: 0.01\n",
      "Epoch: 19410, MSE: 0.2274951482706812, Learning Rate: 0.01\n",
      "Epoch: 19411, MSE: 0.2274951482706941, Learning Rate: 0.01\n",
      "Epoch: 19412, MSE: 0.22749514827070638, Learning Rate: 0.01\n",
      "Epoch: 19413, MSE: 0.2274951482707197, Learning Rate: 0.01\n",
      "Epoch: 19414, MSE: 0.22749514827073228, Learning Rate: 0.01\n",
      "Epoch: 19415, MSE: 0.2274951482707447, Learning Rate: 0.01\n",
      "Epoch: 19416, MSE: 0.22749514827075723, Learning Rate: 0.01\n",
      "Epoch: 19417, MSE: 0.22749514827077022, Learning Rate: 0.01\n",
      "Epoch: 19418, MSE: 0.22749514827078304, Learning Rate: 0.01\n",
      "Epoch: 19419, MSE: 0.2274951482707959, Learning Rate: 0.01\n",
      "Epoch: 19420, MSE: 0.22749514827080836, Learning Rate: 0.01\n",
      "Epoch: 19421, MSE: 0.22749514827082115, Learning Rate: 0.01\n",
      "Epoch: 19422, MSE: 0.22749514827083356, Learning Rate: 0.01\n",
      "Epoch: 19423, MSE: 0.22749514827084644, Learning Rate: 0.01\n",
      "Epoch: 19424, MSE: 0.227495148270859, Learning Rate: 0.01\n",
      "Epoch: 19425, MSE: 0.22749514827087167, Learning Rate: 0.01\n",
      "Epoch: 19426, MSE: 0.2274951482708844, Learning Rate: 0.01\n",
      "Epoch: 19427, MSE: 0.22749514827089676, Learning Rate: 0.01\n",
      "Epoch: 19428, MSE: 0.22749514827090975, Learning Rate: 0.01\n",
      "Epoch: 19429, MSE: 0.227495148270922, Learning Rate: 0.01\n",
      "Epoch: 19430, MSE: 0.2274951482709353, Learning Rate: 0.01\n",
      "Epoch: 19431, MSE: 0.22749514827094716, Learning Rate: 0.01\n",
      "Epoch: 19432, MSE: 0.22749514827096076, Learning Rate: 0.01\n",
      "Epoch: 19433, MSE: 0.22749514827097297, Learning Rate: 0.01\n",
      "Epoch: 19434, MSE: 0.22749514827098594, Learning Rate: 0.01\n",
      "Epoch: 19435, MSE: 0.2274951482709982, Learning Rate: 0.01\n",
      "Epoch: 19436, MSE: 0.22749514827101078, Learning Rate: 0.01\n",
      "Epoch: 19437, MSE: 0.22749514827102435, Learning Rate: 0.01\n",
      "Epoch: 19438, MSE: 0.22749514827103615, Learning Rate: 0.01\n",
      "Epoch: 19439, MSE: 0.22749514827104922, Learning Rate: 0.01\n",
      "Epoch: 19440, MSE: 0.2274951482710617, Learning Rate: 0.01\n",
      "Epoch: 19441, MSE: 0.22749514827107434, Learning Rate: 0.01\n",
      "Epoch: 19442, MSE: 0.22749514827108686, Learning Rate: 0.01\n",
      "Epoch: 19443, MSE: 0.22749514827109987, Learning Rate: 0.01\n",
      "Epoch: 19444, MSE: 0.22749514827111247, Learning Rate: 0.01\n",
      "Epoch: 19445, MSE: 0.22749514827112471, Learning Rate: 0.01\n",
      "Epoch: 19446, MSE: 0.22749514827113765, Learning Rate: 0.01\n",
      "Epoch: 19447, MSE: 0.22749514827115055, Learning Rate: 0.01\n",
      "Epoch: 19448, MSE: 0.2274951482711634, Learning Rate: 0.01\n",
      "Epoch: 19449, MSE: 0.22749514827117576, Learning Rate: 0.01\n",
      "Epoch: 19450, MSE: 0.22749514827118875, Learning Rate: 0.01\n",
      "Epoch: 19451, MSE: 0.2274951482712013, Learning Rate: 0.01\n",
      "Epoch: 19452, MSE: 0.22749514827121425, Learning Rate: 0.01\n",
      "Epoch: 19453, MSE: 0.2274951482712268, Learning Rate: 0.01\n",
      "Epoch: 19454, MSE: 0.22749514827123946, Learning Rate: 0.01\n",
      "Epoch: 19455, MSE: 0.22749514827125236, Learning Rate: 0.01\n",
      "Epoch: 19456, MSE: 0.22749514827126507, Learning Rate: 0.01\n",
      "Epoch: 19457, MSE: 0.22749514827127743, Learning Rate: 0.01\n",
      "Epoch: 19458, MSE: 0.22749514827129017, Learning Rate: 0.01\n",
      "Epoch: 19459, MSE: 0.22749514827130274, Learning Rate: 0.01\n",
      "Epoch: 19460, MSE: 0.22749514827131528, Learning Rate: 0.01\n",
      "Epoch: 19461, MSE: 0.22749514827132827, Learning Rate: 0.01\n",
      "Epoch: 19462, MSE: 0.22749514827134096, Learning Rate: 0.01\n",
      "Epoch: 19463, MSE: 0.22749514827135367, Learning Rate: 0.01\n",
      "Epoch: 19464, MSE: 0.22749514827136613, Learning Rate: 0.01\n",
      "Epoch: 19465, MSE: 0.22749514827137918, Learning Rate: 0.01\n",
      "Epoch: 19466, MSE: 0.22749514827139172, Learning Rate: 0.01\n",
      "Epoch: 19467, MSE: 0.2274951482714037, Learning Rate: 0.01\n",
      "Epoch: 19468, MSE: 0.22749514827141665, Learning Rate: 0.01\n",
      "Epoch: 19469, MSE: 0.22749514827142917, Learning Rate: 0.01\n",
      "Epoch: 19470, MSE: 0.22749514827144246, Learning Rate: 0.01\n",
      "Epoch: 19471, MSE: 0.22749514827145448, Learning Rate: 0.01\n",
      "Epoch: 19472, MSE: 0.2274951482714673, Learning Rate: 0.01\n",
      "Epoch: 19473, MSE: 0.22749514827148057, Learning Rate: 0.01\n",
      "Epoch: 19474, MSE: 0.22749514827149267, Learning Rate: 0.01\n",
      "Epoch: 19475, MSE: 0.22749514827150585, Learning Rate: 0.01\n",
      "Epoch: 19476, MSE: 0.2274951482715182, Learning Rate: 0.01\n",
      "Epoch: 19477, MSE: 0.22749514827153106, Learning Rate: 0.01\n",
      "Epoch: 19478, MSE: 0.2274951482715434, Learning Rate: 0.01\n",
      "Epoch: 19479, MSE: 0.22749514827155637, Learning Rate: 0.01\n",
      "Epoch: 19480, MSE: 0.2274951482715689, Learning Rate: 0.01\n",
      "Epoch: 19481, MSE: 0.22749514827158202, Learning Rate: 0.01\n",
      "Epoch: 19482, MSE: 0.22749514827159478, Learning Rate: 0.01\n",
      "Epoch: 19483, MSE: 0.227495148271607, Learning Rate: 0.01\n",
      "Epoch: 19484, MSE: 0.22749514827161965, Learning Rate: 0.01\n",
      "Epoch: 19485, MSE: 0.22749514827163247, Learning Rate: 0.01\n",
      "Epoch: 19486, MSE: 0.22749514827164513, Learning Rate: 0.01\n",
      "Epoch: 19487, MSE: 0.227495148271658, Learning Rate: 0.01\n",
      "Epoch: 19488, MSE: 0.22749514827167078, Learning Rate: 0.01\n",
      "Epoch: 19489, MSE: 0.22749514827168313, Learning Rate: 0.01\n",
      "Epoch: 19490, MSE: 0.22749514827169628, Learning Rate: 0.01\n",
      "Epoch: 19491, MSE: 0.22749514827170886, Learning Rate: 0.01\n",
      "Epoch: 19492, MSE: 0.227495148271721, Learning Rate: 0.01\n",
      "Epoch: 19493, MSE: 0.22749514827173414, Learning Rate: 0.01\n",
      "Epoch: 19494, MSE: 0.22749514827174663, Learning Rate: 0.01\n",
      "Epoch: 19495, MSE: 0.22749514827175893, Learning Rate: 0.01\n",
      "Epoch: 19496, MSE: 0.2274951482717719, Learning Rate: 0.01\n",
      "Epoch: 19497, MSE: 0.2274951482717842, Learning Rate: 0.01\n",
      "Epoch: 19498, MSE: 0.22749514827179793, Learning Rate: 0.01\n",
      "Epoch: 19499, MSE: 0.22749514827181008, Learning Rate: 0.01\n",
      "Epoch: 19500, MSE: 0.22749514827182224, Learning Rate: 0.01\n",
      "Epoch: 19501, MSE: 0.22749514827183548, Learning Rate: 0.01\n",
      "Epoch: 19502, MSE: 0.22749514827184805, Learning Rate: 0.01\n",
      "Epoch: 19503, MSE: 0.22749514827186051, Learning Rate: 0.01\n",
      "Epoch: 19504, MSE: 0.22749514827187348, Learning Rate: 0.01\n",
      "Epoch: 19505, MSE: 0.2274951482718861, Learning Rate: 0.01\n",
      "Epoch: 19506, MSE: 0.22749514827189876, Learning Rate: 0.01\n",
      "Epoch: 19507, MSE: 0.2274951482719111, Learning Rate: 0.01\n",
      "Epoch: 19508, MSE: 0.22749514827192427, Learning Rate: 0.01\n",
      "Epoch: 19509, MSE: 0.22749514827193676, Learning Rate: 0.01\n",
      "Epoch: 19510, MSE: 0.2274951482719496, Learning Rate: 0.01\n",
      "Epoch: 19511, MSE: 0.22749514827196193, Learning Rate: 0.01\n",
      "Epoch: 19512, MSE: 0.22749514827197492, Learning Rate: 0.01\n",
      "Epoch: 19513, MSE: 0.22749514827198766, Learning Rate: 0.01\n",
      "Epoch: 19514, MSE: 0.22749514827199993, Learning Rate: 0.01\n",
      "Epoch: 19515, MSE: 0.2274951482720131, Learning Rate: 0.01\n",
      "Epoch: 19516, MSE: 0.22749514827202574, Learning Rate: 0.01\n",
      "Epoch: 19517, MSE: 0.2274951482720381, Learning Rate: 0.01\n",
      "Epoch: 19518, MSE: 0.2274951482720503, Learning Rate: 0.01\n",
      "Epoch: 19519, MSE: 0.22749514827206316, Learning Rate: 0.01\n",
      "Epoch: 19520, MSE: 0.22749514827207612, Learning Rate: 0.01\n",
      "Epoch: 19521, MSE: 0.22749514827208858, Learning Rate: 0.01\n",
      "Epoch: 19522, MSE: 0.2274951482721021, Learning Rate: 0.01\n",
      "Epoch: 19523, MSE: 0.22749514827211445, Learning Rate: 0.01\n",
      "Epoch: 19524, MSE: 0.2274951482721269, Learning Rate: 0.01\n",
      "Epoch: 19525, MSE: 0.22749514827213954, Learning Rate: 0.01\n",
      "Epoch: 19526, MSE: 0.22749514827215217, Learning Rate: 0.01\n",
      "Epoch: 19527, MSE: 0.22749514827216433, Learning Rate: 0.01\n",
      "Epoch: 19528, MSE: 0.22749514827217726, Learning Rate: 0.01\n",
      "Epoch: 19529, MSE: 0.22749514827219022, Learning Rate: 0.01\n",
      "Epoch: 19530, MSE: 0.2274951482722028, Learning Rate: 0.01\n",
      "Epoch: 19531, MSE: 0.2274951482722153, Learning Rate: 0.01\n",
      "Epoch: 19532, MSE: 0.2274951482722277, Learning Rate: 0.01\n",
      "Epoch: 19533, MSE: 0.22749514827224077, Learning Rate: 0.01\n",
      "Epoch: 19534, MSE: 0.2274951482722531, Learning Rate: 0.01\n",
      "Epoch: 19535, MSE: 0.22749514827226608, Learning Rate: 0.01\n",
      "Epoch: 19536, MSE: 0.22749514827227874, Learning Rate: 0.01\n",
      "Epoch: 19537, MSE: 0.22749514827229153, Learning Rate: 0.01\n",
      "Epoch: 19538, MSE: 0.22749514827230424, Learning Rate: 0.01\n",
      "Epoch: 19539, MSE: 0.22749514827231648, Learning Rate: 0.01\n",
      "Epoch: 19540, MSE: 0.22749514827232953, Learning Rate: 0.01\n",
      "Epoch: 19541, MSE: 0.22749514827234224, Learning Rate: 0.01\n",
      "Epoch: 19542, MSE: 0.22749514827235498, Learning Rate: 0.01\n",
      "Epoch: 19543, MSE: 0.22749514827236772, Learning Rate: 0.01\n",
      "Epoch: 19544, MSE: 0.22749514827238018, Learning Rate: 0.01\n",
      "Epoch: 19545, MSE: 0.22749514827239292, Learning Rate: 0.01\n",
      "Epoch: 19546, MSE: 0.22749514827240602, Learning Rate: 0.01\n",
      "Epoch: 19547, MSE: 0.22749514827241843, Learning Rate: 0.01\n",
      "Epoch: 19548, MSE: 0.2274951482724309, Learning Rate: 0.01\n",
      "Epoch: 19549, MSE: 0.22749514827244358, Learning Rate: 0.01\n",
      "Epoch: 19550, MSE: 0.22749514827245612, Learning Rate: 0.01\n",
      "Epoch: 19551, MSE: 0.22749514827246897, Learning Rate: 0.01\n",
      "Epoch: 19552, MSE: 0.22749514827248193, Learning Rate: 0.01\n",
      "Epoch: 19553, MSE: 0.22749514827249487, Learning Rate: 0.01\n",
      "Epoch: 19554, MSE: 0.22749514827250716, Learning Rate: 0.01\n",
      "Epoch: 19555, MSE: 0.2274951482725195, Learning Rate: 0.01\n",
      "Epoch: 19556, MSE: 0.22749514827253306, Learning Rate: 0.01\n",
      "Epoch: 19557, MSE: 0.2274951482725449, Learning Rate: 0.01\n",
      "Epoch: 19558, MSE: 0.22749514827255776, Learning Rate: 0.01\n",
      "Epoch: 19559, MSE: 0.22749514827257042, Learning Rate: 0.01\n",
      "Epoch: 19560, MSE: 0.22749514827258346, Learning Rate: 0.01\n",
      "Epoch: 19561, MSE: 0.22749514827259565, Learning Rate: 0.01\n",
      "Epoch: 19562, MSE: 0.22749514827260867, Learning Rate: 0.01\n",
      "Epoch: 19563, MSE: 0.22749514827262124, Learning Rate: 0.01\n",
      "Epoch: 19564, MSE: 0.22749514827263403, Learning Rate: 0.01\n",
      "Epoch: 19565, MSE: 0.22749514827264625, Learning Rate: 0.01\n",
      "Epoch: 19566, MSE: 0.22749514827265974, Learning Rate: 0.01\n",
      "Epoch: 19567, MSE: 0.22749514827267145, Learning Rate: 0.01\n",
      "Epoch: 19568, MSE: 0.22749514827268463, Learning Rate: 0.01\n",
      "Epoch: 19569, MSE: 0.2274951482726975, Learning Rate: 0.01\n",
      "Epoch: 19570, MSE: 0.2274951482727096, Learning Rate: 0.01\n",
      "Epoch: 19571, MSE: 0.22749514827272227, Learning Rate: 0.01\n",
      "Epoch: 19572, MSE: 0.22749514827273506, Learning Rate: 0.01\n",
      "Epoch: 19573, MSE: 0.22749514827274783, Learning Rate: 0.01\n",
      "Epoch: 19574, MSE: 0.22749514827276043, Learning Rate: 0.01\n",
      "Epoch: 19575, MSE: 0.22749514827277287, Learning Rate: 0.01\n",
      "Epoch: 19576, MSE: 0.2274951482727862, Learning Rate: 0.01\n",
      "Epoch: 19577, MSE: 0.2274951482727989, Learning Rate: 0.01\n",
      "Epoch: 19578, MSE: 0.2274951482728113, Learning Rate: 0.01\n",
      "Epoch: 19579, MSE: 0.2274951482728238, Learning Rate: 0.01\n",
      "Epoch: 19580, MSE: 0.2274951482728371, Learning Rate: 0.01\n",
      "Epoch: 19581, MSE: 0.22749514827284895, Learning Rate: 0.01\n",
      "Epoch: 19582, MSE: 0.22749514827286182, Learning Rate: 0.01\n",
      "Epoch: 19583, MSE: 0.22749514827287462, Learning Rate: 0.01\n",
      "Epoch: 19584, MSE: 0.22749514827288755, Learning Rate: 0.01\n",
      "Epoch: 19585, MSE: 0.22749514827290016, Learning Rate: 0.01\n",
      "Epoch: 19586, MSE: 0.22749514827291242, Learning Rate: 0.01\n",
      "Epoch: 19587, MSE: 0.2274951482729254, Learning Rate: 0.01\n",
      "Epoch: 19588, MSE: 0.22749514827293796, Learning Rate: 0.01\n",
      "Epoch: 19589, MSE: 0.22749514827295086, Learning Rate: 0.01\n",
      "Epoch: 19590, MSE: 0.22749514827296324, Learning Rate: 0.01\n",
      "Epoch: 19591, MSE: 0.22749514827297587, Learning Rate: 0.01\n",
      "Epoch: 19592, MSE: 0.22749514827298806, Learning Rate: 0.01\n",
      "Epoch: 19593, MSE: 0.2274951482730012, Learning Rate: 0.01\n",
      "Epoch: 19594, MSE: 0.22749514827301365, Learning Rate: 0.01\n",
      "Epoch: 19595, MSE: 0.22749514827302691, Learning Rate: 0.01\n",
      "Epoch: 19596, MSE: 0.2274951482730395, Learning Rate: 0.01\n",
      "Epoch: 19597, MSE: 0.22749514827305195, Learning Rate: 0.01\n",
      "Epoch: 19598, MSE: 0.22749514827306477, Learning Rate: 0.01\n",
      "Epoch: 19599, MSE: 0.22749514827307765, Learning Rate: 0.01\n",
      "Epoch: 19600, MSE: 0.22749514827308986, Learning Rate: 0.01\n",
      "Epoch: 19601, MSE: 0.22749514827310274, Learning Rate: 0.01\n",
      "Epoch: 19602, MSE: 0.22749514827311532, Learning Rate: 0.01\n",
      "Epoch: 19603, MSE: 0.2274951482731283, Learning Rate: 0.01\n",
      "Epoch: 19604, MSE: 0.22749514827314082, Learning Rate: 0.01\n",
      "Epoch: 19605, MSE: 0.22749514827315348, Learning Rate: 0.01\n",
      "Epoch: 19606, MSE: 0.2274951482731661, Learning Rate: 0.01\n",
      "Epoch: 19607, MSE: 0.22749514827317857, Learning Rate: 0.01\n",
      "Epoch: 19608, MSE: 0.2274951482731912, Learning Rate: 0.01\n",
      "Epoch: 19609, MSE: 0.22749514827320422, Learning Rate: 0.01\n",
      "Epoch: 19610, MSE: 0.22749514827321646, Learning Rate: 0.01\n",
      "Epoch: 19611, MSE: 0.227495148273229, Learning Rate: 0.01\n",
      "Epoch: 19612, MSE: 0.2274951482732425, Learning Rate: 0.01\n",
      "Epoch: 19613, MSE: 0.22749514827325454, Learning Rate: 0.01\n",
      "Epoch: 19614, MSE: 0.22749514827326792, Learning Rate: 0.01\n",
      "Epoch: 19615, MSE: 0.22749514827328027, Learning Rate: 0.01\n",
      "Epoch: 19616, MSE: 0.2274951482732929, Learning Rate: 0.01\n",
      "Epoch: 19617, MSE: 0.22749514827330586, Learning Rate: 0.01\n",
      "Epoch: 19618, MSE: 0.22749514827331813, Learning Rate: 0.01\n",
      "Epoch: 19619, MSE: 0.22749514827333067, Learning Rate: 0.01\n",
      "Epoch: 19620, MSE: 0.2274951482733432, Learning Rate: 0.01\n",
      "Epoch: 19621, MSE: 0.22749514827335648, Learning Rate: 0.01\n",
      "Epoch: 19622, MSE: 0.22749514827336914, Learning Rate: 0.01\n",
      "Epoch: 19623, MSE: 0.22749514827338171, Learning Rate: 0.01\n",
      "Epoch: 19624, MSE: 0.22749514827339437, Learning Rate: 0.01\n",
      "Epoch: 19625, MSE: 0.22749514827340675, Learning Rate: 0.01\n",
      "Epoch: 19626, MSE: 0.22749514827341968, Learning Rate: 0.01\n",
      "Epoch: 19627, MSE: 0.22749514827343242, Learning Rate: 0.01\n",
      "Epoch: 19628, MSE: 0.22749514827344447, Learning Rate: 0.01\n",
      "Epoch: 19629, MSE: 0.22749514827345743, Learning Rate: 0.01\n",
      "Epoch: 19630, MSE: 0.22749514827347025, Learning Rate: 0.01\n",
      "Epoch: 19631, MSE: 0.2274951482734828, Learning Rate: 0.01\n",
      "Epoch: 19632, MSE: 0.22749514827349535, Learning Rate: 0.01\n",
      "Epoch: 19633, MSE: 0.2274951482735086, Learning Rate: 0.01\n",
      "Epoch: 19634, MSE: 0.2274951482735208, Learning Rate: 0.01\n",
      "Epoch: 19635, MSE: 0.22749514827353384, Learning Rate: 0.01\n",
      "Epoch: 19636, MSE: 0.2274951482735461, Learning Rate: 0.01\n",
      "Epoch: 19637, MSE: 0.22749514827355882, Learning Rate: 0.01\n",
      "Epoch: 19638, MSE: 0.2274951482735717, Learning Rate: 0.01\n",
      "Epoch: 19639, MSE: 0.22749514827358397, Learning Rate: 0.01\n",
      "Epoch: 19640, MSE: 0.22749514827359715, Learning Rate: 0.01\n",
      "Epoch: 19641, MSE: 0.2274951482736096, Learning Rate: 0.01\n",
      "Epoch: 19642, MSE: 0.22749514827362233, Learning Rate: 0.01\n",
      "Epoch: 19643, MSE: 0.2274951482736348, Learning Rate: 0.01\n",
      "Epoch: 19644, MSE: 0.22749514827364772, Learning Rate: 0.01\n",
      "Epoch: 19645, MSE: 0.22749514827366052, Learning Rate: 0.01\n",
      "Epoch: 19646, MSE: 0.22749514827367276, Learning Rate: 0.01\n",
      "Epoch: 19647, MSE: 0.227495148273686, Learning Rate: 0.01\n",
      "Epoch: 19648, MSE: 0.2274951482736985, Learning Rate: 0.01\n",
      "Epoch: 19649, MSE: 0.22749514827371062, Learning Rate: 0.01\n",
      "Epoch: 19650, MSE: 0.22749514827372386, Learning Rate: 0.01\n",
      "Epoch: 19651, MSE: 0.2274951482737364, Learning Rate: 0.01\n",
      "Epoch: 19652, MSE: 0.22749514827374898, Learning Rate: 0.01\n",
      "Epoch: 19653, MSE: 0.22749514827376152, Learning Rate: 0.01\n",
      "Epoch: 19654, MSE: 0.227495148273774, Learning Rate: 0.01\n",
      "Epoch: 19655, MSE: 0.22749514827378706, Learning Rate: 0.01\n",
      "Epoch: 19656, MSE: 0.2274951482737993, Learning Rate: 0.01\n",
      "Epoch: 19657, MSE: 0.22749514827381187, Learning Rate: 0.01\n",
      "Epoch: 19658, MSE: 0.22749514827382503, Learning Rate: 0.01\n",
      "Epoch: 19659, MSE: 0.22749514827383777, Learning Rate: 0.01\n",
      "Epoch: 19660, MSE: 0.22749514827385064, Learning Rate: 0.01\n",
      "Epoch: 19661, MSE: 0.2274951482738631, Learning Rate: 0.01\n",
      "Epoch: 19662, MSE: 0.22749514827387576, Learning Rate: 0.01\n",
      "Epoch: 19663, MSE: 0.22749514827388861, Learning Rate: 0.01\n",
      "Epoch: 19664, MSE: 0.22749514827390094, Learning Rate: 0.01\n",
      "Epoch: 19665, MSE: 0.2274951482739135, Learning Rate: 0.01\n",
      "Epoch: 19666, MSE: 0.22749514827392645, Learning Rate: 0.01\n",
      "Epoch: 19667, MSE: 0.2274951482739388, Learning Rate: 0.01\n",
      "Epoch: 19668, MSE: 0.22749514827395156, Learning Rate: 0.01\n",
      "Epoch: 19669, MSE: 0.22749514827396425, Learning Rate: 0.01\n",
      "Epoch: 19670, MSE: 0.22749514827397718, Learning Rate: 0.01\n",
      "Epoch: 19671, MSE: 0.22749514827399017, Learning Rate: 0.01\n",
      "Epoch: 19672, MSE: 0.2274951482740026, Learning Rate: 0.01\n",
      "Epoch: 19673, MSE: 0.22749514827401543, Learning Rate: 0.01\n",
      "Epoch: 19674, MSE: 0.22749514827402784, Learning Rate: 0.01\n",
      "Epoch: 19675, MSE: 0.22749514827404027, Learning Rate: 0.01\n",
      "Epoch: 19676, MSE: 0.2274951482740531, Learning Rate: 0.01\n",
      "Epoch: 19677, MSE: 0.2274951482740659, Learning Rate: 0.01\n",
      "Epoch: 19678, MSE: 0.22749514827407874, Learning Rate: 0.01\n",
      "Epoch: 19679, MSE: 0.22749514827409126, Learning Rate: 0.01\n",
      "Epoch: 19680, MSE: 0.22749514827410353, Learning Rate: 0.01\n",
      "Epoch: 19681, MSE: 0.2274951482741164, Learning Rate: 0.01\n",
      "Epoch: 19682, MSE: 0.22749514827412884, Learning Rate: 0.01\n",
      "Epoch: 19683, MSE: 0.22749514827414136, Learning Rate: 0.01\n",
      "Epoch: 19684, MSE: 0.2274951482741546, Learning Rate: 0.01\n",
      "Epoch: 19685, MSE: 0.2274951482741668, Learning Rate: 0.01\n",
      "Epoch: 19686, MSE: 0.2274951482741792, Learning Rate: 0.01\n",
      "Epoch: 19687, MSE: 0.2274951482741925, Learning Rate: 0.01\n",
      "Epoch: 19688, MSE: 0.2274951482742051, Learning Rate: 0.01\n",
      "Epoch: 19689, MSE: 0.22749514827421802, Learning Rate: 0.01\n",
      "Epoch: 19690, MSE: 0.2274951482742304, Learning Rate: 0.01\n",
      "Epoch: 19691, MSE: 0.22749514827424308, Learning Rate: 0.01\n",
      "Epoch: 19692, MSE: 0.22749514827425601, Learning Rate: 0.01\n",
      "Epoch: 19693, MSE: 0.22749514827426823, Learning Rate: 0.01\n",
      "Epoch: 19694, MSE: 0.22749514827428083, Learning Rate: 0.01\n",
      "Epoch: 19695, MSE: 0.22749514827429354, Learning Rate: 0.01\n",
      "Epoch: 19696, MSE: 0.2274951482743061, Learning Rate: 0.01\n",
      "Epoch: 19697, MSE: 0.227495148274319, Learning Rate: 0.01\n",
      "Epoch: 19698, MSE: 0.22749514827433157, Learning Rate: 0.01\n",
      "Epoch: 19699, MSE: 0.2274951482743444, Learning Rate: 0.01\n",
      "Epoch: 19700, MSE: 0.22749514827435696, Learning Rate: 0.01\n",
      "Epoch: 19701, MSE: 0.2274951482743699, Learning Rate: 0.01\n",
      "Epoch: 19702, MSE: 0.22749514827438236, Learning Rate: 0.01\n",
      "Epoch: 19703, MSE: 0.22749514827439501, Learning Rate: 0.01\n",
      "Epoch: 19704, MSE: 0.22749514827440726, Learning Rate: 0.01\n",
      "Epoch: 19705, MSE: 0.2274951482744209, Learning Rate: 0.01\n",
      "Epoch: 19706, MSE: 0.22749514827443276, Learning Rate: 0.01\n",
      "Epoch: 19707, MSE: 0.22749514827444575, Learning Rate: 0.01\n",
      "Epoch: 19708, MSE: 0.22749514827445863, Learning Rate: 0.01\n",
      "Epoch: 19709, MSE: 0.22749514827447054, Learning Rate: 0.01\n",
      "Epoch: 19710, MSE: 0.227495148274484, Learning Rate: 0.01\n",
      "Epoch: 19711, MSE: 0.22749514827449613, Learning Rate: 0.01\n",
      "Epoch: 19712, MSE: 0.22749514827450942, Learning Rate: 0.01\n",
      "Epoch: 19713, MSE: 0.22749514827452125, Learning Rate: 0.01\n",
      "Epoch: 19714, MSE: 0.22749514827453451, Learning Rate: 0.01\n",
      "Epoch: 19715, MSE: 0.22749514827454728, Learning Rate: 0.01\n",
      "Epoch: 19716, MSE: 0.22749514827456016, Learning Rate: 0.01\n",
      "Epoch: 19717, MSE: 0.22749514827457204, Learning Rate: 0.01\n",
      "Epoch: 19718, MSE: 0.22749514827458514, Learning Rate: 0.01\n",
      "Epoch: 19719, MSE: 0.22749514827459782, Learning Rate: 0.01\n",
      "Epoch: 19720, MSE: 0.22749514827461012, Learning Rate: 0.01\n",
      "Epoch: 19721, MSE: 0.2274951482746231, Learning Rate: 0.01\n",
      "Epoch: 19722, MSE: 0.22749514827463574, Learning Rate: 0.01\n",
      "Epoch: 19723, MSE: 0.22749514827464815, Learning Rate: 0.01\n",
      "Epoch: 19724, MSE: 0.22749514827466116, Learning Rate: 0.01\n",
      "Epoch: 19725, MSE: 0.22749514827467382, Learning Rate: 0.01\n",
      "Epoch: 19726, MSE: 0.22749514827468673, Learning Rate: 0.01\n",
      "Epoch: 19727, MSE: 0.22749514827469902, Learning Rate: 0.01\n",
      "Epoch: 19728, MSE: 0.22749514827471162, Learning Rate: 0.01\n",
      "Epoch: 19729, MSE: 0.22749514827472442, Learning Rate: 0.01\n",
      "Epoch: 19730, MSE: 0.22749514827473724, Learning Rate: 0.01\n",
      "Epoch: 19731, MSE: 0.2274951482747496, Learning Rate: 0.01\n",
      "Epoch: 19732, MSE: 0.22749514827476264, Learning Rate: 0.01\n",
      "Epoch: 19733, MSE: 0.227495148274775, Learning Rate: 0.01\n",
      "Epoch: 19734, MSE: 0.22749514827478784, Learning Rate: 0.01\n",
      "Epoch: 19735, MSE: 0.22749514827480047, Learning Rate: 0.01\n",
      "Epoch: 19736, MSE: 0.22749514827481368, Learning Rate: 0.01\n",
      "Epoch: 19737, MSE: 0.227495148274826, Learning Rate: 0.01\n",
      "Epoch: 19738, MSE: 0.22749514827483813, Learning Rate: 0.01\n",
      "Epoch: 19739, MSE: 0.2274951482748511, Learning Rate: 0.01\n",
      "Epoch: 19740, MSE: 0.22749514827486375, Learning Rate: 0.01\n",
      "Epoch: 19741, MSE: 0.2274951482748763, Learning Rate: 0.01\n",
      "Epoch: 19742, MSE: 0.22749514827488873, Learning Rate: 0.01\n",
      "Epoch: 19743, MSE: 0.22749514827490128, Learning Rate: 0.01\n",
      "Epoch: 19744, MSE: 0.22749514827491446, Learning Rate: 0.01\n",
      "Epoch: 19745, MSE: 0.2274951482749267, Learning Rate: 0.01\n",
      "Epoch: 19746, MSE: 0.2274951482749398, Learning Rate: 0.01\n",
      "Epoch: 19747, MSE: 0.22749514827495268, Learning Rate: 0.01\n",
      "Epoch: 19748, MSE: 0.22749514827496534, Learning Rate: 0.01\n",
      "Epoch: 19749, MSE: 0.22749514827497788, Learning Rate: 0.01\n",
      "Epoch: 19750, MSE: 0.2274951482749901, Learning Rate: 0.01\n",
      "Epoch: 19751, MSE: 0.22749514827500336, Learning Rate: 0.01\n",
      "Epoch: 19752, MSE: 0.22749514827501593, Learning Rate: 0.01\n",
      "Epoch: 19753, MSE: 0.2274951482750284, Learning Rate: 0.01\n",
      "Epoch: 19754, MSE: 0.2274951482750408, Learning Rate: 0.01\n",
      "Epoch: 19755, MSE: 0.22749514827505335, Learning Rate: 0.01\n",
      "Epoch: 19756, MSE: 0.22749514827506603, Learning Rate: 0.01\n",
      "Epoch: 19757, MSE: 0.22749514827507902, Learning Rate: 0.01\n",
      "Epoch: 19758, MSE: 0.22749514827509146, Learning Rate: 0.01\n",
      "Epoch: 19759, MSE: 0.2274951482751042, Learning Rate: 0.01\n",
      "Epoch: 19760, MSE: 0.22749514827511724, Learning Rate: 0.01\n",
      "Epoch: 19761, MSE: 0.22749514827512965, Learning Rate: 0.01\n",
      "Epoch: 19762, MSE: 0.2274951482751424, Learning Rate: 0.01\n",
      "Epoch: 19763, MSE: 0.22749514827515546, Learning Rate: 0.01\n",
      "Epoch: 19764, MSE: 0.2274951482751681, Learning Rate: 0.01\n",
      "Epoch: 19765, MSE: 0.22749514827518005, Learning Rate: 0.01\n",
      "Epoch: 19766, MSE: 0.22749514827519365, Learning Rate: 0.01\n",
      "Epoch: 19767, MSE: 0.22749514827520562, Learning Rate: 0.01\n",
      "Epoch: 19768, MSE: 0.2274951482752187, Learning Rate: 0.01\n",
      "Epoch: 19769, MSE: 0.22749514827523135, Learning Rate: 0.01\n",
      "Epoch: 19770, MSE: 0.22749514827524384, Learning Rate: 0.01\n",
      "Epoch: 19771, MSE: 0.2274951482752562, Learning Rate: 0.01\n",
      "Epoch: 19772, MSE: 0.22749514827526923, Learning Rate: 0.01\n",
      "Epoch: 19773, MSE: 0.2274951482752817, Learning Rate: 0.01\n",
      "Epoch: 19774, MSE: 0.22749514827529477, Learning Rate: 0.01\n",
      "Epoch: 19775, MSE: 0.22749514827530698, Learning Rate: 0.01\n",
      "Epoch: 19776, MSE: 0.22749514827531997, Learning Rate: 0.01\n",
      "Epoch: 19777, MSE: 0.22749514827533238, Learning Rate: 0.01\n",
      "Epoch: 19778, MSE: 0.22749514827534545, Learning Rate: 0.01\n",
      "Epoch: 19779, MSE: 0.2274951482753575, Learning Rate: 0.01\n",
      "Epoch: 19780, MSE: 0.22749514827537004, Learning Rate: 0.01\n",
      "Epoch: 19781, MSE: 0.22749514827538292, Learning Rate: 0.01\n",
      "Epoch: 19782, MSE: 0.227495148275396, Learning Rate: 0.01\n",
      "Epoch: 19783, MSE: 0.22749514827540857, Learning Rate: 0.01\n",
      "Epoch: 19784, MSE: 0.2274951482754209, Learning Rate: 0.01\n",
      "Epoch: 19785, MSE: 0.22749514827543332, Learning Rate: 0.01\n",
      "Epoch: 19786, MSE: 0.2274951482754464, Learning Rate: 0.01\n",
      "Epoch: 19787, MSE: 0.22749514827545872, Learning Rate: 0.01\n",
      "Epoch: 19788, MSE: 0.22749514827547196, Learning Rate: 0.01\n",
      "Epoch: 19789, MSE: 0.22749514827548428, Learning Rate: 0.01\n",
      "Epoch: 19790, MSE: 0.2274951482754967, Learning Rate: 0.01\n",
      "Epoch: 19791, MSE: 0.22749514827550996, Learning Rate: 0.01\n",
      "Epoch: 19792, MSE: 0.22749514827552225, Learning Rate: 0.01\n",
      "Epoch: 19793, MSE: 0.227495148275535, Learning Rate: 0.01\n",
      "Epoch: 19794, MSE: 0.22749514827554773, Learning Rate: 0.01\n",
      "Epoch: 19795, MSE: 0.22749514827556017, Learning Rate: 0.01\n",
      "Epoch: 19796, MSE: 0.22749514827557285, Learning Rate: 0.01\n",
      "Epoch: 19797, MSE: 0.22749514827558542, Learning Rate: 0.01\n",
      "Epoch: 19798, MSE: 0.22749514827559836, Learning Rate: 0.01\n",
      "Epoch: 19799, MSE: 0.22749514827561101, Learning Rate: 0.01\n",
      "Epoch: 19800, MSE: 0.22749514827562328, Learning Rate: 0.01\n",
      "Epoch: 19801, MSE: 0.22749514827563647, Learning Rate: 0.01\n",
      "Epoch: 19802, MSE: 0.22749514827564898, Learning Rate: 0.01\n",
      "Epoch: 19803, MSE: 0.22749514827566167, Learning Rate: 0.01\n",
      "Epoch: 19804, MSE: 0.2274951482756744, Learning Rate: 0.01\n",
      "Epoch: 19805, MSE: 0.22749514827568657, Learning Rate: 0.01\n",
      "Epoch: 19806, MSE: 0.2274951482757, Learning Rate: 0.01\n",
      "Epoch: 19807, MSE: 0.2274951482757124, Learning Rate: 0.01\n",
      "Epoch: 19808, MSE: 0.2274951482757248, Learning Rate: 0.01\n",
      "Epoch: 19809, MSE: 0.22749514827573736, Learning Rate: 0.01\n",
      "Epoch: 19810, MSE: 0.22749514827575074, Learning Rate: 0.01\n",
      "Epoch: 19811, MSE: 0.22749514827576287, Learning Rate: 0.01\n",
      "Epoch: 19812, MSE: 0.22749514827577577, Learning Rate: 0.01\n",
      "Epoch: 19813, MSE: 0.22749514827578826, Learning Rate: 0.01\n",
      "Epoch: 19814, MSE: 0.22749514827580078, Learning Rate: 0.01\n",
      "Epoch: 19815, MSE: 0.22749514827581382, Learning Rate: 0.01\n",
      "Epoch: 19816, MSE: 0.22749514827582648, Learning Rate: 0.01\n",
      "Epoch: 19817, MSE: 0.22749514827583922, Learning Rate: 0.01\n",
      "Epoch: 19818, MSE: 0.2274951482758521, Learning Rate: 0.01\n",
      "Epoch: 19819, MSE: 0.22749514827586353, Learning Rate: 0.01\n",
      "Epoch: 19820, MSE: 0.22749514827587716, Learning Rate: 0.01\n",
      "Epoch: 19821, MSE: 0.22749514827588974, Learning Rate: 0.01\n",
      "Epoch: 19822, MSE: 0.2274951482759027, Learning Rate: 0.01\n",
      "Epoch: 19823, MSE: 0.22749514827591483, Learning Rate: 0.01\n",
      "Epoch: 19824, MSE: 0.22749514827592793, Learning Rate: 0.01\n",
      "Epoch: 19825, MSE: 0.22749514827594014, Learning Rate: 0.01\n",
      "Epoch: 19826, MSE: 0.22749514827595316, Learning Rate: 0.01\n",
      "Epoch: 19827, MSE: 0.22749514827596518, Learning Rate: 0.01\n",
      "Epoch: 19828, MSE: 0.22749514827597864, Learning Rate: 0.01\n",
      "Epoch: 19829, MSE: 0.22749514827599096, Learning Rate: 0.01\n",
      "Epoch: 19830, MSE: 0.22749514827600323, Learning Rate: 0.01\n",
      "Epoch: 19831, MSE: 0.22749514827601622, Learning Rate: 0.01\n",
      "Epoch: 19832, MSE: 0.22749514827602896, Learning Rate: 0.01\n",
      "Epoch: 19833, MSE: 0.22749514827604117, Learning Rate: 0.01\n",
      "Epoch: 19834, MSE: 0.22749514827605383, Learning Rate: 0.01\n",
      "Epoch: 19835, MSE: 0.227495148276067, Learning Rate: 0.01\n",
      "Epoch: 19836, MSE: 0.2274951482760798, Learning Rate: 0.01\n",
      "Epoch: 19837, MSE: 0.22749514827609213, Learning Rate: 0.01\n",
      "Epoch: 19838, MSE: 0.22749514827610512, Learning Rate: 0.01\n",
      "Epoch: 19839, MSE: 0.22749514827611764, Learning Rate: 0.01\n",
      "Epoch: 19840, MSE: 0.22749514827613007, Learning Rate: 0.01\n",
      "Epoch: 19841, MSE: 0.22749514827614303, Learning Rate: 0.01\n",
      "Epoch: 19842, MSE: 0.22749514827615536, Learning Rate: 0.01\n",
      "Epoch: 19843, MSE: 0.22749514827616815, Learning Rate: 0.01\n",
      "Epoch: 19844, MSE: 0.22749514827618084, Learning Rate: 0.01\n",
      "Epoch: 19845, MSE: 0.22749514827619355, Learning Rate: 0.01\n",
      "Epoch: 19846, MSE: 0.22749514827620557, Learning Rate: 0.01\n",
      "Epoch: 19847, MSE: 0.22749514827621833, Learning Rate: 0.01\n",
      "Epoch: 19848, MSE: 0.22749514827623152, Learning Rate: 0.01\n",
      "Epoch: 19849, MSE: 0.22749514827624387, Learning Rate: 0.01\n",
      "Epoch: 19850, MSE: 0.22749514827625675, Learning Rate: 0.01\n",
      "Epoch: 19851, MSE: 0.22749514827626932, Learning Rate: 0.01\n",
      "Epoch: 19852, MSE: 0.22749514827628198, Learning Rate: 0.01\n",
      "Epoch: 19853, MSE: 0.22749514827629502, Learning Rate: 0.01\n",
      "Epoch: 19854, MSE: 0.22749514827630768, Learning Rate: 0.01\n",
      "Epoch: 19855, MSE: 0.22749514827632003, Learning Rate: 0.01\n",
      "Epoch: 19856, MSE: 0.22749514827633277, Learning Rate: 0.01\n",
      "Epoch: 19857, MSE: 0.22749514827634532, Learning Rate: 0.01\n",
      "Epoch: 19858, MSE: 0.22749514827635858, Learning Rate: 0.01\n",
      "Epoch: 19859, MSE: 0.22749514827637063, Learning Rate: 0.01\n",
      "Epoch: 19860, MSE: 0.2274951482763833, Learning Rate: 0.01\n",
      "Epoch: 19861, MSE: 0.22749514827639597, Learning Rate: 0.01\n",
      "Epoch: 19862, MSE: 0.22749514827640868, Learning Rate: 0.01\n",
      "Epoch: 19863, MSE: 0.22749514827642128, Learning Rate: 0.01\n",
      "Epoch: 19864, MSE: 0.22749514827643388, Learning Rate: 0.01\n",
      "Epoch: 19865, MSE: 0.22749514827644657, Learning Rate: 0.01\n",
      "Epoch: 19866, MSE: 0.22749514827645925, Learning Rate: 0.01\n",
      "Epoch: 19867, MSE: 0.22749514827647208, Learning Rate: 0.01\n",
      "Epoch: 19868, MSE: 0.2274951482764846, Learning Rate: 0.01\n",
      "Epoch: 19869, MSE: 0.22749514827649742, Learning Rate: 0.01\n",
      "Epoch: 19870, MSE: 0.22749514827651007, Learning Rate: 0.01\n",
      "Epoch: 19871, MSE: 0.22749514827652215, Learning Rate: 0.01\n",
      "Epoch: 19872, MSE: 0.22749514827653547, Learning Rate: 0.01\n",
      "Epoch: 19873, MSE: 0.22749514827654813, Learning Rate: 0.01\n",
      "Epoch: 19874, MSE: 0.22749514827656078, Learning Rate: 0.01\n",
      "Epoch: 19875, MSE: 0.22749514827657333, Learning Rate: 0.01\n",
      "Epoch: 19876, MSE: 0.22749514827658576, Learning Rate: 0.01\n",
      "Epoch: 19877, MSE: 0.2274951482765987, Learning Rate: 0.01\n",
      "Epoch: 19878, MSE: 0.22749514827661096, Learning Rate: 0.01\n",
      "Epoch: 19879, MSE: 0.22749514827662426, Learning Rate: 0.01\n",
      "Epoch: 19880, MSE: 0.2274951482766361, Learning Rate: 0.01\n",
      "Epoch: 19881, MSE: 0.22749514827664924, Learning Rate: 0.01\n",
      "Epoch: 19882, MSE: 0.22749514827666178, Learning Rate: 0.01\n",
      "Epoch: 19883, MSE: 0.22749514827667444, Learning Rate: 0.01\n",
      "Epoch: 19884, MSE: 0.2274951482766875, Learning Rate: 0.01\n",
      "Epoch: 19885, MSE: 0.22749514827669995, Learning Rate: 0.01\n",
      "Epoch: 19886, MSE: 0.2274951482767125, Learning Rate: 0.01\n",
      "Epoch: 19887, MSE: 0.22749514827672518, Learning Rate: 0.01\n",
      "Epoch: 19888, MSE: 0.22749514827673833, Learning Rate: 0.01\n",
      "Epoch: 19889, MSE: 0.22749514827675046, Learning Rate: 0.01\n",
      "Epoch: 19890, MSE: 0.22749514827676334, Learning Rate: 0.01\n",
      "Epoch: 19891, MSE: 0.2274951482767759, Learning Rate: 0.01\n",
      "Epoch: 19892, MSE: 0.22749514827678846, Learning Rate: 0.01\n",
      "Epoch: 19893, MSE: 0.22749514827680117, Learning Rate: 0.01\n",
      "Epoch: 19894, MSE: 0.22749514827681425, Learning Rate: 0.01\n",
      "Epoch: 19895, MSE: 0.22749514827682651, Learning Rate: 0.01\n",
      "Epoch: 19896, MSE: 0.2274951482768392, Learning Rate: 0.01\n",
      "Epoch: 19897, MSE: 0.22749514827685152, Learning Rate: 0.01\n",
      "Epoch: 19898, MSE: 0.22749514827686487, Learning Rate: 0.01\n",
      "Epoch: 19899, MSE: 0.22749514827687706, Learning Rate: 0.01\n",
      "Epoch: 19900, MSE: 0.22749514827689002, Learning Rate: 0.01\n",
      "Epoch: 19901, MSE: 0.22749514827690254, Learning Rate: 0.01\n",
      "Epoch: 19902, MSE: 0.22749514827691553, Learning Rate: 0.01\n",
      "Epoch: 19903, MSE: 0.227495148276928, Learning Rate: 0.01\n",
      "Epoch: 19904, MSE: 0.2274951482769398, Learning Rate: 0.01\n",
      "Epoch: 19905, MSE: 0.22749514827695305, Learning Rate: 0.01\n",
      "Epoch: 19906, MSE: 0.2274951482769659, Learning Rate: 0.01\n",
      "Epoch: 19907, MSE: 0.22749514827697845, Learning Rate: 0.01\n",
      "Epoch: 19908, MSE: 0.22749514827699124, Learning Rate: 0.01\n",
      "Epoch: 19909, MSE: 0.22749514827700318, Learning Rate: 0.01\n",
      "Epoch: 19910, MSE: 0.22749514827701658, Learning Rate: 0.01\n",
      "Epoch: 19911, MSE: 0.2274951482770287, Learning Rate: 0.01\n",
      "Epoch: 19912, MSE: 0.22749514827704145, Learning Rate: 0.01\n",
      "Epoch: 19913, MSE: 0.22749514827705408, Learning Rate: 0.01\n",
      "Epoch: 19914, MSE: 0.22749514827706652, Learning Rate: 0.01\n",
      "Epoch: 19915, MSE: 0.2274951482770794, Learning Rate: 0.01\n",
      "Epoch: 19916, MSE: 0.22749514827709186, Learning Rate: 0.01\n",
      "Epoch: 19917, MSE: 0.22749514827710496, Learning Rate: 0.01\n",
      "Epoch: 19918, MSE: 0.2274951482771176, Learning Rate: 0.01\n",
      "Epoch: 19919, MSE: 0.22749514827712985, Learning Rate: 0.01\n",
      "Epoch: 19920, MSE: 0.2274951482771431, Learning Rate: 0.01\n",
      "Epoch: 19921, MSE: 0.22749514827715522, Learning Rate: 0.01\n",
      "Epoch: 19922, MSE: 0.2274951482771679, Learning Rate: 0.01\n",
      "Epoch: 19923, MSE: 0.22749514827718093, Learning Rate: 0.01\n",
      "Epoch: 19924, MSE: 0.22749514827719344, Learning Rate: 0.01\n",
      "Epoch: 19925, MSE: 0.22749514827720618, Learning Rate: 0.01\n",
      "Epoch: 19926, MSE: 0.2274951482772187, Learning Rate: 0.01\n",
      "Epoch: 19927, MSE: 0.2274951482772317, Learning Rate: 0.01\n",
      "Epoch: 19928, MSE: 0.227495148277244, Learning Rate: 0.01\n",
      "Epoch: 19929, MSE: 0.2274951482772565, Learning Rate: 0.01\n",
      "Epoch: 19930, MSE: 0.2274951482772694, Learning Rate: 0.01\n",
      "Epoch: 19931, MSE: 0.22749514827728237, Learning Rate: 0.01\n",
      "Epoch: 19932, MSE: 0.22749514827729447, Learning Rate: 0.01\n",
      "Epoch: 19933, MSE: 0.22749514827730738, Learning Rate: 0.01\n",
      "Epoch: 19934, MSE: 0.22749514827731998, Learning Rate: 0.01\n",
      "Epoch: 19935, MSE: 0.22749514827733258, Learning Rate: 0.01\n",
      "Epoch: 19936, MSE: 0.2274951482773455, Learning Rate: 0.01\n",
      "Epoch: 19937, MSE: 0.22749514827735837, Learning Rate: 0.01\n",
      "Epoch: 19938, MSE: 0.22749514827737086, Learning Rate: 0.01\n",
      "Epoch: 19939, MSE: 0.22749514827738326, Learning Rate: 0.01\n",
      "Epoch: 19940, MSE: 0.2274951482773963, Learning Rate: 0.01\n",
      "Epoch: 19941, MSE: 0.22749514827740883, Learning Rate: 0.01\n",
      "Epoch: 19942, MSE: 0.22749514827742112, Learning Rate: 0.01\n",
      "Epoch: 19943, MSE: 0.22749514827743406, Learning Rate: 0.01\n",
      "Epoch: 19944, MSE: 0.2274951482774469, Learning Rate: 0.01\n",
      "Epoch: 19945, MSE: 0.2274951482774595, Learning Rate: 0.01\n",
      "Epoch: 19946, MSE: 0.22749514827747203, Learning Rate: 0.01\n",
      "Epoch: 19947, MSE: 0.2274951482774848, Learning Rate: 0.01\n",
      "Epoch: 19948, MSE: 0.22749514827749726, Learning Rate: 0.01\n",
      "Epoch: 19949, MSE: 0.22749514827750997, Learning Rate: 0.01\n",
      "Epoch: 19950, MSE: 0.22749514827752265, Learning Rate: 0.01\n",
      "Epoch: 19951, MSE: 0.2274951482775349, Learning Rate: 0.01\n",
      "Epoch: 19952, MSE: 0.22749514827754808, Learning Rate: 0.01\n",
      "Epoch: 19953, MSE: 0.22749514827756043, Learning Rate: 0.01\n",
      "Epoch: 19954, MSE: 0.22749514827757286, Learning Rate: 0.01\n",
      "Epoch: 19955, MSE: 0.22749514827758568, Learning Rate: 0.01\n",
      "Epoch: 19956, MSE: 0.2274951482775984, Learning Rate: 0.01\n",
      "Epoch: 19957, MSE: 0.2274951482776113, Learning Rate: 0.01\n",
      "Epoch: 19958, MSE: 0.22749514827762346, Learning Rate: 0.01\n",
      "Epoch: 19959, MSE: 0.2274951482776363, Learning Rate: 0.01\n",
      "Epoch: 19960, MSE: 0.22749514827764888, Learning Rate: 0.01\n",
      "Epoch: 19961, MSE: 0.22749514827766212, Learning Rate: 0.01\n",
      "Epoch: 19962, MSE: 0.22749514827767428, Learning Rate: 0.01\n",
      "Epoch: 19963, MSE: 0.2274951482776873, Learning Rate: 0.01\n",
      "Epoch: 19964, MSE: 0.22749514827769995, Learning Rate: 0.01\n",
      "Epoch: 19965, MSE: 0.22749514827771233, Learning Rate: 0.01\n",
      "Epoch: 19966, MSE: 0.22749514827772532, Learning Rate: 0.01\n",
      "Epoch: 19967, MSE: 0.22749514827773776, Learning Rate: 0.01\n",
      "Epoch: 19968, MSE: 0.22749514827775055, Learning Rate: 0.01\n",
      "Epoch: 19969, MSE: 0.22749514827776238, Learning Rate: 0.01\n",
      "Epoch: 19970, MSE: 0.2274951482777754, Learning Rate: 0.01\n",
      "Epoch: 19971, MSE: 0.2274951482777883, Learning Rate: 0.01\n",
      "Epoch: 19972, MSE: 0.22749514827780082, Learning Rate: 0.01\n",
      "Epoch: 19973, MSE: 0.2274951482778136, Learning Rate: 0.01\n",
      "Epoch: 19974, MSE: 0.2274951482778265, Learning Rate: 0.01\n",
      "Epoch: 19975, MSE: 0.227495148277839, Learning Rate: 0.01\n",
      "Epoch: 19976, MSE: 0.22749514827785175, Learning Rate: 0.01\n",
      "Epoch: 19977, MSE: 0.22749514827786393, Learning Rate: 0.01\n",
      "Epoch: 19978, MSE: 0.22749514827787717, Learning Rate: 0.01\n",
      "Epoch: 19979, MSE: 0.22749514827788966, Learning Rate: 0.01\n",
      "Epoch: 19980, MSE: 0.22749514827790232, Learning Rate: 0.01\n",
      "Epoch: 19981, MSE: 0.22749514827791464, Learning Rate: 0.01\n",
      "Epoch: 19982, MSE: 0.22749514827792697, Learning Rate: 0.01\n",
      "Epoch: 19983, MSE: 0.22749514827794015, Learning Rate: 0.01\n",
      "Epoch: 19984, MSE: 0.22749514827795295, Learning Rate: 0.01\n",
      "Epoch: 19985, MSE: 0.22749514827796558, Learning Rate: 0.01\n",
      "Epoch: 19986, MSE: 0.22749514827797834, Learning Rate: 0.01\n",
      "Epoch: 19987, MSE: 0.22749514827799094, Learning Rate: 0.01\n",
      "Epoch: 19988, MSE: 0.22749514827800318, Learning Rate: 0.01\n",
      "Epoch: 19989, MSE: 0.22749514827801648, Learning Rate: 0.01\n",
      "Epoch: 19990, MSE: 0.22749514827802916, Learning Rate: 0.01\n",
      "Epoch: 19991, MSE: 0.22749514827804168, Learning Rate: 0.01\n",
      "Epoch: 19992, MSE: 0.22749514827805403, Learning Rate: 0.01\n",
      "Epoch: 19993, MSE: 0.22749514827806694, Learning Rate: 0.01\n",
      "Epoch: 19994, MSE: 0.22749514827807968, Learning Rate: 0.01\n",
      "Epoch: 19995, MSE: 0.22749514827809209, Learning Rate: 0.01\n",
      "Epoch: 19996, MSE: 0.2274951482781045, Learning Rate: 0.01\n",
      "Epoch: 19997, MSE: 0.22749514827811776, Learning Rate: 0.01\n",
      "Epoch: 19998, MSE: 0.2274951482781299, Learning Rate: 0.01\n",
      "Epoch: 19999, MSE: 0.2274951482781427, Learning Rate: 0.01\n",
      "Epoch: 20000\n",
      "Training completed\n",
      "Training model 2 with topology [10, 10, 10]\n",
      "Epoch: 0, MSE: 0.4863969625626785, Learning Rate: 0.1\n",
      "Epoch: 1, MSE: 0.49461773327731606, Learning Rate: 0.099995\n",
      "Epoch: 2, MSE: 0.49448823764293764, Learning Rate: 0.09999000000000001\n",
      "Epoch: 3, MSE: 0.358500076062627, Learning Rate: 0.099985\n",
      "Epoch: 4, MSE: 0.30513924331307174, Learning Rate: 0.09998000000000001\n",
      "Epoch: 5, MSE: 0.2969530216246081, Learning Rate: 0.09997500000000001\n",
      "Epoch: 6, MSE: 0.2935220215757972, Learning Rate: 0.09997\n",
      "Epoch: 7, MSE: 0.29016746847023167, Learning Rate: 0.09996500000000001\n",
      "Epoch: 8, MSE: 0.28819234771545477, Learning Rate: 0.09996000000000001\n",
      "Epoch: 9, MSE: 0.2900834132025971, Learning Rate: 0.09995500000000002\n",
      "Epoch: 10, MSE: 0.28643236228831076, Learning Rate: 0.09995000000000001\n",
      "Epoch: 11, MSE: 0.28288382430094405, Learning Rate: 0.099945\n",
      "Epoch: 12, MSE: 0.2658421413805746, Learning Rate: 0.09994\n",
      "Epoch: 13, MSE: 0.23397436078702724, Learning Rate: 0.099935\n",
      "Epoch: 14, MSE: 0.20581318966187417, Learning Rate: 0.09993\n",
      "Epoch: 15, MSE: 0.22980142083950836, Learning Rate: 0.099925\n",
      "Epoch: 16, MSE: 0.3113537289076393, Learning Rate: 0.09992000000000001\n",
      "Epoch: 17, MSE: 0.2703030421286929, Learning Rate: 0.099915\n",
      "Epoch: 18, MSE: 0.19413719212035194, Learning Rate: 0.09991\n",
      "Epoch: 19, MSE: 0.24234017538002384, Learning Rate: 0.09990500000000001\n",
      "Epoch: 20, MSE: 0.1840753145447553, Learning Rate: 0.0999\n",
      "Epoch: 21, MSE: 0.18716634730862244, Learning Rate: 0.09989500000000001\n",
      "Epoch: 22, MSE: 0.19866135086259384, Learning Rate: 0.09989\n",
      "Epoch: 23, MSE: 0.14573043093236554, Learning Rate: 0.099885\n",
      "Epoch: 24, MSE: 0.15516276159306236, Learning Rate: 0.09988000000000001\n",
      "Epoch: 25, MSE: 0.10758737099005312, Learning Rate: 0.099875\n",
      "Epoch: 26, MSE: 0.1255411694916879, Learning Rate: 0.09987000000000001\n",
      "Epoch: 27, MSE: 0.1295039643042196, Learning Rate: 0.09986500000000001\n",
      "Epoch: 28, MSE: 0.13618720469087492, Learning Rate: 0.09986\n",
      "Epoch: 29, MSE: 0.11777887287343801, Learning Rate: 0.09985500000000001\n",
      "Epoch: 30, MSE: 0.11258631945551303, Learning Rate: 0.09985000000000001\n",
      "Epoch: 31, MSE: 0.1098313910337131, Learning Rate: 0.099845\n",
      "Epoch: 32, MSE: 0.12036863108126616, Learning Rate: 0.09984\n",
      "Epoch: 33, MSE: 0.1005474931309297, Learning Rate: 0.09983500000000001\n",
      "Epoch: 34, MSE: 0.12108688937102842, Learning Rate: 0.09983\n",
      "Epoch: 35, MSE: 0.14245944662411805, Learning Rate: 0.099825\n",
      "Epoch: 36, MSE: 0.122082006728245, Learning Rate: 0.09982\n",
      "Epoch: 37, MSE: 0.08734646171359524, Learning Rate: 0.099815\n",
      "Epoch: 38, MSE: 0.11856407483940445, Learning Rate: 0.09981000000000001\n",
      "Epoch: 39, MSE: 0.1504353168436757, Learning Rate: 0.099805\n",
      "Epoch: 40, MSE: 0.18774360518160935, Learning Rate: 0.0998\n",
      "Epoch: 41, MSE: 0.13823045781296064, Learning Rate: 0.09979500000000001\n",
      "Epoch: 42, MSE: 0.10219715457350916, Learning Rate: 0.09979\n",
      "Epoch: 43, MSE: 0.11951609790602766, Learning Rate: 0.09978500000000001\n",
      "Epoch: 44, MSE: 0.09175883230769984, Learning Rate: 0.09978000000000001\n",
      "Epoch: 45, MSE: 0.08373657706266024, Learning Rate: 0.099775\n",
      "Epoch: 46, MSE: 0.09939078143680284, Learning Rate: 0.09977000000000001\n",
      "Epoch: 47, MSE: 0.09649114508343057, Learning Rate: 0.099765\n",
      "Epoch: 48, MSE: 0.09625069971517157, Learning Rate: 0.09976000000000002\n",
      "Epoch: 49, MSE: 0.1331152043792033, Learning Rate: 0.09975500000000001\n",
      "Epoch: 50, MSE: 0.0937676456709038, Learning Rate: 0.09975\n",
      "Epoch: 51, MSE: 0.1039684606560488, Learning Rate: 0.099745\n",
      "Epoch: 52, MSE: 0.08998359790189592, Learning Rate: 0.09974\n",
      "Epoch: 53, MSE: 0.11134926843635273, Learning Rate: 0.099735\n",
      "Epoch: 54, MSE: 0.1081334555761921, Learning Rate: 0.09973\n",
      "Epoch: 55, MSE: 0.07459731420609372, Learning Rate: 0.09972500000000001\n",
      "Epoch: 56, MSE: 0.07503850702201824, Learning Rate: 0.09972\n",
      "Epoch: 57, MSE: 0.06361403552600568, Learning Rate: 0.099715\n",
      "Epoch: 58, MSE: 0.07789423955237396, Learning Rate: 0.09971000000000001\n",
      "Epoch: 59, MSE: 0.07490657196354246, Learning Rate: 0.099705\n",
      "Epoch: 60, MSE: 0.0823637007647996, Learning Rate: 0.09970000000000001\n",
      "Epoch: 61, MSE: 0.11061698605337364, Learning Rate: 0.099695\n",
      "Epoch: 62, MSE: 0.1302699138129251, Learning Rate: 0.09969\n",
      "Epoch: 63, MSE: 0.11139546029388642, Learning Rate: 0.09968500000000001\n",
      "Epoch: 64, MSE: 0.06112207879008498, Learning Rate: 0.09968\n",
      "Epoch: 65, MSE: 0.07386519596660762, Learning Rate: 0.09967500000000001\n",
      "Epoch: 66, MSE: 0.06661899155920877, Learning Rate: 0.09967000000000001\n",
      "Epoch: 67, MSE: 0.06563454779660977, Learning Rate: 0.099665\n",
      "Epoch: 68, MSE: 0.06233734842438755, Learning Rate: 0.09966000000000001\n",
      "Epoch: 69, MSE: 0.06746033196026391, Learning Rate: 0.09965500000000001\n",
      "Epoch: 70, MSE: 0.07105033307920006, Learning Rate: 0.09965000000000002\n",
      "Epoch: 71, MSE: 0.10627917263151411, Learning Rate: 0.099645\n",
      "Epoch: 72, MSE: 0.07429403062363758, Learning Rate: 0.09964\n",
      "Epoch: 73, MSE: 0.07877318723847529, Learning Rate: 0.099635\n",
      "Epoch: 74, MSE: 0.062136953124301605, Learning Rate: 0.09963\n",
      "Epoch: 75, MSE: 0.08797703360552489, Learning Rate: 0.099625\n",
      "Epoch: 76, MSE: 0.06272270906137487, Learning Rate: 0.09962\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(models):\n",
    "    print(f\"Training model {i + 1} with topology {topologies[i]}\")\n",
    "    # Train the model\n",
    "    model.train(X_train, y_train, epochs=20_000, tol=0.01, patience=2000, patience_start=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d328b3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.60%\n"
     ]
    }
   ],
   "source": [
    "ys = []\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Predicting with model {i + 1} with topology {model.topology}\")\n",
    "    # Predict\n",
    "    _y = model.predict(X_test)\n",
    "    ys.append(_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22827bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.60%\n",
      "True Positives: 234\n",
      "False Positives: 73\n",
      "True Negatives: 169\n",
      "False Negatives: 24\n",
      "Precision: 76.22%\n",
      "Recall: 90.70%\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(models):\n",
    "    print(f\"Model {i + 1} with topology {model.topology}\")\n",
    "    print(f\"Results:\")\n",
    "    true_labels = y_test.flatten()\n",
    "    true_positives = np.sum((np.round(ys[i]) == 1) & (true_labels == 1))\n",
    "    false_positives = np.sum((np.round(ys[i]) == 1) & (true_labels == -1))\n",
    "    true_negatives = np.sum((np.round(ys[i]) == -1) & (true_labels == -1))\n",
    "    false_negatives = np.sum((np.round(ys[i]) == -1) & (true_labels == 1))\n",
    "    accuracy = (true_positives + true_negatives) / (true_positives + false_positives + true_negatives + false_negatives)\n",
    "    print(f\"Accuracy: {accuracy:.2%}\")\n",
    "    print(f\"True Positives: {true_positives}\")\n",
    "    print(f\"False Positives: {false_positives}\")\n",
    "    print(f\"True Negatives: {true_negatives}\")\n",
    "    print(f\"False Negatives: {false_negatives}\")\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    print(f\"Precision: {precision:.2%}\")\n",
    "    print(f\"Recall: {recall:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376669e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael-albuquerque/repos/ia-av2/evaluator.py:23: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = np.sum(true_positives) / (np.sum(true_positives) + np.sum(false_positives))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.0), np.float64(nan), np.float64(0.0))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluator import Evaluator\n",
    "\n",
    "evaluator = Evaluator(model)\n",
    "evaluator.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5249c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.92, 'Rtulos')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_plot = X.T\n",
    "y_plot = model.predict(X)\n",
    "y_plot = y_plot.flatten()\n",
    "\n",
    "fig = plt.figure(1, figsize=(20, 5))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "ax.scatter(X_plot[:, 0], X_plot[:, 1], X_plot[:, 2], c=y_plot, s=5, cmap=\"viridis\")\n",
    "ax.set_title(\"Rtulos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
